{"id":"6bQeKcszAY","text":"The authors introduce FastCPH as a novel CoxPH implementation. It runs in O(n), enables deep learning while including tie-awareness as well as efron\/breslow approximations. It is the first method that does this, and I hence vote 'accept'.","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"rLqe5g337Mq","text":"I thank the authors for their submission, which I enjoyed reading. Overall I found the manuscript to present an interesting combination of ideas relating to causality and reinforcement learning and will therefore be a valuable addition to the workshop. \n\nDetailed comments\n\nThe authors propose cause effect modeling agent (CEMA) - a generative network which is designed to infer cause-effect relationships between an actor and the object of manipulation within an RL setting. The proposed model is able to infer latent influence from the actor state on the object state.\n\nThe authors claim that for an agent to exhibit robust and generalizable behaviors, they must incorporate some degree of “compression” within their learned representation of their environment. In this work, they explore the use of latent state factorization to achieve this goal and propose a hierarchical latent variable model to model visual control problems. In particular, they propose to decompose an input image into a robot image component (actor) and an object image component (object that is acted upon). This separation is implemented via segmentation mask. In this way they explicitly parameterize the cause-effect relationship between actor and object. \n\nVia a series of experiments, the authors demonstrate that CEMA (for which the agent follows a factorized generative model) is able to obtain comparable performance to Dreamer (Hafner et al., 2019), thus showing that it is possible to introduce structure knowledge (e.g., about the cause effect structure) into the agent. \n\nThe authors further claim their proposed model is able to infer cause-effect relationships by studying the mutual information between the inputs\/outputs of each distribution. For example, the authors claim that “object latent mutual information is maximized at some moment after the drawer starts to move.” I must admit that I did not fully understand why changes in the mutual information between variables is indicative of inferred causal structure - could it not be possible that the MI between variables changes without causal associations? It’s also unclear how pre-imposed causal structure affects these quantities. Would it be possible add similar plots for e.g., Dreamer as a comparison ?\n\nFinally, one experiment that would go a long way towards convincing me that cause-effect relationships had indeed been inferred would be to replace the mask segmentation which is used to separate input images into actor\/object images with an attention layer. Then each component of the factorized agent would have access to the entire image and would need to learn which components of it to attend to. Simple attention maps or saliencies of the image could then demonstrate that the actor and object components where indeed focusing on the right aspects of the image. This would also demonstrate that the proposed method can potentially scale to scenarios when the segmentation of images is not available. \n\nTypos\/minor:\n\n- Section 5: “In figure 4 we show the comparison of $I(u, (s,c)), ..$. Do the $u$, $s$ and $c$ variables require a time subscript here (i.e., $u_t$, etc) ?\n- section 5: “The robot’s goal is to open the drawer while the position of the can vary between tasks” -> missing noun\n- Figure 4: it would be helpful to make vertical line dashed\/dotted to avoid color confusion (e.g., between the red and orange lines)\n","sentences":[{"sentence_type":"1","sentence":"I must admit that I did not fully understand why changes in the mutual information between variables is indicative of inferred causal structure - could it not be possible that the MI between variables changes without causal associations?","rephrased":"Could you please clarify how changes in the mutual information between variables indicate an inferred causal structure? It would be helpful to understand if there could be scenarios where the MI between variables changes without implying causal associations."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1868,2105,"Maybe"]],"Comments":[]}
{"id":"X8mfXIOYQs","text":"Sprial sampling of MRI data is very time efficient may requires special reconstruction algorithms to reduce artifacts.\nThis method introduced a CNN-based method to deblur spiral-sampled MRI data.\nA novel method was introduced to synthesize distorted data with augmented field maps.\nBut the IR with ref field map seems to have better performances than the proposed method.","sentences":[{"sentence_type":"2","sentence":"But the IR with ref field map seems to have better performances than the proposed method.","rephrased":"However, it would be beneficial to compare the proposed method's performance with that of the IR with ref field map, which has shown promising results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[282,371,"Confirmed"]],"Comments":[]}
{"id":"Skg0oMcwsE","text":"This paper describes alternate approaches to scheduling activities in an environment with scarce computational resources such that a backtracking search is not possible.  Three approaches are taken to ensuring that high priority tasks are not missed.  The first two approaches provide guards on a nominal pre-defined schedule and the third approach introduces a limited form of backtracking by making multiple schedule runs.\n\nThe paper presents the work in terms of scheduling activities on board the planned 2020 Mars rover. As such the results are interesting to the SPARK community. \n\nThe paper is confusing as to whether its goal is to create a schedule versus the ability to adjust an existing schedule during execution to take advantage of shorter than modeled activity durations.   The paper introduces the concept of a switch set which is priority ordered set of activities out of which one must be scheduled with a preference to schedule the highest priority activity that still allows all the other mandatory activities to schedule.  Most of the paper involves scheduling switch sets.  While switch sets are interesting,  I am not sure how the problem is solved without switch sets.   Scheduling is an intractable problem.  How does the approach get good schedules with no backtracking?  This is especially concerning given that the evaluation problems only have a single switch set.\n\nThe authors need to clarify the scenario in which the planner will operate and how the new approaches impact this scenario. \n\nBased on the example given the approach guarding for time is not sound and can result in schedules that do not schedule all mandatory activities. \n\n","sentences":[{"sentence_type":"1","sentence":"The paper is confusing as to whether its goal is to create a schedule versus the ability to adjust an existing schedule during execution to take advantage of shorter than modeled activity durations.","rephrased":"The paper could provide more clarity on whether its goal is to create a schedule or to adjust an existing schedule during execution to accommodate shorter than expected activity durations."},{"sentence_type":"1","sentence":"While switch sets are interesting,  I am not sure how the problem is solved without switch sets.","rephrased":"It would be beneficial if the paper could elaborate on how the problem might be addressed in the absence of switch sets."},{"sentence_type":"2","sentence":"Scheduling is an intractable problem.  How does the approach get good schedules with no backtracking?","rephrased":"The paper could further explain how the proposed approach achieves effective scheduling without backtracking, given the intractability of the problem."},{"sentence_type":"1","sentence":"This is especially concerning given that the evaluation problems only have a single switch set.","rephrased":"This aspect is particularly important to address, as the evaluation problems presented involve only a single switch set."},{"sentence_type":"2","sentence":"Based on the example given the approach guarding for time is not sound and can result in schedules that do not schedule all mandatory activities.","rephrased":"The paper could provide a more robust justification for the time-guarding approach, ensuring that it can reliably schedule all mandatory activities."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[588,786,"Maybe"],[1096,1192,"Confirmed"],[1195,1296,"Confirmed"],[1298,1393,"Maybe"],[1521,1666,"Confirmed"]],"Comments":[]}
{"id":"SJx5gjF2FB","text":"This paper proposes to learn a kernel for training MMD-GAN by optimizing over the probability distribution that defines the kernel by means of random features. This is unlike the usual setting of MMD-GAN where the kernel is parametrized by composing a fixed top-kernel with a discriminator network that is optimized during training. The main motivation for this approach is to avoid having to 'manually' fix some parameters of the top-level kernel like the bandwidth of the RBF kernel. They provide an algorithm to achieve such optimization in probability space along with some consistency results and perform experiments on MNIST and Cifar10 to demonstrate empirically the advantage of such an approach over those that fix the top-level kernel.\n\nTheory:\n\tTheorem 4.1 provides a convergence result of an oracle finite-sample estimator: that is the one obtained by exactly solving the optimization problem in 19b. In that case, they show the consistency of the proposed estimator. The result is somehow expected but the proof relies on nice duality results for measures and is very technical.\t\nThe clarity of the proof could be improved:\n- Currently, the structure of the main proof mixes direct lemma (lemma B.7) with less obvious ones (lemma B.6). Also, some concepts are introduced in the main proof but not necessary for its understanding: The notion of Orlicz norm is in introduced in Definition B.3 on the fly to state lemma B.6, but only equations 50 and 51 are used in this lemma which does not make use of the notion of Orlicz norm at all.\n\n\tTheorem 4.1 doesn't say anything about the consistency of the algorithm itself. To partly address this, the authors show in theorem 4.2 that as the number of particles grows the empirical process converges to a McKean Vlasov PDE (equation 22). This means that the proposed algorithm is approximating some gradient flow in metric space (25). \n- However, this gradient flow is a non-convex optimization problem and there is no guarantee that a global solution is reached.  Recent work provides cases when global convergence occurs [Chizat2018] but it is not the case in general. Some further clarification about the connection between Thm 4.1 and Thm 4.2 would be therefore useful.\n\t\nThm 4.2 is also curious in the sense that the process defined by equation 16, which is noisy since it relies on one sample from the data, would converge towards (22) which is a Mc-valsov equation with a drift only (no diffusion or other noise).  What happened to the noise coming from sampling from P_v  and P_w in equation 16? Wouldn't there be some sort of diffusion term as in [Hu2018]?\n\t\nMore generally it would be nice to have a discussion of the assumptions and results in the paper as they seem to rely on methods that people in the machine learning community are not totally familiar with.\n\t\nExperiments:  The experiments are not convincing for several reasons:\n - The comparison with the other methods is somehow unfair since the bandwidth is manually tuned for the competing methods. It is easy to adaptively learn the bandwidth as well:  in this case, it will be just an additional parameter of a discriminator network. This was done in [Arbel2018] where a single gaussian kernel is used and a regularization of the critic allows to learn the bandwidth without manual tuning. Does the proposed method offer an additional advantage compared to those?\n- In practice and for a scaling parameter alpha=1, isn't the algorithm strictly equivalent to considering an MMD-GAN with a dot product kernel and a discriminator given by the feature \\phi(x,\\zeta)?\n- Mnist and Cifar10 are somehow very simple, what would happen on more complicated datasets (CelebA or imagenet)?\n\n- I also think there is an ablation that is missing: If the auto-encoder also needs to be optimized then does it also help to optimize over the particles as well or is optimizing the auto-encoder discriminator enough to achieve a similar performance? In other words, does optimizing the auto-encoder compensate for the need to learn the distribution mu? Of course, this would depend on how the auto-encoder is parametrized but I don't see why it wouldn't in many cases.\n\n\nOverall, I'm not convinced that the proposed approach would lead to any substantial improvement for MMD-GAN in practice, and the experiments are not really convincing as they are now. However, I find the theoretical results interesting and might be used to better analyse the dynamics of GAN's. But as the paper is currently framed, it is hard to put these theoretical results in perspective.\n","sentences":[{"sentence_type":"2","sentence":"The experiments are not convincing for several reasons:","rephrased":"The experiments could be strengthened by addressing several concerns:"},{"sentence_type":"2","sentence":"Overall, I'm not convinced that the proposed approach would lead to any substantial improvement for MMD-GAN in practice, and the experiments are not really convincing as they are now.","rephrased":"Overall, it remains unclear how the proposed approach would lead to substantial improvements for MMD-GAN in practice, and further work may be needed to enhance the persuasiveness of the experiments."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[2846,2901,"Confirmed"],[4179,4362,"Confirmed"]],"Comments":[]}
{"id":"SklmeUmZ2E","text":"The paper discusses different aspects of explanations, particularly in the context of sequential decision making. Many of these issues have been discussed before (e.g. some in the author's own previous work [IAAI 2017]) and indeed algorithms exist that have begun addressing aspects of these problems since then. Unfortunately, the most recent works referred to in the paper (other than the author's own) are mostly from ages ago. In that context, I am not sure that the paper advances the state of our understanding of the different aspects of XAIP. The contribution would have been much more appealing if it was able to contextualize the same ideas in light of the state of the art.\n\nThe difference between process accounts and preference accounts is quite stark in recent literature -- this is better described as model-based algorithm-agnostic explanations or not. Most of the explanations\/visualization work in the planning literature has been about process, while all the recent work [Fox et al. 2017] and its follow-ups, and model reconciliation [Chakraborti et al. 2017] and its follow-ups have been model-based algorithm-agnostic. Personally, I think \"preference accounts\" is a misnomer. Section 2.1 refers to some existing examples of process accounts. I would have loved to see the same for ideas expressed in Section 2.2 on how they manifest themselves in different forms in recent efforts in the XAIP community.\n\n> I couldn't understand the point of \"conceptual inference\" as a separate concept in Section 3. Surely this happens as part of both \"plan generation\" and \"plan execution\"?\n\n> Similar to the concern above, I would refer to the visualization and explanation attempts in the most recent UISP workshops at ICAPS for some examples of the discussion in Section 4.\n\n> (For the sake of completeness) The author makes a note that explanations being retrospective doesn't make much of a difference to the explanation process for \"process accounts\". In the context of \"preference accounts\" in the cases of plan generation versus execution, retrospection actually plays a role. Such as not needing to explain that something is executable if the plan has already been executed. \n","sentences":[{"sentence_type":"2","sentence":"Unfortunately, the most recent works referred to in the paper (other than the author's own) are mostly from ages ago.","rephrased":"It would be beneficial for the paper to include more recent works in the field to strengthen its relevance and show how it builds upon or differs from current research trends."},{"sentence_type":"1","sentence":"Personally, I think \"preference accounts\" is a misnomer.","rephrased":"The term \"preference accounts\" might not be the most accurate descriptor in this context, and it could be helpful to consider alternative terminology that aligns more closely with current literature."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":[],"entities":[[313,430,"Confirmed"],[1140,1196,"Confirmed"]],"Comments":[]}
{"id":"dwEwHK1pMk","text":"This paper studies test-time adversarial robustness through a maximin framework and illustrate non-trivial robustness (under transfer attack) using domain adversarial neural network (DANN) to Linf-norm and unseen adversarial attacks. While I agree that test-time adaptation is an important and practical approach for adversarial robustness, the current version, in my opinion, does not deliver significantly novel insights, nor considering a reasonably practical threat model. My main concerns are detailed as follows.\n\n1. Impractical threat model: At test time, the maximin threat model (Def. 2) assumes the attacker to make move prior to the defender's action, which limits the attacker's ability and weakens the robustness evaluation. More importantly, it may create a false of security\/robustness, as pointed out by (Athalye et al. 2018), that the robustness gain may actually come from information obfuscation and thus the results may fail to provide meaningful robustness evaluation. Although the authors mention the maximin threat model is a weaker (attack) model and part of the goal is to find an adaptation method that is \"good\" in this attack-move-first scenario, I couldn't see the practical utility and contributions form these results. Even in the test-time adaptation setting, the \"defender-move-first\" setting should be more practical. Better motivation and use cases are needed to justify why the considered setting is important.\n\n2. Due to the assumption of the considered maximin threat model, the experiments are limited to comparing accuracy on transfer attacks, which provide limited understanding of the true robustness of the victim model. Moreover, the baseline models in comparison are too weak and unfair. To have a fair comparison, the authors are suggested to compare robustness on robust models such as TRADES [R1] and adversarially trained models with unlabeled data [R2,R3], so that the baseline models also use unlabeled data. If DANN shows limited robustness against white-box attacks but stronger robustness against transfer attacks, one can only conclude that transfer attack is a weaker threat model, which is a known result. I do not see new insights from the reported results.\n\n[R1] https:\/\/arxiv.org\/abs\/1901.08573\n\n[R2] https:\/\/papers.nips.cc\/paper\/9298-unlabeled-data-improves-adversarial-robustness.pdf\n\n[R3] https:\/\/deepmind.com\/research\/publications\/Are-Labels-Required-for-Improving-Adversarial-Robustness\n\n3. In addition to the issue of impractical threat model and lacking motivation, this paper contains too many high-level discussions accompanied with limited or even no empirical evidence. The theorem presented in the paper is a natural use of maximin inequality.  In my opinion, the current version requires significant revision. I suggest the authors carefully motivate the research goals (especially answering why the studied problems and settings are important), consolidate the claims on test-time robustness with convincing evidence, and make a broader connection to other test-time defenses other than DANN.","sentences":[{"sentence_type":"2","sentence":"the current version, in my opinion, does not deliver significantly novel insights, nor considering a reasonably practical threat model.","rephrased":"While the current version presents a unique approach, it could benefit from providing more novel insights and considering a more practical threat model."},{"sentence_type":"2","sentence":"I couldn't see the practical utility and contributions form these results.","rephrased":"It would be helpful if the paper could further clarify the practical utility and contributions of these results."},{"sentence_type":"2","sentence":"the baseline models in comparison are too weak and unfair.","rephrased":"For a more equitable comparison, it is recommended that the baseline models be strengthened."},{"sentence_type":"2","sentence":"this paper contains too many high-level discussions accompanied with limited or even no empirical evidence.","rephrased":"The paper would benefit from including more empirical evidence to support the high-level discussions presented."},{"sentence_type":"2","sentence":"In my opinion, the current version requires significant revision.","rephrased":"The paper could be improved with substantial revisions to address the concerns mentioned."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[341,476,"Confirmed"],[1175,1249,"Confirmed"],[1674,1732,"Maybe"],[2533,2640,"Confirmed"],[2717,2782,"Confirmed"]],"Comments":[]}
{"id":"BEAS7F3O-4","text":"These are several concerns:\n1. In the view of motivation, I don't think the motivation is strong enough and is convincing. Also, I don't think rewarding correct predictions but not penalizing incorrect ones is a reasonable way. In my opinion,  rewarding the correct predictions may be a good way, but penalizing the incorrect ones should also be important. \n2. In the view of experiments, though the authors add Table 7 in the appendix, which is the result for training 90 epochs, I still doubt why Eureka Loss does not work better than recent works when training 200 epochs (which is also a common setting recently). And it seems that using CE at the beginning of training is important, and +CB$^+$ works the best.  Moreover, In table 2, the results on \"few\" are especially not very good comparing with others, which makes it harder for me to believe that rewarding the high-likelihood area really matters a lot for tail classes. It seems that the experiment results are not strong enough to support the proposed opinion.","sentences":[{"sentence_type":"2","sentence":"I don't think the motivation is strong enough and is convincing.","rephrased":"The motivation could be strengthened and made more compelling to better establish the importance of the study."},{"sentence_type":"1","sentence":"I still doubt why Eureka Loss does not work better than recent works when training 200 epochs (which is also a common setting recently).","rephrased":"It would be helpful if the authors could provide further analysis or discussion on why Eureka Loss does not outperform recent works when training for 200 epochs, as this is a common practice in recent studies."},{"sentence_type":"2","sentence":"It seems that the experiment results are not strong enough to support the proposed opinion.","rephrased":"The experimental results could be bolstered to more convincingly support the proposed hypothesis."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[58,122,"Confirmed"],[481,617,"Maybe"],[931,1022,"Not concerning"]],"Comments":[]}
{"id":"zcXYTJJO6_2","text":"Pros.\n1.\tThis paper introduced the new design in potential by generalizing the depth-separable convolution. The proposed method extend common separable convolutions to more generalized & improved separable convolution.\n2.\tIt demonstrated that generalized separable methods surpassed previous convolution methods in performance with a small number of parameters compared with existing separable methods.\n3.    They have studied concrete analysis for flop's complexities. This supports that their approach is optimal among group separable convolutions.\n\nCons.\n1.\tThe arguments about ad hoc design are self-contradictory. The introduction section mentioned that \"Instead of setting these hyperparameters in an ad hoc fashion, we design a novel and principled scheme.\" However, in the experiment section, it seems that optimal separable methods also require hyperparameter (namely, overlap coefficient) tuning to obtain the best results.\n2.\tThe authors claimed that by introducing the proposed convolution, the model size could be reduced. However, we can observe from Table 3 that model size is reduced by 0.1M (approximately 3 percent). This is a bit incremental even they achieved 1% accuracy up.\n3.\tIn appendix section E, we can see that the GPU inference time of the proposed method is slower than other methods. To explain such a disadvantage, the authors say that PyTorch's implementation of group convolution is inefficient. However, it is believed that whenever group convolution is implemented in an efficient manner when considering the architecture of GPU, one-by-one convolution is the most memory-efficient design choice compared to other design choices, including group convolution.\n","sentences":[{"sentence_type":"2","sentence":"The arguments about ad hoc design are self-contradictory.","rephrased":"The discussion on ad hoc design appears to have some inconsistencies."},{"sentence_type":"2","sentence":"This is a bit incremental even they achieved 1% accuracy up.","rephrased":"While the model size reduction is modest, the improvement in accuracy is noteworthy."},{"sentence_type":"2","sentence":"However, it is believed that whenever group convolution is implemented in an efficient manner when considering the architecture of GPU, one-by-one convolution is the most memory-efficient design choice compared to other design choices, including group convolution.","rephrased":"It may be worth exploring whether one-by-one convolution could be a more memory-efficient design choice than group convolution when implemented efficiently on GPU architectures."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[561,618,"Confirmed"],[1135,1195,"Maybe"],[1429,1693,"Maybe"]],"Comments":[]}
{"id":"IR_AVxFF0I","text":"This paper demonstrates that averaging the weights of a vision or language model over the last $k$ checkpoints can speed up training in the middle phase. The introduced method is called LAtest Weight Averaging (LAWA) and the paper explores different degrees of freedom, e.g. number of averaged checkpoints and type of average operation. LAWA's benefits are measured in time savings of GPU hours. The paper also discusses directions for future work.\n\n---\n\nI think the paper would benefit from a short \"Conclusion\" section at the end that restates the most important findings.\n\n---\n\nMiscellaneous comments:\n- Fig. 2 is referenced before Fig. 1. Maybe swap them?\n","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"RMeUd9fmjyj","text":"\nThe paper proposes a framework for image manipulation via natural language text using a neuro-symbolic approach. The authors propose NeuroSIM, an image manipulation model based on the Neuro-Symbolic Concept Learner (NSCL). \n\n$Pros$\n- The authors propose changing the source image by manipulating its scene representation graph given an instruction parsed from the natural language. The devised Manipulation Network adapts the scene graph without the need to work directly on the image.\n- The results of the NeuroSIM model seem to be especially competitive in the low data regime, which may be a desired property if access to larger datasets is impossible. The proposed method seems to also work better for multi-hop instructions. \n\n$Cons$\n-  The results from the multi-hop instructions are interesting; however,  they could have also been better investigated – i.e., Similarly to the results from Table 1, what would be the outcome in a higher data regime (larger beta?). Why is only R1 reported in this table? \n-  The Description of the training of the Semantic Pruning Module, Visual Representation Network, and Concept Quantization Network is very vague. Understandably, the authors do not want to waste space in the main text to explain methods adapted from some other work. However, some more detailed explanations could be included in the appendix. It would make the reading more accessible, and it is important to understand the input of the three abovementioned components since the proposed framework relies heavily on them. Have the components been adapted from a trained NSCL module or trained\/fine-tuned with other parts of NeuroSIM?\n \nI would like to state that even though I find this work quite interesting, it is outside of the scope of my everyday research, and hence I am not very familiar with the subject of the work and the problems it is trying to solve. ","sentences":[{"sentence_type":"2","sentence":"Understandably, the authors do not want to waste space in the main text to explain methods adapted from some other work.","rephrased":"While the authors may have aimed to conserve space in the main text, providing more detailed explanations of methods adapted from other works in the appendix would enhance the paper's clarity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1159,1279,"Not concerning"]],"Comments":[]}
{"id":"HyxFPP0g3E","text":"The paper formalizes and provides a solver for branching-bounded Contingent Planning.  This problem generalizes both conformant and contingent planning by allowing sensing actions to be bounded.  If no sensing actions take place, then the problem is equal to conformant planning, while allowing unbounded sensing actions is fully contingent planning. A sweet spot somewhere in the middle is more realistic for many problems, where the agent might want to take up to k sensing actions.  This paper formalizes k-bounded contingent planning and provides an important step toward linking these two kinds of problems.\n\nGenerally, the paper is clear and easy to read.  My main concern relates to how well it fits with the workshop aims.  Although I can see how it might be used for explainable planning, the paper itself doesn't make a very strong claim.  Still, I do think the general approach may be useful to bring to the attention of folks attending the workshop.\n\nMy rating reflects the papers alignment with the workshop and _not_ the technical content, which is top notch.","sentences":[{"sentence_type":"1","sentence":"Although I can see how it might be used for explainable planning, the paper itself doesn't make a very strong claim.","rephrased":"While the paper's potential application in explainable planning is evident, it would be beneficial if the authors could articulate their claims more strongly."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[732,848,"Not concerning"]],"Comments":[]}
{"id":"jKUMWjDJk3V","text":"Strengths:\n1. The paper presents an simple and elegant way to test plasticity in the neural networks. They accomplish this by freezing their original neural network and adding two function (neural networks) whose sum is zero initially and one of them is trainable. Thus, we have a increases capacity neural network with same number of trainable variables with the same function value initially at all points in the input domain.\n2. The paper is able to detach the effect of exploration from plasticity by testing empirically if the performance during training is affected during plasticity injection.\n3. The empirical evaluation is thorough on the Atari learning environment which clearly shows that loss of plasticity can be identified, and increased plasticity through their method could make the RL training more performant and even memory efficient.\n4. The ablations have done a good effort to remove any other potential sources of changes introduced due to their plasticity injections that could be confounding their analysis.\n5. The paper is quite relevant to the workshop as it directly addresses the question of reincarnating RL.","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"r1xX5KR0OB","text":"\n\n###Summary###\n\nThis paper tackles the transfer learning problem with the double-blind unsupervised domain adaptation, where either the source or the target domain cannot observe the data in the other domain, but data from both domains are used for training. The high-level intuition of this paper is based on the observation that in some practical settings, the transferring source data to the target domain is restricted due to the privacy policy. The goal is to learn a classifier which performs well in target classification task under double-blind constraint. \n\nThe setting of this paper is slightly different from the conventional domain adaptation. In this paper, the source domain has abundant unlabeled data and a small number of labeled data. The target domain only contains a limited number of unlabeled data.\n\nThe paper proposes a transfer alignment network (TAN) which comprises two autoencoders, one trained on the source domain and one trained on the target domain. In the domain adaptation phase, the model leverages an aligner to transfer the output of the target encoder to an aligned latent variable.  The aligner is trained to map the target code to source code on the target unlabeled data. The objective function is L2 distance between the source code and the mapped target code. \n\nThe whole pipeline is trained with four steps:\n1) The source encoder and source decoder are trained with L2 reconstruction loss.\n2) The source encoder and source classifier are trained with cross-entropy classification loss.\n3) The target encoder and target decoder are trained with L2 reconstruction loss.\n4) Train the aligner to map target code to source code on target unlabeled data with L2 distance loss.\n\nThe paper proposes to compare the TAN with three baselines: S(UL):  a stack of encoder and a neural network classifier trained using source data and tested on target data without finetuning. S(UL)-T(U): a model retrains the S(UL) with the target unlabeled data. S(UL)-T(U)-Large: a model which is similar to S(UL)-T(U) but contains more layers and parameters in MLP.\n\nThe experiments are performed on five multivariate datasets: HIGGS, HEPMASS, SUSY, Sensorless, and Gas. \n\n\n### Novelty ###\n\nThe experimental setting proposed in this paper is interesting. However, the proposed model is trivial. The TAN model is composed of autoencoders and aligner. The training losses in the framework are L2 reconstruction loss and L2 distance loss. Thus, the novelty of this paper is incremental.\n\nThe experimental results in this paper are weak. First of all, the datasets used in this paper are not standard benchmarks. Secondly, the baselines in this paper are too trivial.   \n\n\n###Clarity###\n\nOverall, the paper is well organized and logically clear. The images are well-presented and well-explained by the captions and the text. \n\n###Pros###\n\n1) The paper proposes an interesting transfer learning framework where either the source or the target domain cannot observe the data in the other domain. \n\n2) The paper is applicable to many practical scenarios since the data privacy in the real-world application is critical. \n\n3) The paper is overall well-organized. The claims of the paper are verified by the experimental results.\n\n###Cons###\n\n1) The paper proposes double-blind unsupervised domain adaptation as accessing the source and target domains is restricted in some practical settings. However, the source and target domain share the models trained on themselves, as well as the features extracted from the source domain and target domain data. The information about the original data can be recovered with the shared features and weights, which violates the settings proposed in this paper. \n\n2) The main issue of this paper is the novelty is incremental. The proposed model is trivial as it only contains the auto-encoders and L2 loss. \n\n3) The experimental part of this paper is weak. The datasets used in this paper are not the standard domain adaptation benchmark. It would be nice to see how does the proposed model work on standard domain adaptation benchmarks such as Office31, VisDA, Office-Home, DomainNet, etc.\n\nVisDA: The Visual Domain Adaptation Challenge\nhttps:\/\/arxiv.org\/pdf\/1710.06924.pdf\nOffice-Home : Deep Hashing Network for Unsupervised Domain Adaptation\nhttp:\/\/hemanthdv.org\/OfficeHome-Dataset\/\n\nThe baselines used in this paper is also trivial. It is desirable to compare the proposed method with state-of-the-art domain adaptation methods.\n\nBased on the summary, cons, and pros, the current rating I am giving now is \"reject\". I would like to discuss the final rating with other reviewers, ACs.\n\n","sentences":[{"sentence_type":"2","sentence":"However, the proposed model is trivial.","rephrased":"However, the proposed model appears to be quite straightforward."},{"sentence_type":"2","sentence":"The experimental results in this paper are weak.","rephrased":"The experimental results in this paper could be strengthened."},{"sentence_type":"2","sentence":"Secondly, the baselines in this paper are too trivial.","rephrased":"Additionally, the baselines in this paper could be more challenging."},{"sentence_type":"2","sentence":"The main issue of this paper is the novelty is incremental.","rephrased":"The main issue of this paper is that the novelty appears to be incremental."},{"sentence_type":"2","sentence":"The baselines used in this paper is also trivial.","rephrased":"The baselines used in this paper could also be more robust to better demonstrate the effectiveness of the proposed method."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2272,2311,"Confirmed"],[2502,2550,"Confirmed"],[2626,2680,"Confirmed"],[3713,3772,"Confirmed"],[4334,4383,"Confirmed"]],"Comments":[]}
{"id":"tQgm2nhJUv","text":"This paper addresses estimation of a certain type of OT distance, substance robust wasserstein distances, by Patty and Cuturi, 2019\n\nI don't think this paper is suited for publication since it lacks enough substance. \n\n1)There is gross error in the abstract: the curse of dimensionality doesn't refer any cubic scaling, but on an exponential dependence in dimension.\n2)the first 4 pages are spent on elementary definitions. This appears as an unnecessary padding. I suggest authors put that kind of definitions in the appendix and\/or cite relevant literature, e.g. the paper by Patty and Cuturi.\n3)The overall idea, although sensible, appears unjustified. Why would the community be interested in this problem? In the current papers, authors claim they are generalizing the results of Patty et al. Nonetheless it is unclear whether there is reasons for wanting to create such generalized framework. It would be helpful if the authors had a concrete application to showcase their results.\n4)Experimental results are weak, and comparisons with other methods are lacking, so it is hard to judge what are the actual gains.\n\n","sentences":[{"sentence_type":"2","sentence":"I don't think this paper is suited for publication since it lacks enough substance.","rephrased":"The paper could benefit from additional substance to strengthen its case for publication."},{"sentence_type":"2","sentence":"There is gross error in the abstract: the curse of dimensionality doesn't refer any cubic scaling, but on an exponential dependence in dimension.","rephrased":"There is a significant error in the abstract regarding the curse of dimensionality; it typically refers to an exponential dependence on dimension rather than cubic scaling."},{"sentence_type":"2","sentence":"the first 4 pages are spent on elementary definitions. This appears as an unnecessary padding.","rephrased":"The first four pages focus on elementary definitions, which might be better placed in an appendix or supported by citations to streamline the paper's introduction."},{"sentence_type":"1","sentence":"The overall idea, although sensible, appears unjustified.","rephrased":"While the overall idea is sensible, further justification could be provided to clarify its significance to the community."},{"sentence_type":"2","sentence":"Experimental results are weak, and comparisons with other methods are lacking, so it is hard to judge what are the actual gains.","rephrased":"Strengthening the experimental results and including comparisons with other methods would provide a clearer understanding of the benefits of this approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[133,216,"Confirmed"],[221,366,"Maybe"],[369,463,"Maybe"],[598,655,"Confirmed"],[656,710,"Missed by Model"],[990,1118,"Confirmed"]],"Comments":[]}
{"id":"Bknbc_kxG","text":"Summary:\n\nThe Value-Iteration-Network (VIN) architecture is modified to have a softmax loss function at the end. This is termed SVIN. It is then applied in a behavior cloning manner to the task of rover path planning from start to goal from overhead imagery.\n\nSimulation results on binary obstacle maps and using real-world Mars overhead orbiter maps are shown. On the simulation maps SVIN is shown to achieve 15-20% better lower training error than VIN.\n\nOne the Mars images it trains up to 45% training accuracy. (What was testing accuracy?)\n\n\nComments:\n\n- Section 1.1: \"Autonomous driving techniques also exist, though they lack the ability to do high level planning to choose paths that are advantageous for longer term navigation.\" --This is not true. See any of the numerous good systems described in literature. See the special editions of the Journal of Field Robotics on DARPA Urban Challenge and Desert Challenge or any of the special editions for the Learning Applied to Ground Robots (LAGR) program for excellent literature describing real-world autonomous ground vehicle systems. And specifically for the case of predicting good long-term trajectories from overhead imagery see: Sofman, B., Lin, E., Bagnell, J. A., Cole, J., Vandapel, N., & Stentz, A. (2006). Improving robot navigation through self‐supervised online learning. Journal of Field Robotics. (Papers related to this have been cited in this paper already).\n\n- Section 4.1: \"During training the output from the VI module is fed to an action selection function to compare those results against actions chosen in the training data.\": What is the action selection function? Is it a local planner (e.g. receding-horizon model-predictive control)? Is it a global planner with access to full map to the goal (e.g. A* run all the way to the goal location assuming that during training the entire map is available)? Same question for Figure 2 where the 'expert action' block doesn't specify who is the expert here (computational or human).\n\n- Section 2: \"Imitation learning for navigation has been studied by other groups as well (Silver et al. 2010)\": That particular paper is about using inverse optimal control (aka inverse reinforcement learning) and not imitation learning for first learning a good terrain cost function and then using it in a receding-horizon fashion. For imitation learning in navigation see \"Learning Monocular Reactive UAV Control in Cluttered Natural Environments\" by Ross et al. and relevant literature cited therein.\n\n- My main concerns with the experiments is that they are not answering two main questions: 1. What is SVIN\/VIN bringing to the table as a function approximator as opposed to using a more traditional but similar capacity CNN? 2. Why are the authors choosing to do essentially behavior cloning as opposed to imitation learning? It is well established (both theoretically and empirically) that imitation learning has mistake bounds which are linear in the time horizon while behavior cloning is quadratic. See Ross et al., \"A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning.\"\n\n- Figure 6: Please mark the goal points. It is not obvious where it is from the field arrows.\n\n- Figure 8: Are white regions high\/low cost? It is not obvious from the pictures what is being avoided by the paths.\n\n- What does 45% accuracy actually mean? Are the predicted paths still usable? No figures showing some qualitative good and bad examples are shown so hard to tell.\n\n- On the rover overhead imagery if a simple A*\/Dijkstra search algorithm was run from start to goal using the DEM as a heuristic cost map, how well will it do compared to SVIN?\n","sentences":[{"sentence_type":"2","sentence":"- Section 1.1: \"Autonomous driving techniques also exist, though they lack the ability to do high level planning to choose paths that are advantageous for longer term navigation.\" --This is not true. See any of the numerous good systems described in literature.","rephrased":"In Section 1.1, it may be beneficial to consider the capabilities of autonomous driving techniques in high-level planning for long-term navigation, as there are several systems described in the literature that address this aspect. For example, the Journal of Field Robotics has special editions on the DARPA Urban Challenge and Desert Challenge, as well as the Learning Applied to Ground Robots (LAGR) program, which provide valuable insights."},{"sentence_type":"1","sentence":"- My main concerns with the experiments is that they are not answering two main questions: 1. What is SVIN\/VIN bringing to the table as a function approximator as opposed to using a more traditional but similar capacity CNN? 2. Why are the authors choosing to do essentially behavior cloning as opposed to imitation learning?","rephrased":"I would like to understand better the unique contributions of SVIN\/VIN as a function approximator compared to traditional CNNs of similar capacity. Additionally, it would be helpful if the authors could clarify their choice of behavior cloning over imitation learning, given the established differences in mistake bounds between the two methods."},{"sentence_type":"1","sentence":"- What does 45% accuracy actually mean? Are the predicted paths still usable? No figures showing some qualitative good and bad examples are shown so hard to tell.","rephrased":"Could you please elaborate on the significance of the 45% accuracy metric? It would be helpful to understand if the predicted paths are still practical, and including figures with qualitative examples of successful and unsuccessful predictions could provide clearer insights."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[557,818,"Not concerning"],[2514,2839,"Not concerning"],[3340,3502,"Maybe"]],"Comments":[]}
{"id":"rygHwa3up7","text":" My main concern is that the authors fail to compare their appproach to any of the modelling approaches discussed in the related works section. In particular, as mentioned by the authors the WTTTE-RNN has a similar architecture and thus would have been a crucial baseline for comparisons.\n Furthermore, I would have liked to see an evaluation on more datasets, especially since the data in Appendix H indicate that the proposed approach is only marginally better than MLE-based model fitting.\nFinally, in addition to the metrics presented, conventional metrics such as the C-statistic would have been interesting.\n\nI further miss a discussion of alternative approaches to achieve well calibrated scores, especially posthoc calibration using the validation set as discussed in Guo et al, ICML 2017.\n\nRelated work is incomplete, for example the use of tensor-trains in RNNs to model EHR data (Yang et al) - would the proposed approach not benefit for the use of such tensorization to better model the high-dimensional, sparse EHR data?\n\n\nreferences:\nGuao et al, On Calibration of Modern Neural Networks, ICML 2017\nYang et al, Modeling progression free survival in breast cancer with tensorized recurrent neural networks and accelerated failure time models, Machine Learning for Healthcare Conference 2017","sentences":[{"sentence_type":"1","sentence":"My main concern is that the authors fail to compare their appproach to any of the modelling approaches discussed in the related works section.","rephrased":"It would be beneficial for the authors to include comparisons of their approach with the modeling approaches discussed in the related works section to strengthen their findings."},{"sentence_type":"2","sentence":"Related work is incomplete, for example the use of tensor-trains in RNNs to model EHR data (Yang et al) - would the proposed approach not benefit for the use of such tensorization to better model the high-dimensional, sparse EHR data?","rephrased":"The related work section could be enhanced by including studies such as the use of tensor-trains in RNNs to model EHR data (Yang et al), which might also suggest potential benefits for the proposed approach in modeling high-dimensional, sparse EHR data."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1,143,"Maybe"],[799,1033,"Maybe"]],"Comments":[]}
{"id":"BdLMha3H8_N","text":"Summary:\nThis paper introduces the concept of contextual feature utility and sensitivity to illustrate the trade-off between robustness and sensitivity. The authors propose Feature Contrastive Learning (FCL) to regularize models to be more sensitive to features that have higher utility, i.e. change the classification loss of the model to a larger extent. FCL first ranks features according to how much they change the loss values. Gaussian perturbations are then added to the top- and bottom-ranked pixels to form negative and positive pairs with the original input respectively. Contrastive learning is conducted by training the feature extractor of the classifier to minimize distance between the two hidden states in a particular positive pair, in order to align feature sensitivity with utility. The authors create a synthetic MNIST classification task where a subset of digit classes are affected by the presence of other digits at the corner of the image, to test a model’s selective sensitivity to input features. Through experiments on the synthetic MNIST and two variants of CIFAR datasets, FCL is shown to improve classification accuracy under noisy conditions while maintaining good clean accuracy.\n\nPros:\n\n+Good direction to train models that strive to have a better balance between robustness against label-preserving perturbations and sensitivity towards label-changing perturbations.\n\n+The idea of using contrastive learning to improve the robustness of models is interesting and could potentially be used for other kinds of perturbations.\n \n \nCons:\n\n-Lack of studies on robustness against adversarial examples (L-p and invariance types), experiments currently only show results on robustness on gaussian\/uniform noise. \n\n-Little theoretical support or justification on why aligning the feature sensitivity and utility proposed here would help balance between sensitivity and robustness (such as against L-p and invariance adversarial examples).\n\nRecommendation:\nWhile the idea of training a model to be both robust and sensitive at the same time is well-motivated and promising, the experiments here fall short of evaluating robustness beyond gaussian\/uniform noise. The claims of the paper would be stronger with robustness evaluation against the widely-studied L-p norm and recent invariance adversarial examples that are also mentioned in this paper.\n \nConsidering the lack of the aforementioned experiments and of more rigorous theoretical support for FCL for robustness that generalizes beyond the gaussian\/uniform noise evaluated here, this paper is still not ready for publication.\n\nOther questions and comments:\nWhat is the performance of the model if Contrastic Learning is done by creating positive pairs by just adding gaussian noise to the original image? \n\nSince the proposed method, FCL, relies on contrastive learning, it would help to discuss prior work on contrastive learning, especially highly similar ones such as: https:\/\/arxiv.org\/pdf\/2006.07589.pdf\n\n\n","sentences":[{"sentence_type":"2","sentence":"Considering the lack of the aforementioned experiments and of more rigorous theoretical support for FCL for robustness that generalizes beyond the gaussian\/uniform noise evaluated here, this paper is still not ready for publication.","rephrased":"To strengthen the paper's claims and readiness for publication, it would be beneficial to include the aforementioned experiments and provide more rigorous theoretical support for FCL's robustness that generalizes beyond the gaussian\/uniform noise evaluated in this study."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2374,2606,"Not concerning"]],"Comments":[]}
{"id":"xmj7bBnBv4","text":"The paper empirically studies the recently observed grokking phenomenon. It observes that it often occurs together with \"slingshot behaviors\" in adaptive optimizers.\n\nThe paper provides an interesting investigation into a deep learning training phenomenon and is thus relevant for this workshop.\n\n\nFeedback:\n- The Figures are in general really hard to read when printed. Perhaps you could use the available space a bit more efficiently.\n- The observations mentioned in Section 2 (e.g. Line 70) are not always that obvious to me in the Figures. For example, you state in Line 64, \"A sharp phase transition [of the norm] then occurs when the model misclassifies training samples\". But there are multiple \"dips\" in the train accuracy plot where no phase transition is visible in the norm. Am I misreading something here?\n- Could explain a bit more why the cosine distance is an appropriate measure for how far a model is flung? Theoretically, it could be flung just straight from model init to a new point, which would not register via the cosine distance, right?\n\nNits:\n- Line 8: \"of the last layer's weights\"\n- Line 17: \"was proposed\" perhaps replace it with \"observed\" as it describes a phenomenon?","sentences":[{"sentence_type":"2","sentence":"The Figures are in general really hard to read when printed. Perhaps you could use the available space a bit more efficiently.","rephrased":"To enhance readability, especially when printed, consider optimizing the use of space in the Figures."},{"sentence_type":"1","sentence":"The observations mentioned in Section 2 (e.g. Line 70) are not always that obvious to me in the Figures.","rephrased":"It would be helpful if the observations in Section 2, such as those on Line 70, were more clearly reflected in the Figures."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[310,436,"Not concerning"],[439,543,"Not concerning"]],"Comments":[]}
{"id":"HHegKEkW1zc","text":"The paper aims to identify the underlying computational problem that existing iterative approaches to object-centric learning are trying to solve. Specifically, the paper classifies existing approaches into two categories: those that meta-learn posterior inference and those that meta-learn parameter estimation. The paper then proposes an optimization problem that unifies these two categories, where the inner layer optimizes ELBO with respect to the per-datapoint parameters (e.g., slot representations, cluster assignments), and the outer layer optimizes the task objective (e.g., reconstruction, classification) with respect to network weights (e.g., encoder and decoder). The paper also suggests some connections to other fields.\n\nPros\n- The paper is well-motivated. A unified problem formulation can shed light on ways to improve the existing methods.\n\nCons\n- The clarity of the paper can be improved. For example, I didn't understand the key difference between the two proposed categories. In particular, why can't Slot Attention fit in the first category?\n- I am not sure whether the proposed framework is general enough. In particular, why does the inner objective have to be ELBO? The paper mentioned that the soft k-means algorithm is known to monotonically improve the ELBO. However, in Slot Attention the soft k-means algorithm is replaced by learnable updates. It is unclear whether the learnable updates is still optimizing the same objective.","sentences":[{"sentence_type":"1","sentence":"I am not sure whether the proposed framework is general enough.","rephrased":"It would be helpful if the paper could further clarify the generality of the proposed framework."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1067,1130,"Confirmed"]],"Comments":[]}
{"id":"BTgzkybmbV","text":"# Clarity\nI found the work easy to follow and well written.\n\n# Quality\nThe applications of the work are clear for epidemiologists and data scientists.\n\n# Originality\nThe data set used is novel, but the methods themselves are well studied and fairly straightforward.\n\n\n\nThe authors describe their experiments for using wastewater based epidemiology (WBE) methods for case count prediction at the national level versus traditional epidemiological methods, which may require more extensive and less commonly available data. The experiments show similar levels of accuracy for prediction of case counts moving forward given prior time series data.\n\nThe work is novel in the questions that it asks and the analysis that it provides on the foundations of WBE. I think that the data set itself could be expanded on, however. The specific value being measured against is only mentioned in Figure 1 (Effective copies of genome per $\\mu L$ ), and it is unclear if there are other predictive factors being looked at.\n\nThe authors note that they aggregate wastewater data to a country level for making predictions due to the biases in data collection, but is national level data granular enough to be useful? The authors could do an analysis on the more regional data as well to see if the accuracy of their predictions holds up at the county\/city level. This could be used as evidence for expansion of this data collection into these more rural areas as well.","sentences":[{"sentence_type":"1","sentence":"The specific value being measured against is only mentioned in Figure 1 (Effective copies of genome per \\\\(\\\\mu L\\\\) ), and it is unclear if there are other predictive factors being looked at.","rephrased":"It would be helpful if the authors could clarify whether other predictive factors were considered, in addition to the effective copies of genome per \\\\(\\\\mu L\\\\) mentioned in Figure 1."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[818,1005,"Confirmed"]],"Comments":[]}
{"id":"rJepWPJ9t4","text":"The authors propose techniques for training image denoising models without supervision, using only corrupted images and seeing each corrupted image once.\n\nPositives:\n- Interesting blind-spot network architecture with \"4-directional\" reading head and shared weights;\n- The Bayesian training is also a nice contribution, and proves to be important in the evaluation;\n- Concisely written and straight to the point\n\nRemarks & questions:\na) One extra baseline I am curious of: one could train N2N under the same constraint of using each image once using extra synthetic noise. Given a corrupted image, one can add extra corruption to obtain copies of it with different noise levels, and this could be enough supervision to train N2N to reasonable accuracy. It would be an interesting additional baseline, since it would use the same constraint as your work.\nb) Inference speed: can you compare the inference speed between your network and other baselines e.g. N2N?\nc) It seems to me that the datasets used in evaluation have standard image artifacts: JPEG, scale, noise... This makes the problematic of designing methods for seeing each image once a bit artificial because N2N is already well suited to the task. I wonder if one could showcase the benefits of the method on datasets with a special type of artifacts, e.g. medical imagery or hyperspectral data.\n\nOverall I think the paper is a worthwhile contribution to the workshop.","sentences":[{"sentence_type":"2","sentence":"This makes the problematic of designing methods for seeing each image once a bit artificial because N2N is already well suited to the task.","rephrased":"It would be beneficial to clarify how the proposed method for seeing each image once offers advantages over N2N, which is already well adapted to the task."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1068,1207,"Confirmed"]],"Comments":[]}
{"id":"BkgW8i5RKB","text":"Paper Summary:\n\nThis paper extends TapNet, a few short learning approach, to the setting of semi-supervised few shot learning. For that, it borrows the idea of soft-labeling from Ren et al 2018, a semi-supervised few shot learning algorithm. Experiments over mini and tiered imagenet compare the approach with alternatives.\n\nReview Summary:\n\nThe paper could be clearer. The main idea of the paper and its goal\/motivation is not concisely given in the intro and abstract. The paper refers to a lot of terminology from TapNet without defining them which makes it difficult to understand. I am not an expert in the field and I have a hard time judging whether the empirical improvement are exceptional but I would advocate against accepting the paper based on clarity alone at this point. Moreover the contribution -- adding soft labeling to TapNet -- seems modest.\n\nDetailed Review:\n\nThe abstract should not be a sketch of the proposed algorithm. It should highlight: what is the problem, what is the key idea of what you propose to address it (one sentence), why is it original and better than prior work, what is the foreseen impact of this work. \n\nThe terminology specific to your problem and family of model need to be defined: what is the clustering space? which clustering? what is the classification space? what is a per class network? None of these concepts are defined.\n\nIn section 2.2, please rephrase \"Nulling of the errors is essentially finding a projection matrix M such that epsilonM = 0 for all n. The resulting M is a matrix whose columns span the task-adaptive classification space\" as \"We identify M such that (i)  epsilonM = 0 for all n and (ii)  M columns span the task-adaptive classification space\". The text make it sounds like your are finding the solution of (i) which happened to also verify (ii) which is not true. For instance, M=0 satistifies (i) but not (ii).","sentences":[{"sentence_type":"2","sentence":"I would advocate against accepting the paper based on clarity alone at this point.","rephrased":"I recommend that the paper's clarity be improved before considering acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[703,785,"Confirmed"]],"Comments":[]}
{"id":"ByeiePV93Q","text":"This paper proposes a hierarchical RNN, where the first layer is note-level and the second level is measure-level. In an experiment on the Nottingham MIDI dataset, they show slight improvements in log-likelihood.\n\nOverall:\n\nThis is an interesting application of hierarchical RNNs. However, hierarchical RNNs are known to improve performance. This is an application of existing work (for example, Alexander Graves' thesis also uses hierarchical RNNs and shows improved performance). For an applications-oriented paper, I would hope to see many more experiments than just one on a tiny dataset, and improvements in log-likelihood that are more than the marginal improvements reported here. The human evaluation is neat but is inconclusive–in a glaring act of omission, the authors do not link to samples generated by their model, while they include samples generated by the competition. For a fair review, one would hope to compare the models side by side to qualitatively judge the reliability of the MTurk experiments.\n\nMinor nits:\n\nI appreciate the human evaluation experiments on MTurk but they are very difficult to understand with the figure 5. Please label the y-axis. Think of a different way to present the results. Do not include the numbers on the bars. \n\nThe acronym HierArchical PolyPhonic musIc gEnerative RNN is destructive; it devalues useful acronyms. Please do not use it.\n\nThe paper has many grammatical and spelling errors. Please hyphenate compound adjectives. \n","sentences":[{"sentence_type":"2","sentence":"The acronym HierArchical PolyPhonic musIc gEnerative RNN is destructive; it devalues useful acronyms. Please do not use it.","rephrased":"The acronym HierArchical PolyPhonic musIc gEnerative RNN seems forced and may not effectively communicate the essence of your model. Consider revising it for clarity and impact."},{"sentence_type":"2","sentence":"The human evaluation is neat but is inconclusive–in a glaring act of omission, the authors do not link to samples generated by their model, while they include samples generated by the competition.","rephrased":"The human evaluation is a good initiative, but it would be more conclusive if the authors provided links to samples generated by their model, as they have done for the competition, to allow for a direct comparison."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[688,884,"Confirmed"],[1265,1388,"Confirmed"]],"Comments":[]}
{"id":"S1lT_rjdtr","text":"This paper investigates representations learned by Siamese trackers. The paper argues that existing trackers rely on saliency detection despite being designed to track by template matching in feature space. An auxiliary detection task is proposed to induce stronger target representations in order to improve tracking performance. Experiments are performed on VOT2018 tracking dataset.\n\nThe paper investigates an interesting and active research problem of stronger object representations for deep visual object tracking. However, the proposed solution of just integrating an additional detection task branch within the Siamese tracking architecture is naive. The main idea of integrating instance driven detection as an auxiliary task is borrowed from [1].  [1] also utilizes a Siamese architecture that is similar to the ones generally used in visual object tracking to localize particular instances of objects. Therefore, the novelty of the proposed tracking approach is limited.\n\nSome recent works, such as [2, 3] have also investigated a similar problem of richer object representations for deep visual tracking. These approaches are desired to be discussed and empirically compared in order to fully validate the strength of the proposed approach. \n\nThe paper shows some qualitative analysis. However, most of it is limited to just few frames of an image sequence. Tracking datasets, such as VOT and OTB, provide additional analysis tools (i.e., attribute analysis) to thoroughly evaluate visual trackers. Such analysis is missing in the paper. For instance, the main argument of this paper is that current approaches rely on center saliency and likely struggle in the presence of occlusion. How does the proposed approach fare, compared to SOTA, on the subset of VOT image sequences that are labeled with occlusion?\n\nOn page 3, it is stated that \"Our model uses a lightweight backbone network (MobileNetV2), and is somewhat simpler than recent state-of-the-art models  .....................  Although the model doesn’t outperform state-of-the-art, it attains competitive performance.\" The reviewer does not fully agree with this statement. A comprehensive empirical evaluation is crucial to fully access the merits of the contributions. State-of-the-art visual object trackers [2, 3, 4] achieve competitive tracking performance while being computationally efficient and fast. Therefore, a proper state-of-the-art comparison is desired to compare the proposed tracker with SOTA methods. Further, currently experiments are only performed on the VOT2018 dataset. The reviewer recommends to perform additional experiments on other large-scale datasets, such as TrackingNet [5] and Lasot [6] and compare the performance with SOTA methods that are also investigating the problem of richer object representations for tracking. \n\n[1] Phil Ammirato, Cheng-Yang Fu, Mykhailo Shvets, Jana Kosecka, Alexander C. Berg: Target Driven Instance Detection. CoRR abs\/1803.04610 (2018).\n[2] Martin Danelljan, Goutam Bhat, Fahad Shahbaz Khan, Michael Felsberg: ATOM: Accurate Tracking by Overlap Maximization. CVPR 2019.\n[3] Goutam Bhat, Martin Danelljan, Luc Van Gool, Radu Timofte: Learning Discriminative Model Prediction for Tracking. CoRR abs\/1904.07220 (2019).\n[4] Bo Li, Wei Wu, Qiang Wang, Fangyi Zhang, Junliang Xing, Junjie Yan: SiamRPN++: Evolution of Siamese Visual Tracking With Very Deep Networks. CVPR 2019.\n[5] Matthias Müller, Adel Bibi, Silvio Giancola, Salman Al-Subaihi, Bernard Ghanem: TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild. ECCV  2018.\n[6] Heng Fan, Liting Lin, Fan Yang, Peng Chu, Ge Deng, Sijia Yu, Hexin Bai, Yong Xu, Chunyuan Liao, Haibin Ling:\nLaSOT: A High-Quality Benchmark for Large-Scale Single Object Tracking. CVPR 2019.\n\n","sentences":[{"sentence_type":"2","sentence":"However, the proposed solution of just integrating an additional detection task branch within the Siamese tracking architecture is naive.","rephrased":"However, the proposed solution of integrating an additional detection task branch within the Siamese tracking architecture could be further developed to enhance its originality and effectiveness."},{"sentence_type":"1","sentence":"The main idea of integrating instance driven detection as an auxiliary task is borrowed from [1].","rephrased":"The concept of integrating instance-driven detection as an auxiliary task seems to have similarities with the approach presented in [1]."},{"sentence_type":"1","sentence":"The reviewer does not fully agree with this statement.","rephrased":"The reviewer suggests a more comprehensive empirical evaluation to strengthen the evidence supporting this statement."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[521,658,"Confirmed"],[659,756,"Confirmed"],[2091,2145,"Not concerning"]],"Comments":[]}
{"id":"HyemrA0d2X","text":"The paper studies the effect of different dropout regimes (unit-wise, channel-wise and layer-wise), locations and probability affect the performance of DenseNet classification model. The experiments are performed on two datasets: CIFAR10 and CIFAR100.\n\nIn order to improve the paper, the authors could take into consideration the following points:\n\n1. The experimental validation is rather limited. Additional experiments on large scale datasets should be performed (e. g. on ImageNet).\n2. The design choices are rather arbitrary. The authors study three different probability schedules. Wouldn't it be better to learn them using recent advances in neural architecture search or in RL.\n3. \"The test error is reported after every epoch and ...\". This suggest that the authors are monitoring the test set throughout the training. Thus, the hyper parameters selected (e. g. the dropout regimes) might reflect overfitting to the test set.\n4. Table 1 misses some important results on CIFAR10 and CIFAR100, as is, the Table suggest that the method described in the paper is the best performing method on these datasets (and it is not the case). Moreover, the inclusion criteria for papers to appear in Table 1 is not clear. Could the authors correct the Table and add recent results on CIFAR10 and CIFAR100?\n5. Section 4.1: \"... a perfect size for a model of normal size to overfit.\"  This statement is not clear to me. What is a normal size model? Moreover, claiming that CIFAR10 and CIFAR100 is of perfect size to overfit seems to be a bit misleading too. Please rephrase.\n6. Section 3.3: what do the authors mean by deterministic probability model?\n7. Abstract: \"DenseNets also face overfitting problem if not severer\". I'm not aware of any evidence for this. Could the authors add citations accordingly?\n8. Some discussions on recent approaches to model regularizations and connections to proposed approach are missing. The authors might consider including the following papers: https:\/\/arxiv.org\/pdf\/1708.04552.pdf, https:\/\/arxiv.org\/pdf\/1802.02375.pdf, among others.\n\nOverall, the paper is easy to understand. However, the originality of the paper is rather limited and it is not clear what is the added value to for the community from such paper. I'd encourage the authors to include additional experiments, correct misleading statements and add a discussion of model regularization techniques in the related work section.","sentences":[{"sentence_type":"2","sentence":"The design choices are rather arbitrary.","rephrased":"The rationale behind the design choices could be further elaborated to strengthen the paper."},{"sentence_type":"3","sentence":"The paper is easy to understand. However, the originality of the paper is rather limited and it is not clear what is the added value to for the community from such paper.","rephrased":"While the paper is easy to understand, it would be beneficial to highlight the novel contributions more clearly to emphasize the value it adds to the community."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[490,530,"Maybe"],[2110,2247,"Confirmed"]],"Comments":[]}
{"id":"gRNM1v_eNuk","text":"The main contributions are on the theoretical side.\nMy main concerns are about originality\/novelty. The upper and lower bound on stability are adaptations of the claims of Bassily et al. (2020).\nMoreover, methods of weight perturbation were already investigated empirically  (see for example - Adversarial weight perturbation helps robust generalization, Neurips2020), and some theoretical justifications were also provided in follow-up papers.\n\nMoreover, there are glaring omissions in the literature review, especially on the theoretical side and regrading weights perturbation methods.\n\nOn the other hand, I think that the main research question is interesting and important. ","sentences":[{"sentence_type":"2","sentence":"Moreover, there are glaring omissions in the literature review, especially on the theoretical side and regrading weights perturbation methods.","rephrased":"However, the literature review could be more comprehensive, particularly regarding the theoretical aspects and weight perturbation methods."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[446,588,"Confirmed"]],"Comments":[]}
{"id":"0BNgxmH5rU","text":"**Summary:** The authors propose a new architecture (CAT for Convolutional\nAttention Layer) for Graph Neural Networks that combines GCNs (Graph\nConvolutional Networks) and GATs (Graph Attention Networks). An example with\nsynthetic data shows (theoretically and empirically) that the optimal choice\namong the three architectures depends on the data. Thus, the paper introduces\nL-CAT (Learnable Convolutional Attention Layer) which is able to interpolate\nbetween CAT, GCN and GAT. \n\n**Strengths, Weaknesses & Questions:**\n- Overall, the paper is well-structured and nicely written. The introduction\nclearly explains the context of the work and the contribution of the paper. The\nsecond section *Preliminaries* provides a good overview on GNNs. Theoretical\nfindings are discussed and also validated empirically. \n- Line 63-69: As a non-expert, I have difficulties understanding the CSBM\nexample. I would have appreciated if you had provided more *intuition* on what\nthe quantities mean and what their impact on separation *difficulty* is\n(especially for the quantities $p$, $q$ and $\\Vert\\mu\\Vert$). \n- Line 113-115: You claim that \"CAT and L-CAT [...] mostly improve test accuracy\nwith respect to their baseline model\" (I guess this baseline refers to GCN?).\nI'm confused about how you arrived at this statement since there is only one\ncase (*Facebook PagePage*) out of six, where CAT or L-CAT significantly\noutperform the GCN baseline. In all other cases, if I understand correctly, GCN\nis better on average or the improvements of CAT\/L-CAT are insignificant. \n\n**Minor:**\n- Line 37: At this point, I was wondering what the objective for the GNN was. Is\nit node classification, learning a node embedding, or something else?\n- Line 47: What does it mean for a graph to be *noisy*? It seems that this\nrefers to the parameter $q$ (line 104) but also to $\\sigma$ (as in the middle\nfigure on page 4). Maybe clarify this by providing a more precise definition. \n- Theorem 1 and Corollary 2: What are $\\Omega$ and $\\omega$?\n- Table 1: In the *GitHub* column, none of the results are underlined.\n- Top figure on page 4: I don't understand what is shown here. What is the\naverage node degree and what does the accuracy improvement on the y-axis refer\nto?","sentences":[{"sentence_type":"2","sentence":"I'm confused about how you arrived at this statement since there is only one case (*Facebook PagePage*) out of six, where CAT or L-CAT significantly outperform the GCN baseline. In all other cases, if I understand correctly, GCN is better on average or the improvements of CAT\/L-CAT are insignificant.","rephrased":"Could you please clarify the basis for the statement that 'CAT and L-CAT mostly improve test accuracy with respect to their baseline model'? It appears that in the case of *Facebook PagePage*, CAT or L-CAT significantly outperform the GCN baseline, but in the other cases, the performance seems comparable or the improvements are not substantial. Additional data or discussion here would be helpful."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1257,1559,"Maybe"]],"Comments":[]}
{"id":"U26GZfrMKJ","text":"**Summary:**\n\nThe paper studies the problem of forgetting during fine-tuning of pre-trained models in RL.\nThe primary contributions are two-fold: first, authors analyze the phenomenon in a grid-world environment consisting of two stages, where the pre-training is done on the 2nd stage, and demonstrate that the harder the 1st stage is, the lower the knowledge retention about the optimal behavior on the 2nd stage is going to be.\nThe second contribution is an analysis of continual learning techniques for avoiding forgetting on a sequence of robotic manipulation tasks, where the pre-training is done on the last tasks of the sequence. The conclusion is that EWC and experience replay allow largely alleviating forgetting.\nThe authors argue that the problem setting studied might be relevant when dealing with foundation models in deep RL.\n\n\n**Quality:**\n\nThe motivation of the paper is relevant to the scope of the workshop.\nI enjoyed the minimalistic setting clearly isolating the problem.\nThe insights from the setting make sense: the more gradient updates on states outside of the pre-training dataset the agent makes, the lower the knowledge retention is on the states from the pre-training data.\n\n\n**Clarity:** \n\nOverall, the paper is clearly written and it is possible to understand all claims and details of experiments supporting the claims.\nThe reviewer recommends improving the rigor of statements and avoiding non-falsifiable phrases of the form: \"high forgetting and overall poor performance.\"\n\n\n**Significance:**\n\nThe significance of the paper is limited. The main issue is the research methodology: both of the settings are somewhat contrived and it is unclear to which extent the challenges in these settings would be encountered in practice.\nThe insight from the grid-world environment that the pre-training behavior gets forgotten is a known issue in the continual learning literature [1].\nLikewise, the main practical conclusion is somewhat underwhelming: \"continual learning techniques mostly address forgetting issues\" does not give much insight.\n\n\nMisc:\n* I'd recommend avoiding the term \"Compositional MDPs\" --- it might be misleading as there's a vast literature on compositional generalization (e.g. [2])\n* The huggingface link is not properly anonymized, suggesting that the submission is from https:\/\/parallax.co.in\/\n\nOverall recommendation:\nThe reviewer leans towards recommending the paper for acceptance to the workshop. It might spur a discussion at the workshop about the issues with fine-tuning of the pre-trained models. Extending results beyond the toy environment and a single sequence of control tasks would increase the significance of the paper.\n\n[1] Kirkpatrick, James, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan et al. \"Overcoming catastrophic forgetting in neural networks.\" Proceedings of the national academy of sciences 114, no. 13 (2017): 3521-3526.\n\n[2] Loula, Joao, Marco Baroni, and Brenden M. Lake. \"Rearranging the familiar: Testing compositional generalization in recurrent networks.\" arXiv preprint arXiv:1807.07545 (2018).","sentences":[{"sentence_type":"2","sentence":"The significance of the paper is limited.","rephrased":"While the paper presents interesting findings, the significance could be enhanced by addressing the broader implications of the research methodology."},{"sentence_type":"2","sentence":"Likewise, the main practical conclusion is somewhat underwhelming: \"continual learning techniques mostly address forgetting issues\" does not give much insight.","rephrased":"The practical conclusion could be strengthened by providing more detailed insights into how continual learning techniques address forgetting issues."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1530,1571,"Maybe"],[1910,2069,"Confirmed"]],"Comments":[]}
{"id":"r1xi3s4_j4","text":"The paper proposes a constrained multi-criteria path-planning algorithm with path distance and human intervention as two objective functions. A neural network is built to predict the feasibility of driving through particular edges without human intervention. Such feasibility is then encoded in the path planning algorithm. The application and results are interesting. \n\nHere are some suggestions on improving presentations: \n- I read \"user preferences\" Section 5, but i had no clue what it is. Later I figured out it is linked to \"autonomous feasibility\" discussed in the previous sections. Please make this link more explicitly. \n- in Section 2, instance I = (s,d,M) is defined, but s, d are not used in the formulation in Section 5.\n- In Eqn (7,8), v'v is not defined. \n- The optimization objective function is mentioned in the text. Can you write it down mathematically for the purpose of completeness of the formulation?\n- The experiment could be elaborated more.  As the outputs of NNs are used as parameters of the optimization model, the performance of NNs in terms of accuracy should be discussed in the results. It is not clear what values of vector x are used, how many edges etc, in the experiments.\n- The authors state learning-based methods have significantly few approaches for multi-criteria optimization, compared to single criterion optimization problems. As a reader, I would like to see some discussions in the paper on what could have been different on handling multi or single objectives in your problem? Is it a straightforward extension (from single objective), or does it involve additional technical challenges? ","sentences":[{"sentence_type":"2","sentence":"I read \"user preferences\" Section 5, but i had no clue what it is.","rephrased":"In Section 5, the term \"user preferences\" is introduced, but its connection to the \"autonomous feasibility\" discussed earlier is not immediately clear. Clarifying this relationship would enhance the reader's understanding."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[428,494,"Confirmed"]],"Comments":[]}
{"id":"_J8YcyrYZqb","text":"## Summary:\n\nIn this paper, the authors propose Language-Image Value Learning (LIV), an approach for joint vision-language representation learning as well as reward learning from action-free videos with text annotations. Their method combines the goal-conditioned image representation learning objective from Value Implicit Pre-Training (VIP) with the InfoNCE objective used in CLIP for vision-language representation learning. First, the authors pretrain their representation using LIV on the EpicKitchen dataset (a large dataset of narrated videos of humans completing kitchen tasks). Then, they use the frozen representation as a backbone for a policy trained on two continuous control benchmarks, FrankaKitchen and Meta-World. LIV can be used both as a pre-training and fine-tuning objective. The authors show that LIV pre-trained representations outperform related methods on the considered benchmarks.\n\n## Strengths:\n- The authors propose a new method LIV that builds on two recent approaches, VIP and CLIP.\n- The authors stipulate clear criteria that pre-trained representations should fulfil and design their method accordingly:\n    - Aligning the vision and language to permit grounded language specifications\n    - Capture task-specific progress grounded in language\n    - Domain generic pre-training + domain-specific fine-tuning\n- The authors stipulate 3 research questions that they seek to answer in their experiments (pre-training, fine-tuning, language-conditioned reward specification). The subsequent experiments are well designed to answer their research questions.\n- The presented results show that their method outperforms related methods compared in this work (significantly?)\n- The LIV objective can be used both for pre-training, fine-tuning, as well as for reward learning.\n\n## Weaknesses:\n- Evaluation methodology:\n    - The method is evaluated on a narrow set of down-stream tasks from Meta-World (6 tasks) and FrankaKitchen (5 tasks). Overall, the Meta-World benchmark contains 50 and FrankaKitchen 10 tasks. Also, the selected tasks are relatively simple, compared to the remaining tasks in the benchmark. Why are these particular ones selected? Showing results on more tasks would strengthen the paper.\n    - The presented results exhibit high standard deviations (across 3 seeds) and significance tests are not conducted. Therefore, it is not clear whether LIV outperforms other approaches across settings. The word 'significantly' is used, however.\n        - Table 1, Meta-World: LIV-EPIC vs. CLIP one-hot\n        - Table 2, Meta-World: CLIP+LIV vs. Random+CLIP vs. Random+VIP-I vs. LIV-EPIC+LIV\n        - Table 3, Meta-World: LIV-EPIC (Fine-Tuned) vs. LOREL\n    - Reporting IQM and 95% confidence intervals (as proposed by https:\/\/arxiv.org\/abs\/2108.13264) would make the results more convincing, especially given the low number of seeds.\n    - Adding additional baselines would be beneficial. Currently, the policy is trained via behaviour cloning. How would the BC baselines without pre-trained representations compare? How do established offline RL algorithms compare?\n    - The authors state (lines 305-311), that they evaluate two trained policy checkpoints at the midpoints of training and end of training, and select the higher scores. What's the reasoning behind this?\n- Without task-information, LIV performs considerably better than competitor methods. The authors make the argument that the learned language representation is better suited for identifying the tasks. When provided with additional tasks information (One-Hot), the competitor methods all improve. However, for LIV, the opposite is the case. Why is that? Shouldn't this result in even better performance?\n- The authors make the argument that clip fine-tuning performs is wasteful, as it ignores all but the last few frames of each demonstration. This results in poor performance when a small number of samples is available (FrankaKitchen). Why wouldn't it be possible to use more frames across the demonstration? Then the performance gap may narrow.\n- Lacking comparison of different Vision and language backbones.\n- For the reward learning experiments, why is this specific model-based planning setup selected?\n- Minor:\n    - Figure 3: Add better descriptions, i.e., performance improvement over what? (Performance when task info is provided)\n    - Figure 4: what does 'over its ablations' mean?\n    - Figure 5: Axis descriptions. Would some sort of cluster analysis (e.g., via t-SNE) make this point stronger?\n    - Table 3: make additional column for the fine-tuning approach. Currently, it's written in parentheses and it's a bit confusing.\n    - Description of One-Hot setting: in Section 5.1 it is unclear what One-Hot refers to. Add a short description of what this means (i.e., that the task ID is provided?).\n    - Use same font-size in Figures.\n\n## Overall review:\nIn this paper, the authors propose LIV a method for joint vision-language representation learning as well as reward learning for visual control. Currently, the empirical results look promising, but are still limited in scope. Overall, we believe the papers fits the workshop well.\n\n\n\n\n\n","sentences":[{"sentence_type":"1","sentence":"The presented results show that their method outperforms related methods compared in this work (significantly?)","rephrased":"The presented results suggest that their method may outperform related methods compared in this work, though further statistical analysis could help confirm the significance of these findings."},{"sentence_type":"2","sentence":"The authors make the argument that clip fine-tuning performs is wasteful, as it ignores all but the last few frames of each demonstration.","rephrased":"The authors argue that clip fine-tuning may not be optimally efficient, as it primarily utilizes the last few frames of each demonstration."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1587,1698,"Confirmed"],[3715,3853,"Not concerning"]],"Comments":[]}
{"id":"r1xlT9d5oH","text":"* Note: I highlight I did not assess the model design, which is the main contribution of the paper, and  did not know the background of prior work of system design to really assess the novelty of the work, my score is solely based on the experiments. \n I am an expert in machine learning\/computer vision, so I could assess the experiments in terms of their validity and relevance from the machine learning\/vision perspective, however, I may not be the best person to evaluate the design choices of the system. Therefore I choose the low experience for my background.\n\n* Paper summary: The paper proposes a framework to evaluate machine learning models in a hardware-agnostic way.\nTo evaluate the models using this framework, the user needs to specify the pre-processing, inference, and post-processing steps and the required software\/hardware stack. The authors argue that this is important to consider the  HW\/SW stack to allow a fair evaluation and reproducibility. Models are specified using a model specification called manifest.\n\n* The authors assume that SW\/HW stack change the results of deep learning models a lot, and this is the main assumption in this work, however, normally in practice HW\/SW stack wont change the results.\n\n* I found the experiments either not related to the point of the paper or being very trivial not helping to backing up the arguments of the paper. \n\n\n* In section 4.1, the authors consider different preprocessing operations and study their impact on the model performance, however, the fact that preprocessing impact the results is trivial in machine learning. In the same section, color layout and data layout, cropping and resizing, where the authors discussed about for instance how changing the data representation from NCHW or NHWC change the results, this is also trivial, because if you change the dimensions, you need to also change the model in a way that handles this change of dimension, therefore, this is clear that the results will change accordingly as well. Such experiments does not back up the main argument of the paper, which argues for fair evaluation between neural models, nor provides informative information to the reader.\n\nOn section 4.1, the experiment of type conversion and normalization, again this is mathematically clear that the order would change the results,  let's call imgByte=x, then by substituting given\nvalues for mean and standard evaluation, equation (b) is simplified to (b) = (x-127.5)\/((127.5)*(255)) \nhowever simplification of (c) results in (x\/255-0.5)\/0.5 = (x-0.5*255)\/(0.5*255)=(x-127.5)\/(0.5*255) \nthe dominator of (b) and (c) are not equal, therefore, this is trivial that the results of these two \nthe expression would not be the same. The author posed it as a new finding, but this is trivial that mathematically\nthese two equations would not be equal. Again, this experiment does not add any value to the paper.\n\nIn section 4.2, in Figure 9, the authors show a plot of the CPU latency for different batch sizes and instances,\ntogether with GPU throughput for different batch sizes, i.e., images\/seconds. The authors show latency for CPU\ninstances, versus throughput for GPU instance, since these two measures are not shown for both instances, this is \nnot supported from the text, how actually authors compare this two instance and draw the conclusion that which instance is more efficient since there is no value shown for CPU throughput. Apart from that, I don't see how this section and determining if GPU or CPU instances of  Amazon compute cloud is more cost-efficient is related to the point of this paper which is on reproducibility. Also please have a look at Amazon webpage:\nhttps:\/\/docs.aws.amazon.com\/dlami\/latest\/devguide\/gpu.html\nHere, they explicitly mention that \"A GPU instance is recommended for most deep learning purposes. Training new models will be faster on a GPU instance than a CPU instance. You can scale sub-linearly when you have multi-GPU instances or if you use distributed training across many instances with GPUs.\",  so having this experiment again neither back up the arguments in the paper, nor add value to the paper.\n\n* The major issue with this submission is that the experiments are not related to the arguments of the paper, and are not conveying any message towards backing up the arguments of the paper.\n\n* Another crucial problem is that to allow a fair comparison especially in neural models, as shown in several studies(see [1] as a sample), this is important to account for random seeds and study how it impacts the model performance, to allow a fair evaluation of the models this is important to consider this factor, fair evaluation of models is argued to be the main point of this paper, however, the authors does not consider this factor in the paper, nor study it in the experiments.\n\n[1] Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks, Nils Reimers and Iryna Gurevych\n\n\n\n","sentences":[{"sentence_type":"2","sentence":"The authors assume that SW\/HW stack change the results of deep learning models a lot, and this is the main assumption in this work, however, normally in practice HW\/SW stack wont change the results.","rephrased":"While the authors posit that variations in SW\/HW stacks significantly impact deep learning model results, which is a central assumption of this work, it would be beneficial to consider that in many practical scenarios, the HW\/SW stack may not lead to substantial changes in outcomes."},{"sentence_type":"2","sentence":"I found the experiments either not related to the point of the paper or being very trivial not helping to backing up the arguments of the paper.","rephrased":"The relevance of the experiments to the paper's main points could be strengthened, and additional non-trivial evidence may help in supporting the paper's arguments more effectively."},{"sentence_type":"2","sentence":"Such experiments does not back up the main argument of the paper, which argues for fair evaluation between neural models, nor provides informative information to the reader.","rephrased":"It would be helpful if the experiments could be more closely aligned with the paper's main argument of advocating for fair evaluation between neural models, thereby offering more informative insights to the reader."},{"sentence_type":"2","sentence":"Again, this experiment does not add any value to the paper.","rephrased":"Further clarification on how this experiment enhances the paper's value would be beneficial."},{"sentence_type":"2","sentence":"so having this experiment again neither back up the arguments in the paper, nor add value to the paper.","rephrased":"It would be constructive to see how this experiment could be better integrated to support the paper's arguments and contribute to its overall value."},{"sentence_type":"2","sentence":"The major issue with this submission is that the experiments are not related to the arguments of the paper, and are not conveying any message towards backing up the arguments of the paper.","rephrased":"A major area for improvement in this submission could be to ensure that the experiments are more closely related to the paper's arguments and effectively contribute to reinforcing those arguments."},{"sentence_type":"2","sentence":"Another crucial problem is that to allow a fair comparison especially in neural models, as shown in several studies(see [1] as a sample), this is important to account for random seeds and study how it impacts the model performance, to allow a fair evaluation of the models this is important to consider this factor, fair evaluation of models is argued to be the main point of this paper, however, the authors does not consider this factor in the paper, nor study it in the experiments.","rephrased":"To enhance the paper's focus on fair evaluation, it would be advantageous to consider the impact of random seeds on model performance, as this is a significant factor demonstrated in several studies, including [1]. Addressing this could strengthen the paper's arguments and contribute to its novelty."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[1037,1235,"Confirmed"],[1239,1383,"Confirmed"],[2011,2184,"Confirmed"],[2845,2904,"Confirmed"],[4041,4144,"Confirmed"],[4148,4336,"Confirmed"],[4340,4825,"Confirmed"]],"Comments":[]}
{"id":"Bkxzx1DdKN","text":"This paper proposed a method for training a convolutional neural network (CNN) from few examples (few-shot learning) for the task of semantic segmentation. The proposed technique allows use to incrementally update the weights of the CNN when encountering examples from classes the networks has not seen before. The paper builds on the idea of weight imprinting, introducing an adaptive weight imprinting scheme that enables updating the weights of previously learned classes. The results on the PASCAL-5^i dataset look convincing, however the text lacks clarity and needs to be proofread and corrected.  Specifically, I have the following questions\/comments: \n\n    Multiple grammatical and syntactical  errors make the text hard to follow, e.g.,  the last sentence of the first paragraph of the introduction does not make sense, and citations need fixing. \n\n    \"Masked weight imprinting is performed on multiple resolution levels in order to improve the segmentation accuracy\" --> the multiscale nature of the algorithm is not captured by eq. 2. It is not clear how weight imprinting is performed at multiple resolutions. \n\n    What does \"interleaved with backpropagation\" mean? This should be clarified in the text. ","sentences":[{"sentence_type":"2","sentence":"Multiple grammatical and syntactical  errors make the text hard to follow, e.g.,  the last sentence of the first paragraph of the introduction does not make sense, and citations need fixing.","rephrased":"The manuscript could benefit from a thorough proofreading to address several grammatical and syntactical issues that currently impede readability. For instance, the last sentence of the first paragraph in the introduction could be clarified, and the citations require attention."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[665,855,"Confirmed"]],"Comments":[]}
{"id":"4t58U8YwEn","text":"The main contribution seem to be state-of-the-art zero-shot results on commonsense tasks obtained using albert-xxlarge-v2. However, the authors talk about concepts such as compositionality and I am not sure how this relates the main experiments in the paper.\n\n*Strength*:\n- Best zero-shot results on commonsense datasets (as claimed by the authors, I only checked a couple of references to see if that claim holds true)\n\nThe main *weakness* of the paper is that the writing is confusing, which makes it difficult to see what the main point of the paper is. The authors seem to argue for multiple statements that show up once in the paper and are then dropped or forgotten. An example from the abstract: \"We provide evidence for the following conclusion: a language model with relatively few parameters, trained for relatively few steps, can perform robustly across language tasks in a manner that demonstrates compositionality, at the cost of GPU-time for language evaluation.\" It is unclear to me where compositionality is being demonstrated in the experiments. (Maybe in the experiments with the 20 sentence pairs? But I wouldn't consider those enough evidence.)\n\nAdditionally, some of the statements made by the authors seem wrong or at least misleading:\n- The authors argue against finetuning by proving a quote from Bender and Koller (2020) on page 3, but I don't see how the quote is related to finetuning as opposed to general language models.\n- The authors state in 3.1.1: \"We first became aware of PLL scoring using language models via Salazar et al. (2020), and to our understanding their arxiv submission of that paper in late 2019 is the first treatment of the approach in the machine learning literature\" However, I believe this approach has been around much longer as a way to score pairs (or sets) of sentences. For example, Linzen et al. (2016) use effectively the same approach with LSTM language models (https:\/\/arxiv.org\/pdf\/1611.01368.pdf).\nI would recommend to revise those statements for future versions of the paper.","sentences":[{"sentence_type":"2","sentence":"The main *weakness* of the paper is that the writing is confusing, which makes it difficult to see what the main point of the paper is.","rephrased":"A significant area for improvement is the clarity of the writing, which could be enhanced to better convey the main points of the paper."},{"sentence_type":"2","sentence":"The authors seem to argue for multiple statements that show up once in the paper and are then dropped or forgotten.","rephrased":"The paper would benefit from a more consistent development of the key arguments presented, ensuring they are fully explored and integrated throughout the manuscript."},{"sentence_type":"2","sentence":"Additionally, some of the statements made by the authors seem wrong or at least misleading:","rephrased":"Additionally, there are some statements by the authors that may benefit from further clarification or supporting evidence to avoid potential misunderstandings:"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[421,556,"Confirmed"],[557,672,"Confirmed"],[1166,1257,"Confirmed"]],"Comments":[]}
{"id":"S1xnGsw7fN","text":"This paper introduces a project for structuring Wikipedia by aggregating the outputs from different systems through ensemble learning. It presents a case study of entity and attribute extraction from Japanese Wikipedia. \n\nMy major concern is the lack of methodological contribution. \n- Ensemble learning, which seems most like the methodological contribution, is applied in a straightforward way. The finding that ensemble learning gives better results than individual learners is trivial.\n- Authors state that a key feature of the project is using bootstrapping or active learning. This, however, is not explained in the paper nor supported by experimental results.\n\nClarification or details are needed for steps introduced by section 3-6:\n- In \"Extended Named Entity\", why would the top-down ontology ENE better than the inferred or crowd created ones? I think each of them has pros and cons.\n- In \"Categorization of Wikipedia Entities\", is training data created by multiple annotators? what is the agreement between the multiple annotators for the test (and the training) data? How much error of the machine learning model is caused by incorrect human annotations?\n- In \"Share-Task Definition\", \"We give out 600 training data for each category.\" does it mean 600 entities?\n- In \"Building the Data\", what is the performance of experts and crowds in the different stages?\n\nWriting should be improved. Some examples:\n- what does it mean by \"15 F1 score improvement on a category\".\n- a lot of text in the abstract is repeated in the introduction.\n- \"For example, ”Shinjuku Station” is a kind of railway station is a type of ...\": not a sentence.\n- \"4 show the most frequent categories\": should be Table 1.\n- page 8, \"n ¿ t\"L corrupted symbol.\n\nAs the last comment, I wonder how (much) this ensemble learning method can be better than crowd based KBC methods, as motivated by abstract and introduction. I would assume that machine learning has similar reliability issue as crowdsourcing even when ensemble learning is used. ","sentences":[{"sentence_type":"2","sentence":"The finding that ensemble learning gives better results than individual learners is trivial.","rephrased":"While the paper demonstrates that ensemble learning outperforms individual learners, it would be beneficial to discuss more about how this approach contributes methodologically beyond what is already known."},{"sentence_type":"1","sentence":"I think each of them has pros and cons.","rephrased":"It would be helpful if the paper could provide a more detailed comparison of the top-down ontology ENE with the inferred or crowd-created ones, highlighting their respective advantages and disadvantages."},{"sentence_type":"1","sentence":"As the last comment, I wonder how (much) this ensemble learning method can be better than crowd based KBC methods, as motivated by abstract and introduction.","rephrased":"Finally, it would be informative if the paper could elaborate on the advantages of the ensemble learning method over crowd-based KBC methods, as suggested in the abstract and introduction."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[397,489,"Maybe"],[855,894,"Not concerning"],[1743,1900,"Not concerning"]],"Comments":[]}
{"id":"H1-nFopxM","text":"The paper proposes a new approach (Minerva) to perform query answering on knowledge bases via reinforcement learning. The method is intended to answer queries of the form (e,r,?) on knowledge graphs consisting of dyadic relations. Minerva is evaluated on a number of different datasets such as WN18, NELL-995, and WikiMovies.\n\nThe paper proposes interesting ideas to attack a challenging problem, i.e., how to perform query answering on incomplete knowledge bases. While RL methods for KG completion have been proposed recently (e.g., DeepPath), Minerva improves over these approaches by not requiring the target entity. This property can be indeed be important to perform query answering efficiently. The proposed model seems technically reasonable and the paper is generally written well and good to understand. However, important parts of the paper seem currently unfinished and would benefit from a more detailed discussion and analysis.\n\nMost importantly, I'm currently missing a better motivation and especially a more thorough evaluation on how Minerva improves over non-RL methods. For instance, the authors mention multi-hop methods such as (Neelakantan, 2015; Guu, 2015) in the introduction. Since these methods are closely related, it would be important to compare to them experimentally (unfortunately, DeepPath doesn't do this comparison either). For instance, eliminating the need to pre-compute paths might be irrelevant when it doesn't improve actual performance. Similarly, the paper mentions improved inference time, which indeed is a nice feature. However, I'm wondering, what is the training time and how does it compare to standard methods like ComplEx. Also, how robust is training using REINFORCE?\n\nWith regard to the experimental results: The  improvements over DeepPath on NELL and on WikiMovies are indeed promising. I found the later results the most convincing, as the setting is closest to the actual task of query answering. However, what is worrying is that Minerva doesn't do well on WN18 and FB15k-237 (for which the results are, unfortunately, only reported in the appendix). On FB15k-237 (which is harder than WN18 and arguably more relevant for real-world scenarios since it is a subset of a real-world knowledge graph), it is actually outperformed by the relatively simple DistMult method. From these results, I find it hard to justify that \"MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods\", as stated in the abstract.\n\nFurther comments:\n- How are non-existing relations handled, i.e., queries (e,r,x) where there is no valid x? Does Minerva assume there is always a valid answer?\n- Comparison to DeepPath: Did you evaluate Minerva with fixed embeddings? Since the experiments in DeepPath used fixed embeddings, it would be important to know how much of the improvements can be attributed to this difference. \n- The experimental section covers quite a lot of different tasks and datasets (Countries, UMLS, Nations, NELL, WN18RR, Gridworld, WikiMovies) all with different combinations of methods. For instance, countries is evaluated against ComplEx,NeuralLP and NTP; NELL against DeepPath; WN18RR against ConvE, ComplEx, and DistMult; WikiMovies against MemoryNetworks, QA and NeuralLP. A more focused evaluation with a consistent set of methods could make the experiments more insightful.","sentences":[{"sentence_type":"2","sentence":"However, important parts of the paper seem currently unfinished and would benefit from a more detailed discussion and analysis.","rephrased":"However, there are sections of the paper that could be further developed, and I would recommend a more detailed discussion and analysis in these areas."},{"sentence_type":"2","sentence":"However, what is worrying is that Minerva doesn't do well on WN18 and FB15k-237 (for which the results are, unfortunately, only reported in the appendix).","rephrased":"However, I am concerned about Minerva's performance on WN18 and FB15k-237, and I suggest that the results for these datasets be discussed more prominently in the main text rather than only in the appendix."},{"sentence_type":"2","sentence":"From these results, I find it hard to justify that \"MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods\", as stated in the abstract.","rephrased":"Given these results, it would be helpful if the authors could provide further justification for the claim in the abstract that \"MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods\"."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[814,941,"Confirmed"],[1955,2109,"Confirmed"],[2327,2512,"Confirmed"]],"Comments":[]}
{"id":"BZ8ziSQ74Ya","text":"The paper proposes a new benchmark: Training models from scratch on ImageNet, using only a single GPU and less than 24 hours of \n\nThe paper proposes a new benchmark: The target is to reach the highest top-1 accuracy on ImageNet1k after training for at most 24 hours using a single GPU.\nThey then describe two variations to current Vision Transformer training procedures. The resulting approach results in an improved performance on this benchmark.\n\nThe first modification is aimed at including locality in the ViT architecture by modifying the feed-forward part of the transformer with an additional convolutional layer.  The second modification introduces training with images of reduced resolution during the beginning of training.\n\nThe paper introduces an interesting problem of speeding up the training of Vision Transformers. The introduced modification show potential in the presented experiments.\n\nFeedback:\n- I wonder if it could be more beneficial to first introduce the new benchmark properly, before describing the \"solution\" to it.\n- Do you have results on how well those speed advantages in the 24-hour regime translate to full training, e.g. whether there are also speed advantages when training to the accuracy of DeiT-S after 72 hours presented in Table 1?\n- The presented method of \"Image size-based curriculum learning\" seems quite similar to \"Progressive Image Resizing\" (e.g. described here: https:\/\/docs.mosaicml.com\/en\/v0.9.0\/method_cards\/progressive_resizing.html#attribution). Could add a statement in the paper about how your method differs?\n- In Figure 2 (right) you present image size-based curriculum learning with multiple hyperparameters. Which version was used for the results in Table 1?\n\nNits:\n- You could compress sequential citations, e.g. in Line 15: \"[2-12]\" instead of listing them all.\n- I am not sure that the statement in Line 95 that image size is a proxy for image difficulty is valid. Why should smaller images be easier? If anything, information is lost.\n- Line 104: \"except[s]\"\n- Line 110: \"which is [a] well-known\"\n- Line 115: \"there [are] no existing results\" ","sentences":[{"sentence_type":"2","sentence":"I am not sure that the statement in Line 95 that image size is a proxy for image difficulty is valid. Why should smaller images be easier? If anything, information is lost.","rephrased":"The statement in Line 95 that image size is a proxy for image difficulty could benefit from further clarification or evidence. It might be helpful to consider how the reduction in image size could impact the complexity of the task, as some information may be lost with smaller images."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1827,1999,"Confirmed"]],"Comments":[]}
{"id":"BExbq92fCW9","text":"This paper proposes a method to learn object representation and train the model in a self-supervised manner with a contrastive loss. Ablation studies involving different kinds of attention maps and object losses are conducted to prove the efficacy. However, why isn't there any baselines in the experiment section to compare with? It is necessary to show whether your method outperforms other state-of-the-art models, for example, the vanilla self-supervised learning methods of contrastive learning and simCLR.","sentences":[{"sentence_type":"1","sentence":"However, why isn't there any baselines in the experiment section to compare with?","rephrased":"However, it would be beneficial to include baseline comparisons in the experiment section to contextualize the performance of your method against existing models."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[249,330,"Not concerning"]],"Comments":[]}
{"id":"r1lf1kprY4","text":"This paper presents a method to train deep NN with noisy labels by adding a variance regularization term.  The authors show\/derive that such variance regularization term is an unbiased estimator of Jacobian norm of the neural network. As previous literature (Sokolic et al; Novak et al. 2018) show that this Jacobian norm is highly related to the generalization performance of NN, the authors conclude that minimizing their proposed variance regularization term can also help model generalization.  Finally, the authors conduct experiments on CIFAR-10 AND CIFAR-100 datasets and show their proposed learning objective can be used to train a NN robust to noise. The experimental results are strikingly good. \n\nOverall the paper is interesting, the major question is why EXACTLY minimizing the norm of Jacobian of NN can help improve the model robustness. I am not very familiar with the work (Sokolic et al; Novak et al. 2018) and thus I would appreciate a (high-level) description of those previous studies' major ideas. Furthermore, I am wondering why the authors treat good \"generalization\" of NN as the same as good \"robustness\" of NN. The authors describe label noise in Section 2.1 but I don't see how such label noise is modeled later in the regularization term design. Finally, I am a little bit confused about the derivation of the equation between equation (3) and (4), from lim_{\\tau -> 0} ... to \\frac{1}{N} \\sum_{i=1}^{N} Tr(...). More explanation on this part is appreciated. \n\nThe structure of the paper is good and writing is overall clear. There are still some places can be improved. First, at the begining of section 2, the authors write a K-class classifier f from ..., it's better to explicitly state the function f is from R^{d} to R^{K}, instead of being a scalar-valued function. This can make later discussion on Jacobian matrix more clear. Second, the connection of section 2.1 with later parts is not clear. Finally, there are some typos listed below:\n1. in the third line of section 2.1, there are two contiguous \",\"s .\n2. in the last line of page 2, there are two contiguous \",\"s .\n3. in the second line of page 3, there are two contiguous \",\"s .\n4. in the second line of section 4.1, what are the \"Sec. 5.5 and Sec. 5.6\"?\n\n\n","sentences":[{"sentence_type":"1","sentence":"The experimental results are strikingly good.","rephrased":"The experimental results are notably impressive."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[661,706,"Not concerning"]],"Comments":[]}
{"id":"ZxSp780WWy","text":"(+) the paper is nicely written and easy to follow\n(+) the idea of synthesizing data with blurring related to long spiral acquisition for subsequent training of a residual network for artifact reduction is reasonable\n(+) the graphical abstract in Figure 1 is neat. (Note that the . is missing in the caption)\n(+) evaluation is performed on both, synthetic and real test data\n\n(-) evaluation on the synthetic test data is limited to MFI and IR based on the reference field map, only.\nA comparison of your method to MFI and IR with estimated field maps would be interesting.\n(-) the runtime evaluation (12.3 ms per frame)  provided in the conclusion should be part of the experiments section.\nPlease note duration of the comparative methods as well.\n\nI recommend acceptance of this short paper.","sentences":[{"sentence_type":"1","sentence":"(-) evaluation on the synthetic test data is limited to MFI and IR based on the reference field map, only.","rephrased":"It would be beneficial to expand the evaluation on synthetic test data beyond MFI and IR by including comparisons with estimated field maps."},{"sentence_type":"1","sentence":"(-) the runtime evaluation (12.3 ms per frame)  provided in the conclusion should be part of the experiments section.","rephrased":"Including the runtime evaluation (12.3 ms per frame) in the experiments section would enhance the paper's clarity and allow for direct comparison with other methods."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[376,482,"Maybe"],[573,690,"Not concerning"]],"Comments":[]}
{"id":"BJgv7YQcYS","text":"This paper aims at solving geometric bin packing (2D or 3D) problems using a deep reinforcement learning framework. Namely, the framework is based on the actor-critic paradigm, and uses a conditional query learning model for performing composite actions (selections, rotations) in geometric bin packing. Experiments are performed on several instances of 2D-BPP and 3D-BPP,\n\nOverall, bin packing problems are challenging tasks for DRL, and I would encourage the authors to pursue this research topic. Unfortunately, I believe that the current manuscript is at a too early stage for being accepted at ICLR, due to the following reasons:\n\n(a) The paper is littered with spelling\/grammar mistakes (just take the second sentence: “With the developing” -> “development”). For the next versions of the manuscript, I would recommend using a spell\/grammar checker.\n\n(b) In the related work section, very little is said about Bin Packing Problems. There are various classes of BPPs, and it would be relevant to briefly present them. Moreover, BPPs have been extensively studied in theoretical computer science, with various approximation results. Again, a brief discussion about those results would be relevant. Notably, several classes of geometric bin packing problems admit polynomial-time approximation algorithms (for extended surveys about this topic, see e.g.  Arindam Khan’s Ph.D. thesis 2015; Christensen et. al. Computer Science Review 2017).  \n\n(c) According to the problem formulation and the experiments, it seems that the authors are studying a restricted subclass of 2D\/3D bin packing problems: there is only “one” bin, so (it seems that) the authors are dealing with geometric knapsack problems (with rotations). Note that the 2D Knapsack problem with rotations admits a 3\/2 + \\epsilon - approximation algorithm (Galvez et. al., FOCS 2017). A. Khan has also found approximation algorithms for the 3D Knapsack problem with rotations. So, even if those results do not preclude the use of sophisticated DRL techniques for solving geometric knapsack problems, it would be legitimate to empirically compare these techniques with the polytime asymptotic approximation algorithms already found in the literature.\n\n(d) The problem formulation is very unclear. Namely, the state representation is ambiguous: $s_p$ is obviously not a boolean variable, but a boolean vector (where each component is associated with an item). Nothing is said about actions and transitions and rewards (we have to read the AC framework in order to get a clue of these components). We don’t know if it is an episodic MDP (which is usually the case in DRL approaches to combinatorial optimization tasks). Also, it seems that the MDP is specified for a single instance of 3D-BPP. But this looks wrong since it should include the distribution of all instances of 3D-BPP.   \n\n(e) The Actor-Critic framework, coupled with a conditional query learning algorithm, is unfortunately unintelligible due to the fact that many notations are left unspecified. For example, in Eq (1) what are the dimensions K and V? In Eq (2) what is d_i? In the algorithm what is n_{gae}? Also in the algorithm, what are l’_i, w’_i and h’_i? Etc. \n\n(f) Even if the aforementioned issues are fixed, it seems that the framework is using many hyper-parameters (\\gamma, \\beta, \\alpha_t, etc.) which are left unspecified. Under such circumstances, it is quite impossible to reproduce experiments. \n","sentences":[{"sentence_type":"2","sentence":"Unfortunately, I believe that the current manuscript is at a too early stage for being accepted at ICLR,","rephrased":"While the manuscript presents promising ideas, it may benefit from further development to meet the acceptance criteria of ICLR."},{"sentence_type":"2","sentence":"The paper is littered with spelling\/grammar mistakes","rephrased":"The paper contains several spelling and grammar mistakes that could be addressed with careful proofreading or the use of a spell\/grammar checker."},{"sentence_type":"2","sentence":"The Actor-Critic framework, coupled with a conditional query learning algorithm, is unfortunately unintelligible","rephrased":"The explanation of the Actor-Critic framework, in conjunction with the conditional query learning algorithm, could be clarified to enhance the reader's understanding."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[500,604,"Confirmed"],[640,692,"Confirmed"],[2851,2963,"Confirmed"]],"Comments":[]}
{"id":"Qj-L5s0CTJo","text":"This paper reviews an existing Python feature engineering library, Automunge. It describes Automunge's functions operating on numeric (as opposed to categorical) input data. It describes notions of transformations, operations available to bin, inject noise, process sequential data and integer sets. \n\nThe Automunge library implements what the data scientist might expect from a library of feature transforms for numerical data. It is not particularly rich or original. The library structure is not made clear in the paper. It is a pity that the paper does not compare to any other feature engineering library, although there are very many available. \n\nThe experiments section reports two experiments on one dataset; it reports AUC and accuracy metrics under different feature pre-processing: this reporting is hardly relevant and does not demonstrate any interesting property of Automunge. For instance, it would be interesting to see whether Automunge is particularly flexible, clear, or convenient when one wants to implement chains of transformations. It is not clear why, table 8, it is interesting to observe 100%, 5% and 0.25% of data regimes, nor why we should average over these three.\n\nTables 3 and 5, and none of the figures are mentioned in the text, let alone commented upon. The figures are left unexplained and contain undefined abreviations (NArw, DPo3, DPo6). I could not make sense of them. The family tree structure which seems to be the object of Table 3 is not explained, and I could not make sense of it, though it seems to be important. \n\nIn table 4, I could not understand what the columns refer to; equally, the transformations mentioned there are left undefined: for instance, in case, as I assume, \"Number of standard deviations from the mean\" is $x \\mapsto round(|(x_i - µ) \/ \\sigma) |)$ (or maybe the absolute value needs to be replaced by round brackets? this is left ambiguous), it should be properly defined. Similarly, what is \"Powers of ten\"? Does it mean $x \\mapsto round(\\log_{10} x) $ ? The id strings are cryptic. It is not clear why identifiers seem to be all limited to four characters; this makes the entire naming scheme very difficult to follow, as abreviations seem arbitrary; in addition, this is contrary to Python variable naming conventions, particularly naming conventions in popular and successful ML libraries, which prefer explicit and long-form function and argument naming over abreviated and cryptic ones.\nTable 6 refers to categoric noise injections, but the paper was meant to be about numeric input variables, so I'm not clear what it is doing here.\n\nThe text is hard to understand. This is in part, but not only, due to long-winded, unclear sentences: for instance the very first sentence is obscure and ill-structured, with several syntax errors, for instance the repeated and often incorrect usage of \"such as\". Throughout the text, syntax issues make the text hard to understand. Examples of this:\n- \"data transformations ... are to be directed for application to a distinct feature set as input\"\n- such as multiplicative properties at, above, or below.\n- potentially including custom defined transformation functions with minimal requirements of simple data structures\n- the last sentence of sec3\n- the first sentence of sec4 is needlessly intricate and seems to say nothing more than \"Automunge transformations are invertible\".\n- the paragraph below figure 2\n- a given ratio of input entries are flipped to one of the other encodings between which have a uniform probability\n\nThe very last conclusion paragraph is surprising and seems irrelevant. Similarly, the paper mentions quantum computation for reasons that escape my comprehension, section 2.\n\nThe paper is so hard to understand that it does not allow one to evaluate possible upsides of Automunge on its own merit. After quite some hesitation, I have to assign this paper a severe rating due to the conjunction of several severe shortcomings.","sentences":[{"sentence_type":"2","sentence":"It is not particularly rich or original.","rephrased":"The library could benefit from more distinctive features that set it apart from existing solutions."},{"sentence_type":"2","sentence":"this reporting is hardly relevant and does not demonstrate any interesting property of Automunge.","rephrased":"The relevance of this reporting could be enhanced by demonstrating more of Automunge's unique properties."},{"sentence_type":"1","sentence":"I could not make sense of them.","rephrased":"It would be helpful if the figures were explained more clearly, as their current presentation is challenging to interpret."},{"sentence_type":"1","sentence":"The text is hard to understand.","rephrased":"The clarity of the text could be improved for better comprehension."},{"sentence_type":"3","sentence":"After quite some hesitation, I have to assign this paper a severe rating due to the conjunction of several severe shortcomings.","rephrased":"Due to the issues identified, I find it necessary to recommend a thorough revision before considering this paper for publication."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[429,469,"Confirmed"],[793,890,"Confirmed"],[1377,1408,"Confirmed"],[2609,2640,"Confirmed"],[3837,3964,"Confirmed"]],"Comments":[]}
{"id":"H1l0JeopFB","text":"The contribution of the paper is the following two findings: 1. Despite the fact that local minima are connected in the loss landscape the functions corresponding to the points on the curve are significantly distinct. 2. The points along the training trajectory correspond to similar functions. \n\nOriginality and novelty. Both findings do not seem quite new. The first conclusion can be mostly derived from Figure 2 right [1]. Moreover, the difference between functions on the curve in terms of predictions is the main motivation of Fast Geometric Ensembling. The second conclusion is also not quite new and there were several approaches to overcome it e.g. SWA [2]. I appreciate that the authors did a much broader investigation of this phenomena than it was done in previous works. Another drawback is lack of practical implications. It is known that ensembling based on dropout is worse than independent networks, but the main advantage of this and similar approaches is memory efficiency. \n\nThe clarity. The paper is well written, contains all necessary references and is easy to follow. The provided experimental results and supporting plots are also clear and contain the necessary description. The only part that I found a bit confusing is radial plots. I would recommend the authors to add more rigorous description of how they constructed these plots to increase clarity of the paper. Can the authors please also clarify how they derived formulas for the expected fractional difference for f^* and f functions in the section 3.2? \n\nOverall, it is an interesting paper, but the findings are not quite new.\n[1]  Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin, Dmitry P Vetrov, and Andrew G Wilson. Loss surfaces, mode connectivity, and fast ensembling of DNNs. InNeurIPS, 2018\n[2] Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, and Andrew Gordon Wilson. Av-eraging weights leads to wider optima and better generalization.arXiv preprint arXiv:1803.05407,2018\n","sentences":[{"sentence_type":"2","sentence":"Both findings do not seem quite new.","rephrased":"While the findings build upon existing knowledge, it would be beneficial to highlight more clearly the novel aspects of this research."},{"sentence_type":"2","sentence":"Another drawback is lack of practical implications.","rephrased":"It would be advantageous for the paper to discuss potential practical implications to enhance its impact."},{"sentence_type":"1","sentence":"It is known that ensembling based on dropout is worse than independent networks, but the main advantage of this and similar approaches is memory efficiency.","rephrased":"While ensembling based on dropout may not always perform as well as independent networks, it's worth noting the memory efficiency benefits of this approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[322,358,"Confirmed"],[784,835,"Confirmed"],[836,992,"Maybe"]],"Comments":[]}
{"id":"ssW9JQNeeNw","text":"I appreciate the detailed study performed by the authors, however I do not think this paper is suitable for publication at NeurIPS as it focuses on a particular application without introducing any technical novelty, and the task is somewhat contrived for the application domain. \n\nThe task of ab initio reconstruction for homogeneous proteins is well-studied\/solved. The authors should benchmark against a state of the art algorithm. \n\nFundamentally, the method relies on a training set of previously posed images, so the task they are addressing is not a realistic setting. As the authors discuss, if this approach were extended to be trained across multiple datasets and could predict orientations for a new (real) dataset zero-shot, it would be very high impact; however I am not convinced from the current results that extending this approach is promising. The paper lacks theoretical grounding, which the authors admit, and I am not convinced that there are any generalization properties for functions on distances between projection images (to unseen proteins).\n\n\n","sentences":[{"sentence_type":"2","sentence":"I do not think this paper is suitable for publication at NeurIPS as it focuses on a particular application without introducing any technical novelty, and the task is somewhat contrived for the application domain.","rephrased":"While the paper presents a detailed study, it may benefit from demonstrating more technical novelty or broader applicability to be a strong fit for publication at NeurIPS."},{"sentence_type":"2","sentence":"The task they are addressing is not a realistic setting.","rephrased":"The task addressed in the paper could be made more relevant by considering a wider range of realistic settings."},{"sentence_type":"2","sentence":"I am not convinced from the current results that extending this approach is promising.","rephrased":"The current results could be strengthened with additional evidence to support the potential of extending this approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[66,278,"Confirmed"],[519,573,"Maybe"],[774,860,"Confirmed"]],"Comments":[]}
{"id":"vQ5wnWF6YmR","text":"The paper is well-structured and the algorithm is well supported by the theorems. The paper compared the complexity thoroughly, though there is no improvement. The numerical results verified that the proposed algorithm is more accurate than the baselines. \n\nThe paper has the following issues.\n\n1. In Table 2, the sketch size in ALS+TensorSketch [37] could be much smaller than proposed ALS+TensorSketch if $\\epsilon$ is very small (very accurate fitting). When $\\epsilon$ is small enough,  the  sketch size in ALS+TensorSketch [37]  is also much smaller than that of the proposed one.\n\n2. Observed from Table 2, the LS subproblem cost of ALS+TensorSketch [37] is less than proposed two methods,  especially when the rank of ground-truth tensor is high.\n\n3. The abbreviations of the proposed algorithms and the baselines are very confusing. What does TS-ref stand for?\n\n4. In the experiments, where are the results of the two algorithms (ALS+TensorSketch and ALS+TTM) proposed in [37]?\n\n5. The paper did not report the per-sweep cost numerically in the experiment.\n\n6. In Figure (a), the fitness of Lev Tucker+CP dropped significantly at sweep 4. Is the algorithm unstable?\n\n7. It is not clear why the fitness on the synthetic data are always very low, e.g. <0.4 in Figure 1(a).","sentences":[{"sentence_type":"2","sentence":"The paper compared the complexity thoroughly, though there is no improvement.","rephrased":"While the paper provides a thorough complexity comparison, it would be beneficial to see how this translates into improvements over existing methods."},{"sentence_type":"1","sentence":"The abbreviations of the proposed algorithms and the baselines are very confusing. What does TS-ref stand for?","rephrased":"The abbreviations used for the proposed algorithms and the baselines could be clarified for better understanding. Could you please explain what TS-ref stands for?"},{"sentence_type":"1","sentence":"It is not clear why the fitness on the synthetic data are always very low, e.g. <0.4 in Figure 1(a).","rephrased":"Could you provide some insight into the consistently low fitness scores on the synthetic data, as observed in Figure 1(a)?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[82,159,"Maybe"],[758,868,"Confirmed"],[1178,1278,"Maybe"]],"Comments":[]}
{"id":"GS9QqvJjJa","text":"The paper studies the interplay of SAM with batchnorm, finding that in many situations, the SAM perturbation applied to just the batch norm learnable parameters has increased performance.  This has potential value as a training trick and also is an interesting observation worth investigating more deeply.","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"fxQcljG59Uo","text":"This is a generally solid paper using the dual formation to provide some unified view of RL and IL algorithms. The paper provides some theoretical theorems, but lacks a good story that strings these theorems together. Experiments are descent in demonstrating the efficacy of their new algorithm. However, there is only one set of experiments provided. The contributions from this paper have good intentions, but it likely to only be of significance to a small portion of the community. ","sentences":[{"sentence_type":"2","sentence":"The contributions from this paper have good intentions, but it likely to only be of significance to a small portion of the community.","rephrased":"The contributions from this paper are promising and could be particularly impactful within its specialized niche in the community."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[352,485,"Confirmed"]],"Comments":[]}
{"id":"Bkg3hb3-9E","text":"This paper presents new datasets for give languages and proposes a new framework (SAT) for font image datasets generation. I think this paper makes reasonable contribution to the literature.","sentences":[{"sentence_type":"1","sentence":"I think this paper makes reasonable contribution to the literature.","rephrased":"The paper contributes positively to the literature with its new datasets and SAT framework."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[123,190,"Not concerning"]],"Comments":[]}
{"id":"rkg9el6B9V","text":"The paper proposes AlignFlow, an efficient way of implementing cycle consistency principle using invertible flows. The paper is clearly written and I really enjoyed reading it!\nPros:\n- Clever combination of existing ideas (use invertible mappings rather than encoder-decoder pairs in cycleGAN)\n- simple to implement \n- works well in practice\n\nThis paper proposes a related idea and might be worth discussing:\nInvertible Autoencoder for domain adaptation https:\/\/arxiv.org\/pdf\/1802.06869.pdf\n","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"HyxTMY0aKS","text":"This paper studies the implicit regularization in deep learning under the over-parameterized setting. In specific, the authors study the neural network outputs and “pre-activation values” on line segments connecting two training data inputs and characterize an implicit regularization based on it. I have the following concerns:\n\nFirst of all, it is not clear to me why Theorem 2 is relevant to “implicit regularization”. To my knowledge, implicit regularization or implicit bias statements in prior works cited in this paper are all about the convergence to a specific solution for underdetermined problems. For example, “among all solutions that fits the data, gradient descent converges to minimum distance solution to initialization (linear model square loss), maximum margin solution (linear model exponential loss), minimum nuclear norm solution (matrix sensing with small initialization)”. In comparison, Theorem 2 just gives some bounds that holds for every sgd iteration. I cannot see any connection between Theorem 2 and implicit regularization.\n\nMoreover, the authors’ claim “the implicit regularization in over-parameterized DNNs has not been identified” is not correct. As the authors mentioned,  the neural network is close to its linear approximation model with respect to weight parameters at initialization. Therefore the implicit bias of (stochastic) gradient descent for DNNs in the over-parameterized regime is essentially implicit bias of (stochastic) gradient descent for linear models (for square loss). In Arora et al., 2019b it has been proved that infinitely wide neural networks trained with gradient flow converges to the NTK-based kernel regression solution.  So at least for gradient flow with square loss, the implicit bias of DNNs has been well-studied. In fact in a missed reference [2], essentially the implicit bias for both gradient descent and stochastic gradient descent has been studied. The remark “in most cases, the authors used GD to derive their results by the NTK analysis” is also not convincing. Allen-Zhu et al., 2018a,b, Allen-Zhu & Li, 2019 and missed references [1,2,3,4] all studied SGD of over-parameterized neural networks, and some are not exactly in the so-called NTK regime. The authors should also compare their generalization bounds with existing results for SGD (Allen-Zhu et al., 2018a, Allen-Zhu & Li, 2019) and [3].\n\nFinally, Theorem 4 only considers one-dimensional models, which is not a very interesting problem setting. Its proof might also be flawed. In fact, the setting in Section 4 is not consistent with Theorem 1, since Theorem 1 requires that all inputs have unit norm and their last coordinate should be a constant. For one dimensional case, this means all inputs must be the same scalar! Even if we ignore the last coordinate assumption in Theorem 1, for 1D case all inputs are still reduced to +1 or -1’s. \n\n\n[1] Difan Zou, Yuan Cao, Dongruo Zhou, Quanquan Gu, Stochastic Gradient Descent Optimizes Over-parameterized Deep ReLU Networks\n[2] Samet Oymak, Mahdi Soltanolkotabi, Overparameterized Nonlinear Learning: Gradient Descent Takes the Shortest Path?\n[3] Yuan Cao, Quanquan Gu, Generalization Bounds of Stochastic Gradient Descent for Wide and Deep Neural Networks\n[4] Difan Zou, Quanquan Gu, An Improved Analysis of Training Over-parameterized Deep Neural Networks\n\n\n\n\n","sentences":[{"sentence_type":"1","sentence":"First of all, it is not clear to me why Theorem 2 is relevant to \\","rephrased":"I would appreciate further clarification on how Theorem 2 relates to the concept of implicit regularization, as the connection is not immediately apparent to me."},{"sentence_type":"2","sentence":"Moreover, the authors' claim \\","rephrased":"It seems there might be a misunderstanding regarding the authors' statement that 'the implicit regularization in over-parameterized DNNs has not been identified.' Existing literature, such as Arora et al., 2019b, suggests that this area has been explored, particularly in the context of gradient flow with square loss in infinitely wide neural networks."},{"sentence_type":"2","sentence":"Finally, Theorem 4 only considers one-dimensional models, which is not a very interesting problem setting.","rephrased":"Theorem 4's focus on one-dimensional models may limit the broader applicability of the results. Expanding the scope to include higher-dimensional models could potentially make the findings more compelling."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[330,395,"Confirmed"],[1057,1086,"Not concerning"],[2380,2486,"Confirmed"]],"Comments":[]}
{"id":"ROU8iV22sb","text":"The problem statement of this paper is very vague. Apparently, authors have already published a greedy sphere packing and they try to make it rotation invariant or experiment its properties under an arbitrary 3D rotation. Reading the paper, I could not figure out what are the challenges of this problem. Why if we have a set of spheres, we cannot simply rotate all of them against a point or axis and preserve the desired properties such as distance between the sphere centers (apparently this was the key in defining the feature). Is it due to re-voxelization? Why sphere packing at the first place? Why not simply using voxels? ... The paper has not been motivated well.\n\nAside form the lack of clarity of the intention of the paper, it suffers from presentation issues. Teaser has no informative caption and it is confusing to see the first Figure with graphs that are not fully understandable and in the text there is no reference to this figure. The same for many other figures in the paper: no reference in the text, no informative caption (e.g., Figure 4, 5, 6, 8, etc).\n\nIntroduction is a mix of related work and motivation and the paper suffers from the lack of having an actual related work and also a good motivation. There are many papers related to shape descriptors and also sphere packing and they have not been cited in the paper. \n\nUnnecessary\/obvious information is given. Providing rotation along different axis is not necessary. These are common knowledge in the Graphics community and they are not needed to be repeated in the paper. Instead the algorithm (which does not have a number in the paper) needs more explanation and a better presentation. \n\nAside from many problems about presentation and also technical issues, the contribution of the paper is unknown and marginal and I do not believe that it advances Graphics state of the art. The paper is clearly below the GI acceptance bar.","sentences":[{"sentence_type":"3","sentence":"The paper is clearly below the GI acceptance bar.","rephrased":"The paper may need significant improvements to meet the GI acceptance criteria."},{"sentence_type":"3","sentence":"Aside from many problems about presentation and also technical issues, the contribution of the paper is unknown and marginal and I do not believe that it advances Graphics state of the art.","rephrased":"The paper could benefit from a clearer articulation of its contributions and how it advances the field of Graphics."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[1674,1863,"Confirmed"],[1864,1913,"Confirmed"]],"Comments":[]}
{"id":"ryxHNSeUtS","text":"Summary: \nThe authors propose quantize the weights of a neural network by enabling a fractional number of bits per weight. They use a network of differentiable XOR gates that maps encrypted weights to higher-dimensional decrypted weights to decode the parameters on-the-fly and learn both the encrypted weights and the scaling factors involved in the XOR networks by gradient descent.\n\nStrengths of the paper:\n- The method allows for a fractional number of bits per weights and relies of well-known differentiable approximations of the sign function. Indeed, virtually any number of bits\/weights can be attained by varying the ratio N_in\/N_out.\n- The papers displays good results on ImageNet for a ResNet-18.\n\nWeaknesses of the paper:\n- Some arguments that are presented could deserve a bit more precision. For instance, quantizing to a fractional number of bits per weights per layer is in itself interesting. However, if we were to quantize different layers of the same network with distinct integer  ratio of bits per weights (say 1 bit per weight for some particular layers and 2 bits per weight for the other layers), the average ratio would also be fractional (see for instance \"Hardware-aware Automated Quantization with Mixed Precision\", Wang et al., where the authors find the right (integer) number of bits\/weights per layer using RL). Similarly, using vector quantization does allow for on-chip low memory: we do not need to re-instantiate the compressed layer but we can compute the forward in the compressed domain (by splitting the activations into similar block sizes and computing dot products). \n- More extensive and thorough experiments could improve the impact of the paper. For instance, authors could compress the widely used (and more challenging) ResNet-50 architecture, or try other tasks such as image detection (Mask R-CNN). The table is missing results from: \"Hardware Automated Quantization\", Wang et al ; \"Trained Ternary Quantization\", Zhu et al ; \"Deep Compression\",  Han et al; \"Ternary weight networks\", Li et al (not an extensive list).\n- Similarly, providing some code and numbers for inference time would greatly strengthen the paper and the possible usage of this method by the community. Indeed, I wonder what the overhead of decrypting the weights on-the-fly is (although it only involves XOR operations and products)\n- Small typos: for instance, two points at the very end of section 5.\n\nJustification fo rating:\nThe proposed method is well presented and illustrated. However, I think the paper would need either (1) more thorough experimental results (see comments above, points 2 and 3 of weaknesses) or (2) more justifications for its existence (see comments above, point 1 of weaknesses).","sentences":[{"sentence_type":"2","sentence":"However, I think the paper would need either (1) more thorough experimental results (see comments above, points 2 and 3 of weaknesses) or (2) more justifications for its existence (see comments above, point 1 of weaknesses).","rephrased":"To enhance the paper's impact, I recommend expanding the experimental results as suggested in points 2 and 3 of the weaknesses, or providing additional justifications for the proposed method as discussed in point 1 of the weaknesses."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2508,2732,"Confirmed"]],"Comments":[]}
{"id":"B1ePMbbcnQ","text":"In this work the authors propose and analyse generative models as defences against adversarial examples. In addition, three detection methods are introduced and an extension to deep features is suggested.\n\nMy main concerns are as follows (details below):\n* Important prior work is not mentioned.\n* Evaluation with direct attacks is only based on (very few) gradient-based techniques, many results are not reliable.\n* There are signs of gradient masking (the common problem of robustness evaluation, in particular of only gradient-based techniques are used).\n* The way detection rates are taken into account in the perfect knowledge scenario is confusing.\n\n### Style\nI like the idea of testing many different factorisation structures. However, that comes with the drawback that one needs to constantly check back what the abbreviations mean. Together with the three detection methods, the manuscript is quite confusing at times and should definitely be streamlined. One suggestion: remove the detection methods: I did not find any real conclusion about them but they are definitely side-tracking users away from the main results.\n\n### Prior work\nThere is at least one closely related prior work not mentioned here: the analysis by synthesis model [1]. This model uses a variational auto encoder to learn class conditional distributions and shows high robustness on MNIST. Please make clear what your contribution is over this paper (other than testing several other factorisations).\n\n### Evaluation problems\nThe robustness of models should be evaluated on different direct attacks ranging from gradient-based to score-based (e.g. NES [2]) to decision-based attacks [3]. Please take a look at [1] to see how a very extensive evaluation might look like. The results can be astonishingly different for different attacks, and so basing conclusion on only one or two attacks is dangerous (in particular if you only use gradient-based ones). One can also see that in your results, just check the variations you get between MIM and PGD. Also, rather then discussing (and showing in detail) results for individual attacks, the minimum adversarial distance for a given sample that can be found by any attack is much more comparable between models (which can also streamline the manuscript).\n\nOne can see signs of gradient masking in your results. For example, in Figure 3 the MIM attacks levels out at 20% for the DBX model. That can happen for iterative attacks if the gradient is masked. Similarly, in Figure 5 DBX-ZK (zero knowledge) is better in both accuracy and detection rate than DBX-PKK (which takes the KL-detection method into account and should thus either be better in accuracy or detection rate).\n\nMore generally, the perfect knowledge case, in which the attacker knows about the detector, should only count samples as adversarials which evade the detector and change the model decision. Thus, the detection rate should be zero. Otherwise I have no idea what trade-off between accuracy and detection rate you are actually targeting and how to compare the results.\n\nAlso, some intermediate results are conflicting with each other. E.g. in 4.1 you state “the usage of bottleneck is beneficial for better robustness”, but for L2 this is not true.\n\nAlso, I am not sure how conclusive the grey-box and black-box scenarios really are: since the substitute is basically a DFX or DFZ, it’s unsurprising that adversarials transfer best to those two models.\n\n### Minor\n * In 4.1 you say “as they fail to find near manifold adversarials”, but I don’t see how there can be L-infty adversarials on MNIST that are on-manifold (remember, MNIST pixel values are basically binary). Plus, in the zero-knowledge scenario there is nothing that enforces staying on this manifold.\n * Result presentation (Figure 3\/5 & Table 1) is very different for different attack scenarios, which makes them hard to compare. Please unify.\n * Is the L2 distance you report in Table 1 the mean (or median) distance to adversarial examples. If so, GBZ (for which you state that C&W “failed on attacking” has actually a smaller mean adversarial distance than some other models (for which C&W is actually quite successful).\n * Grey-box scenario doesn’t make a lot of sense: since the substitute is basically a DFX or DFZ, it’s unsurprising that adversarials transfer best to those two models. A similar confounder makes the black-box results difficult to interpret.\n* Also, taking into account that the paper is two pages longer and thus calls for higher standards\n\nTaken together, I find the general direction of the paper very interesting and I’d definitely encourage the authors to go further. At the current stage, however, I feel that (1) contributions are not sufficiently delineated to prior work, (2) the evaluation is not convincingly supporting the claims and that  (3) the manuscript needs to be streamlined (both in terms of text and figures).\n\n[1] Schott et al. (2018) “Towards the first adversarially robust neural network model on MNIST” (https:\/\/arxiv.org\/abs\/1805.09190)\n[2] Ilyas et al. (2018) “Black-box Adversarial Attacks with Limited Queries and Information” ( [https:\/\/arxiv.org\/abs\/1804.08598)](https:\/\/arxiv.org\/abs\/1804.08598)) \n[3] Brendel et al. (2018) “Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models” (https:\/\/arxiv.org\/abs\/1712.04248)","sentences":[{"sentence_type":"2","sentence":"many results are not reliable.","rephrased":"The reliability of some results could be strengthened by considering a wider range of attack methods."},{"sentence_type":"2","sentence":"remove the detection methods: I did not find any real conclusion about them but they are definitely side-tracking users away from the main results.","rephrased":"It may be beneficial to focus more on the main results and clarify the conclusions drawn from the detection methods to avoid potential confusion."},{"sentence_type":"2","sentence":"basing conclusion on only one or two attacks is dangerous","rephrased":"Drawing conclusions from a limited set of attacks could be improved by including a more diverse array of attack methods to ensure robustness."},{"sentence_type":"1","sentence":"Also, taking into account that the paper is two pages longer and thus calls for higher standards","rephrased":"Considering the additional length of the paper, it would be helpful to ensure that the content meets the expected high standards of clarity and depth."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[384,414,"Not concerning"],[981,1128,"Confirmed"],[1824,1881,"Not concerning"],[4431,4527,"Confirmed"]],"Comments":[]}
{"id":"rJRfJZKxf","text":"The paper introduces two alternatives to value iteration network (VIN) proposed by Tamar et al. VIN was proposed to tackle the task of learning to plan using as inputs a position and an image of the map of the environment. The authors propose two new updates value propagation (VProp) and max propagation (MVProp), which are roughly speaking additive and multiplicative versions of the update used in the Bellman-Ford algorithm for shortest path. The approaches are evaluated in grid worlds with and without other agents.\n\nI had some difficulty to understand the paper because of its presentation and writing (see below). \n\nIn Tamar's work, a mapping from observation to reward is learned. It seems this is not the case for VProp and MVProp, given the gradient updates provided in p.5. As a consequence, those two methods need to take as input a new reward function for every new map. Is that correct?\nI think this could explain the better experimental results\n\nIn the experimental part, the results for VIN are worse than those reported in Tamar et al.'s paper. Why did you use your own implementation of VIN and not Tamar et al.'s, which is publicly shared as far as I know?\n\nI think the writing needs to be improved on the following points:\n- The abstract doesn't fit well the content of the paper. For instance, \"its variants\" is confusing because there is only other variant to VProp. \"Adversarial agents\" is also misleading because those agents act like automata.\n\n- The authors should recall more thoroughly and precisely the work of Tamar et al., on which their work is based to make the paper more self-contained, e.g., (1) is hardly understandable.\n\n- The writing should be careful, e.g., \nvalue iteration is presented as a learning algorithm (which in my opinion is not) \n\\pi^* is defined as a distribution over state-action space and then \\pi is defined as a function; ...\n\n- The mathematical writing should be more rigorous, e.g., \np.2:\nT: s \\to a \\to s', \\pi : s \\to a\nA denotes a set and its cardinal\nIn (1), shouldn't it be \\Phi(o)? all the new terms should be explained\np. 3:\ndefinition of T and R \nshouldn't V_{ij}^k depend on Q_{aij}^k?\nT_{::aij} should be defined\nIn the definition of h_{aij}, should \\Phi and b be indexed by a?\n\n- The typos and other issues should be fixed:\np. 3:\nK iteration\nwith capable\np.4:\nclose 0\np.5:\nour our\ns^{t+1} should be defined like the other terms\n\"The state is represented by the coordinates of the agent and 2D environment observation\" should appear much earlier in the paper. \n\"\\pi_\\theta described in the previous sections\", notation \\pi_\\theta appears the first time here...\n3x3 -> 3 \\times 3\nofB\nV_{\\theta^t w^t}\np.6:\nthe the\nFig.2's caption:\nWhat does \"both cases\" refer to? They are three models.\nReferences:\net al.\nYI WU\n","sentences":[{"sentence_type":"1","sentence":"I had some difficulty to understand the paper because of its presentation and writing (see below).","rephrased":"The paper's presentation and writing could be clearer to facilitate understanding (see suggestions below)."},{"sentence_type":"1","sentence":"I think the writing needs to be improved on the following points:","rephrased":"The writing could be enhanced in the following areas:"},{"sentence_type":"2","sentence":"The abstract doesn't fit well the content of the paper.","rephrased":"The abstract could more accurately reflect the content of the paper."},{"sentence_type":"2","sentence":"value iteration is presented as a learning algorithm (which in my opinion is not)","rephrased":"It may be beneficial to reconsider the presentation of value iteration, as it is typically not characterized as a learning algorithm."},{"sentence_type":"1","sentence":"The typos and other issues should be fixed:","rephrased":"Addressing the typos and other issues would improve the paper's clarity:"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[523,621,"Maybe"],[1178,1243,"Maybe"],[1246,1301,"Confirmed"],[1700,1781,"Confirmed"],[2252,2295,"Maybe"]],"Comments":[]}
{"id":"iKhsMiVcUA","text":"This paper combines sharpness-aware minimization and self-distillation in one method called SADT. The presentation is reasonably clear. The experiments are impressive because SADT outperforms SAM, which is sota.  If the results are not cherry picked, this is a very important contribution -- which I would like to see as a follow up conference paper. Accept!\n\nPlease fix though: The legend in Figure 2 is much too small. ","sentences":[{"sentence_type":"2","sentence":"If the results are not cherry picked, this is a very important contribution -- which I would like to see as a follow up conference paper.","rephrased":"To ensure the robustness of the results, it would be beneficial to see a follow-up study that confirms these findings. This could make for a significant contribution and I would be eager to see it presented at a conference."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[213,350,"Maybe"]],"Comments":[]}
{"id":"SelEHbD6xq","text":"**1. Summary and Contributions**\n\nThe paper first considers identifiability from data theoretically, then actual identification in practice. The authors refer to identifiability as their interest in recovering the structural causal model alongside a decoding model (which maps latent factors to the original data space) when being given mixed (meaning both observational and interventional) data from the original data space. The paper proves said identifiability under strict assumptions. The paper further provides an empirical investigation in support of the identifiability theorem using toy and semi-realistic data sets to corroborate the identifiability result.\n\n**2. Strengths**\n\nThe paper has several noteworthy strengths, considered one-by-one in the following list (the list is ordered in correspondence to the paper presentation):\n\n* The proposed problem is of high interest, since progress in learning causal representations is an arguably crucial step for developing next generation learning systems.\n* The motivation is written clearly as the authors reference works that are relevant (even determining) for their proposed ideas.\n* The proposed identifiability result, which suggests that optimizing the given mixed data is sufficient for recovering the necessary causal quantities of interest, since it provides both certainty for settings in which any practitioner might satisfy the provided assumptions plus the techniques used for proving this key theorem might be used for future relaxations of the theorem.\n* Corroborating the identifiability result with practical empirics on synthetic data (sanity check) but also semi-realistic data which involves actual low-level pixel observations of images that are high-dimensional and carry aleatoric uncertainty.\n* The critical discussion of the key assumptions in the appendix, since assumptions like perfect, atomic interventions or observing all interventions are arguably very strict and an average practitioner should not be expecting these assumptions to hold for general problem settings of interest.\n\n**3. Weaknesses**\n\nThe paper suffers from several disadvantages (ranging in importance from minor to more fundamental) that however IMHO can be improved upon mostly quickly as they are mostly aspects of presentation. Thereby, the following list - again one-by-one - aims to provide specific pointers with improvement suggestions if applicable (please note, the list is unordered):\n\n* The official OSC workshop submission guideline suggested an unlimited appendix officially but asked for the authors to only include minor details. This setting does not apply here since the authors provide the proof of the theorem in its entirety within the appendix where said theorem is the first key and arguably main result of the paper. Furthermore, 12 pages of appendix over 5 pages of main paper seems disproportionate to what I would believe the workshop organizers intended with the original statement on limitations for the submissions. Nonetheless, I've considered the complete appendix for my review, but have noted for myself to be aware of potential biases or unfairness when reviewing other papers for OSC that do not violate the given limitations and recommendations. IMHO both the story line of this work and their presentation lend themselves better to an extended treatise that might go beyond the format of common conference papers and rather into that of common journals.\n* The authors might consider saving presentation space for this OSC workshop by avoiding a definition like the SCM in its entirety as done in Def.1 on p.2 or overview-\/introductory-type of paragraphs to their subsections when they are identifiable from the given context (e.g. first paragraph in Sec.2). The extra space can then be rescheduled for e.g. including key elements of the actual proof which otherwise had to be resorted to the appendix.\n* The authors might consider aligning their notation with common notation used in causality literature like Pearl 2009, Peters et al. 2017 or Bareinboim et al. 2020 to foster consistency within the community, since there does not seem to be a particular advantageous reason for choosing otherwise.\n* The mostly informally stated definition of the LCM isomorphism, which would benefit from either more rigor or aided schematic visualization.\n* The key assumptions are arguably very strict and therefore restrict the relevance of the certainty provided by the proven theorem.\n\n**3. Correctness, Clarity, and Literature**\n\nNo contradictions or any sort of relevant mistake have been detected in the paper. Existing bodies of work are being referenced accordingly.\n\n**4. Reproducibility, Code Release, and Assumptions**\n\nSufficient details for reproduction are being provided. Unfortunately, without actual code. All key assumptions for the method are being pointed out explicitly (in the appendix).","sentences":[{"sentence_type":"2","sentence":"The paper suffers from several disadvantages (ranging in importance from minor to more fundamental) that however IMHO can be improved upon mostly quickly as they are mostly aspects of presentation.","rephrased":"The paper has several areas for improvement, particularly in presentation, which I believe can be addressed effectively and swiftly."},{"sentence_type":"2","sentence":"Furthermore, 12 pages of appendix over 5 pages of main paper seems disproportionate to what I would believe the workshop organizers intended with the original statement on limitations for the submissions.","rephrased":"The balance between the 12-page appendix and the 5-page main paper may not align with the workshop organizers' expectations regarding submission limitations, which is something the authors may want to consider."},{"sentence_type":"2","sentence":"Nonetheless, I've considered the complete appendix for my review, but have noted for myself to be aware of potential biases or unfairness when reviewing other papers for OSC that do not violate the given limitations and recommendations.","rephrased":"I have taken the complete appendix into account for my review, while also being mindful to maintain fairness and avoid bias when reviewing other papers for OSC that adhere to the given limitations and recommendations."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2091,2288,"Confirmed"],[2798,3002,"Confirmed"],[3003,3239,"Confirmed"]],"Comments":[]}
{"id":"ySEkG5pcaB","text":"This paper concerns lobe segmentation from Thoracic CT images using deep learning. This is certainly not the first paper on this topic, but the novelty of this approach is the weighted Dice coefficient, which puts special emphasis on the regions near the lobe boundary. This is not completely novel, as something similar was done already in Gerard et al. Also this paper doesn't have a large amount of data. However, as preliminary work, it is a good idea and shows promise.","sentences":[{"sentence_type":"1","sentence":"This is certainly not the first paper on this topic, but the novelty of this approach is the weighted Dice coefficient, which puts special emphasis on the regions near the lobe boundary.","rephrased":"While this paper builds upon existing work in the field, it introduces a novel weighted Dice coefficient that emphasizes regions near the lobe boundary, which could be a valuable contribution."},{"sentence_type":"2","sentence":"This is not completely novel, as something similar was done already in Gerard et al.","rephrased":"The concept of emphasizing regions near the lobe boundary has been explored before, as seen in Gerard et al., but this paper's specific implementation of the weighted Dice coefficient may offer new insights."},{"sentence_type":"2","sentence":"Also this paper doesn't have a large amount of data.","rephrased":"The dataset used in this study is somewhat limited in size, which may affect the generalizability of the results, but the findings are nonetheless intriguing."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[83,269,"Confirmed"],[270,354,"Confirmed"],[355,407,"Maybe"]],"Comments":[]}
{"id":"SkldKJN1oN","text":"In this paper the authors provide an overview of challenges and opportunities of exploiting AI planning for supporting cloud migration. Cloud migration is the process of moving data, applications and services from an original IT platform to a cloud environment. The process usually involves 4 main steps, that are briefly described in the paper.\nThe authors suggest that AI Planning could be used in the (surprise surprise) planning step of the cloud migration process. They outline a basic framework that could be used for this purpose and highlight future challenges.\n\nThe area of application is particularly interesting, and I am not aware of previous planning use in the domain. While the short paper is (necessarily) at a very high level, I'm confident the paper could provide a valuable contribution to the workshop, and can foster some interesting discussions.","sentences":[{"sentence_type":"2","sentence":"The authors suggest that AI Planning could be used in the (surprise surprise) planning step of the cloud migration process.","rephrased":"The authors propose the innovative use of AI Planning in the planning step of the cloud migration process, which is an insightful addition."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[346,469,"Not concerning"]],"Comments":[]}
{"id":"HyggZ2a-5S","text":"The paper proposes an approach to find a map between two feature spaces to maximize correlation between them and to use the resulting map for inference. A theoretical exposition is given and some empirical results are provided showing that the approach speeds up convergence on supervised MNIST and can be used for image completion (again on MNIST).\n\nThe paper should be rejected for the following reasons. First, the approach looks very similar to deep CCA, but the connection is never mentioned. This connection needs to be clarified. The objective function needs to be clearly stated and related to the loss function in eq. (7). In particular, I would suggest to give a clear definition of the problem before delving into the theory in section 2. In its current version, it is difficult to assess how the parts of section 2 relate to the overall objective. The paper severely lacks in relation to relevant related work. Half(!) of the 14 referenced papers are by the author himself. This can be verified since the double blind review process is compromised as the paper links to code in the author’s public github account. Finally, the empirical results are quite incomplete. It is not clear how the results compare to generative methods like VAEs, which are referenced as a motivation for this work in this work.\n\nThe improvement in convergence from RFA for supervised learning is interesting and this aspect deserves more analysis. It would be useful to look at the total amount of computation required to reach a given loss. I also wonder how this differs from simply mapping the output of the first network to a low-rank space via PCA. Is the dual-view really necessary in this case since the information content in the label space must be very limited, beyond simple class balance statistics?\n","sentences":[{"sentence_type":"2","sentence":"The paper should be rejected for the following reasons.","rephrased":"The paper could be improved in several areas before consideration for acceptance."},{"sentence_type":"2","sentence":"The paper severely lacks in relation to relevant related work.","rephrased":"The paper could benefit from a more comprehensive review of relevant related work."},{"sentence_type":"2","sentence":"Half(!) of the 14 referenced papers are by the author himself.","rephrased":"The authors should ensure a more balanced citation of external work in addition to their own."},{"sentence_type":"3","sentence":"This can be verified since the double blind review process is compromised as the paper links to code in the author’s public github account.","rephrased":"The integrity of the double-blind review process should be maintained, and as such, any links to the authors' code repositories should be anonymized."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[351,406,"Confirmed"],[860,922,"Confirmed"],[923,985,"Confirmed"],[986,1125,"Confirmed"]],"Comments":[]}
{"id":"hF6gXS_asmk","text":"-It is known that Assumption 3 equation (10) (bounded variance) with Assumption 2 (strong convexity) leads to a contradiction. Thus having these two assumptions together is strong.\nThere are some recent works that overcome Assumption 3 by a different assumption known as the expected smoothness like in the following work: Gower,  R.  M.,  Richtarik,  P.,  and  Bach,  F.    Stochastic quasi-gradient methods: Variance reduction via Jacobian sketching.arxiv:1805.02632, 2018.\nThe authors may revise their strongly convex results part using this kind of assumption.\n\n-In proposition 1 equation (13), it is not clear what the authors mean by the probability of a random variable. I checked the proof but I did not understand it either. \n\n-Some reported results are already known in the literature and the paper gives the impression that these results are new, especially that the authors give the proofs.\nExamples of such results: the unbiasedness of the quantization, its bounded variance, and the first part of theorem 1...\n\n-Page 5, concerning the quadratic example: this is a trivial case and the only case where one can hope the lower bound to match the upper bound. In fact, alpha = beta iff L=mu and from Assumptions 1 & 2 we get that F is quadratic with mu=L which implies H = mu I.\n\n- Equation (20): for me this one of the main results of the paper. But I did not see its proof anywhere?","sentences":[{"sentence_type":"2","sentence":"Some reported results are already known in the literature and the paper gives the impression that these results are new, especially that the authors give the proofs.","rephrased":"The authors may want to clarify how their results build upon existing literature, as some results such as the unbiasedness of the quantization and its bounded variance appear to be well-established. Providing context on how these results are integrated into the new contributions could enhance the paper's originality."},{"sentence_type":"2","sentence":"Page 5, concerning the quadratic example: this is a trivial case and the only case where one can hope the lower bound to match the upper bound.","rephrased":"On page 5, regarding the quadratic example, it would be beneficial to discuss its significance in greater detail, as it may seem straightforward to those familiar with the subject. Explaining its relevance to the broader context of the work could help underscore its importance."},{"sentence_type":"1","sentence":"Equation (20): for me this one of the main results of the paper. But I did not see its proof anywhere?","rephrased":"Equation (20) appears to be a significant result of the paper. It would be helpful if the authors could provide the proof or clarify where it can be found in the manuscript."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[737,902,"Confirmed"],[1026,1169,"Maybe"],[1292,1394,"Confirmed"]],"Comments":[]}
{"id":"BkgYfE5o3Q","text":"This paper proposes a justification to one observation on VAE: \"restricting the family of variational approximations can, in fact, have a positive regularizing effect, leading to better generalization\". The explanation given in this work is based on Gaussian mean-field approximation.\n\nI had trouble to understand some parts of this paper, since some of the sentences do not make sense to me. For example\n\n- the sentence under eq. (2)\n- the sentence \"Bacause the identity of the datapoint can never be learned by ...\" What is the identity of a dat point?\n\nIt looks like section 2.1 wants to show the connections between eq. (2) and other popularly used inference methods. Somehow, those connections are not clear to me.\n\nBesides some issues in the technical details, the major problem of this paper is that it uses the data processing inequality (DPI) in a **wrong** way.\n\nAs in (Cover and Thomas, 2012), which is also cited in this paper, DPI is defined on a Markov chain X -> Y -> Z and we have I(X,Y) >= I(X,Z). \n\nHowever, based on the definition of \\theta and \\tilde{\\theta} given in the first sentence of section 2.3, the relation between \\theta, \\tilde{\\theta} and D should be: D <- \\theta -> \\tilde{\\theta} (if it is a generative model) or D -> \\theta -> \\tilde{\\theta} (if a discriminative model). Either case, I don't think we can have the inequality in eq. (5).  ","sentences":[{"sentence_type":"2","sentence":"I had trouble to understand some parts of this paper, since some of the sentences do not make sense to me.","rephrased":"I found some parts of the paper challenging to understand, and I believe certain sentences could be clarified."},{"sentence_type":"3","sentence":"the major problem of this paper is that it uses the data processing inequality (DPI) in a **wrong** way.","rephrased":"A significant concern I have is with the application of the data processing inequality (DPI); it appears to be inconsistent with standard definitions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[286,392,"Confirmed"],[767,871,"Maybe"]],"Comments":[]}
{"id":"lF-NjoDyDrY","text":"**Paper summary**\n\nThe main goal of this paper is to show that LSTM units in a network trained to solve a T-maze task, show similar activity patterns as neurons in rats solving a similar task. Specifically, the authors make the following claims: (1) an RNN learning the task by  a combination of reinforcement and predictive learning produces internal representations with consistent extrafield firing associated with consequential decision points, (2) the network’s representation, once trained, follows a forward sweeping pattern similar to those found in rats and (3) a higher proportion of units in the trained network show strong selectivity for the choice phase of the task than for spatial topology, as seen in rats.\n\n**Pros**\n1. The submission is clear, well-written and the execution is competent. \n2. I find the approach well motivated and the problem interesting for the current state of the field.\n3. The authors provide a sufficient amount of details so that reproducibility should be possible.\n\n**Cons**\n\nI have concerns about key points of the paper and the interpretation of the results:\n\n1. One of the main results of the paper is the observation that the network produces a forward-moving representation similar to the one observed in rats at the decision point. However, the way the authors simulate this is by freezing the agent at such point and keeping the LSTM running, repeating the same constant observation. The LSTM was trained on trajectories on the maze, so in this trajectory (which was never used during training), the network is completely out of distribution. The activity of any network in this situation is difficult to interpret. Because the network was trained with a predictive loss on two very specific sequences of observations, it seems plausible that it is robust to the change of input statistics and follows the same sequence, maybe with some instabilities. Note that the cue was present, which explains why the correct sequence is followed. \nIn the network trained also by RL in particular, the authors interpret this as “The agent appears to be sampling the trajectory concerning the alternate return arm of the maze before ultimately settling on the rewarding return arm”. But this is, in my opinion, an over-interpretation, as the agent has no sampling capability in the first place (there is no generative model of observations), nor any particular planning mechanism. Alternatively, the authors may be claiming that this jumping behavior happens only after the RL training and not before, in which case they should emphasize this difference and quantify it explicitly. Although in this case, a simple explanation for this could be that due to the epsilon-greedy, only during the RL training the network is exposed to the wrong cue-arm combination. Therefore, the LSTM would be less able to rely on the cue, which could explain the jump between attractors in the out-of-distribution case. In the discussion section, the authors claim “We demonstrate that extrafield firing activity [..] emerges when a simulated agent [...] pauses at decision points - suggesting intrinsic dynamics are encoding the future planned trajectory of the agent.”. I find this to be an over-claim, as the agent doesn’t pause (it can’t) and doesn’t plan (for any common definition of planning). I would be more convinced if the agent was able to pause (as an additional action) and this behavior was observed in the LSTM activity in this situation, which is closer to the biological case.\n\n2. The pre-train stage is done on trajectories that correspond to the solved task. This means that the LSTM trained by the predictive loss is not exposed to the general structure of the environment but to the specific solution of the task, including the cue-choice association and the exact sequence of observations in each of the two correct trajectories. The authors draw a parallel with the pre-training phase in behavioral experiments (Johnson & Redish, 2007) in which rats usually run each trajectory separately (by having the other one blocked). However, in my opinion, this is problematic for their analysis. First it’s unclear to what extent the network is learning by RL as during the pre-training it has already learnt to predict the observation corresponding to the correct turn (wich corresponds to one of the two actions). Second, the LSTM is exposed only to the correct cue-arm trajectories, which I think is the reason why the forward-looking sweeps only follow these trajectories (see previous point). This is more similar to a demonstration than to pre-training. A more conventional pre-training would leave the agent to explore freely to implicitly learn the structure of the environment (a la Tollman). On the other hand, the argument of following the protocol of the behavioral experiments also doesn’t fully work as the rats are still producing motor outputs and even being rewarded during the pre-training phase (Johnson & Redish, 2007).\n\n3. Finally, a more general concern is the main point of the paper. If I understand correctly, the main claim is the similarity of the observations between the RNN agent and the experimental findings in rats. However, given that there are plenty of arbitrary choices when training an RNN, I believe the results are not particularly explanatory.  I would encourage the authors to formulate better alternative hypothesis and controlled experiments. For example, I would find it interesting to show that the forward-sweeping observations done in rats, which is often interpreted as a signature of planning or prediction of the consequences of future actions, arises simply from a next-step prediction loss in an overtrained rat.\n\nMinor concerns: \n\n- “As such, a network of Gated Recurrent Units [...] or vanilla RNN units was unable to perform well in either the pre-training or joint RL task due to these prevalent long term dependencies.”  How many steps are there between cue and choice, and between choice and reward? \n\n- Related to the previous point: “We attempted to run the reinforcement learning task alone in a maze with no wall colours or environment statistics except the cue. In this scenario the network is not able to learn the task due to a lack of self-localisation.” If I understand correctly, there is a constant number of steps between the cue and the moment where the choice has to be made. I would tend to believe that an LSTM can learn to make a prediction only based on the number of timesteps, regardless of the lack of wall observations (e.g. 2 sequence problem in Hochreiter and Schmidhuber, 1997).\n\nDetails: \n\n- It would be good to clarify what exactly is the action set of the agent. \n- I would like to know how exactly are activity maps obtained. The authors mention “Place fields determined by contiguous locality with average activity exceeding 30% peak unit activity during a single left trajectory followed by a right trajectory” but I don’t find this particularly clear. I also found it difficult to understand the bottom row of Fig 3. \n- Fig 5 should be referred to in the paragraph starting with “In stark contrast to the dynamics of the LSTM network following predictive pre-training...”\n- Why is the return to start representation in Fig. 6 different for right and left trajectories?\n\n\n","sentences":[{"sentence_type":"2","sentence":"I find this to be an over-claim, as the agent doesn’t pause (it can’t) and doesn’t plan (for any common definition of planning).","rephrased":"The claim regarding the agent's pausing and planning might be ambitious given the current model's capabilities. It would be beneficial to clarify these aspects or provide additional evidence to support the claim."},{"sentence_type":"2","sentence":"However, given that there are plenty of arbitrary choices when training an RNN, I believe the results are not particularly explanatory.","rephrased":"The training of RNNs involves a number of choices that could influence the results. It would be helpful if the authors could discuss how these choices were made and how they might affect the conclusions drawn."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[3190,3318,"Confirmed"],[5183,5318,"Confirmed"]],"Comments":[]}
{"id":"BkgEMMW937","text":"This work is well-written, but the quality of some sections can be improved significantly as suggested in the comments. I have a few main concerns that I explain in detailed comments. Among those, the paper argues that the algorithms converge without discussing why. Also, the amount of overestimation of the Q-values are one of my big concerns and not intuitive for me in the game of Prisoner's Dilemma that needs to be justified. For these reasons, I am voting for a weak reject now and conditional on the authors' rebuttal, I might increase my score later.\n\n1) I have a series of questions about Prisoner's Dilemma example. I am curious to see what are the Q-values for t=100000 in PD. Is table 1h shows the converged values? What I am expecting to see is that the Q-values should converge to some values slightly larger than 3, but the values are  ~ 30. It is important to quantify how much bias you add to the optimal solution by reward shaping, and why this difference in the Q-values are observed.\n\n2) One thing that is totally missing is the discussion of convergence of the proposed method. In section 3.4, you say that the Q-values converge, but it is not discussed why we expect convergence. The only place in the paper which I can make a conjecture about the convergence is in figure 4c which implicitly implies the convergence of the Mission DQN, but for the other one, I don't see such an observation. Is it possible to formalize the proposed method in the tabular case and discuss whether the Q-values should converge or not? Also, I would like to see the comparison of the Q-values plots in the experiments for both networks.\n\n3) The intuition behind (2) should be better clarified. An example will be informative. I don't understand what |Z_a| is doing in this formula.\n\n4) One of the main contributions of the paper is proposing the reward shaping mechanism. When I read section 3.3, I was expecting to see some result for policy gradient algorithms as well, but this paper does not analyze these algorithms. That would be very nice to see its performance in PG algorithms though. In such case that you are not going to implement these algorithms, I would suggest moving this section to the end of the paper and add it to a section named discussion and conclusion.\n\n5) Is it possible to change the order of parts where you define $\\hat{r}$ with the next part where you define $z_a$? I think that the clarity of this section should be improved. This is just a suggestion to explore. I was confused at the first reading when I saw $z_a$, \"evaluation of transition\" and then (2) without knowing how you define evaluation and why.\n\n6) Is there any reason that ablation testing is only done for trio case? or you choose it randomly. Does the same behavior hold for other cases too?\n\n7) Why in figure 4a, random is always around zero?\n\n8) What will happen if you pass the location of the agent in addition to its observation? In this way, it is possible to have one  Dual-Q-network shared for all agents. This experiment might be added to the baselines in future revisions.\n\nMinor: \n* afore-mentioned -> aforementioned\nsection 4.2: I-DQN is used before definition\n* Is it R_a in (4)?\n* I assume that the table 1f-1h are not for the case of using independent Q-learning. Introducing these tables for the first time right after saying \"This is observed when we use independent Q-learning\" means that these values are coming from independent Q-learning, while they are not as far as I understand. Please make sure that this is correct.\nsection 4.1: * who's -> whose\n* This work is also trying to answer a similar question to yours and should be referenced: \"Learning Policy Representations in Multiagent Systems, by Grover et al. 2018\"\n* Visual illustrations of the game would be helpful in understanding the details of the experiment. Preparing a video of the learned policies also would informative.\n-----------------------------------------------\nAfter rebuttal: after reading the answers, I got answers to most of my questions. Some parts of the paper are vague that I see that other reviewers had the same questions. Given the amount of change required to address these modifications, I am not sure about the quality of the final work, so I keep my score the same.","sentences":[{"sentence_type":"2","sentence":"For these reasons, I am voting for a weak reject now and conditional on the authors' rebuttal, I might increase my score later.","rephrased":"Based on these concerns, my current recommendation is a weak reject. However, I am open to revisiting this decision after considering the authors' rebuttal and any subsequent revisions they may make."},{"sentence_type":"2","sentence":"Given the amount of change required to address these modifications, I am not sure about the quality of the final work, so I keep my score the same.","rephrased":"Considering the extent of the revisions needed, I remain uncertain about the potential quality of the final manuscript. Therefore, I am maintaining my initial score at this time."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[432,559,"Maybe"],[4131,4278,"Maybe"]],"Comments":[]}
{"id":"wKLcjK9rVJ","text":"A new hyperparameter optimization package is proposed, which can be easily integrated into the training pipeline and with comparable performance to existing packages, while running fast. The results look promising and the content is presented clearly.","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"B_WxplDBJfc","text":"Overall: Paper is fairly clear, unsure regarding novelty, related work and citations referencing key assumptions borrowed from previous work are notably missing, but willing to give the authors the benefit of the doubt. Overall, assumptions that both the generative model and the classifier behave when encountered by unseen inputs, as is required by the proposal, are somewhat \"swept under the rug\". While the experiments section is sufficient, would suggest the authors invest effort in a more convincing evaluation demonstrating that the generative model and classifier do behave, and the proposed method does work and is applicable, in a wide variety of practically relevant scenarios. \n\nSpecifics:\n- Why was terminology changed from $m_1$ and $m_2$ to $m_e$ and $m_c$?\n- It should be noted that practically, the pretrained generative model will be imperfect, and thus there may be a distribution shift between the collected dataset and the generations from the perspective of the classifier. \n- Furthermore, the do-intervention does not correspond to a sample from the latent prior, so the generation as well as the classifier in that case may perform less well than normal due to distribution shift. \n- While the authors do address these points, I do take some issue with the following statement \"modern deep generative models and classifiers can indeed satisfy the above requirements for many practical usecases (Denton et al., 2019; Brown et al., 2020).\" There is plenty of evidence that classifiers generically are not calibrated, especially w.r.t. distribution shift. Furthermore, there is a body of literature, pushed by Eric Nalisnick and colleagues, on how generic generative models can behave poorly when fed unseen inputs. Simply citing the two works above while omitting the body of literature which highlights the brittleness of both generative models and classifiers is a fairly drastic omission. \n- Citations and related work needs to be improved, i.e. statements like this \"In addition to standard assumptions from causality (unconfoundedness, positivity, SUTVA)\" are not very helpful at the very least without citations which readers can consult for the details.  \n- Grammatical checks, \"We subsequently the generative average treatment effect (GATE)\"","sentences":[{"sentence_type":"2","sentence":"Overall, assumptions that both the generative model and the classifier behave when encountered by unseen inputs, as is required by the proposal, are somewhat \"swept under the rug\".","rephrased":"It would be beneficial for the paper to more explicitly address how the generative model and the classifier are expected to perform with unseen inputs, as this is a critical aspect of the proposal."},{"sentence_type":"2","sentence":"While the authors do address these points, I do take some issue with the following statement \"modern deep generative models and classifiers can indeed satisfy the above requirements for many practical usecases (Denton et al., 2019; Brown et al., 2020).\" There is plenty of evidence that classifiers generically are not calibrated, especially w.r.t. distribution shift.","rephrased":"The authors might consider strengthening their argument by addressing the existing evidence that classifiers may not be well-calibrated with respect to distribution shifts, which could affect the applicability of the proposed method in practical scenarios."},{"sentence_type":"2","sentence":"Simply citing the two works above while omitting the body of literature which highlights the brittleness of both generative models and classifiers is a fairly drastic omission.","rephrased":"Including a broader range of literature, particularly studies that discuss the limitations of generative models and classifiers, would provide a more balanced view and potentially strengthen the paper's contributions."},{"sentence_type":"1","sentence":"Citations and related work needs to be improved, i.e. statements like this \"In addition to standard assumptions from causality (unconfoundedness, positivity, SUTVA)\" are not very helpful at the very least without citations which readers can consult for the details.","rephrased":"Enhancing the citations and related work, especially for standard assumptions from causality, would be helpful for readers and could provide additional context and support for the paper's framework."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[220,400,"Confirmed"],[1209,1577,"Not concerning"],[1738,1914,"Maybe"],[1918,2183,"Not concerning"]],"Comments":[]}
{"id":"tah6z7YJH_","text":"Summary:\nThe authors do CRL from interventional data. They assume that the true and learned decoders are given by expanding the latent to all polynomial terms up to some order, followed by an injective linear map. They show that if an encoder exists, which can reconstruct all supported data points, the learned and true latent must be affinely related. Subsequently, when there exist interventional datasets in which one true latent does not change, but all other true latents do, this intervened latent variable can be identified by finding the constant dimension. Doing so, the learned latents differ from the true latents by a diagonal affine transformation.\n\nStrengths:\n- Strong conclusions from an an interesting new set of assumptions.\n- In particular, the assumptions in theorem 2 seems quite applicable to real-world use-cases (once the latents have been affinely identified).\n- Quite readable given the space constraints.\n\nWeaknesses:\n- A solid discussion about the applicability of the assumptions is missing.\n- I'm not sure I agree with the fact that the full-rank properties are \"minimal assumptions\". Much work in causal representation learning is occupied in regimes in which the conclusion of theorem 1 is not satisfied.\n- Regarding the generalisation beyond polynomial decoders: there is still a limitation that a general decoder can be approximated by a full-rank polynomial decoder. This excludes any non-full-rank polynomial decoder. The statement of theorem 4 is not very clear on this.\n\nSuggestion for improvement\/clarification:\n- Say how one would actually learn the model. Currently, I only see a loss function in the caption of fig 1.\n- I don't understand fig 2c.\n- Clarify the definition of $\\tilde A$ in (10) as the rows mapping to $\\hat z$.\n- In (4), replace $z$ with $\\hat z$ to clarify that this concerns learned latents.\n- Clarify: In Assumption 5, what is $\\tilde G$ in the context of a non-linear g?","sentences":[{"sentence_type":"2","sentence":"I'm not sure I agree with the fact that the full-rank properties are \"minimal assumptions\".","rephrased":"The characterization of the full-rank properties as \"minimal assumptions\" may warrant further justification, as much work in causal representation learning operates under different conditions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1023,1114,"Not concerning"]],"Comments":[]}
{"id":"SJek4zZ45V","text":"This work describes a simple method to visualize and understanding GANS. The method starts with identifying semantic object classes in an image (with a supervised semantic segmentation network) and then manipulates the network units to study the impact. It shows cool applications of object-level control of images.\n\nMy main concern of this approach is I'm not sure if the method is image-specific or not. If it is, that means for the same object occurring in different images, there will be different network units responsible. If this is the case there wouldn't be much conclusion which can be drawn from the results.","sentences":[{"sentence_type":"1","sentence":"My main concern of this approach is I'm not sure if the method is image-specific or not.","rephrased":"I would like to understand whether the method is image-specific or generalizable across different images."},{"sentence_type":"2","sentence":"If this is the case there wouldn't be much conclusion which can be drawn from the results.","rephrased":"If the method is image-specific, it would be helpful to discuss how this might limit the generalizability of the conclusions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[317,405,"Not concerning"],[529,619,"Confirmed"]],"Comments":[]}
{"id":"r1xjRtB1cB","text":"This paper proposes an integration of neuroevolution and gradient-based learning for reinforcement learning applications. The evolutionary algorithm focuses on sparse reward and multiagent\/team optimization, while the gradient-based learning is used to inject selectively improved genotypes in the population.\nThis work addresses a very hot topic, i.e. the integration of NE and DRL, and the proposed method offers the positive side of both without introducing major downsides. The presented results come from a relatively simple but useful multiagent benchmark which has broad adoption. The paper is well written, presents several contributions that can be extended and ported to other work, and the results are statistically significant.\n\nThere is one notable piece missing which forces me to bridle my enthusiasm: a discussion of the genotype and of its interpretation into the network phenotype. The form taken by the actual agent is not explicitly stated; following the adoption of TD3 I would expect a policy and two critics, for a grand total of three neural networks, but this remains unverified. And if each agent is composed of three neural networks, and each individual represents a team, does this mean that each genotype is a concatenation of three (flattened) weight matrices per each agent in the team? What is the actual genotype size? It sounds huge, I would expect to be at least several hundred weights; but then this would clash with the proposed minuscule population size of 10 (recent deep neuroevolution work from Uber uses populations THREE orders of magnitude larger). Has the population size been proportionated to the genotype dimensionality? Would it be possible to reference the widely adopted defaults of industry standard CMA-ES? Speaking of algorithms, where is the chosen EA implementation discussed? The overview seems to describe a textbook genetic algorithm, but that has been overtaken as state-of-the-art since decades, constituting a poor match for TD3.\n\nOmitting such a chapter severely limits not only the reproducibility of the work but its full understanding. For example, does the EA have sufficient population size to contribute significantly to the process, or is it just performing as a fancy version of Random Weight Guessing? Could you actually quickly run RWG with direct policy search (rather than random action selection) to establish the effective complexity of the task? My final rating after rebuttal will vary wildly depending on the ability to cover such an important piece of information. \n\nA few minor points, because I think that the paper appearance deserves to match the quality of the content:\n- The images are consistently too small and hard to read. I understand the need to fit in the page limit by the deadline, but for the camera ready version it will be necessary to trim the text and rescale all images.\n- The text is well written but often slowing down the pace for no added value, such as by dedicating a whole page to discussing a series of previously published environments.\n- The hyperparameters of the evolutionary algorithm look completely unoptimized. I would expect a definite improvement in performance with minimal tuning.\n- The \"standard neuroevolutionary algorithm\" from 2006 presented as baseline has not been state-of-the-art for over a decade. I would understand its usage as a baseline if that is indeed the underlying evolutionary setup, but otherwise I see no use for such a baseline.\n\n-----------------------------------------------------------------------------------------------\n# Update following the rebuttal phase\n-----------------------------------------------------------------------------------------------\n\nThank you for your work and for the extended experimentation. I am confident the quality of the work is overall increased.\n\nThe core research question behind my original doubt however remains unaddressed: does the EC part of the algorithm sensibly support the gradient-descent part, or is the algorithm basically behaving as a (noisy) multi-agent TD3?\nSuch a contribution by itself would be undoubtedly important. Submitting it as a principled unification of EC and DL however would be more than a simple misnomer: it could mislead further research in what is an extremely promising area.\n\nThe scientific approach to clarify this point would be to design an experiment showcasing the performance of MARL using a range of sensible population sizes. To understand what \"sensible\" means in this context, I refer to a classic:\nhttp:\/\/www.cmap.polytechnique.fr\/~nikolaus.hansen\/cec2005ipopcmaes.pdf\nA lower bound for the population size with simple \/ unimodal fitness functions would be $4+floor(3*log(10'000)) = 31$. With such a complex, multimodal fitness though, no contribution from the EA can be expected (based on common practice in the EC field) without at least doubling or tripling that number. The upper bound does not need to be as high as with the recent Uber AI work (10k), but certainly showing the performance with a population of a few hundreds would be the minimum necessary to support your claim. A population size of 10 represents a proper lower bound for a genotype of up to 10 parameters; it is by no means within a reasonable range with your dimensionality of 10'000 parameters, and no researcher with experience in EC would expect anything but noise from such results -- with non-decreasing performance uniquely due to elitism.\nThe new runs in Appendice C only vary the population size for the ES algorithm, proposed as a baseline. No performance of MARL using a sensible population size is presented.\n\nThe fundamental claim is thereby unsustainable by current results. The idea is extremely intriguing and very promising, easily leading to supportive enthusiasm; it is my personal belief however that accepting this work in such a premature stage (and with an incorrect claim) could stunt further research in this direction.\n\n[By the way, the reference Python CMA-ES implementation runs with tens of thousands of parameters and a population size of 60 in a few seconds per generation on a recent laptop: the claim of performance limitations as an excuse for not investigating a core claim suggests that more work would be better invested prior to acceptance.]\n","sentences":[{"sentence_type":"2","sentence":"Omitting such a chapter severely limits not only the reproducibility of the work but its full understanding.","rephrased":"Including a chapter on the genotype and its interpretation into the network phenotype would greatly enhance the reproducibility and understanding of the work."},{"sentence_type":"2","sentence":"For example, does the EA have sufficient population size to contribute significantly to the process, or is it just performing as a fancy version of Random Weight Guessing?","rephrased":"It would be beneficial to clarify whether the evolutionary algorithm's population size is adequate to make a significant contribution to the process, as opposed to a simpler approach like Random Weight Guessing."},{"sentence_type":"2","sentence":"My final rating after rebuttal will vary wildly depending on the ability to cover such an important piece of information.","rephrased":"My final rating will be influenced by the inclusion of this important information in the rebuttal phase."},{"sentence_type":"2","sentence":"The hyperparameters of the evolutionary algorithm look completely unoptimized.","rephrased":"The hyperparameters of the evolutionary algorithm appear to have room for optimization."},{"sentence_type":"2","sentence":"The \"standard neuroevolutionary algorithm\" from 2006 presented as baseline has not been state-of-the-art for over a decade.","rephrased":"The \"standard neuroevolutionary algorithm\" from 2006 used as a baseline may not reflect the current state-of-the-art."},{"sentence_type":"3","sentence":"The fundamental claim is thereby unsustainable by current results.","rephrased":"The fundamental claim would benefit from additional evidence to be fully supported by the current results."},{"sentence_type":"3","sentence":"it is my personal belief however that accepting this work in such a premature stage (and with an incorrect claim) could stunt further research in this direction.","rephrased":"I believe that further development of the work and clarification of the claims could significantly contribute to advancing research in this promising area."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[1994,2102,"Maybe"],[2103,2274,"Confirmed"],[2425,2546,"Maybe"],[3051,3129,"Confirmed"],[3206,3329,"Confirmed"],[5627,5693,"Confirmed"],[5788,5949,"Confirmed"]],"Comments":[]}
{"id":"1C9kgdJt2JO","text":"The authors examine important claims in machine learning. However, in its current state, this manuscript reads more like a high-level blogpost than a paper that would appear as a full publication in a top ML conference. The manuscript can be substantially improved if the authors provide more evidence for their claims about ML research directions. It would be especially beneficial to back up their argument with some statistics that can quantify the trends they describe instead of solely relying on quotes from a handful of papers ( for example, some statistics about number of papers on a certain topic with a certain claim). Below are some more specific issues that I have with the manuscript:\n\n1. The exposition is filled with unnecessarily inflammatory language. Some examples just from the first 50 lines: L4 \"gave rise to a hype loaded with ambitious promises and overstatements\", L6 'supervised learning went, for many, from glory to shame\", L49 \"based on misconceptions and overstatements about biological\n47 learning, and amplified by overselling nomenclature\". The manuscript would benefit from toning this down and allowing factual evidence to make its point. Here is the one that gave me the most pause: L180 \"would it not be worth reconsidering some research programmes?\". This seems to be completely the opposite of \nthe authors' self-described goal of being descriptive rather than prescriptive. \n\n2. The authors ​dismiss important challenges to modern ML by unfairly equating them to much more extreme versions of these challenges in human intelligence. For example, the authors dismiss the importance of addressing out-of-distribution generalization in ML by saying that humans are also limited in their \nability to transfer to new domains, as exemplified by the difficulty to learn a new unrelated language. Out-of-distribution generalization comes in many challenging forms to ML systems (e.g. changes in the label distribution (P(Y)), changes in the input feature distribution (P(X)), and changes in P(Y|X))). The example of humans learning a different language is an example of changing all of these distributions, which is an extreme form of out-of-distribution generalization. ML systems are shown to be sensitive to much milder changes in the problem setting. \n\n3. The contributions of this manuscript are not clear. It's not clear to me what this manuscript offers as a conclusion that is not already pursued in ML.\n- Two of the four conclusions that are drawn -- that evaluation beyond singe task performance is important and that a theoretical understanding of complex supervised objectives is important -- have been steadily growing directions in the field for over 5 years now.\n- One of the other 2 conclusions is that ML should temper its expectation about how sample efficient learning should be because humans are exposed to more supervision than is suggested in the ML literature. The authors oversimplify the aims in many of these ML works.\nML researchers don't expect that an ML system will develop abilities to generalize to a new class out of thin air. Of course a system needs to be exposed to \"relevant samples\" in order to learn. Not all of these samples however have to come from the specific class. \nThe hope is that a sample efficient ML system will be able to generalize from previously learned related examples in order to support fast learning of new examples.\n- The last remaining conclusion is that it would be great to distill progress in ML methods into a standardized nomenclature. I agree, as do many other ML researchers. A fitting contribution for a venue such as NeurIPS would be to actually suggest such a nomenclature. I don't consider a call for such nomenclature to be enough of a contribution.\n\n\n","sentences":[{"sentence_type":"1","sentence":"The manuscript can be substantially improved if the authors provide more evidence for their claims about ML research directions.","rephrased":"The manuscript would benefit from additional evidence supporting the authors' claims about ML research directions."},{"sentence_type":"2","sentence":"The exposition is filled with unnecessarily inflammatory language.","rephrased":"The manuscript's tone could be more neutral, particularly in its language choices, to strengthen the academic rigor."},{"sentence_type":"2","sentence":"The contributions of this manuscript are not clear.","rephrased":"It would be helpful if the authors could clarify the unique contributions of this manuscript."},{"sentence_type":"2","sentence":"The authors oversimplify the aims in many of these ML works.","rephrased":"The manuscript might consider a more nuanced discussion of the aims in these ML works to reflect the complexity of the field."},{"sentence_type":"2","sentence":"I don't consider a call for such nomenclature to be enough of a contribution.","rephrased":"While a call for standardized nomenclature is valuable, the manuscript could be strengthened by providing concrete suggestions or frameworks for such nomenclature."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[220,348,"Not concerning"],[703,769,"Confirmed"],[2292,2343,"Confirmed"],[2917,2977,"Maybe"],[3679,3756,"Confirmed"]],"Comments":[]}
{"id":"S1xtjozaYr","text":"This paper proposed a new realistic setting for few-shot learning that we can obtain representations from a pre-trained model trained on a large-scale dataset, but cannot access its training details. Also, there may be a large domain shift between the dataset of the pre-trained model and our dataset. For the pre-trained model, they will not only use its weights but also use it to generate a spatial attention map and help the model focuses on objects of images. Back to the standard few-shot classification problem, they will first adapt the model with base class samples and then adapt to novel classes.\n\nThe proposed new setting is very meaningful since we already have many powerful pre-trained models and why not exploit its usage for few-shot learning problems. However, I doubt the novelty and effectiveness of the attention way used in the paper. The attention module helps the model focuses on the objects not the background, which is absolutely correct. But there are already some relevant studies in the missing reference Large-Scale Long-Tailed Recognition in an Open World, CVPR2019. Also, from the results, the significant improvements come from the weights of the pre-trained model but not the attention used. Is the attention way used in the paper a good way to exploit the pre-trained model for few-shot classification problems?\n\nAlso, I am curious about the dense classification used in the adaptation phase. Will it achieve similar performance with finetuning using just standard loss?\n\nBtw, according to the formatting instructions, the abstract should be limited in one paragraph.\n\n=========================================================\nAfter Rebuttal:\n\nI thank the author for the response.\n\nI do see there are differences in the way of generating attention masks between the proposed work and (Liu et al.). But the improvements from the attention module is not significant, especially when using all base data.\n\nI keep my original scores.","sentences":[{"sentence_type":"2","sentence":"However, I doubt the novelty and effectiveness of the attention way used in the paper.","rephrased":"However, I would like to see further justification for the novelty and effectiveness of the attention mechanism used in the paper."},{"sentence_type":"2","sentence":"But the improvements from the attention module is not significant, especially when using all base data.","rephrased":"I would appreciate more evidence or discussion on the impact of the attention module, particularly when all base data is used, as the improvements appear to be modest."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[770,856,"Confirmed"],[1834,1937,"Maybe"]],"Comments":[]}
{"id":"BylefLP02X","text":"The paper presents an interesting approach to change point detection. I agree we need more general model to capture the change. However, unfortunately, they did not place the contribution correctly with respect to existing literature. The comments for prior work seem to be highly biased. For instance,  in Section 2, \"these methods either have unrealistic assumptions, such as defining changes as a large difference in covariance matrix\". I would like to comment that, covariance change can capture a large number of changes in real applications and these are not unrealistic assumptions. \n\nThe \"pyramid\" recurrent neural network seems to be a extension of RNN using the idea of multi-scale structure. Could be interesting.\n\nThe paper gives too much emphasis on the \"merit\" of the neural networks on capturing the change patterns. However, there is a very important aspect been ignored or hiding: in order to train neural networks to capture anomaly patterns, since neural networks are highly over-parameterized model, usually there won't be a large number of samples for anomalies. Therefore, in many situations, it is simply unpractical to train neural networks to capture post-change samples. \n\nThere is a large body of literature on change point detection in statistics etc. (the author mentioned one, Chen and Zhang 2015, more over, the comment that \"they can only detect abrupt change\" is wrong, the method is quite general).\n\nThe paper fails to have any comparison with existing methods. For instance, how does the proposed method compare with hoteling T-square statistic, or CUSUM statistic, or generalize likelihood ratio statistic, or MMD statistic (non-parametric approach)? Without any comparison, it does not make sense to claim proposed method is superior. \n","sentences":[{"sentence_type":"2","sentence":"However, unfortunately, they did not place the contribution correctly with respect to existing literature.","rephrased":"However, it would be beneficial if the authors could more clearly position their contribution within the context of existing literature."},{"sentence_type":"2","sentence":"The comments for prior work seem to be highly biased.","rephrased":"The comments on prior work could be perceived as somewhat subjective; a more balanced view would be helpful."},{"sentence_type":"2","sentence":"The paper fails to have any comparison with existing methods.","rephrased":"The paper would be strengthened by including comparisons with existing methods."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[128,234,"Confirmed"],[235,288,"Confirmed"],[1434,1495,"Maybe"]],"Comments":[]}
{"id":"T5yH4xKy-lo","text":"Strengths: The paper makes a convincing argument that on an individual level, confidence calibration may be misguided while their definition makes more sense. It is also true that a natural algorithm to achieve many notions of multi-label calibration is to reduce it to the binary case, as the paper suggests.\nWeaknesses: I think the definition also has obvious drawbacks that the authors do not discuss. In particular I am not convinced that calibrating only the top label makes sense. In practice it just means that you partition the data by the top label and then calibrate each partition separately (as the algorithm they suggest effectively does). The predictions outside the top label make no difference. It should be noted that satisfying this requirement is very easy. Pick the most common label and assign to all points the expectation of that label. Thus, the point of calibration is to do it to an existing classifier *with out* sacrificing other good properties such as loss minimization. Since the top label doesn't change by the calibrator the accuracy is unchanged, but the typical loss function for multi-class is cross entropy. \n\nDetailed comments:\n- Please explain better why calibrating only the top label is sufficient. Typically we assume that c(x) returns a vector of probabilities of dimension L, not just the top label out of the L.\n- At the beginning of section 2, please define confidence better. The arg max of the expression is a class (a number in [L]), not a pair (c,h), so the definition is confusing. \n- I am not very familiar with confidence calibration as is defined here, but it must have some good properties no? Please discuss them and contrast with your definition as well.\n- I'm not sure I fully understand the contribution of Section 3. Sure, some notions are reductions from binary classifiers, so lend themselves to be computed via binary calibrators. Is there anything more you can say? (for instance, is error being compounded?, is loss minimization being affected? are there computational tradeoffs?).\n- In table 2 and 3 it is worth noting that scaling algorithms are not designed to bring down ECE or TL ECE.","sentences":[{"sentence_type":"2","sentence":"I think the definition also has obvious drawbacks that the authors do not discuss.","rephrased":"The definition could be strengthened by addressing potential drawbacks that were not discussed in the paper."},{"sentence_type":"2","sentence":"It should be noted that satisfying this requirement is very easy.","rephrased":"It would be beneficial to discuss the complexity of satisfying this requirement in more detail."},{"sentence_type":"1","sentence":"Pick the most common label and assign to all points the expectation of that label.","rephrased":"An example to consider is selecting the most common label and assigning to all points the expectation of that label, and then discussing the implications of this approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[322,404,"Confirmed"],[711,776,"Not concerning"],[777,859,"Not concerning"]],"Comments":[]}
{"id":"ROYppUoqt2E","text":"**Summary:** The paper empirically compares two approaches for transfer\nlearning: FE (feature extraction) and FT (fine-tuning). This comparison includes\nmultiple tasks and different metrics (e.g. performance and CO2 footprint). The\nauthors also investigate the impact of the amount of available data.\n\n**Strengths, Weaknesses & Questions:**\n- Overall, the paper is well-written. The methodology is clearly explained and\nthe authors also discuss limitations of their work. The experimental details are\ndescribed in the appendix. \n- Due to my very limited experience with FE and FT, I would have appreciated a\nmore detailed explanation of the two methods. \n- Line 53: For the FT approach, SGD with a fixed batch size of $64$ is used.\nThis parameter can have a crucial impact on the resulting performance, but this\nis neither discussed nor investigated in the paper. \n- Line 71-75: I am skeptical whether this comparison is fair since you are\nusing 24 hyperparameter configurations for FT and only 4 configurations for the\nFE approach. It is not clear to me to which extent this imbalance biases your\nresults in favor of FT. \n- Line 86-90: The definition of *human cost* is not clear to me: What exactly do\nyou mean by *analysis of multiple training curves*? Can't the extraction of the\nrelevant information be fully automated? \n- Line 103-107: I don't fully understand this section. For example, the Oxford\nFlower data set does not match the two categories you mention. I also don't\nunderstand the *distinction at around $25$ instances per class*. Left and right\nof this threshold, there are cases where FT outperforms FE. \n- Line 110: Do you have an explanation for why FT outperforms FE on data sets\nwith overlap?\n- Line 129: This statement is a bit too strong in my opinion. FT still\noutperforms FE in 4 cases (by a lot), has almost identical performance in 2\ncases (Caltech 101 and MIT ISR), and is slightly worse than FE in 4 cases. \n- Line 130-133: I'm confused by these statements. For under $7$ training samples\nper class, almost all data sets show negative y-values indicating that FE outperforms FT. This is in contradiction with your statement.\n- Line 133-135, 144-146: I find these statements questionable and quite\nspeculative.\n\n**Minor:**\n- Typos: Line 10: *a* $\\rightarrow$ *an*, Line 100: *buy* $\\rightarrow$ *by*\n- Line 58: You could have included a link to an anonymous GitHub repo with your\ncode. \n- Figure 1: A text within the plot like *FT better* for positive y-values and\n*FE better* for negative values would allow faster orientation. \n","sentences":[{"sentence_type":"2","sentence":"I am skeptical whether this comparison is fair since you are using 24 hyperparameter configurations for FT and only 4 configurations for the FE approach.","rephrased":"I am curious about the fairness of the comparison given the use of 24 hyperparameter configurations for FT versus only 4 for FE, and I wonder if this might introduce a bias in the results favoring FT."},{"sentence_type":"2","sentence":"I find these statements questionable and quite speculative.","rephrased":"These statements appear to be based on assumptions that may not be fully supported by the data, and I would appreciate further clarification or evidence."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[879,1032,"Maybe"],[2179,2238,"Maybe"]],"Comments":[]}
{"id":"5BB6QDXhQ6","text":"Authors propose the novel technique for neuro-symbolic program induction. For this, they combine program synthesis, neural compilation and differentiable optimization together. \n\nThe novel algorithm offers interesting insights into one-to-one mapping between programs and their compilation as neural-network's weights. Since the neural-compilation probabilistic is, the process of decompilation is noisy as well. Nonetheless, the percent of perfectly recovered algorithms (Table 1) is impressive. It follows that the combination of synthesis and optimization allows for recovery of such algorithms as Fibonacci functions.\n\nDespite the impressive results, it is difficult to judge the performance of the proposed algorithm since there are no comparisons with other works brought forward. It would largely improve the quality of the paper if the authors will add experimental settings where such comparison will be of at most importance.\n\nSmall remarks and wishes:\nThe described neural compilation process (Section 2.1) is detailed and insightful for the reader to understand the premise of the new algorithm. However, one cannot follow Eq. (8) and (9) since the meaning of the operators $\\odot$ and $\\otimes$ is not specified. Are these operators elementwise (scalar) or vectorwise (tensor) to be understood? The same can be stated about Eq. (10). Sadly, in Eq. (11) the source of the variable $h$ is not explained. Is it the halt state as described at the beginning of the subsection? \n\nThe references should be doubly checked. Some of them include a link exclusively to arXiv [13, 17, 29, 32, 33, 36, 37, 39, 41] and some are not complete [21, 26, 27]. It would be much better either replace the links to arXiv all together, or make the remark that some references are accessible exclusively as arXiv-preprints.","sentences":[{"sentence_type":"1","sentence":"Sadly, in Eq. (11) the source of the variable $h$ is not explained.","rephrased":"It would be helpful if the authors could clarify the source of the variable $h$ in Eq. (11)."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1347,1414,"Maybe"]],"Comments":[]}
{"id":"Skl3LnM_KE","text":"The authors propose a loss function that encourages different samples to be mapped to different feature vectors. The loss is analyzed both in the context of an autoencoder and a single layer supervised neural network.\nOne issue the authors would consider is introducing more clarity in the exposition of the work. For instance, you never really specify the exact inputs and outputs of your autoencoder. \nMy main criticism would be that OVR overly relies on the quality of the neighboring samples in a minibatch to identify the loss. if you have a mini-batch of datapoints of the same class it would not work at all. However, even in the case where you have a minibatch of 128 and an expected 12 data points of each class for CIFAR-10 I would expect a lot of \"noisy information\" steering the loss towards the wrong result. That problem might alleviate in the  case of many labels and highly diverse datasets.\nI think in total the work leaves a lot to be desired. 1. The loss can be broken by the right construction of the dataset. 2. The loss might do better with a rich dataset which is probably not the case for most applications discussed in the LLD workshop.","sentences":[{"sentence_type":"2","sentence":"I think in total the work leaves a lot to be desired.","rephrased":"While the work presents interesting ideas, there are several areas that could be further developed and refined."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[908,961,"Confirmed"]],"Comments":[]}
{"id":"S1emuKXW5E","text":"This paper presents an end-to-end approach for generating protein backbones using generative adversarial networks, an important direction in applying deep generative models for generating complex, highly-structured biological data (proteins).  First, a generative model (DCGAN) is used to generate pairwise distance matrices between atoms on the backbone. Second, a recover network transforms the distance matrix into the underlying 3D coordinates of the backbone. Finally, the recovered coordinates are post-edited by a recurrent error correction model. \n\nIn the experimental section, the authors present a rich set of qualitative evaluations, with examples and case studies demonstrating that the underlying latent space is smooth, and small steps in the latent space of the generator correspond to realistic deformations of the protein backbone. Unseen test examples are also encoded in the latent space. The authors conclude the paper by outlining an approach to iteratively refined generative backbones to host foldable sequences.\n\nThe paper is clearly written and the method is novel. My only comment is that it seems the submission lacks quantitive analysis, with most conclusions, were drawn from illustrative case studies. Additionally, the authors could also try using the Rosetta energy function as part of the discriminator, directly optimizing the generated structures to have low energy.","sentences":[{"sentence_type":"1","sentence":"My only comment is that it seems the submission lacks quantitive analysis, with most conclusions, were drawn from illustrative case studies.","rephrased":"While the paper provides valuable qualitative insights, it would be beneficial to complement these with more quantitative analysis to strengthen the conclusions, which seem to be primarily drawn from illustrative case studies."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1091,1231,"Not concerning"]],"Comments":[]}
{"id":"BEegDAGQ1Mc","text":"The paper investigates the problem of causal discovery, more specifically the challenge in video causal discovery systems to model instantaneous and dynamical change in the underlying causal graph in the intuitive physics domain (bouncing balls or tower of stacked blocks).  The main idea is to use a state-space model wherein the adjacency matrix of the causal graph is modeled as a latent variable and learned using the standard ELBO objective. \n\nPros:\nModel has been evaluated on the benchmark CoPhy dataset and against a strong baseline method designed for the same benchmark.   \nThe research question under consideration is highly relevant to the workshop theme.\n\nHowever, there are significant issues with regards to the experiments and results reported as described below.\n\nCons:\n\nThe experimental setup and results section is poorly recorded with many discrepancies between what is claimed versus what is reported. In “Downstream tasks and Datasets” the authors mention that they use all 3 datasets (i.e. BlockTowerCF, BallsCF and  CollisionCF) from the CoPhy benchmark. Further, the caption of Table 1 reads “Quantitative results on three physical scenarios of the CoPhy dataset and Fabric dataset. We compare with state-of-the-art methods: CoPhyNet (Baradel et. al 2020) and V-CDN (Li et. al 2020). Non-existent experiments are marked by hyphens”. However, the Table 1 only compares the proposed model against CoPhyNet and only on 2 datasets — BlockTowerCF and CollisionCF. No results have been reported on BallsCF and the Fabric dataset. Results for the V-CDN baseline are also missing. It’s unclear what the last sentence of the caption means since there are no hyphenated results shown in Table 1.       \n\nWriting: The writing and presentation could be significantly improved to enhance the clarity of exposition and readability. Below are some typos\/errors I found: \n\n- “property of nonstationary” -> “property of non-stationarity”\n\n- “… show that the proposed achieves” -> “… show that the proposed model\/method achieves”\n\n- “… is essential for intelligence systems in understanding the complex mechanisms in the physical world.“ missing citation.\n\n- “… as shown in Figure ??” — missing reference (latex error)\n\n- “… predict $\\hat{x}^t$ is the mode of $p(x^t | x^{1:t-1} ; \\theta)$ and do further prediction conditioning on this prediction” - sentence construction could be improved.\n\n- “… given the observed $d$ agents ” — what is an agent in this context? \n\n- “… node $x_j^t$ is associates” -> “… node $x_j^t$ is associated”\n\n- “… we invoke the state-space model (SSM) (?, Yang et. al …)” — missing reference\/latex error\n\n- In eq. 4 $\\alpha_t \\sim p(\\alpha_t | h_t)$ -> unclear notation. Further, the time variable ’t’ is alternating used as both a superscript and \nsubscript in different situations which is difficult to follow for the reader. \n\n- “… causal structure to estimate” -> “… causal structure to estimate”\n\n- “… experimental protocols in (Baradel et. al 2020) to examine the generalizability of” — sentence incomplete. \n\n- “3.2 DISCUSSIONS” -> “3.2 DISCUSSION”\n\n- “… interested in assessing our versus” -> “… interested in assessing our model\/method versus”    \n\n- “… dynamics over time and approache object interactions with fully-connected graph convolution (??)” -> “… dynamics over time and approaches object” + missing citation\n\n- “… seen in Table 1 that out model” -> “… seen in Table 1 that our model”\n\n- “… propose an state-space model” -> “… propose a state-space model”\n\n- “… justify that our delivers” -> “justify that our model\/method delivers”\n","sentences":[{"sentence_type":"2","sentence":"The experimental setup and results section is poorly recorded with many discrepancies between what is claimed versus what is reported.","rephrased":"The experimental setup and results section could benefit from clearer recording to resolve discrepancies between the claims and the reported results."},{"sentence_type":"2","sentence":"Non-existent experiments are marked by hyphens.","rephrased":"It appears that some experiments are not included in Table 1, as indicated by the absence of results where one might expect hyphens."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[788,922,"Confirmed"],[1309,1355,"Not concerning"]],"Comments":[]}
{"id":"r1ea_iJZ9V","text":"The main idea of the paper is to algorithmically label (or pseudolabel) a large amount of image data so that the model pre-trained on these data can better transfer to some target task. The idea is to use some specialized (also pre-trained) models that can identify certain classes as soft labeling functions (i.e., at pre-training time, use the distance to the average output activations as the pre-training learning signal).\n\nThe idea is intuitive and seems working, but the downside of the approach is that it requires these gold-standard specialized models used for source labeling (or known labeled datasets used to construct such models). Of course, this is just a pre-training method, and the goal is to transfer the model to a target domain that has some (limited) gold-standard annotations. However, the approach seems quite heuristic, it's unclear whether such pre-training introduces any biases (during pre-training), and generally a more thorough analysis of how the quality of the known labeled data affects model pretraining is necessary.","sentences":[{"sentence_type":"2","sentence":"However, the approach seems quite heuristic, it's unclear whether such pre-training introduces any biases (during pre-training), and generally a more thorough analysis of how the quality of the known labeled data affects model pretraining is necessary.","rephrased":"However, the approach appears to be somewhat heuristic. It would be beneficial to clarify whether such pre-training introduces any biases, and a more comprehensive analysis of how the quality of the known labeled data influences model pretraining would be valuable."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[800,1052,"Confirmed"]],"Comments":[]}
{"id":"lBDZ95_iW59","text":"Strengths\n- This paper provides an interesting application of using ML.\n\nWeakness\n- Lack of ML technique related novelty: this paper directly leverages the existing ML techniques, eg., FedAvg and AutoEncoder, w\/o proposing new techniques. I think this is just a pure ML application paper. \n- Motivation doubt: I wonder whether there will be the malicious venders in the real world. If the vender wants to pollute the global model, then the malicious data\/model will affect the vender's own prediction accuracy as well, then why does he\/she want to do that. Not sure whether the authors can address the motivation clearer.\n- Why Antoencoder is picked for anomaly detection? Why not the other approaches?","sentences":[{"sentence_type":"2","sentence":"I think this is just a pure ML application paper.","rephrased":"The paper could benefit from a clearer demonstration of novelty in its ML techniques."},{"sentence_type":"1","sentence":"I wonder whether there will be the malicious venders in the real world.","rephrased":"It would be helpful if the authors could further clarify the real-world applicability of their model, particularly concerning the presence of malicious vendors."},{"sentence_type":"1","sentence":"Not sure whether the authors can address the motivation clearer.","rephrased":"The authors might consider elaborating on the motivation behind their approach to enhance the paper's clarity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[239,288,"Confirmed"],[310,381,"Confirmed"],[557,621,"Confirmed"]],"Comments":[]}
{"id":"RaS8YFh7eqh","text":"#### Summary:\n\nIn more mathematical fields, theorem provers and similar systems can validate claims made about formal systems.  However, many research contributions come in the form of papers, and thus they are never validated in this way.  Math researchers can express their contributions in a special purpose language to do this, but that places an additional burden on them to learn this skill.\n\nAn alternative would be to \"translate\" the research into formal languages which could be operated on by automated systems.  This seems to be the goal of this paper, which looks at using translation to disambiguate some expressions from STEM documents written in LaTeX, which maps it into an sTex document.  Previous research in this area used more hand-specified transformations, and was evaluated on different data.  This makes this work closely related to existing work, but not directly comparable.\n\nThe main finding of this work is that pre-trained transformer models outperform more traditional fully-supervised translation systems on this task.  It is difficult to guage precisely to what extent the proposed method solves the task, or to fully grasp what aspect of the translation problem is being solved.\n\n\n\n#### Strong points: \n\nThe proposed approach of using transformers and large in-domain pre-training is similar to a lot of recent work which has shown to work well in practice, and is therefore well-motivated.  The task itself is important and improvements in this area could have broad range of impact that would even be good to the ML field itself, so even a practical improvement using fairly standard ML would be a useful contribution.\n\nThe authors are clearly knowledgable on the topic, and discuss and cite a great deal of the literature and libraries relevant to the problem.  It's a heavy paper -- there's a very extensive set of work that's been studied and referenced.\n\n\n#### Weak Points\n\nIn the start of section 4, a number of systems were listed.  Each of these was an attempt to automate the formalization process, but there was no attempt to compare against these methods.\n\nAs noted towards the end of section 4, the target transformation for much of the document is the identity.  Given that actually a lot of this text should not change, is phrasing it as translation the best choice?  It seems that phrasing it this way sets up the NMT baselines to perform poorly, since a lot of training is necessary to prime the model to learn this identity transformation, and that data is not given to those models.\n\nThe evaluation methodology is confusing.  For instance, it seems some of the data is generated via an automated procedure, both in the supervised learning (Section 5) and in the Synthesizing Training Data section.  It makes it difficult as a reader to understand why this is not a chicken-and-egg type of scenario: if automated methods produce the dataset, which is then used to train the model, then why are those methods not sufficient for the end task?  This may be a problem that arises from introducing so many domain-specific libraries and formalisims, that it leaves the reader with a great deal of difficult to understand precisely what the transformation is accomplishing and from what type of data.\n\nIt was also bizarre in the results section how the baselines were dismissed in writing, their results were never presented.  If the baselines are truly that bad, then do they suffice as baselines?  The authors choose these instead of the existing formalization methods, so why make the contrast with methods that are not in a position to perform the task well?\n\n\n#### Recommendation\n\nBecause the presentation makes it difficult to fully grasp the problem setting, precisely what is being learned, precisely what is failing, it is difficult to recommend the paper for acceptance.  It is actually very understandable that this particular paper has this problem, because the authors are forced to introduce many unfamiliar concepts -- the problem setting, the types of formalisms used, the libraries used in creating the data, etc.  These are all things that are outside the scope of the typical ICLR paper and thus warrant a clear introduction, but space is limited.  I could easily imagine this paper filling up 12-14 pages just with the same content presented here.  But ultimately the paper is not written in a way that can properly convey the scope of the work and narrow in on precisely the targetted problem and why it's difficult and important.\n\nThen the experimental section is quite short and lacks important comparisons.  Given the lack of suitable baselines, I would not be able to recommend accepting the paper without real comparisons to other work in this area.  Again this could be a space concern, but the paper overall spends too much time leading up to methodology\/experiments, and then is very light on actual experimental content.  Factor in that the model is used in a very off-the-shelf way, and doesn't treat the problem setting really any different than a standard translation task, it is hard to see real novelty in the modeling contribution either.\n\nOverall I think the work is promising, but it is far too rough in its current state to be considered for acceptance without significant revision.  It would need major restructing and refocusing, more experiments, and more analysis.\n\n\n#### Presentation\n\nI feel like there's a lot of domain specific meanings to terminology that makes it more difficult than necessary to understand by a general ML audience.  Take for instance, formal and informal.  To most language users, a scientific paper is a formal document -- it uses formal language.  So it takes me some time as a reader to get into the actual data section and understand truly what is meant by informal here.  There are many things of this nature that would be better to clarify up-front, so the reader with the typical ML background and biases doesn't carry around incorrect concepts of what the paper is about, for longer than is necessary.\n\n\nThe citation format is incorrect.\n\nSmall typos throughout.\n\n\n#### In considering author response:\n\nThank you to the authors for continuing discussion on the points raised in my review, and for further clarifying the nature of the data as a kind of unidirectional ambiguity problem.   I understand this better now and can see a contribution in releasing this data \/ data-generating process for other researchers studying autoformalization.  On account of this I'm going to raise my initial scoring.\n\nOn the subject of methodology, I still think there are reasons to reconsider this work.  As discussed, the translation baselines were not great.  I think it's not really fair to compare those models without pre-training on data that was too small to learn basic tree properties.  It is possible that translation models that perform string-to-tree translation would perform better here(1), though results from natural language translation would hint towards the pre-trained models still performing better.  Translation models used in the domain of programs seem more suitable as well, and there's a good number of these, and there is a natural desire to generate strings that reflect a properly nested tree (2).  There is also work on mapping strings to knowledgebase queries that seems similar in input\/output (IIRC, Luke Zettlemoyer's had a number of important papers in this line).\n\nBut at best these would still be comparisons of mostly off-the-shelf translation models, which doesn't leave the reader with much of a takeaway.\n\nSo I'm left feeling that if the authors want a useful quantitative comparison, these methods should be explored.  Pre-trained model beats model trained on only in-domain data is not to me a story significant enough to warrant inclusion in the conference, even if it contributes a new dataset (as the modeling is presented as a contribution here).  Even off-the-shelf methods can of course be part of an important contribution when the authors show that they have pushed the field further with an important result (say, GPT) but I do not feel the evaluation in this case supports that conclusion.\n\nIt seems more natural given that none of these methods are likely to out-perform a vanilla pre-trained translation model, that the problem description and qualitative evaluation are of the utmost importance.  I would really recommend expanding this beyond half a page, to give the reader a better idea of what problems are solved and what are remaining.  It also seems that some of the errors pointed out (like those involving ellipses) would likely be remedied by additional synthetic data.  As I'm the most dissenting reviewer, I would still hope the authors attempt to improve the results section with the additional page upon acceptance.\n\n1.\nTowards String-To-Tree Neural Machine Translation\nRoee Aharoni, Yoav Goldberg\n\n2.\nTree-to-tree Neural Networks for Program\nTranslation\nXinyun Chen, Chang Liu, Dawn Song\n\n","sentences":[{"sentence_type":"1","sentence":"It is difficult to guage precisely to what extent the proposed method solves the task, or to fully grasp what aspect of the translation problem is being solved.","rephrased":"It would be helpful to clarify to what extent the proposed method solves the task and to elaborate on the specific aspects of the translation problem that are being addressed."},{"sentence_type":"2","sentence":"It was also bizarre in the results section how the baselines were dismissed in writing, their results were never presented.","rephrased":"It was unexpected that in the results section, the baselines were not discussed in detail and their results were not presented."},{"sentence_type":"2","sentence":"But ultimately the paper is not written in a way that can properly convey the scope of the work and narrow in on precisely the targetted problem and why it's difficult and important.","rephrased":"Ultimately, the paper could benefit from a clearer presentation that more effectively conveys the scope of the work and focuses on the targeted problem, its challenges, and its importance."},{"sentence_type":"2","sentence":"Overall I think the work is promising, but it is far too rough in its current state to be considered for acceptance without significant revision.","rephrased":"Overall, the work is promising and with significant revision, it could be considered for acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1051,1211,"Confirmed"],[3246,3369,"Confirmed"],[4313,4495,"Confirmed"],[5120,5265,"Confirmed"]],"Comments":[]}
{"id":"S1DRG7chm","text":"This paper presents a method for learning about the parts and motion dynamics of a video by trying to predict future frames.  Specifically, a model based on optical flow is defined, noting that the motion of hierarchically related parts are additive.  Flow fields are represented using an encoder\/decoder architecture and a binary structural matrix encodes the representations between parts.  This matrix is predicted given the previous frame and flow field.  This is then used to estimate a new flow field and generate a possible future frame.  The system is trained to predict future frames using an L2 loss on the predicted image and motion field and regularized to prefer more compact and parsimonious representations.\n\nThe method is applied to synthetic datasets generated by moving shapes or MNIST digits and shown to work well compared to some recent baseline methods for part segmentation and hierarchy representation.  It is also applied and qualitatively evaluated for future frame prediction on an atari video game and human motion sequences.  The qualitative evaluation shows that part prediction is plausible but the results for future frame prediction are somewhat unclear as there are no baseline comparisons for this aspect of the task.\n\nOverall the approach seems very interesting and well motivated.   However, the experimental comparisons are limited and baselines are lacking.  Further, some relevant related work is missing.\n\nSpecific concerns:\n- Motion segmentation has been studied for a long time in computer vision, a comparison against some of these methods may be warranted.  See, e.g., Mangas-Flores and Jepson, CVPR 2013.\n- There is some missing related work on learning part relations.  See, e.g., Ross, et al IJCV 2010 and Ross and Zemel JMLR 2006.\n- There is also some missing work on future frame prediction.  In particular, PredNet seems relevant to discuss in the context of this work and as a baseline comparison method.  See Lotter et al ICLR 2017.\n- A reasonable baseline might be simply to apply the previous frames motion field to generate the next frame.  This would be a good comparison to include.\n- The \"Human Studies\" section is very unclear.  How is \"same tree structure\" defined exactly and how were humans asked to annotate the tree structure?  If it's about the hierarchical relationship, then I would expect humans to always be pretty consistent with the hierarchy of body parts and suggests that the model is doing relatively poorly.  If it's some other way, then this needs to be clarified.  Further, how was this study performed?  If this section can't be thoroughly explained it should be removed from the paper as it is at best confusing and potentially very misleading.\n- The system only considers a single frame and flow-field for part prediction.  From this perspective, the effectiveness of the method seems somewhat surprising.\n- The system takes as input both a frame and a flow field.  I assume that flow field is computed between I0 and I1 and not I1 and I2, however this is never specified anywhere I can find in the manuscript.  If this is not the case, then the problem setup is (almost) trivial.\n\n","sentences":[{"sentence_type":"2","sentence":"If this section can't be thoroughly explained it should be removed from the paper as it is at best confusing and potentially very misleading.","rephrased":"It would be beneficial to provide a more detailed explanation of the 'Human Studies' section. Clarifying how the tree structure is defined and how the annotations were collected could enhance the reader's understanding and ensure the section contributes effectively to the paper."},{"sentence_type":"1","sentence":"The system only considers a single frame and flow-field for part prediction. From this perspective, the effectiveness of the method seems somewhat surprising.","rephrased":"The system's ability to predict parts from a single frame and flow-field is intriguing. It would be interesting to see how the method performs when considering multiple frames, which could potentially improve the robustness of the predictions."},{"sentence_type":"2","sentence":"If this is not the case, then the problem setup is (almost) trivial.","rephrased":"Clarification on whether the flow field is computed between I0 and I1 or I1 and I2 would be helpful, as it has significant implications for the complexity of the problem setup."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2584,2725,"Confirmed"],[3094,3162,"Confirmed"]],"Comments":[]}
{"id":"49qNYOdaLu","text":"The paper proposes a simple transformer architecture, called Transplit, for efficient energy demand forecasting. It is based on chunking the input sequence before passing it into an encoder-decoder transformer model. By using much less parameters than alternative methods, it is signigicantly faster and cheaper to train, while achieving comparable performance to the relevant baselines.\n\nSince the proposed method seems to improve the feasibility of using neural network based models for energy demand forecasting, I recommend to accept the paper.","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"rx-l2yr30Zc","text":"Overall, I enjoyed reading the paper. \nThe idea was well-presented and could be understood.\n\nPros: \n* Interesting idea to incorporate counter-factual reasoning into credit assignment\n* Approach was useful to prune policies to produce a simple and effective policy\n\nCons: \n* Design choices behind Equation 2 are not justified. For example, the approach could have evaluated the value of a policy pi with action at t wrto each of the remaining action at time t. This also yields a metric that measures causal contribution of action at t. It would be more informative to discuss the motivations behind deriving this equation.\n* \"Our hypothesis is that many trained policies are needlessly complex...\" - this statement does not have any justification and without it, it is hard to agree with this statement.\n* The paper needs to discuss how such a method can scale to domains with uncountably many states \/ domains with function approximation. Also, are there ways to combine this approach with existing approaches for credit assignment (e.g., eligibility traces)?","sentences":[{"sentence_type":"2","sentence":"Design choices behind Equation 2 are not justified.","rephrased":"The rationale behind the design choices for Equation 2 could be further elaborated to strengthen the paper."},{"sentence_type":"2","sentence":"\"Our hypothesis is that many trained policies are needlessly complex...\" - this statement does not have any justification and without it, it is hard to agree with this statement.","rephrased":"It would be beneficial if the paper could provide empirical evidence or theoretical justification for the hypothesis that many trained policies are needlessly complex."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[274,325,"Maybe"],[625,803,"Maybe"]],"Comments":[]}
{"id":"g88vOtuB8R","text":"\nQuality\nThe paper is written in an understandable manner. The experiments are done on (or shown on) a limited set and the authors don’t compare with other baseline methods for case trend analysis of COVID-19\n\nClarity\nIt can be improved further to make contributions of the authors clearly delineated from the existing literature. The explanation of the graph can be better if it is shown visually, but I understand that there are space limitations for this submission\n\nOriginality\nThe idea is something that is already explored by other researchers to answer different or similar questions related to the pandemic forecasting\n\nSignificance\nThe work is significant to the workshop given the problem it is tackling. This is also interesting to society given the possibilities of other epidemics\n\nPros\nCompare different error metrics and also perform a statistical test to show the significance\nThey show that the addition of mobility is helping in the forecasting; counties with earlier trends can also help predict those with later.\n\nCons\nNo baseline comparison apart from their own method without spatial information\nMissing citations:\n1) mobility network related - Mobility network models of COVID-19 explain inequities and inform reopening; this and follow-up works seem closely connected to what the authors explore\n2) Trends are more important than actual numbers in terms of pandemic forecasts\n3) Using information from one county to help the other \nI am aware of works from the CDC forecasting hub, XPRIZE pandemic challenge, etc that have discussed these issues. It would be relevant to cite those papers and show how this work is different \n","sentences":[{"sentence_type":"2","sentence":"The idea is something that is already explored by other researchers to answer different or similar questions related to the pandemic forecasting","rephrased":"While the idea has been previously explored in the context of pandemic forecasting, it would be beneficial to highlight how this work diverges from or builds upon existing research."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[482,626,"Confirmed"]],"Comments":[]}
{"id":"16Kaa-mOfHg","text":"Overall evaluation:\n* The paper fits perfectly within the framework of this workshop as it investigates how the plasticity of a RL model changes throughout the training, which is necessary for reusing it further. \n* The paper is very clearly written. The experiments are well-motivated, the chain of thought of the authors is easy to follow and the appendix contains a lot of useful details.\n* The technical quality of the paper is quite high, especially for a workshop paper. The authors run experiments on the whole Atari 57 benchmark, use multiple seeds and apply good practices in terms of looking out for statistical significance. \n* The results are of high interest to the community.\n\nAs such, I think this paper is a very good fit for this venue. Below, I attached some comments and suggestions, but I still think the paper is very good.\n\nFeedback and comments:\n* The results in Figure 6, right worry me a bit. That is, looking at the \"Unfrozen injection @ 0\", it seems that simply having two \"heads\"  solves the problem. Granted, you save some computation if you apply injection after some time, but it seems that the plasticity loss here is not a fundamental issue, the network architecture was wrong. As you say, and I agree, \"RL agents typically employ networks that were originally proposed for stationary problems, but perhaps a specialized parameterization would suit the non-stationary nature of RL better\". But it seems that the specialized parameterization seems to be the crucial point here, not the plasticity loss during the training - you can just change it before you train and it works just as well. Also, I wonder if having two heads is enough or if we need the $\\theta'_1, \\theta'_2$ distinction from Equation 1.\n* I would be interested to see the same experiments in some other domains. For example, do your observations transfer to continuous control problems such as DMControl or Mujoco? In particular, I wonder how important is the image encoding - can we see the same or \"raw\" states?\n* I would appreciate a more thorough comparison to Progressive Networks since that method seems very similar to the proposed plasticity injection. Obviously, there are a few things that are different (randomly initialized columns, etc), but the two ideas seem deeply connected.\n* The plasticity loss experiment in Figure 1 is quite striking, especially since it technically does not include any kind of RL, just simple MSE minimization in a continual learning setting. I think more details about this experiment should be included. What was the average return of the RL policy used for this experiment? What was the architecture used? Do we see the same behaviour for other tasks? Similar experiments were run previously in the Ash & Adams and Beriaru et al. papers you cite, but I don't think the results were quite as striking. It would be quite interesting to pinpoint the exact reason for this plasticity loss. In particular [1] shows that the input masking in RL impacts the performance quite a lot. One possible hypothesis would be that some of the neurons corresponding to certain inputs activations \"die\" in the early phase of the training when these pixels are not important. And later, when these start being important, we can no longer activate them. I'm not saying that is the correct solution here, but a more in-depth investigation would be quite valuable for the community.\n* I don't think the code was shared, and I think it would be interesting to tinker with it.\n* I don't think the exact network architecture is mentioned anywhere explicitly. I assume you use the one from the Double DQN paper, but I think it's quite an important point of the paper and as such it would be useful to write it down explicitly (size of the convolutional layers, the width of the head, etc).\n\n[1] On Lottery Tickets and Minimal Task Representations in Deep Reinforcement Learning, Marc Aurel Vischer*, Robert Tjarko Lange*, Henning Sprekeler, ICLR 2022\n ","sentences":[{"sentence_type":"1","sentence":"The results in Figure 6, right worry me a bit.","rephrased":"The results in Figure 6, right, raise some questions that could be addressed."},{"sentence_type":"1","sentence":"I don't think the code was shared, and I think it would be interesting to tinker with it.","rephrased":"Sharing the code would be beneficial for further exploration and replication of your results."},{"sentence_type":"1","sentence":"I don't think the exact network architecture is mentioned anywhere explicitly.","rephrased":"It would be helpful if the exact network architecture were detailed explicitly in the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[871,917,"Not concerning"],[3406,3495,"Not concerning"],[3498,3576,"Not concerning"]],"Comments":[]}
{"id":"rJxR8XGzFH","text":"Summary:\nIn this empirical study, the authors attempt to identify a minimal entropy version of an image such that the image may be correctly classified by a human or computer. The authors then compare the efficacy of a human and computer to maintain accuracy in the presence of a reduced entropy representation of an image. The authors find that machines are more sensitive to reductions in entropy due to image resolution than humans (as opposed to color or cropping). In addition, the authors find that humans are generally better at identifying minimal entropy images than machines.\n\n1. Corruption results not surprising. \n\nAlthough the authors offer some intriguing methods, I found the results to not be compelling nor improve our understanding of the relative differences between human and machine perception. While identifying that humans are less sensitive to a reduction in resolution, this result is not terribly surprising given that networks are known to suffer from aliasing artifacts, e.g.\n\n  Geodesics Of Learned Representations\n  Olivier J. Henaff & Eero P. Simoncelli\n  https:\/\/www.cns.nyu.edu\/pub\/lcv\/henaff16b-reprint.pdf\n\n2. Unclear what we learn from the method.\n\nI am not too clear about what specific insights the methods provide in this paper. Estimating the entropy associated with each image corruption -- while interesting -- does not lead to any substantive analysis nor conclusions as far as I can tell. Given the lack of benefit to analyzing the entropy, I am left to really just consider these methods to be image corruptions that downsample the resolution or desaturate the images. These corruptions are not terribly novel with respect to previous work, e.g.\n\n  Generalisation in humans and deep neural networks\n  https:\/\/arxiv.org\/pdf\/1808.08750.pdf\n\n  Benchmarking Neural Network Robustness to Common Corruptions and Perturbations\n  https:\/\/arxiv.org\/abs\/1903.12261\n\nTo summarize, my feedback is the following:\n\n1. Please justify the use of entropy to quantify the distortion. What does entropy provide above and beyond just parameterizing the distortion (e.g. image resolution, color saturation)?\n\n2. Are there other results above-and-beyond sensitivity to image resolution that distinguishes human and machine in these experiments? These results seem to be largely known by just considering corruptions such as low pass filters, etc. presented in the above papers.\n\n\nMinor Comments:\n\n- The authors should provide a figure with example images in the main text showcasing how each method corrupts an image.","sentences":[{"sentence_type":"2","sentence":"Corruption results not surprising.","rephrased":"The results regarding corruption were somewhat expected, given the known issues with networks and aliasing artifacts."},{"sentence_type":"2","sentence":"I found the results to not be compelling nor improve our understanding of the relative differences between human and machine perception.","rephrased":"The results could be further strengthened to enhance our understanding of the relative differences between human and machine perception."},{"sentence_type":"2","sentence":"Unclear what we learn from the method.","rephrased":"It would be helpful to clarify the specific insights gained from the methods used in this paper."},{"sentence_type":"2","sentence":"Given the lack of benefit to analyzing the entropy, I am left to really just consider these methods to be image corruptions that downsample the resolution or desaturate the images.","rephrased":"It would be beneficial to discuss the advantages of analyzing entropy in more detail to distinguish these methods from standard image corruption techniques like downsampling resolution or desaturation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[590,624,"Confirmed"],[679,815,"Confirmed"],[1145,1183,"Confirmed"],[1433,1613,"Confirmed"]],"Comments":[]}
{"id":"4g8t-dZMv_","text":"Authors propose to apply information bottleneck to network structured data which is represented by graphs whose nodes are assigned features. \nThe idea seems promising but the authors need to improve their manuscript considerably. In particular, the probabilistic model underlying the IB framework needs to be made clear right from the start. Which random graphs do you consider ? \n\n- \"... GCN outputs the node embeddings X from the following process:... \" what does that mean ? \n- \"...the GIB seeks for the most informative yet compressed representation Z by optimizing the following objective .. \" what is the domain of the optimization problem here ? and what do you mean precisely by \"compresse representation\" ","sentences":[{"sentence_type":"2","sentence":"The idea seems promising but the authors need to improve their manuscript considerably.","rephrased":"The idea is promising, and there are opportunities for the authors to strengthen their manuscript further."},{"sentence_type":"1","sentence":"what does that mean ?","rephrased":"Could you please clarify what is meant by this process?"},{"sentence_type":"1","sentence":"what is the domain of the optimization problem here ? and what do you mean precisely by \"compresse representation\"","rephrased":"Could you specify the domain of the optimization problem and elaborate on what is meant by 'compressed representation'?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[142,229,"Confirmed"],[456,477,"Confirmed"],[599,713,"Confirmed"]],"Comments":[]}
{"id":"Hyl5XKfpKH","text":"This paper contributes a new dataset for testing label corruption robustness. The authors attempted to make the dataset represent \"real-world noise.\" The hamartia is that they used the \"search by image\" feature from Google, so that \"similar\" images were what is determined \"similar\" by a convnet. In this way it is not clear their noise is any more real than what is seen in previous works (such as the Gold Loss Correction paper which used labels from a weak classifier as a source of label noise). The hamartia also makes their experimental findings and takeaways about \"real noise\" questionable, as it is not clear they are testing real noise but consequences of properties of convnet embeddings. However this paper still contributes a dataset, hence this paper still is some sort of contribution. However, with this flaw, it is not clear that it is enough for ICLR.\n\nSmall things:\n\n> robust learning is experiencing a reminiscence in the deep learning era\nrenaissance?\n\n>  ImageNet architectures generalize well on noisy data when the networks are fine-tuned. Comparing the first and second rows in Fig. 2, we observe that the test accuracy for fine-tuning is higher than that for training from scratch on both Red and Blue noise\nThis section should cite _Using Pre-Training Can Improve Model Robustness and Uncertainty_ (ICML 2019) since that is a main conclusion of their paper.\n\n> Inception-ResNet-V2 (Szegedy et al., 2017) is used as the default network architectures\nUnfortunately they're probably using some form of Inception to compute image similarities, which was how the \"real noise\" dataset was curated.","sentences":[{"sentence_type":"2","sentence":"The hamartia is that they used the \"search by image\" feature from Google, so that \"similar\" images were what is determined \"similar\" by a convnet.","rephrased":"A potential limitation is the use of the \"search by image\" feature from Google, which relies on a convnet's definition of \"similar\" images. This approach may not fully capture the real-world noise the authors aim to represent."},{"sentence_type":"2","sentence":"However, with this flaw, it is not clear that it is enough for ICLR.","rephrased":"While the dataset is a valuable contribution, the concern regarding the methodology for generating 'real noise' might need to be addressed further to strengthen the submission for ICLR."},{"sentence_type":"1","sentence":"Unfortunately they're probably using some form of Inception to compute image similarities, which was how the \"real noise\" dataset was curated.","rephrased":"It would be helpful to clarify if a form of Inception was used to compute image similarities for curating the 'real noise' dataset, as this could influence the results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[150,296,"Not concerning"],[801,869,"Not concerning"],[1476,1618,"Confirmed"]],"Comments":[]}
{"id":"2lBrBGxZ187","text":"The authors propose to binarize weights and activations of generative VAE and Flow++ models. As Weight Normalization is commonly used in these models, the authors notice that Euclidean norm of binary [-1;1] vector is a square root of it’s length, such that Weight Normalization can be reduced to affine scaling. They propose to call this scaling Binary Weight Normalization, and evaluate it on CIFAR and ImageNet datasets.\n\nOverall, motivation for binarizing generative models is unclear. To the best of my knowledge, training such generative models is an active research topic, and, unlike in image classifiers, object detectors, language and translation models, are not applied in practice in real systems where execution time and memory footprint matters. Researchers who train such generative would not apply binarization as:\n- training such models is already difficult and optimization is often unstable, so adding an extra variable might make it even more difficult;\n- to keep baselines simple;\n- final execution time does not matter.\nIt is also very likely that, in case such generative models find applied use-cases where execution time and memory footprint would matter, they would have undergone several research iterations and updates such that new binarization techniques would need to be developed.\n\nAs affine scaling is no longer a weight normalization, it is probably incorrect to call it that. An experiment ablating an architecture with\/without the proposed binary weight normalization is missing. Also, as generative models are often evaluated qualitatively, the paper would benefit from including several samples from binarized models, to show that quality does not degrade.\n\nLiterature review also lacks several more recent binarization techniques such as [1] and [2] (more can be found there). It is not clear if one were to pick a simple (or more recent) binarization technique they would encounter difficulties.\n\nOverall, due to unclear motivation, introduction of binary weight normalization which is not weight normalization, and incomplete literature review I propose rejection.\n\n[1] Mark D. McDonnell, Training wide residual networks for deployment using a single bit for each weight, at ICLR 2018. \n[2] Gu et al. Projection Convolutional Neural Networks for 1-bit CNNs via Discrete Back Propagation, at AAAI 2019.","sentences":[{"sentence_type":"1","sentence":"Overall, motivation for binarizing generative models is unclear.","rephrased":"The motivation for binarizing generative models could be made clearer."},{"sentence_type":"2","sentence":"Researchers who train such generative would not apply binarization as:","rephrased":"Researchers who train such generative models may have reservations about applying binarization due to:"},{"sentence_type":"2","sentence":"final execution time does not matter.","rephrased":"final execution time may not be a primary concern."},{"sentence_type":"1","sentence":"It is also very likely that, in case such generative models find applied use-cases where execution time and memory footprint would matter, they would have undergone several research iterations and updates such that new binarization techniques would need to be developed.","rephrased":"Should such generative models find applied use-cases where execution time and memory footprint are significant, they may undergo several research iterations, potentially leading to the development of new binarization techniques."},{"sentence_type":"2","sentence":"As affine scaling is no longer a weight normalization, it is probably incorrect to call it that.","rephrased":"Considering that affine scaling differs from traditional weight normalization, it may be beneficial to reconsider the terminology used."},{"sentence_type":"3","sentence":"Overall, due to unclear motivation, introduction of binary weight normalization which is not weight normalization, and incomplete literature review I propose rejection.","rephrased":"In light of the unclear motivation, the unconventional use of the term 'binary weight normalization', and the incomplete literature review, I would recommend further revisions before considering acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[424,488,"Confirmed"],[759,829,"Confirmed"],[1003,1040,"Confirmed"],[1041,1311,"Not concerning"],[1313,1409,"Confirmed"],[1936,2104,"Confirmed"]],"Comments":[]}
{"id":"p_UyKCZ2gm","text":"***Strengths***\n1. The paper is easy to follow and the motivation is very clear.\n2. The topic is interesting and can attract much attention from industry research.\n3. The proposed method is intuitive and well-designed. The part of finding important tokens might benefit other research lines such as the over- and under-translation of NMT.\n\n***Weaknesses***\n1. In the paper, the authors repeatedly mention the relationship between NMT efficiency and output length. So, why not show the change of output length after the adversarial attacks? I think the sentence length is a more direct metric to evaluate NMT efficiency and is hardware-independent. \n2. A very simple solution to the attack is applying some constraints to the beam search process of NMT. For example, terminating the decoding when the output is twice the length of the input (please refer to --max-len-b of fairseq-generate). If a simple constraint can solve the issue, the contribution of the paper will be significantly decreased.\n3. Since the proposed method is more relevant to practical NMT systems, so, how about the results (Section 4.4) on Google translator or other online systems?\n\n**It would be nice if the authors could add some experimental results of the above weaknesses during the author response.**","sentences":[{"sentence_type":"2","sentence":"If a simple constraint can solve the issue, the contribution of the paper will be significantly decreased.","rephrased":"Implementing constraints in the beam search process, such as terminating the decoding when the output is twice the length of the input, could be an interesting area to explore and may provide a straightforward enhancement to NMT efficiency."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[891,997,"Not concerning"]],"Comments":[]}
{"id":"tXICHqIQmO2","text":"The paper presents the hypothesis that trained networks of subsequent IMP levels are linearly connected with a zero error barrier. Building on top of this idea, they present an adaptive pruning heuristic that suggests a pruning ratio in each pruning iteration.\n\nOverall, the paper presents an interesting study of the LTH phenomenon. The empirical analysis looks sound and is presented well.\nThe presentation of the paper could be improved in a few aspects (see below) but is good.\n\nFeedback:\n- Line 113 mentions that a pruning ratio of 10% is used, but Line 117 uses a minimum of 20%. Is there a reason to test 10% then?\n- Figure 4 is a bit confusing to me. It should probably be read from right to left since iterations of IWP reduce the number of weights remaining, right? What is the black line indicating? Shouldn't this be something like the original network's performance, e.g. what is achievable with 100% weights remaining? In the text, you mention that you need to retrain 7 instead of 11 times, but I am not sure exactly what this is comparing (perhaps you compare how many steps it took to reach a net with ~8% of weights?).\n- The figures are generally a bit small, stretching them to the full textwidth should help with readability. Perhaps the results on ResNet20 could be moved to the appendix.\n- The formatting of the References could be cleaned up. E.g., Line 160 uses all caps.\n- Section 2.1 is really difficult to understand. Perhaps connecting it more to Figure 1 or Figure 3 could help.\n\nNits:\n- Line 6: \"or a[n] early training stage\"\n- Line 77: \"we s[t]ill find\"\n- Line 93: \"ResNet-18 [trained] on CIFAR-100\"\n- Line 125: \"such[s] as ImageNet\"","sentences":[{"sentence_type":"2","sentence":"Section 2.1 is really difficult to understand.","rephrased":"Section 2.1 could benefit from additional clarity to enhance understanding."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1398,1444,"Confirmed"]],"Comments":[]}
{"id":"SpzxRdXMlMc","text":"This paper proposes an approach to learn an invariant casual representation to improve generalization in both imitation and reinforcement learning. The paper is well positioned for this workshop, and provides extensive theoretical support for results\n\nI unfortunately do not have much background on casual representation learning, and could not fully analyze the theoretical results. However -- I have a question for the authors. In practice, in many real world environments, there isn't a clear casual graph for a particular reward. For example, let's say the reward is making a cup a tea. What would be the appropriate casual representation to enable an agents to effectively make the cup of tea? How would you deal with partial observability in such a setting?","sentences":[{"sentence_type":"1","sentence":"I unfortunately do not have much background on casual representation learning, and could not fully analyze the theoretical results.","rephrased":"While my expertise in causal representation learning is limited, which restricted my ability to fully analyze the theoretical results, I am eager to understand more about how your approach addresses the challenges in this field."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[252,383,"Not concerning"]],"Comments":[]}
{"id":"S8Fku7gfLw","text":"This work proposed an approach that generates radiology reports from chest x-ray images by splitting pathology-related sentences and the others. The authors should run a model without the pathology(abnormal) sentence generation and show the results to shed some light on how much gains we actually obtain from doing that. The experimental setup should be more rigorous. Does the training\/validation\/test split guarantee no patient overlap across the subsets? Do the results of the other methods come from their papers or experiments reproduced by the authors?\n","sentences":[{"sentence_type":"1","sentence":"The experimental setup should be more rigorous.","rephrased":"To strengthen the study, the experimental setup could benefit from additional rigor."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[322,369,"Not concerning"]],"Comments":[]}
{"id":"rJgwL3sDKN","text":"Summary:\nThe authors design an architecture for building a geometry-aware latent representation of a scene, and test this by querying a view from the latent representation and comparing it with the actual view.\n\nThe paper is structured well, it is clear on what the authors would like to say. Recently geometry-aware architectures have gained importance, and the task for which the authors have shown results is promising.\n\nThe authors designed a geometry-aware deep neural network, and trained it on multiple (but limited) viewpoints of multiple scenes to make a 3D latent representation of each scene. They then query a novel viewpoint of each scene and make a prediction loss on that to train the network in a self-supervised manner.\n\nAlthough it is \"self-supervised\", it is not clear whether the \"novel\" viewpoints used while training are within the training set, because if they are not, then the training data is actually as big as the number of iterations used to train. It would be helpful if the authors could clarify on this.\n\nThe authors show that their architecture is able to give quality results for scenes with more objects than those on which the network was trained, which provides evidence to the generalizability of the network. This is a very good result, provided we are clear on the \"limited\"-ness of the training data.\n\nThe authors have compared their results with those of another recent architecture that tried to tackle the same problem. The results seem to be in favour of this paper, especially in the case of more objects in the scene. It is worth noting that the other method was not geometry-aware by design, as this paper is.","sentences":[{"sentence_type":"2","sentence":"Although it is \"self-supervised\", it is not clear whether the \"novel\" viewpoints used while training are within the training set, because if they are not, then the training data is actually as big as the number of iterations used to train.","rephrased":"It would be beneficial for the authors to clarify whether the 'novel' viewpoints used during training are part of the training set or external to it, as this has implications for the perceived size of the training data and the self-supervised nature of the approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[738,977,"Not concerning"]],"Comments":[]}
{"id":"SJe97j5FKr","text":"This paper proposes a “concise” version of the well-established Transformer model. The main proposal is to explicitly set the head size in the Transformer model instead of having to divide (share) representation ability amongst heads. \n\nThis paper is poorly written and after an entire 2-page long-winded introduction, the reader is left wondering what is the main contribution of this work. The term “concise” is also not well-defined and left vague to readers. I re-read this paper multiple times and the only concluding finding I have is that this paper proposes an explicit way of setting the projection dimension regardless of the number of heads. \n\nAfter many mathematical formulations, theorems (seemingly ornamental, or handwavy actually), the final contribution seems to be to set the head size of BERT (size of each head) to 128. This is really trivial. The authors kept teasing a “different” way to do this, but this left the reader completely unsatisfied when the different way refers to explicitly setting each head to 128 and using a smaller model overall. \n\nThe value 128 is derived from a theorem derived by the authors, which suggests that each head should at least be greater or equal than the sequence length (the sequence length here stated by the authors is 128). I’m not very convinced by the argument. While it is intuitive that each head has to be sufficiently large, being under-sized can be made up for with multiple heads. It is also not clear why every X and P must be expressed with transforms W_q and W_k. P here represents the affinity matrix between tokens in a sequence.  It does not make any sense to me to ensure that every variation of P can be expressed because P is literally the pairwise scores between every token in the fully-connected attention graph. \n\nWhile I did not have the luxury of time to parse the Appendix to validate the legitimacy of the proof, I think the overall shortcomings of the paper (highly non-readable, bad presentation and perhaps a fair attempt at masking the lack of contribution) warrants a clear reject from me. \n","sentences":[{"sentence_type":"2","sentence":"This paper is poorly written and after an entire 2-page long-winded introduction, the reader is left wondering what is the main contribution of this work.","rephrased":"The paper could benefit from a clearer and more concise introduction that directly leads to the main contribution of the work."},{"sentence_type":"3","sentence":"After many mathematical formulations, theorems (seemingly ornamental, or handwavy actually), the final contribution seems to be to set the head size of BERT (size of each head) to 128. This is really trivial.","rephrased":"The mathematical formulations and theorems presented could be better connected to the main contribution, which is setting the head size of BERT to 128. It would be helpful to clarify why this is not a trivial change and how it impacts the model's performance."},{"sentence_type":"2","sentence":"The authors kept teasing a \\","rephrased":"The paper could be improved by providing a clearer explanation of the proposed method without building unnecessary anticipation."},{"sentence_type":"3","sentence":"While I did not have the luxury of time to parse the Appendix to validate the legitimacy of the proof, I think the overall shortcomings of the paper (highly non-readable, bad presentation and perhaps a fair attempt at masking the lack of contribution) warrants a clear reject from me.","rephrased":"Although I was unable to thoroughly review the Appendix, the paper could be improved in terms of readability and presentation. A more transparent demonstration of the contribution would be beneficial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[237,391,"Confirmed"],[655,863,"Confirmed"],[1796,2080,"Confirmed"]],"Comments":[]}
{"id":"bXQdGqYlDN","text":"Quality:\n\nThe quality of the paper is good overall. The authors present an approach to estimating COVID-19 snapshots using a modified Network Scale-up Method (NSUM) and validate their estimates against official data. The data preprocessing stage helps enhance the reliability of the collected data, and the privacy preservation aspect adds value to the study. However, there are some limitations, such as the lack of comparisons with other estimation methods or its limited generalizability.\n\nClarity:\n\nThe paper is generally well-written and presents the information in a clear manner but does have a few typos and items which could have been explained some more. The introduction provides adequate background information about the need for indirect survey methods and the challenges associated with official COVID-19 data. The methodology section explains the data preprocessing techniques well, but could benefit from further clarification. For example, the NSUM technique is only cited but not explained anywhere, and also the choice of setting ri=15 is not justified (why not 5 or 10?).\n\nOriginality:\n\nThe paper cites that the use of indirect surveys to estimate different variables using NSUM is not something new, it also cites that this has also been done for estimating different indicators during the COVID-19 pandemic. \n\nSignificance:\n\nThe significance of this work lies in its potential to provide valuable insights into COVID-19 indicators, especially in settings where official data is limited or unreliable. The indirect survey method offers a practical solution to estimate important epidemiological information, which can aid decision makers and researchers in understanding the spread of the disease and acting accordingly. The paper's comparison with official data and validation of estimates add credibility to its findings, further highlighting its significance.\n\nPros:\n\n- Justification for Indirect Surveys: The paper provides a strong rationale for using indirect surveys, highlighting privacy preservation and other benefits.\n\n- Validated and Discussed Results: The paper presents well-validated results and provides a comprehensive discussion of the findings.\nUse of Cronbach's Alpha Coefficient: The paper employs Cronbach's alpha coefficient, a reliable measure of internal consistency, enhancing the robustness of the analysis.\n\n- Acknowledgment of Sample Size Limitation: The paper recognizes the limitation of the sample size and discusses its potential impact on the accuracy and generalizability of the estimates.\n\n- Data Preprocessing Stage: The paper includes a well-described data preprocessing stage, which enhances the reliability and quality of the collected data.\n\n\nCons:\n\n- Need for Comparison to Validate Modifications and NSUM Choice: The paper should include a comparison with other methods to validate the modifications made and the selection of the Network Scale-up Method (NSUM).\n\n- Insufficient Elaboration on NSUM and Choice of \"ri\": The paper should provide more explanation and elaboration on NSUM and the selection of \"ri\" to improve reader understanding.\n\n- Limited Generalizability: The study's focus on a specific time period and a restricted set of countries (China, Australia, and the UK) limits the generalizability of the results to other countries and different time periods.\n\n- Few typos: 1- Typo in mortality rate, should be 0.72 not 0.22 based on table (line 218 right column).  2- Variable naming is either not consistent or not explained sufficiently in equations 1 and 2, would be good to clarify here what the \"a\", \"b\", \"alpha\", and \"beta\" variables represent\n\n\nIn summary, this paper presents a good approach to estimate COVID-19 indicators using the Network Scale-up Method. While it has strong results, there are also limitations to consider. Further elaboration could address a lot of these limitations.","sentences":[{"sentence_type":"1","sentence":"The paper should include a comparison with other methods to validate the modifications made and the selection of the Network Scale-up Method (NSUM).","rephrased":"It would be beneficial for the paper to include a comparison with other methods to further validate the modifications made and the selection of the Network Scale-up Method (NSUM)."},{"sentence_type":"1","sentence":"The paper should provide more explanation and elaboration on NSUM and the selection of \"ri\" to improve reader understanding.","rephrased":"Providing additional explanation and elaboration on NSUM and the selection of \"ri\" would enhance reader understanding."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[2777,2925,"Not concerning"],[2982,3106,"Not concerning"]],"Comments":[]}
{"id":"HkgdPJ_9hQ","text":"Summary:\nThis paper presents a framework for generating adversarial perturbations for videos. Specifically, the paper proceeds by using a standard image-based adversarial noise generation setup (such as the FGSM scheme), and applies it to the motion stream of a two-stream action recognition pipeline; this motion stream typically using optical flow images. As such flow generation is usually done offline and thus is not differentiable, the paper resorts to the recent FlowNet 2.0 scheme that uses an end-to-end learnable deep flow generation model. Three variants of the scheme are provided, (i) that perturbs all frames in a flow stack, (ii) that perturbs only a sparse set of frames as decided by the importance of a frame to action classification, and (iii) a variant of (ii) that recalculates the gradients for all frames if the ones selected in (ii) were not adversarial. Experiments are provided on UCF101 dataset and show promise. Analysis is presented on the transferability of  the learned noise to flow images generated via external means.\n\nStrengths:\n1) The different variants of the scheme and sparse selection of the frames to be perturbed are interesting. \n2) The paper makes some interesting observations, namely that (i) only a single frame perturbation might be sufficient to make the video adversarial, and (ii) perturbations computed via FlowNet models are not transferable to those with flow computed via external software -- which is often the practice.\n\nWeaknesses:\n1) I think the main weakness of this paper is the lack of any surprise\/significant novelty in the presented approach. The main idea follows the common trend in adversarial noise generation for image classification problems, except that the inputs are a stack of frames instead of  a single one; however, such a setting do not seem to bring along any non-trivial challenges. In the second contribution of this paper -- on the sparse selection of frames to attack, there is a lack of clarity in how one would do the iterative attacks at test time, given such sparse frame selection is done via computing the frame level saliency values via the classification loss, which depends on ground truth class labels, which are unavailable at test time. \n\n2) There are previous works that have attempted video level adversarial perturbation generation, which the paper do not cite or contrast to; such as a few below. Further, the literature survey fails to provide any compelling motivation as to why video perturbation generation is any difficult than image based noise generation -- it does not appear so from the subsequent text that this problem deserves any special treatment in the considered context.\n[a] Learning Discriminative Video Representations Using Adversarial Perturbations, Wang and Cherian, ECCV 2018\n[b] Sparse Adversarial Perturbations for Videos, Wei et al., arxiv, 2018\n\n3) It is unclear why the paper chose to consider flow produced by a FlowNet model as their inputs for the attack? Why not consider the flow images directly? Of course, the optical flow algorithm may not be differentiable, but that is perhaps besides the point; the focus should be in perturbing flow, in whatever way it is generated. To that end, given that flow (on static camera images) can be sparse, it would be interesting to see how would a perturbation be generated that needs to operate on local regions (where motion happens). In my opinion, using a FlowNet model for flow generation trivializes the proposed algorithm.\n\n4) It could have been interesting if the paper also provided some qualitative results of the optical flow images generated by FlowNet after adding perturbations to the input frames. Are these flow images also quasi-impercitable? \n\nOverall, I think the paper has some observations that may be slightly interesting; however, it lacks novelty and the analysis or presentation are unconvincing.","sentences":[{"sentence_type":"2","sentence":"I think the main weakness of this paper is the lack of any surprise\/significant novelty in the presented approach.","rephrased":"The main weakness of this paper appears to be the incremental nature of the novelty in the presented approach."},{"sentence_type":"1","sentence":"It is unclear why the paper chose to consider flow produced by a FlowNet model as their inputs for the attack? Why not consider the flow images directly?","rephrased":"The rationale for choosing flow produced by a FlowNet model as inputs for the attack over direct flow images could be further clarified."},{"sentence_type":"3","sentence":"In my opinion, using a FlowNet model for flow generation trivializes the proposed algorithm.","rephrased":"Using a FlowNet model for flow generation may simplify the proposed algorithm, which could be addressed in further discussions."},{"sentence_type":"2","sentence":"Overall, I think the paper has some observations that may be slightly interesting; however, it lacks novelty and the analysis or presentation are unconvincing.","rephrased":"Overall, while the paper presents some interesting observations, it would benefit from a more robust analysis and a clearer presentation to strengthen its claims of novelty."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1493,1607,"Confirmed"],[2876,3029,"Not concerning"],[3409,3501,"Confirmed"],[3734,3893,"Confirmed"]],"Comments":[]}
{"id":"xD7mayFdceR","text":"Summary:\nThis paper proposes to account for an additional source of uncertainty during inference, i.e., the uncertainty introduced by the optimization algorithm. The paper uses a neural network to parameterize the optimization algorithm, and proposes intuitive and heuristic techniques for inferring its posterior distribution.\n\nStrong points:\n- The paper provides a novel perspective by considering the uncertainty introduced by the optimization algorithm, which is novel as far as I know.\n- The experiments cover a diverse set of applications, which indeed showcases the generality of the proposed algorithm.\n\nWeak points:\n- Since the main contribution of the paper is accounting for the uncertainty introduced by the optimization algorithm which is very novel, I think a more rigorous definition of this source of uncertainty is needed. In particular, I think the paper needs a clear definition and illustration of $p(g(\\cdot)|\\mathcal{D})$ which is the ultimate distribution the paper is trying to approximate. Analogously, in standard posterior inference, $p(\\omega|\\mathcal{D})$ is defined through the prior $p(\\omega)$ and likelihood $p(\\mathcal{D}|\\omega)$ which links the observed data $\\mathcal{D}$ and the model parameter $\\omega$ by defining how likely $\\mathcal{D}$ is generated by a given $\\omega$. However, I don't see such a clear link if I replace $\\omega$ by $g(\\cdot)$: how should the likelihood $p(\\mathcal{D}|g(\\cdot))$ be interpreted? Does this mean the choice of the optimization algorithm affect how the observed data is generated?\n- Section 2, first paragraph: it says here that for these Bayesian optimization algorithms, \"significant approximation is needed\". But I wonder whether this can be framed as a disadvantage of these algorithms? I think it should not be a disadvantage as long as these approximations deliver good performances. Also it would be interesting to see the proposed method applied to Bayesian optimization, although this is not an important point.\n- The paper measures the quality of the solution $\\hat{\\omega}$ by $||\\hat{\\omega}-\\omega^*||$ (Equation 3 and in the experimental results). However, I think this may not be very appropriate and $||f(\\hat{\\omega})-f(\\omega^*)||$ would be a better measure, because if $f$ is very non-smooth, even if $||\\hat{\\omega}-\\omega^*||$ is small, $f(\\hat{\\omega})$ may be very large.\n- I think many design choices of the algorithm are too heuristic and lack a rigorous justification. For example, at the bottom of page 3, it is claimed that \"it is important to optimize the following loss\" of Equation 5, but why? Also, defining the different objective functions $f_j(\\cdot)$ by different mini-batches (Equation 6) seems like a convenient and arbitrary choice, and doesn't seem very rigorous. This further calls into question the reliability of the experimental comparisons, since it seems that there isn't a rigorous way to choose these objective functions (I think referred to as \"meta-training set\/objectives\" in the Experiments section), and different choices may affect the performance (this should be explored empirically if possible).\n- For experiments, most baselines under comparison are non-Bayesian methods. This doesn't seem very appropriate since the goal of the paper is to learn a better $p(\\omega^*|\\mathcal{D})$ (Equation 4) which is a distribution. I think more Bayesian methods than non-Bayesian methods should have been compared with. For example, for the image classification experiment, the only Bayesian method under comparison is the VI paper from 2015, since then, there have been a number of more recent works on Bayesian neural networks, and it would be better if more comparisons with BNN is performed.\n- In the experimental comparisons, the paper claims that a tighter confidence bound $r_{\\sigma}$ is better. However, I think this may not be the case. For example, if we are training a Bayesian neural network using a very small dataset, then the posterior $p(\\omega^*|\\mathcal{D})$ isn't supposed to be concentrated right?\n- Table 2: It seems without the curriculum learning trick (which is not a main contribution of this paper), BL2O is significantly outperformed by Adam.\n\nMore minor points:\n- Section 2, first paragraph, third line: here \"Bayesian optimization\" should be replaced by some specific instances of Bayesian optimization algorithms such as predictive entropy search, since what's described here isn't how a generic BO algorithm works but only some BO algorithms. It could be misleading to some readers not familiar with BO.\n- Section 2, last paragraph: I think this paragraph (maybe except for the first sentence) should belong to the end of Introduction instead of here.\n- Figure 1: Error bars should be included.\n\n\n----------------------Update After Rebuttal----------------------------------\n\nI appreciate the response from the authors, and the authors' efforts in significantly revising the Method section. The Method section in the current version looks much better and clear. Most points from the authors' response are reasonable, and some of my concerns are indeed cleared, such as my questions regarding the use of $||\\hat{\\omega}-\\omega^*||$ instead of $||f(\\hat{\\omega})-f(\\omega^*)||$. However, in the revised paper, I still find a few places questionable, so I still have a few concerns which are still about the first and fourth points I raised in my original review:\n\n- In Definition 3.2 of the revised paper, I find this definition of optimal optimizer $g^*$ not fully convincing. I understand that this definition of $g^*$ naturally gives rise to the $F(\\theta^*)$ as in the first line of page 5, however, since our problem is an optimization problem (i.e., to minimize $f$), I think the summation in the definition of $g^*$ should be replaced by minimization. The current definition of using a summation over different iterations could lead to problems in some scenarios. For example, imagine we have optimizer B who quickly converges to a local minimum, and optimizer B who explores the entire search space first (encountering many large $f$ values along the way) and finally converges to the global minimum. Then according to this definition, optimizer A is likely to be defined to be better than optimizer B, which is incorrect. Moreover, another problem with the current definition is that the initialization $\\omega^1_g$ is not specified. I feel that for the sake of defining the optimal optimizer, the argmin over all optimizers $g\\in\\mathcal{G}$ should be based on the same initialization for all optimizers, i.e., $\\omega^1_g$ is the same for all $g\\in\\mathcal{G}$. Since I imagine that for different initializations, the optimal optimizer could be different.\n\n- Equation (5) on page 4, I think the distribution of the initial point $p(\\omega^1_{\\theta^*})$ should appear on the Right Hand Side. Because given the optimizer $\\theta^*$, the distribution of the trajectory $\\mathcal{D}$ clearly depends on the initialization. This may not be a serious problem since $p(\\omega^1_{\\theta^*})$ could be factored into the normalization constant of $p(\\theta^*|\\mathcal{D})$.\n\n- Section 3.6, I still find the motivation for using the Meta-Training Set heuristic. It is stated here that the meta-training set is introduced here to improve the robustness and generalizability of solutions, which seems unrelated to the main objective of quantifying optimizer uncertainty. I think (not sure though) a better motivation could be related to uncertainty regarding the function $f$.\n\n- Although the objective of the paper is to \"further\" consider the uncertainty regarding the optimizer, I feel that the introduced method ONLY considers optimizer uncertainty, and hasn't dealt with $p(\\omega^*|\\mathcal{D},g)$ in a rigorous way. If I understand correctly, samples from $p(\\omega^*|\\mathcal{D},g)$ are obtained by running optimizer $g$ for multiple random initialization points (line 5 of Section 4), and I find this kind of heuristic.\n\nOverall I find this paper very interesting mainly due to the novel perspective of considering this additional source of uncertainty, so although I cannot recommend for acceptance this time, I believe it will be a valuable contribution to the community if the problem formulation can be made more rigorous.\n","sentences":[{"sentence_type":"2","sentence":"I think many design choices of the algorithm are too heuristic and lack a rigorous justification.","rephrased":"The design choices of the algorithm appear to be heuristic; a more rigorous justification could enhance the paper's contribution."},{"sentence_type":"2","sentence":"This further calls into question the reliability of the experimental comparisons, since it seems that there isn't a rigorous way to choose these objective functions.","rephrased":"It would be beneficial to clarify the methodology for choosing these objective functions to strengthen the reliability of the experimental comparisons."},{"sentence_type":"1","sentence":"This doesn't seem very appropriate since the goal of the paper is to learn a better $p(\\omega^*|\\mathcal{D})$ (Equation 4) which is a distribution.","rephrased":"It may be more aligned with the paper's goals to compare with additional Bayesian methods, given that the paper aims to learn an improved distribution $p(\\omega^*|\\mathcal{D})$ (Equation 4)."},{"sentence_type":"1","sentence":"However, I think this may not be the case.","rephrased":"However, there could be scenarios where a tighter confidence bound $r_{\\sigma}$ might not necessarily indicate a better outcome."},{"sentence_type":"2","sentence":"It seems without the curriculum learning trick (which is not a main contribution of this paper), BL2O is significantly outperformed by Adam.","rephrased":"The results suggest that the performance of BL2O without the curriculum learning aspect, which is not a primary focus of this paper, is not as strong as that of Adam."},{"sentence_type":"1","sentence":"I still find a few places questionable, so I still have a few concerns which are still about the first and fourth points I raised in my original review:","rephrased":"There are still some aspects that I find unclear, particularly related to the first and fourth points from my original review, which I believe could be further addressed:"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2372,2469,"Confirmed"],[3205,3352,"Not concerning"],[3825,3867,"Not concerning"],[4051,4191,"Not concerning"],[5261,5413,"Not concerning"]],"Comments":[]}
{"id":"KFvcR3oU-6","text":"The paper examines to what extent the fundamental language models, namely, Luminous, GPT3 and OPT, can talk about causality. By answering the question concerning \"is there a correlation\" and \"is there a causation\", the models are tested on various scenarios and some interesting results are reported.\n\nI like the idea of exploring causality from the language models. This is a novel and interesting research direction. I have several concerns considering the current version of the paper.\n\n1. It seems that the paper is experimental only. The authors may consider to answer more question or provide more insights about the problems like \"is there any theory that can explain the results?\" \"where does the difference between multiple language model come from?\" \"How reliable the current shown results are?\". If intended to do conduct research on experimental level, a more systematical experiments are better and would be more appreciated.\n\n2. Some important experimental details are lacking. It is known that performance of AI models are sometimes sensitive to the model architecture, parameters such as learning rates etc. The authors should put down more details so that the readers can better interpret the results. It would also be better to compare the differences of the language models on architecture level, so that more insights of where the difference come from and how much causal information is captured, can be provided. It would be also useful to show if variance of the performance exist, by conducting experiments using different level of randomness.\n","sentences":[{"sentence_type":"2","sentence":"It seems that the paper is experimental only.","rephrased":"The paper presents an interesting experimental approach. To enhance the study, the authors might consider incorporating theoretical insights or a broader range of questions to deepen the understanding of the results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[493,538,"Confirmed"]],"Comments":[]}
{"id":"kiZrlvGjzd5","text":"This paper studies transfer learning, and in particular studies how full fine-tuning compares against feature extraction in different settings, resulting in insightful advice on which approach to use for what kinds of problems. The paper is well written and easy to follow, and presents results that will be useful to the community.","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"BU5e7Q0PFWc","text":"This paper decompose the representations of the operators into patch mixing and channel mixing, and propose an interesting idea of using reweighting mask to improve the representations of the cross-patch mixing. The proposed Remixer leverages the differences between patches. It can be applied to self-attention, linear and conv layers. The experiments demonstrate the effectiveness of the proposed approach on background challenge. \n\nThe proposed  method has very limited domain to apply due to requirement of patch wise labels. Therefore, it can't be generalized to other major CV problems. The experiments are not comprehensive. It is unclear whether the improvement is due to the extra supervision or increasing the compute or mainly be the proposed representations. \n\nI am around the borderline. Despite the weakness of this work, there is no significant issue for this work (e.g. technically incorrect or off-topic). I rate this paper as \"Accept\".","sentences":[{"sentence_type":"2","sentence":"The proposed  method has very limited domain to apply due to requirement of patch wise labels.","rephrased":"The applicability of the proposed method may be somewhat limited by the requirement for patch-wise labels."},{"sentence_type":"2","sentence":"Therefore, it can't be generalized to other major CV problems.","rephrased":"As a result, there may be challenges in generalizing this method to other major computer vision problems."},{"sentence_type":"2","sentence":"The experiments are not comprehensive.","rephrased":"The experiments could be expanded to further validate the comprehensiveness of the results."},{"sentence_type":"1","sentence":"It is unclear whether the improvement is due to the extra supervision or increasing the compute or mainly be the proposed representations.","rephrased":"It would be beneficial to clarify whether the observed improvements are attributable to the extra supervision, increased computation, or primarily the proposed representations."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[435,529,"Confirmed"],[530,592,"Confirmed"],[593,631,"Confirmed"],[632,770,"Maybe"]],"Comments":[]}
{"id":"7_XKiTKaKZ","text":"I found the paper easy to read and containing interesting results about how some baseline models ourperform more sophisticated ones. I am recommending acceptance, but I have some remaining doubts that I would like to be answered, if possible. Namely:\n1) I do not see very clearly from the text what the authors mean by joint learning. I believe Figure 1 could serve the purpose of actually clarifying what is happening in each scenario; unfortunately, it has a very poor caption. Could the authors add a short description of each of the four schemes in that caption, and label them as a), b), c), and d)? I believe that would help a lot.\n2) I don't understand this sentence \"the lesion class is under-represented\". I guess it is because of the use of the word \"class\", which makes the reader think about classification. Do you actually mean \"slices containing liver lesions were under-represented as opposed as lesion-free slices\"? Because later in the text, the number of examples for each lesion class is mentioned, and they seem pretty balanced. Anyway, if what I am saying is the case, are you using weighted cross-entropy, rather you are oversampling slices with lesions during training?","sentences":[{"sentence_type":"2","sentence":"unfortunately, it has a very poor caption.","rephrased":"however, the caption could be improved for clarity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[437,479,"Confirmed"]],"Comments":[]}
{"id":"SJ9vIX-54","text":"The paper extends the FID metric used for evaluating generative sample quality to video generation. They use I3D network that generalises the Inception architecture to sequential data. The paper provides extensive comparison with other baseline method and does a thorough human evaluation to show that their proposed metric has significant consensus with human evaluation.  ","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"BylIU-_KFH","text":"The paper studies the mean and variance of the gradient norm at each layer for vanilla feedforward, ResNet and DenseNet, respectively, at the initialization step, which is related with Hanin & Ronick 2018 studying the mean and variance of forward activations. They show that ResNet and DenseNet preserve the variance of the layer gradient norm through depths. In comparison, for the vanilla feedforward network, although the mean of the gradient norm is preserved if  is properly initialized, the variance of the layer gradient norm increases over depths, which may explode or decay the gradient at deeper layers. \n\nThe result presented in the paper is interesting, and the theory and empirical verification have a good match. I  recommend the acceptance after the following points are well addressed.\n\n1. The mean and variance of layer activation norm and gradient norm have been studied in the mean field literatures for example [1] and the paper does not have a good comparison with them.\n2. The experiment of  CONCATENATIVE RELU is not convincing given the small tasks intertwined performance.\n\nMinor presentation flaws:\n1. The sentence in Abstract \"This depth invariant result is surprising in light of the literature results that state that the norm of the layer’s activations grows exponentially with the specific layer’s depth.\" is not clear itself because of no relevant reference.\n2. There are many typos such as \"weather\", \"for of\" in the paper. Please carefully correct them.\n3. The values on the y-axis of Figure 2 and Figure3 are not correctly shown.\n\n[1] Greg Yang and Samuel Schoenholz 2017. Mean Field Residual Networks: On the Edge of Chaos\n\n\n#####after rebuttal period, I found a fatal error in the paper#####\n\nIn (13), the network output $y_t^L$ is decomposed into two parts $y^{L,k}_t$ and $\\hat{y}^{L,k}_t$, where $y^{L,k}_t$ is composed of paths that go through weight matrix $W^k$ and $\\hat{y}^{L,k}_t$ is composed of paths that skip weight matrix $W^k$.\n\nIn (14), the paper derives $J^k:=\\frac{\\partial y_t^L}{\\partial W^k} = \\frac{\\partial y^{L,k}_t}{\\partial W^k}$. However, in fact the other part $\\hat{y}^{L,k}_t$ also has gradient with respect to  $W^k$ even if the path $\\gamma_t$ does not go through $W^k$ because the activation $z_{\\gamma_t}$ is a function of  $W^k$ .\n\nWith this error, all the following claims in the paper are wrong. Thus I vote to reject this paper.  \n\nOne can do experiment to verify  that \"Thm. 1 also reveals a surprising property of the gradients in general Relu networks. That is, when the weights are sampled from the same distribution in each layer, the gradient’s magnitude for each layer are equal in expectation, and depend only on the output statistics.\" is wrong for ResNet.","sentences":[{"sentence_type":"2","sentence":"The experiment of  CONCATENATIVE RELU is not convincing given the small tasks intertwined performance.","rephrased":"The experiment involving CONCATENATIVE RELU could be strengthened by addressing the potential confounding factors due to the small scale of the tasks used."},{"sentence_type":"3","sentence":"With this error, all the following claims in the paper are wrong.","rephrased":"This error raises concerns about the validity of the subsequent claims in the paper, which may need to be re-evaluated."},{"sentence_type":"1","sentence":"Thus I vote to reject this paper.","rephrased":"Therefore, I would recommend a reassessment of the paper's findings in light of this issue before considering acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[995,1097,"Not concerning"],[2303,2368,"Confirmed"],[2369,2402,"Not concerning"]],"Comments":[]}
{"id":"ryxKyu6mK4","text":"The paper proposes a re-ranking function to improve program generation on the task of answering questions that use tables as context.\n \nPros:\n1- Interesting task that deserves our attention because of its practical applications.\n2- The ablation study nicely justifies the extra inputs.\n\nCons:\n1- The paper is hard to understand. Also, it contains some typos and grammatical errors.\n2- 0.9-1.1% is a small improvement over MAPO.\n\nQuestions:\n1- If the final score given by NPP is the sum of token values in the candidate program, how do you prevent longer programs to have higher scores?\n2- Did you have to subtract the reward by a baseline to train the search policy with REINFORCE?","sentences":[{"sentence_type":"2","sentence":"The paper is hard to understand. Also, it contains some typos and grammatical errors.","rephrased":"The paper could benefit from additional clarity in some sections, and proofreading to correct typos and grammatical errors."},{"sentence_type":"1","sentence":"0.9-1.1% is a small improvement over MAPO.","rephrased":"While the improvement over MAPO is modest, it would be helpful to discuss the potential impact of this improvement in practical scenarios."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[296,381,"Confirmed"],[385,427,"Not concerning"]],"Comments":[]}
{"id":"S1gUeQYchm","text":"Summary:\nThis paper proposes a novel method for generating novel molecules with some targeted properties. Many studies on how to generate chemically valid molecular graphs have been done, but it is still an open problem due to the essential difficulty of generating discrete structures from any continuous latent space. From this motivation, the 'constrained' Bayesian optimization (BO) is applied and analyzed. Posing 'constraints' on the validity is realized by probability-weighting onto the expected improvement scores in BO. The 'validity' probability is learned beforehand by Bayesian neural nets in a supervised way. As empirical evaluations, two case studies are presented, and quality improvements of generated molecules are observed.\n\nComment:\n- The presentation would be too plain to find what parts are novel contributions. Every part of presentations seems originated from some past studies at the first glance. \n\n- In this paper, how to pose the validity 'constraint' onto Bayesian optimization would be the main concern. Thus if it is acquired through supervised learning of Bayesian neural nets in advance, that part should be explained more in details. How do we collect or setup the training data for that part? Is it valid to apply such trained models to the probability weighting P(C(m)) on EI criteria in the test phase? Any information leakage does not happen?\n\n- The implementations of constrained BO is just directly borrowed from Gelbart, 2015 including parallel BO with kriging believer heuristics? The description on the method is totally omitted and would need to be included.\n\n- How training of Bayesian neural nets for 'Experiment II' are performed? What training datasets are used? Is it the same as those for 'Experiment I' even though the target and problem are very different?\n\nPros:\n- a constrained Bayesian optimization with weighing EI by the probabilities from pre-trained Bayesian neural nets applied to the hot topic of valid molecule generations.\n- Experiments observe the quality improvements\n\nCons:\n- unclear and insufficient descriptions of the method and the problem\n- novel contributions are unclear\n","sentences":[{"sentence_type":"2","sentence":"The presentation would be too plain to find what parts are novel contributions.","rephrased":"It would be helpful if the presentation more clearly highlighted the novel contributions of the work."},{"sentence_type":"2","sentence":"Every part of presentations seems originated from some past studies at the first glance.","rephrased":"At first glance, it appears that many aspects of the presentation may have been influenced by previous studies; it would be beneficial to clarify what distinguishes this work."},{"sentence_type":"2","sentence":"The description on the method is totally omitted and would need to be included.","rephrased":"Including a more detailed description of the method would enhance the paper's clarity and completeness."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[756,835,"Confirmed"],[836,924,"Maybe"],[1525,1604,"Confirmed"]],"Comments":[]}
{"id":"_4X2KRBAW2n","text":"This paper claims that in the context of multi-class image classification using neural networks, in the final classification layer, if we use randomly initialized parameters (with normalization) without any training, we can achieve better performance than if we train those parameters. This is an intriguing claim that can potentially have a very broad impact. The authors provide some motivations based on the error-similarity plots, but no theoretical backing. Without convincing theoretical support, such a claim can only be established through extensive and rigorous experimentation, and I find the experiment description in this paper is short on delivering strong evidence. For example, how many runs to achieve the results in Tables 1-3? What are confidence intervals on the results?  Any statistical significance test done? How were hyperparameters selected?  What about the performance on the ImageNet dataset, which has more classes than the datasets reported in the paper? What distribution was used to initialize the random weights in the classification layer? Is the performance sensitive to the distribution? Is the performance sensitive to the complexity of the model used to learn the representation? How does this compare to other ways of improve multi-class classification such as softmax temperature annealing, label smoothing, adding regularization, etc.? Or as a stretch, does this claim generalize to problems with categorical features?\n\nDetails:\n1. page 2, line 9: do you mean \"maximizing the cosine-similarity\"?","sentences":[{"sentence_type":"2","sentence":"Without convincing theoretical support, such a claim can only be established through extensive and rigorous experimentation, and I find the experiment description in this paper is short on delivering strong evidence.","rephrased":"While the claim is intriguing, it would benefit from additional theoretical support or more comprehensive experimental validation. The current description of the experiments could be expanded to provide stronger evidence for the claim."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[463,679,"Maybe"]],"Comments":[]}
{"id":"gTcuXHpdJy","text":"Strengths:\nI think the paper is tackling an important aspect of the contextual bandit problem, aiming for flexible function classes and efficient implementation. The idea of utilizing regression oracles has been proposed previously, but the authors focused on designing an algorithm that is efficiently implementable for practical usage.\n\nThe generalization of linear bandit is also nice and makes sense.\n\nWeaknesses:\nFirst, the authors argue that \"the availability of such optimization oracle [for solving Eq.(2)] is a very mild assumption in practice.\" In practice, there are algorithms to \"approximately\" solve Eq.(2). To exactly solve for possible non-convex function $f_\\theta$ is not mild. The regret analysis is based on exactly solve Eq.(2). If one allows for approximate solutions for the optimization problem that the paper presents, then it would be fair to allow for similar approximate solutions for the previous works that the authors criticize for not having tractable solutions.\n\nAnother drawback is the lack of comparisons with more recent work including  Foster & Rakhlin, (2020) and Simchi-Levi & Xu (2020). The authors mention Foster & Rakhlin, (2020) once in the introduction but do not directly compare with their algorithm and results despite the fact that it is also a regression oracle-based algorithm with flexible function classes. The paper does not mention Simchi-Levi & Xu (2020) at all, which uses a regression oracle under realizability assumption.\n\n#References\nSimchi-Levi, David, and Yunzong Xu. \"Bypassing the monster: A faster and simpler optimal algorithm for contextual bandits under realizability.\" Available at SSRN 3562765 (2020).\n","sentences":[{"sentence_type":"2","sentence":"To exactly solve for possible non-convex function $f_\\theta$ is not mild.","rephrased":"Solving exactly for potential non-convex functions such as $f_\\theta$ may not be a trivial assumption in practice."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[622,695,"Not concerning"]],"Comments":[]}
{"id":"N2PQVS7cw1b","text":"**Summary:** This paper proposes a pipeline for image classification that allows\nincorporating symbolic domain knowledge. The approach is applied to an MNIST\nvariant where handwritten digits are supposed to be classified given their\n(weighted) sum.\n\n**Strengths, Weaknesses & Questions:**\n- In general, the paper is well-written with a clear and thoughtful structure.\nThe contributions are clear and put into context by referencing relevant related\nwork.\n- Figure 3, line 84-91: The pseudo-code in Figure 3 and the corresponding\ndescriptions in line 84-91 are not understandable to me. A lot of the components\n(like `Ex`, `Unres`, `getUnres`, `resolve` and `img`) are not mentioned in the\ntext at all. If I understand correctly, this is the step, where the symbolic\nconstraint is incorporated but I don't understand where exactly and how it is\nused.\n- Line 92-93: I don't understand why this step is needed. In step 3, every image\nis assigned a label. Isn't that the ultimate goal of the pipeline? \n- Footnote on page 3: I think it is *crutial* to explain how exactly the\nautoencoder is trained since it is used for all $w \\times h$ runs. If I\nunderstand correctly, the difficulty of the problem is dependent on $w$ and $h$.\nPutting it very negatively: If you make it \"easy\" for the autoencoder, e.g. by\nusing $w=h=1$, the good results for the \"hard\" problems (large $w$ and $h$)\nmight be simply due to the well-working auto-encoder\/clustering. \n- Figure 4: I think it would be interesting to isolate the impact of\nincorporating the symbolic constraint on the classification accuracy. In step 3,\neach image is assigned the label of its cluster. What happens if you skip the\nsubsequent step (using the constraints to detect and fix wrong labels) and\ndirectly go to step 4? This way you could show what the effect of your *image\nlabel improvement algorithm* (Figure 3) is.\n- Line 149-150: You claim that your approach scales better than most recent\napproaches in terms of training time. However, you do not provide the training\ntime for any other approach. I'd suggest adding a baseline to your experiments: a\ncommonly used method from the literature. \n\n**Minor:**\n- Line 18-19: If I understand correctly, you claim in this section that\nincorporating domain knowledge as symbolic constraints is especially useful when\nconstraints are too complex to be learned by an ML model. I'm a bit skeptical\nabout that statement since e.g. neural networks are so successful because they\n*can* learn structure that would be hard to put into a symbolic expression.\n- Line 22: What exactly does *high scalability* refer to? Is it the amount of\ndata that has to be processed, the complexity of the task or something else?\n- Line 60: You mention here that the runtime of your approach is linear. \nAccording to Figure 4, it is *constant*.\n- Line 67: I think, the formula is not correct: For $w=2$, $j \\in \\{1, 2\\}$\nyields the exponents $w-1-j = 0$ and $-1$ (where it should be $1$ and $0$).","sentences":[{"sentence_type":"2","sentence":"Putting it very negatively: If you make it \"easy\" for the autoencoder, e.g. by using $w=h=1$, the good results for the \"hard\" problems (large $w$ and $h$) might be simply due to the well-working auto-encoder\/clustering.","rephrased":"It would be beneficial to clarify how the autoencoder's performance with different values of $w$ and $h$ might influence the overall results, as the difficulty of the problem varies with these parameters."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1225,1445,"Not concerning"]],"Comments":[]}
{"id":"rUcl2Q2GRWq","text":"\nThe method proposed in this paper seems better than some other methods in the presented quantitative results. Moreover, it only uses two frames of image information to achieve these good results which is less costly. This method also shows strong generalization in unseen objects and unseen datasets. However, I think the design of your manipulation module, especially context module and object module, is not motivated well. Is this based on empirical results or other theoretical analysis (it is better to cite them if it exists)? Besides, there are some typographical errors such as Table ???. Check carefully again.","sentences":[{"sentence_type":"2","sentence":"However, I think the design of your manipulation module, especially context module and object module, is not motivated well.","rephrased":"However, it would be helpful if the design of the manipulation module, including the context and object modules, were more clearly motivated. Could you please elaborate on whether this is based on empirical results or theoretical analysis, and cite relevant sources if available?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[302,426,"Confirmed"]],"Comments":[]}
{"id":"MEk36OTPBfr","text":"This work presents a 4D spatio-temporal deep learning for end-to-end motion forecasting and estimation using a stream of OCT volumes. The proposed method is validated on OCT 3D sequences. Compared to the alternative 3D CNN strategies, this work shows 4D CNN achieve better motion estimation and forecasting results.\n\nThe motivation is clear. It is easy to follow the paper. Some implementation details are missing (eg. parameter settings). Overall, this short paper shows some promising results of using 4D CNN in motion analysis.   ","sentences":[{"sentence_type":"1","sentence":"Some implementation details are missing (eg. parameter settings).","rephrased":"The paper would benefit from including more implementation details, such as parameter settings, to enhance reproducibility."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[374,439,"Not concerning"]],"Comments":[]}
{"id":"ryxkScFiYV","text":"This paper presents a novel method to match feature similarities for selecting unlabeled samples for active learning to train a model more label-efficiently.\nThe major innovation is to utilize Explanation-Based Attention (EBA) mechanism to improve matching feature similarities, which has been proved effective to attribute feature importance in computer vision domains.\nThe experiments show it outperforms conventional uncertainty-based approaches, especially when classes are imbalanced.\n\nOverall, this paper is a small but focused contribution on active learning and well-written, clear for readers to follow.\nThe presentation can be improved with a more detailed description of notations (e,g. N_b and V_a are not explained, though it's easy to guess their meanings).\nAn illustrative figures of workflow mentioned in the section \"summary for the proposed method\" would be a plus.\nThe paper also enjoys the merit that it has a brief, clear overview of recent AL research to put itself in a broader context.\n\nMy major concerns are two-fold:\n1) the intuition of utilizing integrated gradients (IG) and pseudo-labels is not super clear to me; 2) experiments should be more extensive.\nThe authors assume that the way of using IGs as EBA for evaluating sample similarity by multiplying themselves with descriptor matrices can upweight features that \"a) are not class and instance-level discriminative, b) spatially represent features for a plurality of objects in the input. \"\nThe assumption needs more justification.\nFor example, a) why to use average pooling function for both gradients and features is reasonable, b) the derivation of R_b is of what properties such that the distribution between training data and validation set are more similar iteratively (so we can believe the set of b-th iteration is better than the set of {b-1}-th). Also, experiments can justify the assumption as well with more visual explanations on why the proposed AL method is better and reasonable.\n\nFor the title, I suggest the authors not to use \"explanation-based\" since it is a little bit misleading. Readers may expect the authors use some kinds of explanitions to improve AL. I would say \"Integrated Gradients-based Attention for Deep Active Learning\" would be better.\n\nThat being said, I enjoyed reading this paper and would like to see it accepted with better presentation and more justification, experiments.\n\n","sentences":[{"sentence_type":"2","sentence":"The authors assume that the way of using IGs as EBA for evaluating sample similarity by multiplying themselves with descriptor matrices can upweight features that \"a) are not class and instance-level discriminative, b) spatially represent features for a plurality of objects in the input. \"","rephrased":"It would be helpful if the authors could provide additional justification for their assumption on the use of IGs as EBA. Specifically, clarifying how this approach effectively upweights features that are class and instance-level discriminative, and how it represents features for multiple objects in the input would strengthen the paper."},{"sentence_type":"2","sentence":"For the title, I suggest the authors not to use \"explanation-based\" since it is a little bit misleading. Readers may expect the authors use some kinds of explanitions to improve AL.","rephrased":"I recommend reconsidering the use of \"explanation-based\" in the title, as it might imply a different methodology to readers. Perhaps a title like \"Integrated Gradients-based Attention for Deep Active Learning\" would more accurately reflect the content of the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1184,1474,"Not concerning"],[1981,2162,"Not concerning"]],"Comments":[]}
{"id":"BygvfpMCFS","text":"This paper provides some analyses of the difference between adversarial training and standard training for linear classification problem. In particular, it proves that when the data is \\eps linearly separable, adversarial training converges faster than standard trading. It also argues that when the data is not \\eps linearly separable, adversarial training is more robust to outlier. Simulations are constructed to verify the arguments in the paper but there is no experiments on real dataset. \n\nThe first result of this paper is interesting, that adversarial training converges faster than standard training. Studying the difference between the convergent points between adversarial training and standard training is also an interesting research problem. However, I still have two main concerns about the current version of the paper.\n1. The paper is trying to develop rigorous results, but its writing is arguably not rigorous. Many statement are not clear and some notations are used without definition. Section 4.1 has many vague statements. See more concrete comments below. \n2. I am not sure about the significance of the results in the paper. The results highly depend on the linear setting with convex losses. More than that, Theorem 1 assumes the \\eps strongly linear separable, and Theorem 2 assumes a large \\eps (if the statement is that |w* x_{k,i}| is less than a large number, it seems much less interesting). These are very strong assumptions that are usually not true in practice. Experimental results only cover carefully designed simulation as well.\n\nDetailed comments for item 1 above:\n1. Assumption 3, what is the quantifier for w? Is it for every w? There exists some w? How do you guarantee by “rescale the norm of w” (from the footnote) to make sure that c_1 is not -\\infty?\n2. Lemma 1, this is for every x_i, or some particular x_i?\n3. What is w(t)?\n4. What is the condition on \\eta in Theorem 1? Why it is O(\\eta) in equation (11) or equation (24)?\n5. The claims in section 4.1 seem to be depended on carefully designed examples. Would it still true rigorously for general cases? \n6. In section 4.1.2 first paragraph, why ||w_t|| can not go to infinity? in the third paragraph, how assumption 2 implies p^k_i \/ p^k`_j = o(1), or later  p^k_i \/ p^k`_j = O(1)?\n7. In section 4.2 second paragraph, what is “k_th category”?\n8. Is w^* unique in Theorem 2?\n","sentences":[{"sentence_type":"2","sentence":"The paper is trying to develop rigorous results, but its writing is arguably not rigorous.","rephrased":"While the paper aims to develop rigorous results, the clarity of the writing could be improved to better reflect this rigor."},{"sentence_type":"2","sentence":"Many statement are not clear and some notations are used without definition.","rephrased":"The paper would benefit from clearer statements and defined notations to enhance the reader's understanding."},{"sentence_type":"2","sentence":"I am not sure about the significance of the results in the paper.","rephrased":"The significance of the results could be better articulated, especially in the context of practical applications."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[840,930,"Confirmed"],[931,1007,"Confirmed"],[1085,1150,"Confirmed"]],"Comments":[]}
{"id":"SJehimfIj7","text":"This paper solves Flappy bird by combining DQN and probabilistic programming. I think this is in general a good avenue to explore.\n\nHowever I found the paper to be poorly written. For example, notation is not properly introduced, there are many mathematical mistakes and typos in the written text and citations. This makes it very hard to understand what is actually going on.\n\nIt is also not clear what is the probabilistic program and what are we conditioning on? What is the inference algorithm? Maybe it's useful to expand more on how this ties to the \"RL as inference\" framework (see e.g. Levine, 2018). It seems like we are doing rejection sampling where the condition is \"no collision\". As a result, I'm not sure whether sampling from prior is a competitive baseline.\n\nFor the DQN experiment, the learning curve seems very noisy in a way that it's unclear whether a fair conclusion can be drawn only from one run (as it appears to be done).\n\nThe experiments also feel a bit contrived to make a strong case for probabilistic programming + DQN.","sentences":[{"sentence_type":"2","sentence":"However I found the paper to be poorly written.","rephrased":"However, I found some aspects of the paper's writing could be improved for clarity."},{"sentence_type":"2","sentence":"The experiments also feel a bit contrived to make a strong case for probabilistic programming + DQN.","rephrased":"The design of the experiments could be revisited to more objectively evaluate the case for combining probabilistic programming with DQN."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[132,179,"Confirmed"],[949,1049,"Confirmed"]],"Comments":[]}
{"id":"rJxnt1oTtB","text":"Summary.\n\nThe authors propose a new certified classifier in \\ell_1 norm that is tight. That is to say, upon smoothing a given classifier f with Laplacian noise, a smoothed version of that classifier (probabilistic maximum majority vote) is certified with a radius measured in \\ell_1 norm. The authors show that this bound is tight for binary classifiers. These results are complementary to Cohen et al. results.\n\nMajor comments.\n\n1) The major contribution of this paper is the tightness under the \\ell_1 norm for a binary classifier. I do not find this particularly significant. The question is of what value is such a result other than a mathematical exercise. For instance a good justification that the paper is lacking could be one where authors show that their radius is indeed tighter than all other works. The paper still lacks this (I will elaborate on this later), although, their bounds are indeed tighter than Lecure's et al. Since it is not clear whether or not the new certified smoothed classifier has indeed the largest radius among all other works, then at least a justification for why would one prefer a Laplacian noise of a Gaussian noise. Why is Gaussian smoothing sufficient for this purpose given that we do not know for sure that the radius is larger?  What value\/advantages does this add? The authors motivate their work by saying deriving the tightest \\ell_1 is difficult due to the \"asymmetry\"  of the norm. While I do agree on this; however, this is not enough motivation as we we are doing doing abstract maths here.\n\nThe new derived radius is not really comparable to the Gaussian radius with \\ell_2 radius and this is my major concern. By norm equivalence, we have that \\ell_2 \\leq \\ell_1 \\leq \\sqrt{n} \\ell_2 where n is the dimension. That is to say that the radius computed with \\ell_1 is larger than the \\ell_2 in some cases by a square root of dimension. The authors can correct me on this if I'm wrong, but for a fair comparison in worst case sense the radius of Cohen et al. should be scaled by \\sqrt{n}. In such a scenario, it is really difficult to understand when does it make sense to tackle such a smoothing technique as opposed to Gaussian smoothing.\n\nI would not have asked the authors about such a question if the authors derived generic radius under \\ell_p smoothing (which is difficult of course). To this end, I believe since the motivation is not clear nor the results are generic enough, I find the work incremental specifically after noting that the radius can be deduced from the work of Li et al. where the main contribution here is the tightness of the radius for a binary classifier.\n\n\nMoreover, I believe the paper still requires some polishing in terms of writing and presentation.\n\nSome more comments.\n\nI believe the paper can benefit from some rewriting. Here is a list of things the authors can do to improve the paper.\n\n1) Define what M is, page 3 \"and it is easy to see that M is a mixed random variable\". I believe the authors meant T(x).\n2) The figures are hardly readable. For instance, authors can perhaps increase the legend's font size in figures 4. Also the chosen colors are suboptimal (perhaps the line width of the plots) should be increased. \n3) The section below Theorem 3 should be moved up to before Theorem 3 as this discusses the proof of Theorem 2. Once a Theorem is presented, the proof sketch should follow.\n4) Experiments on the undefended classifier has to be in Figures 6  7 and 8.\n5) Lastly, why are comparison between Cohen et. al. and Lecuyer et. al. in Figure 6 inconsistent with Figure 5 of Cohen et al.","sentences":[{"sentence_type":"2","sentence":"I do not find this particularly significant.","rephrased":"The significance of the contribution could be further highlighted by demonstrating its practical applications or comparing it with other works in the field."},{"sentence_type":"2","sentence":"While I do agree on this; however, this is not enough motivation as we we are doing doing abstract maths here.","rephrased":"While I acknowledge the challenge in deriving the tightest \\\\(ell_1\\\\) norm, further motivation that connects the theoretical results to practical implications would strengthen the paper."},{"sentence_type":"2","sentence":"I believe since the motivation is not clear nor the results are generic enough, I find the work incremental specifically after noting that the radius can be deduced from the work of Li et al.","rephrased":"Clarifying the motivation and demonstrating how the results extend beyond the scope of existing work, such as Li et al., would underscore the novelty of the contribution."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[534,578,"Confirmed"],[1433,1543,"Confirmed"],[2356,2547,"Confirmed"]],"Comments":[]}
{"id":"b0OPmXmY-Kj","text":"This paper considers the stability of the stochastic gradient decent algorithm under different conditions. They show a lower bound for the stability of SGD in the smooth and convex case, and show that the bound can be tightened for linear models. They give a tight bound for the stability of SGD with decreasing step size in the non-convex case.  Then they propose the Hessian Contractive condition, and under this condition a tight bound for the stability of SGD with constant step size is given. \n\npros: 1, They propose the Hessian Contractive condition which is weaker than strongly convex and show that the family of widely used (convex) linear model loss functions will satisfy the Hessian Contractive condition. \n\n2, They analyzed the stability of SGD and give the lower and upper bounds for the stability in many cases. \n\ncons: 1, In Theorem 3, they give a lower bound for the stability of SGD with decreasing step size in the non-convex case. However, this lower bound is larger than the upper bound in Hardt 2016 when T goes to infinity and the other parameters fixed. This contradiction implies that the results in Theorem 3 should be incorrect. \n\n2, They claim the O(1) uniform stability of SGD in under the Hessian Contractive condition. But the uniform bound of $||w^* - w^{*\\prime}||$ is not proved. \n\nAfter the rebuttal.\n\nThe authors partially addressed my concerns. I have read other reviewers' comments. I decide to remain the current score.","sentences":[{"sentence_type":"2","sentence":"This contradiction implies that the results in Theorem 3 should be incorrect.","rephrased":"The apparent contradiction suggests that there may be an error in the results presented in Theorem 3 that warrants further investigation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1078,1155,"Not concerning"]],"Comments":[]}
{"id":"g_WcXXhLDX7","text":"Many Bayesian models have been proposed for multi-task learning. Why does the proposed multi-task neural process achieve superior performance? It is better to compare different models. \n\nThe Gaussian likelihood is not suitable for classification tasks. Authors should consider other likelihood function.\n\nIn experiments, important baselines are missing. Authors should compare with MTL models such as cross-stitch network and MTAN, which can be modified to solve the multi-input multi-output setting. Moreover, multi-task Gaussian process should be compared.","sentences":[{"sentence_type":"1","sentence":"Why does the proposed multi-task neural process achieve superior performance?","rephrased":"Could the authors provide further insights into how the proposed multi-task neural process achieves superior performance compared to other Bayesian models?"},{"sentence_type":"2","sentence":"The Gaussian likelihood is not suitable for classification tasks.","rephrased":"The authors might want to consider alternative likelihood functions, as the Gaussian likelihood may not be the most appropriate for classification tasks."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[65,142,"Not concerning"],[187,252,"Confirmed"]],"Comments":[]}
{"id":"eUeDN2spXct","text":"This paper provides an observation that active learning, which selects unlabeled data to be labeled by a human oracle, can be a strong baseline in data subset selection tasks. The idea is very simple: pretend that the labeled dataset $D$ is unlabeled and let active learning choose a subset of it, then simply use that subset to train the network using the corresponding labels in $D$.\n\nI think this paper can spark interesting discussions.","sentences":[{"sentence_type":"1","sentence":"The idea is very simple","rephrased":"The concept is straightforward and elegantly applies active learning in a novel context."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[176,199,"Not concerning"]],"Comments":[]}
{"id":"H_Wl0Tln0b9","text":"This paper proposes a method to learn causal temporal representations which support multidimensional causal factors (instead of single scalar factors as previously the case in the literature). This requires knowing which causal variable the interventions act on, but not their exact values\/effect.\n\nOverall, I found this paper quite interesting, although it could be more focused as it tries to present a few too many things at once (it presents some theory about minimal causal variable identification, a variational implementation using a temporal VAE architecture, as well as another variation which uses a Normalizing Flow. I might have tried to only select 2 our of the 3).\n\nGiven the focus of the workshop, this work is clearly in-scope and the ability to identify multidimensional factors is quite promising, so I’d recommend acceptance.\n\nComments and questions:\n1. What would happen if the interventions weren’t known and used? The Introduction presents this fact as a characteristic difference to related work, but isn’t it a weakness?\n   1. What would need to change to try to do the structure learning of the causal variables I as well?\n2. For the Normalizing Flow version, did you explore ways to keep fine-tuning the pretrained Autoencoder?\n   1. It is interesting that you can make it work using a frozen AE, but I can imagine this has the usual harsh requirements on the capabilities of the frozen model (e.g. it has to be a “good enough” model and if it does not capture specific causes by itself there is no way to salvage it).\n   2. This section of the work feels a bit less explored than the rest, so it might be pushed to the Appendix for the time being?","sentences":[{"sentence_type":"2","sentence":"it could be more focused as it tries to present a few too many things at once","rephrased":"the paper could benefit from a more streamlined focus, as it currently addresses several topics simultaneously"},{"sentence_type":"1","sentence":"I might have tried to only select 2 our of the 3","rephrased":"It may be beneficial to concentrate on two of the three aspects to maintain a clear focus"},{"sentence_type":"2","sentence":"This section of the work feels a bit less explored than the rest, so it might be pushed to the Appendix for the time being?","rephrased":"This section appears to be less developed compared to the others and could be considered for inclusion in the Appendix for further refinement"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[355,432,"Not concerning"],[628,676,"Not concerning"],[1551,1674,"Not concerning"]],"Comments":[]}
{"id":"BJg4Bsr4K4","text":"This paper instantiates in the context of query reformulation an approach to structure prediction (seq2seq) that is inspired by hierarchical reinforcement learning methods proposed in the early nineties by Singh, Lin, Dietterich, and Hinton. \n\nThis is an experimental paper with well executed experimental design and a broad range of comparative results for doc retrieval and question answering. Although experimentally solid, the paper is light in terms of insights.\n\nOn the positive side, the approach is easily parallelizable and achieves better generalization performance than a model average ensemble. On the negative side, the approach does not lead to significant improvements.\n","sentences":[{"sentence_type":"2","sentence":"Although experimentally solid, the paper is light in terms of insights.","rephrased":"While the experimental design is robust, the paper could benefit from deeper insights into the theoretical underpinnings of the approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[396,467,"Confirmed"]],"Comments":[]}
{"id":"zxnj77UiCj3","text":"The paper is focused on how pretraining with labeled action data benefits acting in unannotated environments. Experiments show that the result is promising compared to the baseline. In this review, we list the strengths and weaknesses of the work.\n\nThe topic fits the guideline of Reincarcinating RL. The background and the related work parts are detailed and help illustrate the innovative insight of the work. The method part can be more specific and there can be some intuitive explanations why ALPT works well. The experiments comparing ALPT with the baseline involve detailed illustrations, but the maze navigation domain results can be expanded.\n\nIn summary, ALPT works well in the two domains mentioned in the paper and illustrates the importance of IDM pretraining and its efficiency on action-limited data.","sentences":[{"sentence_type":"1","sentence":"The method part can be more specific and there can be some intuitive explanations why ALPT works well.","rephrased":"The method section could be enhanced by adding more specificity and providing intuitive explanations for why ALPT is effective."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[412,514,"Not concerning"]],"Comments":[]}
{"id":"Byo_bZRtB","text":"This paper proposes a VAE-based conditional molecular graph generation model. For that purpose, the disentanglement approach is adopted in this paper: learn to separate property information from the structure representation of a molecular graph. The authors use the supervised VAE objective since the KL regularizer in the objective has reportedly disentanglement-promoting effect. The final objective function is a standard VAE ELBO plus a penalty term of the property value prediction error. Non-differentiable property estimation is conducted via stochastic sampling expectation with the help of an external program (RDKit).  \n\nThe proposed model directly optimizes the generation model conditioned on the property values in a single objective function. This is preferable compared to many existing molecular graph generations, where property optimization is often carried out after the core generative models are trained and fixed. \nDerivation of a stable lowerbound (Eq. 11) is another plus. \n\nMy main concern about the paper is a weak survey for disentanglement researches. Since the core of graph generation model is not original of the authors (adopted from Dai+, 2018), the main technical advancement of the paper should be related to the disentangling VAE modeling. \nCurrent researches in disentangling VAEs go beyond the InfoGAN and beta-VAE. I present a part of the must-referred papers below:\n\n[Gao19] Gao+, “Auto-Encoding Total Correlation Explanation”, AISTATS, 2019. \n[Kim_Mnih18] Kim and Mnih, “Disentangling by Factorising”, ICML, 2018.  \n[Ryu19] Ryu+, “Wyner VAE: Joint and Conditional Generation with Succinct Common Representation Learning”, arxiv:1905.10945, 2019. \n\nAmong them, [Ryu19] is closely related to the proposed framework. In my understanding, the variable dependency structure studied in this paper (Fig. 1) is studied by [Ryu19]. The authors should clearly state the novelty of the proposed work in the literature of these disentanglement VAE works. \n\nI think the L_disent (Eq.5) is not a penalty for disentanglement: it enforces the model to correctly predict target property values, and do not say anything for factor disentanglement, correct? \n\nI have a few concerns about the experiment designs. \nIn the table 1, reconstruction performance evaluations, the authors chose string(SMILE)-based molecular graph generation models. However, it is largely admitted in the molecular graph generation studies that the graph-based generative models generally performed better. I want justifications for the choice of string-based generation models. Extending the table 1 with graph?base SotA generation models will strengthen the manuscript greatly. \nFor example:\n\n[Jin18] Jin+, “Junction Tree Variational Autoencoder for Molecular Graph Generation”, ICML, 2018. \n[You18] You+, “Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation”, NeurIPS, 2018. \n\nEspecially, [You18] directly optimize the property values of the generated graph. This is closely related to the goal of this paper, thus a proper reference and discussions are strongly expected. \n\n\nFigure 5. is an attractive visualization of the latent (z, y) vectors. However, the authors do not provide how to understand the figure. I GUESS that the authors want to show that learned z and y are somehow disentangled: the structural changes of molecular graphs are less sensitive to the vertical axis (property value) than the horizontal column (different). Please clearly state key messages of each figure and table. \n\nThere are several presentation issues. They are details, but fairly degrades the readability of the manuscript.  \n- Too small letters (alphabets) in Figure 3, 4, 6, it is simply unreadable so I cannot tell main messages of these figures (So I do not evaluate these figures positively). \n- In table 1, what are the significance figures of the presented scores? Some scores have 3 digits, others have 4 digits. Some are rounded at 0.01 precision but others are round at 0.1 precision. \n\nEvaluation summaries\n+ A graph generation model combining conditional property optimization in a single objective function.\n+ A new lowerbound for stable training (Eq.11)\n+ The property and the structure of the graph are somehow disentangled in the experiment (Fig. 5). \n+- Disentanglement effect is not modeled directly in the proposal. L_disent is not for disentanglement but for property regression.\n-- Survey for disentangling VAEs is not enough. This makes the proposal less convincing in terms of the novelty and the contribution compared to the recent dissent-VAEs. \n- Not compared with SotA graph-based molecular graph generation models. \n- Key messages of figures and tables are not clearly stated (e.g. Fig.5). \n-- Some figures are simply unreadable. The significance figure of the table 1 is unclear. These are formatting details but essential for readability. ","sentences":[{"sentence_type":"2","sentence":"My main concern about the paper is a weak survey for disentanglement researches.","rephrased":"I would recommend a more comprehensive survey of disentanglement research to strengthen the paper's foundation."},{"sentence_type":"1","sentence":"I think the L_disent (Eq.5) is not a penalty for disentanglement: it enforces the model to correctly predict target property values, and do not say anything for factor disentanglement, correct?","rephrased":"Could you clarify how L_disent (Eq.5) contributes to disentanglement? It appears to focus on predicting target property values rather than factor disentanglement."},{"sentence_type":"2","sentence":"There are several presentation issues. They are details, but fairly degrades the readability of the manuscript.","rephrased":"There are several presentation issues that, while minor, could be improved to enhance the manuscript's readability."},{"sentence_type":"2","sentence":"Too small letters (alphabets) in Figure 3, 4, 6, it is simply unreadable so I cannot tell main messages of these figures (So I do not evaluate these figures positively).","rephrased":"The text in Figures 3, 4, and 6 is quite small and challenging to read, which makes it difficult to discern the main messages. Enlarging the text would be beneficial for evaluation."},{"sentence_type":"2","sentence":"-- Some figures are simply unreadable. The significance figure of the table 1 is unclear. These are formatting details but essential for readability.","rephrased":"Improving the legibility of some figures and clarifying the significance figures in Table 1 are important formatting details that would aid in the readability of the manuscript."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[999,1079,"Not concerning"],[1986,2179,"Not concerning"],[3529,3640,"Confirmed"],[3645,3814,"Not concerning"],[4736,4885,"Confirmed"]],"Comments":[]}
{"id":"HJfRKPFeM","text":"SUMMARY.\n\nThe paper presents an extension of word2vec for structured features.\nThe authors introduced a new compatibility function between features and, as in the skipgram approach, they propose a variation of negative sampling to deal with structured features.\nThe learned representation of features is tested on a recommendation-like task.\n\n\n----------\n\nOVERALL JUDGMENT\nThe paper is not clear and thus I am not sure what I can learn from it.\nFrom what is written on the paper I have trouble to understand the definition of the model the authors propose and also an actual NLP task where the representation induced by the model can be useful.\nFor this reason, I would suggest the authors make clear with a more formal notation, and the use of examples, what the model is supposed to achieve.\n\n----------\n\nDETAILED COMMENTS\nWhen the authors refer to word2vec is not clear if they are referring to skipgram or cbow algorithm, please make it clear.\nBottom of page one: \"a positive example is 'semantic'\", please, use another expression to describe observable examples, 'semantic' does not make sense in this context.\nLevi and Goldberg (2014)  do not say anything about factorization machines, could the authors clarify this point?\nEquation (4), what do i and j stand for? what does \\beta represent? is it the embedding vector? How is this formula related to skipgram or cbow?\nThe introduction of structured deep-in factorization machine should be more clear with examples that give the intuition on the rationale of the model.\nThe experimental section is rather poor, first, the authors only compare themselves with word2ve (cbow), it is not clear what the reader should learn from the results the authors got.\nFinally, the most striking flaw of this paper is the lack of references to previous works on word embeddings and feature representation, I would suggest the author check and compare themselves with previous work on this topic.","sentences":[{"sentence_type":"2","sentence":"The paper is not clear and thus I am not sure what I can learn from it.","rephrased":"The paper could benefit from greater clarity to enhance the reader's understanding of its contributions."},{"sentence_type":"2","sentence":"The experimental section is rather poor, first, the authors only compare themselves with word2ve (cbow), it is not clear what the reader should learn from the results the authors got.","rephrased":"The experimental section would be more informative if it included comparisons with a broader range of related models, which would help clarify the unique contributions of the authors' work."},{"sentence_type":"2","sentence":"Finally, the most striking flaw of this paper is the lack of references to previous works on word embeddings and feature representation, I would suggest the author check and compare themselves with previous work on this topic.","rephrased":"To strengthen the paper, it would be beneficial for the authors to include more references to previous works on word embeddings and feature representation and to position their work within this existing literature."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[373,444,"Confirmed"],[1526,1709,"Confirmed"],[1710,1936,"Confirmed"]],"Comments":[]}
{"id":"B9cWGRtsTD","text":"The paper proposed a method to address the distribution mismatch problem in off-policy learning. Its method is to estimate the density ratio between the stationary distribution under the target policy and the data distribution in the replay buffer, and then correct the state distribution with the ratio so that it can use experience from the replay as if they were generated from the target policy.\n\nAlthough I have many questions about the paper, the following two are most important currently and are hoped to be addressed first.\n\nIt seems not clear to me whether this paper considers the tabular case or the function approximation case. It wrote in section 5 that \"our goal is to improve performance of TD learning with function approximation\", but its preliminaries (Section 2), its example (Figure 1), and its main theoretical result (Theorem 1) are all for the tabular case. In fact, the state distribution mismatch only matters when multiple states share the same parameter. For the tabular case, as each state has its own parameter, there is no interference between them, and thus there is no need to make the state distribution on-policy.\n\nEmpirically, all the experiments are designed to solve continuous control problems, where both state and action are continuous. However, the density ratio d^\\pi(s, a) \/ d^D(s, a) is only defined under the discrete setting. In fact, because both state and action spaces are continuous, all elements in the replay buffers are different from others and this ratio makes no sense. Therefore this algorithm doesn't seem appropriate to me for continuous control tasks. ","sentences":[{"sentence_type":"2","sentence":"Therefore this algorithm doesn't seem appropriate to me for continuous control tasks.","rephrased":"Therefore, I am concerned about the applicability of this algorithm to continuous control tasks and would appreciate further clarification on this point."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1527,1612,"Confirmed"]],"Comments":[]}
{"id":"S14kDbqlG","text":"Positive:\n- Interesting approach\n- Hardware validation (the RL field needs more of this!)\n\nNegative:\n- Figure 2: what is the reward here? The one from Section 5.1?\n- No comparisons to other methods: Single pendulum swing-up is a very easy task that has been solved with various methods (mostly in a cart-pole setup). Please compare to existing methods such as PILCO, basic Q-learning, classical methods... \n- I'm not sure what's going on with the grammar in Section 5.3 (\"like crazy\", \"super hot\"...). This section also seems irrelevant (move to an appendix\/supplementary or remove).\n- You should plot a typical control curve for the motors (requested torques). This might explain your heat problem (I'm guessing the motor is effectively controlled by a bang-bang controller).\n- Why did you pick this task? It's fine to only validate on a single task in hardware, but why not include additional simulation results (e.g. double pendulum)?","sentences":[{"sentence_type":"2","sentence":"No comparisons to other methods: Single pendulum swing-up is a very easy task that has been solved with various methods (mostly in a cart-pole setup).","rephrased":"It would be beneficial to include comparisons to other methods. While the single pendulum swing-up task is common and has been approached with various methods, providing a comparative analysis could strengthen the paper."},{"sentence_type":"2","sentence":"I'm not sure what's going on with the grammar in Section 5.3 (\"like crazy\", \"super hot\"...). This section also seems irrelevant (move to an appendix\/supplementary or remove).","rephrased":"The informal language in Section 5.3 could be revised for clarity and professionalism. Additionally, consider whether this section could be more appropriately placed in an appendix or supplementary material, or if it could be omitted without loss of important content."},{"sentence_type":"1","sentence":"Why did you pick this task? It's fine to only validate on a single task in hardware, but why not include additional simulation results (e.g. double pendulum)?","rephrased":"Could you please provide some insight into the choice of this particular task for validation? Including additional simulation results, such as for a double pendulum, might also offer a broader context for your findings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[166,316,"Confirmed"],[409,583,"Confirmed"],[779,937,"Confirmed"]],"Comments":[]}
{"id":"rJgVurunjX","text":"This paper presents a generalization of TransE to Riemannian manifolds. While this work falls into the class of interesting recent approaches for using non-Euclidean spaces for knowledge graph embeddings, I found it very hard to digest (e.g. the first paragraph in Section 3.3). Figure 3 and 4 confused me more than helping me to understand the method. Furthermore, current neural link prediction methods are usually evaluated on FB15k and WN18. In fact, often on the harder variants FB15k-237 and WN18RR. For FB15k and WN18, Riemannian TransE seems to underperform compared to baselines -- even for low embedding dimensions, so I have doubts how useful this method will be to the community and believe further experiments on FB15k-237 and WN18RR need to be carried out and the clarity of the paper, particularly the figures, needs to be improved. Lastly, I would be curious about how the different Riemannian TransE variants compare to TransE in terms of speed?\n\nUpdate: I thank the authors for their response and revision of the paper. To me, results on WN18RR and FB15k-237 are inconclusive w.r.t. to the choice of using Riemannian as opposed to Euclidean space. I therefore still believe this paper needs more work before acceptance.","sentences":[{"sentence_type":"2","sentence":"Figure 3 and 4 confused me more than helping me to understand the method.","rephrased":"I found Figures 3 and 4 to be unclear and they did not aid my understanding of the method as intended. Clarifying these figures could help readers better grasp the concepts."},{"sentence_type":"2","sentence":"I have doubts how useful this method will be to the community","rephrased":"I am uncertain about the method's utility for the community, and I suggest further validation to establish its usefulness."},{"sentence_type":"2","sentence":"I therefore still believe this paper needs more work before acceptance.","rephrased":"I believe that additional work on this paper could strengthen its case for acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[279,352,"Confirmed"],[629,690,"Confirmed"],[1166,1237,"Confirmed"]],"Comments":[]}
{"id":"1v4eOweXsi","text":"This paper shows that multiplicative cyclic learning rate schedules (cosine decay with warm restarts) can be used to construct an accuracy-time tradeoff curve in a single training run for a ResNet-50 trained on Imagenet.  \n\nThe paper is clearly written and understandable throughout. The topic fits well with this workshop. \n\nDrawbacks are:\n- Only data for a ResNet-50 on Imagenet is presented. It is unclear if this approach will work across datasets, loss functions, opimizers, architectures, domains... .\n- The authors claim that their approach also works on ResNet-50 and ResNet-101 trained on CIFAR-10, but are not providing any data. Please provide this data.\n- The source code is not provided, thus it is impossible to evaluate if the experiments are implemented correctly.","sentences":[{"sentence_type":"1","sentence":"It is unclear if this approach will work across datasets, loss functions, opimizers, architectures, domains... .","rephrased":"It would be beneficial to see if this approach can be generalized across different datasets, loss functions, optimizers, architectures, and domains."},{"sentence_type":"2","sentence":"The authors claim that their approach also works on ResNet-50 and ResNet-101 trained on CIFAR-10, but are not providing any data. Please provide this data.","rephrased":"To strengthen the paper, it would be helpful if the authors could include the data supporting their claim that the approach works on ResNet-50 and ResNet-101 trained on CIFAR-10."},{"sentence_type":"2","sentence":"The source code is not provided, thus it is impossible to evaluate if the experiments are implemented correctly.","rephrased":"Providing the source code would enable a thorough evaluation of the experiment implementation and enhance the reproducibility of the results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[395,507,"Not concerning"],[510,665,"Confirmed"],[668,780,"Confirmed"]],"Comments":[]}
{"id":"H_Oga6uEAWc","text":"This paper proposes to evaluate a causal-intervention approach to understanding the effect of different decisions on a policy's reward. The approach is somewhat interesting, but more baselines would help illustrate the value of this approach, and more clarification of details is needed. I consider this paper borderline-reject unless the following details are clarified, but I am scoring it a 2 because there is no 1.5 option.\n\nComments:\n\n* The authors should clarify in detail what the algorithms and environments they used are.\n   - The authors say that they treat the policy as a black box and make no further assumptions about it, but it is necessary to at least report the details of what they used for the experiments in the paper, in order to understand how to interpret the results. For example, in the case that the algorithm was trained with a very low exploration temperature (such that it would be fairly overfit to a particular sequence of actions at convergence, even if other sequences are equally good) vs. very high temperature training might substantially change the conclusions of their approach, by changing how disruptive the intervention is.\n  - similarly, the environments clearly affect the comparisons (e.g. the number of bottleneck states in them, the magnitude of the rewards for different outcomes, etc.) as the authors note in passing. Describe these details in the supplement!\n\n* It seems that the authors would like to claim that there is an essentially *causal* aspect of their work—that is, the fact that it involves an intervention—that is essential to the contribution. They compare to another interventional approach based on SBFL. However, one could ask whether a non-interventional approach could achieve the same benefits. It would be ideal to compare to a non-interventional baseline, but at least some of these issues should be discussed. For example:\n  - Assuming the authors are using a Q-learning approach (which is unclear, see above), the relationships between Q-values of the agent itself in a state are effectively estimates of how important it thinks actions are in that state. Could statistics calculated from the Q-values, without having to actually *do* the other actions, suffice for evaluating the importance of actions?\n  - Relatedly, there is a resemblance between the counterfactual quantity the authors propose, and the advantage function used in algorithms like A2C, with the chief difference being whether the expectation in the second term is over a random policy or the agent's policy. Nevertheless, one might imagine that a similar calculation could be done with the advantage function.\n  - If the authors are using a policy approach that does not compute action values, a similar ranking of importance could be done with statistic over the action probabilities.\n  - These approaches would require the policy to not be a completely black box (at least at the policy outputs), and perhaps that is why the authors neglect them (although it would be possible to estimate the policy distribution empirically by repeatedly sampling in the same state). However, the motivation for strictly black-box policies seems unclear to me; the settings in which it is possible to sample from a policy but not to evaluate its action logits seems quite contrived. The authors should at least motivate this setting better in the paper. And even if this is the ultimate goal, it would still be useful to know how privileged-information comparisons which can access the action values\/logits\/distribution would compare.\n\n\n\n\n","sentences":[{"sentence_type":"2","sentence":"I consider this paper borderline-reject unless the following details are clarified, but I am scoring it a 2 because there is no 1.5 option.","rephrased":"I believe this paper would benefit from further clarification on the following details before I can recommend acceptance. My score reflects the need for these improvements."},{"sentence_type":"2","sentence":"However, the motivation for strictly black-box policies seems unclear to me; the settings in which it is possible to sample from a policy but not to evaluate its action logits seems quite contrived.","rephrased":"The rationale for strictly using black-box policies could be made clearer. It would be helpful if the authors could elaborate on scenarios where sampling from a policy without evaluating its action logits is necessary or beneficial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[288,427,"Confirmed"],[3111,3309,"Confirmed"]],"Comments":[]}
{"id":"RZm6KfIWDn","text":"Authors present their work on applying DeepMedic to segment lesions on NCCT images. The topic of the work is relevant and interesting. The evaluation on two data sets from hospitals not involved in training is a major strength of this work. The major weakness is the limited methodological novelty, since this is merely a validation study.\n\nAs I said, the evaluation is very strong, because authors used images from two hospitals not involved in training. This gives confidence that the performance of this method is reproducible in other studies. This is a major strength and unfortunately not very common in this field.\n\nThe ratio of train\/val\/test data is quite skewed towards train\/val: 204\/48\/20. Do you really need 204+48 images to train DeepMedic to achieve this performance? It might be very interesting to see whether the performance on the 20 test images changes when using less training data. If this method can be trained with less data, it would make it even more attractive to use.\n\n20 test images, although from different hospitals, is still quite limited. Personally, I would have opted to include much more test data and use less training data. Perhaps in future work authors can extend the test set and demonstrate performance on a larger data set.\n\nIt might be interesting to specifically look at small lesions? It is usually not very hard to detect \/ segment large lesions and Dice is always high for larger lesions. Automatic solutions might be key in finding small lesions, since these are also hard to spot visually by an observer. Can authors comment on the performance of small lesion (e.g. below median size)?\n\nPlease report the inter-rater dice also in the text, I could only find it in the figure.","sentences":[{"sentence_type":"2","sentence":"The major weakness is the limited methodological novelty, since this is merely a validation study.","rephrased":"While the study is well-executed, it would be beneficial to see more methodological innovation, as the current work primarily focuses on validation."},{"sentence_type":"1","sentence":"20 test images, although from different hospitals, is still quite limited.","rephrased":"Although the test images come from different hospitals, expanding the test dataset could provide a more robust evaluation of the method's performance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[241,339,"Confirmed"],[997,1071,"Not concerning"]],"Comments":[]}
{"id":"3Ut4wLya3O","text":"**Description of the method**\n\nThis manuscript presents an RL method which leverages pre-trained language and vision models to condition the policy with natural language instructions.  A language model is used to generate subgoals descriptions from task descriptions.  Then a vision language model is given the textual sub-goal and the observation frames.  The VLM is then used to infer if any subgoals have been solved from the collected data. \nCLIP is used to encode images and text from the frames and textual descriptions of the frames (with some finetuning on the actual environment).  InstructGPT is used as the language model to generate subgoals.  Trajectories with solved subgoals are added to the set of experience.  The main component here is that subgoals being solved provides an additional signal to identify successful trajectories.\n\nThis method can solve a highly sparse environment reward and hierarchical tasks such as a block stacking robotic task against a baseline which achieves no reward.  This work then adds an additional “new task buffer”, which is re-initialized at the start of each new task and is used to train the policy with sequntially learned tasks. Samples from the standard buffer are added to the new task buffer for sufficiently similar interactions, hence allowing reuse of the offline data.  Additionally, they present an HRL method where the agent learns a set of skills where the language model decomposes the task into a set of short horizon goals.  They experiment with utilizing real world images of humans stacking objects with their hands during pre-training and then finetune the model on images from the simulation.  This serves as an improvement in zero shot learning from observations.\n\n**Review**\n\nThis paper is relatively well written, but the method is highly complex composed on many parts.  The figures serve well in describing the method in a concise way. I still found many of the textual descriptions hard to follow.\n\nThe work only utilizes a singular stacking task but presents substantial improvements and variations of the method.  I cannot clearly find the performance results for sections 5.3 and 5.4. I also cannot easily find details of the policy network.\n\nI recommend accepting this paper since the utilization of the LLM and VLM for subgoal generation and checking is quite novel, highly interesting to the workshop and the performance improvements on the single yet difficult task are substantial.    The baseline cannot solve the task with any reward.","sentences":[{"sentence_type":"1","sentence":"This paper is relatively well written, but the method is highly complex composed on many parts.","rephrased":"The paper is well written and presents a method that is sophisticated and multifaceted, which is commendable."},{"sentence_type":"2","sentence":"I still found many of the textual descriptions hard to follow.","rephrased":"Some of the textual descriptions could be clarified further to enhance comprehension."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1750,1845,"Not concerning"],[1913,1975,"Not concerning"]],"Comments":[]}
{"id":"B1x_gbizcr","text":"This paper presents a model that is able to associate objects seen in a new time step with the objects seen in previous frames and therefore consider the cases of adding new objects, dropping object no longer visible, but keeping them in memory in case they reappear in the future. The model assumes that the location of the objects is given and the only task to perform is the correct association of instances. Results shows that the proposed approach is better than hand-crafted features on different simulated tasks. Additionally the propose model is shown to help to reduce the computational cost for question answering task.\n\nI lean to reject this paper because in my opinion the proposed method is just a set of predefined rules to train a network to be able to perform object association between a new time step and a memory. Additionally the experimental evaluation is very weak in several points (see below). \n\n- Contribution: this approach proposes a set of rules to train a network to be able to learn the correct association  between two set of features. Additionally, the network is used together with a memory to keep track of previously seen objects. In my understanding the proposed work presents a set of hard-coded rules to train a network for tracking. However, the connection with tracking is presented only in related works (at the end of the paper) and no comparison with other tracking approach is presented. Additionally, the network model that is actually used for the experiments (graph network) is not presented in the main paper, which makes more difficult to understand how the network works for the given task.\n\n- Experimental evaluation: Experiments are performed on a very simple, simulated environment. Objects are very simple to recognize and their location (which is often  a difficult component of the problem) is given. As the task is quite straight forward, the model obtains almost 100% on all tests. Comparisons are made only with hand-crafted features. It is quite evident that a learned similarity measure will be better than hand-crafted distances. \n\nAuthors should explain more clearly that the proposed contribution is a set of rules used to learn a distance between features in order to associate object instances. \nA cleared connection with tracking should be provided from the introduction. In the evaluation there should be a comparison on multiple and more challenging tracking datasets. In this way we can compare the proposed training technique with other tracking approaches that also learn to a distance in order to associate object at different time steps. \n\n","sentences":[{"sentence_type":"2","sentence":"I lean to reject this paper because in my opinion the proposed method is just a set of predefined rules to train a network to be able to perform object association between a new time step and a memory.","rephrased":"I am inclined to not recommend this paper for acceptance as it appears that the proposed method primarily relies on a set of predefined rules for training a network to perform object association between a new time step and a memory."},{"sentence_type":"2","sentence":"Additionally the experimental evaluation is very weak in several points (see below).","rephrased":"Furthermore, the experimental evaluation could be strengthened in several areas as outlined below."},{"sentence_type":"1","sentence":"It is quite evident that a learned similarity measure will be better than hand-crafted distances.","rephrased":"It would be expected that a learned similarity measure might outperform hand-crafted distances."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[631,832,"Confirmed"],[833,917,"Confirmed"],[1994,2091,"Not concerning"]],"Comments":[]}
{"id":"STDgG5o-xWq","text":"This blog post does not focus on an ICLR paper. Moreover the level of the post is not quite appropriate (The ICLR blogpost track remains a research-level track).","sentences":[{"sentence_type":"1","sentence":"This blog post does not focus on an ICLR paper.","rephrased":"The blog post could be more aligned with the focus on ICLR papers as expected for the track."},{"sentence_type":"2","sentence":"Moreover the level of the post is not quite appropriate (The ICLR blogpost track remains a research-level track).","rephrased":"The post would benefit from a more research-oriented approach to meet the ICLR blogpost track's standards."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,47,"Not concerning"],[48,161,"Confirmed"]],"Comments":[]}
{"id":"0c1jBq_qBK-","text":"Strengths\n* Llong range time series forecasting is an interesting problem to investigate.\n* Adding skip connections between encoder and decoder is technically sound\n* The overall experiment results showed the effectiveness of the proposed method.\n\nWeaknesses\n* The organization of this paper is not well. Many technical details are not very clear in the main context\n* The overall technical novelty is limited\n* The effectiveness of the skip connections are not fully assessed\n* More details of the experiments are not provided.\n\nThe main problem of this paper is that the main context (especially the methodology section) is not self-contained. The reader will have to rely on details in the appendix or other papers to fully understand the proposed technique.\n\nAnother concern is the novelty. Skip connections are common practice in U-net and the idea of stabilizing the encoder and decoder by reconstructing the recent past is also not new. Although it is a new application area for skip connections, the overall technical novelty is limited.\n\nIn addition, the ablation study over whether the Skip connections are used or not is not provided.\n\nSeveral related works are not mentioned or compared.\n\n[1] \"Think globally, act locally: A deep neural network approach to high-dimensional time series forecasting.\" Sen, Rajat, Hsiang-Fu Yu, and Inderjit S. Dhillon NeurIPS 2019.\n\n[2] \"Modeling long-and short-term temporal patterns with deep neural networks.\" Lai, Guokun, Wei-Cheng Chang, Yiming Yang, and Hanxiao Liu, SIGIR 2018.\n\n[3] \"Shape and time distortion loss for training deep time series forecasting models.\" Vincent, L. E., and Nicolas Thome NeurIPS 2019.\n\nAs for the experiments:\n1. It is not clear whether the setting in Eq. (1) is consistent with the settings in Informer or Reformer.\n2. It is also not clear how to set y’ in the experiments.\n3. Only two datasets are used for evaluation, which may not be sufficient to show the generalization capability of the proposed technique.\n4. Standard deviations of the prediction results are not provided.\n","sentences":[{"sentence_type":"2","sentence":"The organization of this paper is not well.","rephrased":"The organization of the paper could be improved for better clarity."},{"sentence_type":"2","sentence":"The overall technical novelty is limited","rephrased":"The technical novelty of the paper could be further highlighted and expanded upon."},{"sentence_type":"2","sentence":"More details of the experiments are not provided.","rephrased":"It would be beneficial to include more details of the experiments to support the findings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[261,304,"Not concerning"],[369,409,"Not concerning"],[479,528,"Not concerning"]],"Comments":[]}
{"id":"a3Mzdk8Nq0j","text":"*Originality.* This work builds on a fairly new problem introduced by Chen,\nValiant, and Valiant in NeurIPS`20, whose aim is to study statistical\nestimation when data values are correlated with sample membership. The\nalgorithms proposed in this paper consider an SDP relaxation of the objective\nfunction and then use traditional online gradient descent-based methods to\nachieve the same approximation factor as Chen-Valiant-Valiant for the\n$\\ell_\\infty$ case, but with an explicit bound on the running time. The\nmultiplicative approximation factor in both cases is the result of the SDP\nrelaxation. The extension to the $\\ell_2$ case, together with the simple but\nnovel constant lower bound in Section 3, are nice contributions towards the\noriginality of this work.\n\n*Quality.* Overall, this work is a nice extension of Chen-Valiant-Valiant. The\nmain results are incremental in some sense, but the approach is cleaner and\nallow for further generalization (e.g., the $\\ell_2$-bounded case). The\nexperiments do not really stand out, but they also don't detract from the\nquality of the paper.\n\n*Clarity.* The paper is written pretty well. The introduction could do a better\njob motivating the model, but the message that it generalizes importance\nsampling, snowball sampling, selective prediction, etc. comes across well\nenough. The algorithms and analysis are quite clear, but the paper could\nbenefit from setting up the joint sample-target distribution definition in more\ndetail.\n\n*Significance.* The least compelling part of the paper, in my opinion, is the\nmodel itself (introduced in previous works). Given the problem, the algorithms\npresented seem like good approaches, even though they are mostly theoretical\nand rely on solving SDPs.\n\n*Typos \/ Suggestions*\n- [41] Missing a ',' in the set of data values.\n- [57] Missing space in \"selective prediction[10, 17]\"\n- [95] Even though Definition 1 references [4], the definition is initially\n  somewhat unclear \/ ambiguous to me. A small example would be helpful, or an\n  explicit definition.\n- [110] Typo: \"psd\" --> \"PSD\"\n- [118] Nit: \"Recall that the SDP algorithm...\" -- the reader might never have\n  read [4], and hence can't recall. I suggest just saying that \"The SDP algorithm...\"\n- [207] Typo: \"sdp\" --> \"SDP\"\n- [249] Suggestion: Italicize \\alpha-non-expanding since its the term being defined.\n- [347] Journal is missing for Drucker reference [10]","sentences":[{"sentence_type":"1","sentence":"The main results are incremental in some sense, but the approach is cleaner and allow for further generalization (e.g., the \\\\(ell_2\\\\)-bounded case).","rephrased":"The main results build effectively on prior work, and the approach is cleaner, which paves the way for further generalization, such as the \\\\(ell_2\\\\)-bounded case."},{"sentence_type":"2","sentence":"The least compelling part of the paper, in my opinion, is the model itself (introduced in previous works).","rephrased":"While the model introduced in previous works may benefit from further development, the algorithms presented in this paper are promising and represent good approaches to the problem."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1496,1602,"Confirmed"]],"Comments":[]}
{"id":"Cr3lUEvLAdD","text":"--Summary:\nThe paper proposed a method to learn disentangled representation of shape and appearance for cross-domain (different object categories) data. Build upon FineGAN, the method uses contrastive learning combined with normalized temperature-scaled cross-entropy loss to further disentangle the shape and appearance information.\n\n--Strongness:\n1. The model is slightly novel. They combine contrastive learning with normalized temperature-scaled cross-entropy loss to learn the filter bank to construct the appearance feature histogram.\n2. They perform many experiments including comparisons with baselines and ablation studies on the proposed loss terms. They demonstrate the effectiveness of their approach to generating hybrid images.\n3. The paper is well-organized.\n\n--Weakness:\n1. The motivation is still unclear. I still don't get the point for the usefulness of appearance transfer across two different types of objects (e.g. car and animal) which they claim as their contribution. For example, I don't see the application for applying car appearance to animals.\n2. The comparison baselines are too old. For the appearance transfer comparisons as shown in Figure 4 are the papers before 2018. For example, why don't you compare your model with StarGANv2[1] which also demonstrates appearance transfer to different shapes (e.g. Figure 10)?\n\n--Questions:\n1. I'm curious about the results if you replace the histogram method by just using CNN to extract features on the masked output from FineGAN?\n\n--Recommendation:\nAlthough the authors demonstrate the effectiveness of the proposed method, there are some concerns to be addressed: \n1) Motivation is not intuitive. \n2) There are many more recent papers for transferring appearance to another shape, e.g. StarGANv2[1], which is not included in the experiment.\n\nI currently vote negatively but the authors are strongly encouraged to address these concerns.\n\n[1] StarGAN v2: Diverse Image Synthesis for Multiple Domains, CVPR'20","sentences":[{"sentence_type":"2","sentence":"The model is slightly novel.","rephrased":"The model introduces some novel aspects."},{"sentence_type":"2","sentence":"I still don't get the point for the usefulness of appearance transfer across two different types of objects (e.g. car and animal) which they claim as their contribution.","rephrased":"The practical applications of appearance transfer across two different types of objects (e.g. car and animal), which is claimed as a contribution, could be further clarified."},{"sentence_type":"2","sentence":"I currently vote negatively but the authors are strongly encouraged to address these concerns.","rephrased":"While I have reservations at this stage, I encourage the authors to address these concerns which could change my evaluation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[352,380,"Maybe"],[823,992,"Confirmed"],[1819,1913,"Confirmed"]],"Comments":[]}
{"id":"MliNU_d9Y5H","text":"This work presents a transformer-based policy for offline goal-conditioned task learning. It is a novel and interesting way that the model integrates expert instruction (caption) with the state-action sequences for task trajectory generation. \n\nStrengths：\n1) This work provides an unifying model that combines NLP and RL-sequencee generation for offline-goal-conditioned imitation learning.  As the transformer shows remarkable performance on NLP tasks, this paper presents a natual and intuitive method for AI to learn expert language-conditioned demonstrations.\n2) Unlike other language-conditioned RLs learn the representation of language goals, this work provides an end-to-end way that integarates language goal into the control policy.\n\nWeakness: \n1) This work only presents the comparison results between caption-augmented GPT and non-augmented GPT. It would be nice to see the comparisons with other offline RLs. \n2) Does this caption-augmented offline method also work when the offline dataset contains suboptimal and random trajectories? \n3) Is the caption transformer policy robust? Can it handle stochastic environments and disturbances?\n4) The test environment task is relatively simple. Seeing the following work with more complicated\/continuous tasks would be nice.\n\nDetailed questions:\n1) Table 1: It seems that the caption augmented version only significantly contributes Boss-level if 1M trajectories are given. Why each difficult level has different data-size?\n2) From Fig.4, it indicates that caption-augmented transformer outperforms the baseline on Boss-level difficulty. What about the other two-levels? Can we still get the conclusion?\n3) Does the caption transformer has the task decomposition ability? For example, the agent is in the same environment but is given a new task consists multiple sub-tasks from different goal-conditoned trajectories.\n\nTopics:\nThis work belongs to offline RL\/IL, which can be considered as a sub-topic of Reincarnating RL.","sentences":[{"sentence_type":"1","sentence":"Does this caption-augmented offline method also work when the offline dataset contains suboptimal and random trajectories?","rephrased":"It would be beneficial to explore how the caption-augmented offline method performs when the offline dataset includes suboptimal and random trajectories."},{"sentence_type":"1","sentence":"Is the caption transformer policy robust? Can it handle stochastic environments and disturbances?","rephrased":"Further investigation into the robustness of the caption transformer policy, particularly its ability to handle stochastic environments and disturbances, would be valuable."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[925,1047,"Not concerning"],[1052,1149,"Not concerning"]],"Comments":[]}
{"id":"mkZdk4Ans7","text":"This paper focuses on the application of a geometric deep learning method (spline-based convolutions, Fey et al., 2018) to be able to predict functional retinotopic maps from purely anatomical features using the HCP retinotopy dataset. \n\nPros:\nThe paper is written clearly, with the motivation well explained. \nThe results of this paper are clearly promising, with the method showing not only good prediction of retinotopic maps, but also correctly predicting individual variations. \n\nCons:\nThe authors do not provide references or mention whether the prediction of retinotopic maps in the HCP retinotopy dataset has been tried before, therefore it is unknown whether similar results have already been achieved or not. \nThere is limited description of the method, however, the authors do provide a clear figure of their network. \nThere is limited validation, and no quantitative results presented in the paper. \n","sentences":[{"sentence_type":"1","sentence":"There is limited description of the method, however, the authors do provide a clear figure of their network.","rephrased":"While the description of the method could be more detailed, the authors helpfully include a clear figure of their network."},{"sentence_type":"2","sentence":"There is limited validation, and no quantitative results presented in the paper.","rephrased":"The paper would benefit from additional validation and the inclusion of quantitative results to strengthen the findings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[720,828,"Not concerning"],[830,910,"Confirmed"]],"Comments":[]}
{"id":"HkeTKMDFYV","text":"The authors attempt to improve on Adversarial Feature Learning (AFL) by introducing a distrance between a parametrization of the attribute distribution and the Encoder Distribution. The resulting work appears to be easier to fit and delivers improved results compared to state of the art work.\nThe work seems relatively incremental, however, the results appear to justify the direction.\nHowever, the exposition of the work is rather difficult to follow with notation popping without being previously defined, e.g. L_y section 3 last paragraph. I would strongly urge the authors to focus on clarifying the exposition of the work.","sentences":[{"sentence_type":"1","sentence":"The work seems relatively incremental, however, the results appear to justify the direction.","rephrased":"While the work builds upon existing frameworks, the results provide a compelling justification for this research direction."},{"sentence_type":"2","sentence":"However, the exposition of the work is rather difficult to follow with notation popping without being previously defined, e.g. L_y section 3 last paragraph.","rephrased":"I would suggest that the authors improve the clarity of the exposition, particularly by introducing and defining notations such as L_y in section 3, last paragraph, before they are used."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[294,386,"Not concerning"],[387,543,"Not concerning"]],"Comments":[]}
{"id":"rkxv0JQtYS","text":"Summary\n\nThis paper proposes using Wasserstein Distances to measure the difference between higher-level functions of policies, which this paper terms as \"behaviors\". For example, one such behavior could be the distribution over final states given the policy, or the distribution over returns given policy. Through the lens of these behavioral embeddings, this paper recovers a few important special cases that are well-known in the literature including WD-based TRPO and distributional RL. This paper shows that the dual formulation of the Wasserstein Distance gives the ability to score individual policies based on a given \"behavioral mapping\".\n\nReview\n\nThe idea of generalizing the trust-region of TRPO by using the WD measure and behavior maps is intriguing. The paper introduces many choices of behavior maps that could lead towards interesting algorithms that merit additional study. I think the connections between the proposed family of algorithms and WD-based TRPO and distributional RL is highly motivating.\n\nThere are, however, a several key issues with the empirical study of the proposed methods that make it challenging to assess the value of introducing another partially understood deep policy gradient algorithm. The results show only behavioral studies of the algorithm, not investigating the effects of the WD based regularizer or the effects of the choice of behavioral map. The results are also significantly limited in their statistical significance, making distinguishing between algorithms difficult in most cases. And the comparison of wall-clock time is particularly difficult to assess due to the uncountably many possible sources of noise when comparing wall-clock time of highly complex algorithms. In the following paragraphs, I will expand upon each of these points.\n\nOne of the key contributions of this paper is the ability to define regularizers based on the definition of the behavior map. The paper introduces many such behavior maps, those over state visitation, actions, and returns; however, the paper does not investigate the effects this novel choice has on the results. It is unclear if introducing each of these behavior maps leads towards different results or if they each induce roughly the same final performance of the agent. It would be highly valuable for me to see a more careful study of the effect of choosing each of these behavior maps on a single simple environment, clarifying that this formulation leads to a family of useful algorithms. As it stands, BGPG may only beat TRPO on these domains because it had more meta-parameters to choose between (BGPG introduces many new meta-parameters: choice of behavior map, kernel for produce RKHS, the meta-parameters of that kernel, the meta-parameters of the behavior map like trajectory length, the entropy regularization term in the WD, etc.). Without a careful study, or intuitive explanation of any of these parameter choices, it is unclear if BGPG won simply through overfitting to the problem.\n\nThe statistical significance of the proposed algorithm is impossible to assess in the given form. The comparisons are made using only five random seeds and the standard error bars are frequently quite large. I refer to Henderson et al. 2017 for further explanation as to why five random seeds is simply too few to provide a meaningful comparison between algorithms. Instead, I'll discuss a few of the results in particular. In figure 3a, I notice that the proposed method has high variance until it plateaus around -300 reward; why? In each of the remaining plots of Figure 3, I notice that the propose method is significantly higher variance than any of its competitors. This greatly leads me to suspect that the proposed method would have much lower average performance if studied across a greater number of random seeds. In the walker domain (Figure 3d), why do BGPG and TRPO both plateau at the same point for many timesteps, then eventually BGPG starts improving again? From Figure 5, the paper somewhat misleadingly states that \"BGES is the only method that drives the agent to the goal in both settings.\" However Figure 5 on the left clearly shows that BGES and NSR-ES have indistinguishable performance, and the error bars indicate that neither significantly outperform NoisyNet-TRPO. In fact, due to the high variance of BGES it is unclear if it would drive the agent towards the goal on average if run over more random seeds. On the right, NoisyNet-TRPO noticeably outperforms BGES and is significantly lower variance. The language used to describe Figure 6 is strong, stating that Figure 6 \"proves that the benefits come here not just from introducing the regularizer, but from its particular form.\" However, I tend to disagree that Figure 6 reliably proves anything. Although it appears that BGES is significantly outperforming other methods, the number of meta-parameters over which it gets to optimize makes it difficult to say if the performance gain is from overfitting to the problem or the form of the regularizer. Additionally, good performance demonstrated across a single problem is hardly proof especially using only five random seeds (Henderson et al. 2017 Figure 5).\n\nAlthough this plays comparatively little role in my scoring of the paper, I feel it is necessary to discuss briefly. Because it is impossible to determine the source of the speed differences between the particle approximator and BGPG, the results in Figure 4 are extremely difficult to interpret. It simply could be that BGPG uses slightly more optimized code than the particle approximator, or it could be that there is in fact a significant performance difference between the algorithms. The only true way to discuss performance differences between algorithms generally is through computational complexity for these reasons. In the case that these statistical algorithms share the same computational complexity, then further analysis including convergence rates would be able to shed light on the speed difference. However, wall-clock time vs. performance has so many confounding factors, it is a fairly meaningless unit of measure. For an empirical investigation of speed, I would suggest giving each algorithm similar number of learning steps or similar number of updates to their weights and compare performance in this way.\n\nAdditional Comments (do not affect score)\n\nI'm curious if this work could be extended to the off-policy case. It does seem like a minor disadvantage that distributional RL is well-defined in both the on-policy and off-policy cases, but the proposed family of methods is not. From my reading of the paper, it appears that there is little preventing this extension. Is this true?\n\n--------\nEdit after reading other reviews and rebuttals.\n\nI appreciate the response noting that the meta-parameters of this algorithm were not tuned. I still feel that understanding the sensitivity to these parameters is important to understand how the choice of these parameters impacts the performance. While it is certainly likely that extensive tuning of these parameters could yield even more improved results, it is also quite possible that the chosen parameters have biased the results. If a more intuitive discussion of the choice of meta-parameters could be included in the paper, I would be more willing to concede this point.\n\nI recognize that 3 or 5 random seeds are a standard in the deep RL community, but I think Henderson et al. 2017 make this point better than I could: this is not a standard that we should hold to. I think that using small domains and smaller networks would allow running across more random seeds and providing a much more careful scientific study. This paper does not convincingly show state of the art performance, a metric that is nearly impossibly to define in a field that moves as quickly as ours, so should not strive to follow the same demonstration study design that SOTA papers follow. A paper with strong theoretical motivations (such as this) should compliment with strong empirical understanding of how that theory translates to practice. Instead, having strong theoretical motivations backed by a demonstration that the algorithm still works is much less convincing (to me). I think a more convincing set of experiments that match well with the intended purpose of the paper (theoretical contribution of behavioral embeddings) would be an investigation to _how_ the optimization affects the learned policies or representations. Instead of performance benchmarks, this would provide understanding for the various effects of the new framework.\n\nAfter the rebuttal phase, I now have an additional new concern about the clarity of the writing and the completeness of the empirical details. Many of the results do not mention most of the important details necessary to replicate or even interpret the results. I had assumed that details were consistent across figures (e.g. figure 3 uses 5 random seeds, so I assumed the same to be true for all other figures that did not specify), but the author response made clear that this is not true. In additional, little to no details are provided in the paper referring to the choices of meta-parameters for any algorithm or the methodology used to chose these meta-parameters. After these details were given in the rebuttal, my concerns were greatly alleviated, but not completely removed. It is unclear if the authors intend to update the paper before the final version, but based on the language of the rebuttal (e.g. indicating it is purely a misunderstanding of the paper), I am forced to assume that the paper will not include these important details.\n\nTo summarize. I think the theoretical underpinnings of these paper are extremely motivating and interesting. I do not want to see these innovations lost. However, the current state of the empirical section of the paper leaves too much open for me to be able to recommend an accept at this time. I do not believe a paper should solve everything in one pass (e.g. careful parameter studies, SOTA demonstrations, real-world demonstrations, etc.), but I do not believe this paper demonstrates any one of these convincingly.","sentences":[{"sentence_type":"2","sentence":"The statistical significance of the proposed algorithm is impossible to assess in the given form.","rephrased":"Assessing the statistical significance of the proposed algorithm is challenging with the current data presentation and would benefit from additional information."},{"sentence_type":"2","sentence":"Without a careful study, or intuitive explanation of any of these parameter choices, it is unclear if BGPG won simply through overfitting to the problem.","rephrased":"A more detailed study or an intuitive explanation of the parameter choices would help clarify whether the success of BGPG is due to its design or potential overfitting to the problem."},{"sentence_type":"2","sentence":"The language used to describe Figure 6 is strong, stating that Figure 6 \"proves that the benefits come here not just from introducing the regularizer, but from its particular form.\" However, I tend to disagree that Figure 6 reliably proves anything.","rephrased":"The language used to describe Figure 6 might be perceived as assertive. It may be more accurate to say that Figure 6 suggests the benefits come from the particular form of the regularizer, although further evidence may be needed to support this claim."},{"sentence_type":"1","sentence":"The only true way to discuss performance differences between algorithms generally is through computational complexity for these reasons.","rephrased":"A more robust way to discuss performance differences between algorithms might be through an analysis of computational complexity."},{"sentence_type":"2","sentence":"This paper does not convincingly show state of the art performance, a metric that is nearly impossibly to define in a field that moves as quickly as ours, so should not strive to follow the same demonstration study design that SOTA papers follow.","rephrased":"While the paper does not conclusively demonstrate state-of-the-art performance, which is a challenging benchmark in a rapidly evolving field, it could benefit from a study design that is more aligned with its theoretical contributions rather than current state-of-the-art demonstrations."},{"sentence_type":"2","sentence":"However, the current state of the empirical section of the paper leaves too much open for me to be able to recommend an accept at this time.","rephrased":"The empirical section of the paper could be further developed to address the open questions, which would strengthen the case for acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2846,2999,"Not concerning"],[3001,3098,"Not concerning"],[4530,4779,"Confirmed"],[5683,5819,"Not concerning"],[7688,7934,"Confirmed"],[9803,9943,"Not concerning"]],"Comments":[]}
{"id":"GcR71LzajNH","text":"### Summary\n\nThe authors proposed inverse reinforcement learning (IRL) algorithm based on Monte Carlo expectation-maximization (MCEM) that maximizes the predictive distribution of trajectories given the reward distribution parameter (eq (1)). In my understanding, the knowledge of the environment dynamics is assumed. The authors tried to validate the proposed idea on objectworld (Levine et al., 2011)\n\n### Quality\nThe quality needs to be improved in the sense that a clear theoretical link between the target problem and MC-EM cannot be found in the submission. For example, the main objective (3) is optimized through (4) and (5), but the relation is unclear. There are lots of such things in the submission. \n\n### Clarity\nThe readability of the submission is poor and needs to be improved. Lots of terms are unclear to me (e.g., succinctness, robustness, transferability of rewards). At some part of derivation, I couldn’t understand the motivation. Experiment settings are unclear, and the results are not confident and seem irreproducible with given information. \n\n### Originality\nExploiting the distribution of reward is considered in Bayesian IRL. I think the probabilistic view was originated from Bayesian IRL (e.g., uniform prior on rewards may cover the idea of this work). The submission only sets MaxEntIRL as its baseline, but I think Bayes IRL should have been considered. \n\n### Significance\nThere seems to be a minor contribution \n\n### Detailed comments\n(p.1, `Abstract`) `expert demonstrations may be optimal for many policies`\n- I feel this statement is weird since we haven’t defined the optimality of expert demonstrations.\n\n(p.1, `Abstract`) `we generalize the IRL problem to a well-posed expectation optimization problem stochastic inverse reinforcement learning (SIRL) to recover the probability distribution over reward functions.`\n- SIRL tries to solve the inherent issue of IRL problem, not **generalize** IRL. Also, since Bayesian IRL also recovers the reward distribution, I couldn’t get the major advantage of the SIRL from this statement.\n\n(p.1, `Abstract`) `The solution is succinct, robust, and transferable`\n- Definitions of these expressions seem ambiguous to me. \n\n(p.1, `Abstract`) `a global viewpoint`\n- Again, ambiguous. \n\n(p.1, `Introduction`) \n- It would be better to write it in a more abstract way and separately write down the `Related Work` section.\n- References should be much clearer: LaTeX commands like `\\citet{}` and `\\citep{}` should both be used. \n\n(p.1, `Introduction`) `if the model dynamics are known`\n- Recent works on IRL such as adversarial IRL (Fu et al, 2017) didn’t require the knowledge of model dynamics.\n\n(p.1, `Introduction`) `The recovered reward function provides a succinct, robust, and transferable definition of the learning task`\n- `succinct, robust, and transferable`: Ambiguous\n\n(p.1, `Introduction`) First paragraph\n- Lots of words from `Abstract` seem to be repeated. \n\n(p.1, `Introduction`) `In a real-world scenario, experts always act sub-optimally or inconsistently, which is another challenge.`\n- The sentence seems abrupt. The terms like `sub-optimal` and `inconsistent` here are awkward. \n\n(p.1, `Introduction`) `imposes regular structures of reward functions in a combination of hand-selected features`\n- GAIL (Ho et al, 2016) doesn’t require a hand-crafted feature. \n\n(p.1, `Introduction`) `hand-selected by experts`\n- A word `experts` here seems to imply a reward designer, not an expert on target tasks. I’d rather use a different word here. \n\n(p.1, `Introduction`) `based on demonstrations respectively`\n- `respectively` seems inappropriate. \n\n(p.1, `Introduction`) `Influenced by the work of Finn et al. (2016a;b)`\n- How these references affected AIRL needs to be mentioned. \n\n(p.2, `Introduction`) `because the MaxEnt approach is equipped with the \"transferable\" regular structures over reward functions.`\n- In Ziebart et al., 2008, transferability wasn’t mentioned. \n- I believe the statement -- MaxEnt itself gives transferable reward feature -- is wrong but you should share the correct reference if this is true. \n\n(p.2, `Introduction`) `The solution of SIRL is succinct and robust for the learning task in the meaning that it can generate more than one weight over feature basis functions which compose alternative solutions to the IRL problem`\n- This explanation seems insufficient to understand the meanings of “succinctness” and “robustness”. \n\n(p.2, `Introduction`) `Benefits of the class of the MaxEnt method,`\n- Thanks to the benefits of the class of the MaxEnt method?\n\n(p.2, `Introduction`) `Since of the intractable integration in our formulation,`\n- Due to the intractable integral in our formulation? \n- I think the intractability of the mathematical derivation didn’t need to be mentioned in `Introduction`. \n\n(p.2, `Introduction`) `in a model-based environment`\n- when model dynamics is known? \n\n(p.2, `Introduction`) `In general, the solutions to the IRL problem are not always best-fitting in the previous approaches because a highly nonlinear inverse problem with the limited information is very likely to get trapped in a secondary maximum in the recovery.`\n- I couldn’t understand what the authors wanted to emphasize. \n- It seems like they intended to emphasize the problem of local optima, but I don’t know if such a problem is exactly what’s happening in IRL. \n\n(p.2, `Introduction`) `global exhaustive search`\n- What does `global` imply? Knowledge of dynamics?\n\n(p.2, `Introduction`) `theoretically convergent demonstrated by pieces of literature`\n- is theoretically convergent?\n- How the theorem in the references (Caffo et al., 2005, Chan and Ledolter, 1995)  is applicable to the proposed idea should be much clearer since this is one main advantage that the authors argue. For example, what kind of assumptions are required to acquire global optimality? What is the algorithmic assumption of MC-EM for optimality? How are those assumptions linked with IRL setting?\n\n(p.2, `Introduction`) `is also quickly convergent`\n- converges quickly?\n- How can we guarantee the convergence speed? Empirically or theoretically?\n\n(p.2, `Introduction`) `the preset simple geometric configuration over weight space in which we approximate it with a Gaussian Mixture Model (GMM)`\n- preset -> predefined?\n- approximate it -> approximate\n\n(p.2, `Introduction`) `We generalize the IRL problem`\n- It seems the objective is not a generalization. \n\n(p.2, `Preliminary`) $\\mathcal{T}:=\\mathbb{P}(s_{t+1}=s’|s_t=s, a_t=a)$\n- $\\mathcal{T}(s’|s, a):=\\mathbb{P}(s_{t+1}=s’|s_t=s, a_t=a)$\n\n(p.2, `Preliminary`)  `a sequential of state-action pairs`\n- a sequence of state-action pairs?\n\n(p.2, `Preliminary`) `The estimated complete MDP yields an optimal policy that acts as closely as the expert demonstrations.`\n- The discount factor should be considered as well. \n\n(p.3, `Regular Structure of Reward Functions`) $\\mathcal{N}$\n- I’d rather use a different letter since $\\mathcal{N}$ is used to indicate Gaussian distribution in Section `Second Stage`. \n\n(p.3, `Regular Structure of Reward Functions`) $\\{\\phi_i(s, a)\\}_{i=1}$\n- $\\{\\phi_i(s, a)\\}_{i=1}^M$?\n\n(p.3, `Problem Statement`) $\\mathrm{MDP}\\backslash R:=(\\mathcal{S}, \\mathcal{A}, \\mathcal{T}, \\gamma)$\n- The definition doesn’t match with one without the discount factor $\\gamma$ in `Preliminary`.\n\n(p.3, `Problem Statement`) $\\{\\phi_i(s)\\}_{i=1}^M$\n- $\\{\\phi_i(s, a)\\}_{i=1}^M$?\n\n(p.3, `Problem Statement`) weights $\\mathcal{W}$\n- The definition should be provided. \n- Either $\\mathcal{W}=(\\alpha_1, …, \\alpha_M)$ (for linear model) or the weights of neural network (for non-linear model)?\n\n(p.3, `Problem Statement`) `more likely generates weights to compose reward functions as the ones derived from expert demonstrations`\n- Is this only a special case of Bayesian IRL?\n\n(p.3, `Problem Statement`) `Suppose a representative trajectory class ~`\n- The explanation should be clarified. In my understanding, $\\mathcal{C}_\\epsilon^E$ is a class of sets of trajectories.\n- Why do we need to care such a class with $\\epslion$ threshold?\n\n(p.3, `Problem Statement`) Integrate out unobserved weights $\\mathcal{W}$\n- What does *unobserved* weights mean?\n- Integrate out -> Marginalizing out?\n\n(p.3, `Problem Statement`) trajectory element set $\\mathcal{O}$ assumes to be uniformly distributed for the sake of simplicity in this study\n- I don’t fully understand what’s the advantage of considering a representative trajectory class and why it is required. \n- The section `Note:` tries to explain it, but more explanation or theorems seems to be needed. How can we theoretically guarantee that using a representative trajectory class doesn’t affect our estimation? It seems to me that we cannot guarantee the optimality with this class is the same as the original optimality. \n\n (p.3, `Problem Statement`) $f_{\\mathcal{M}}$\n- How this quantity is related to reward weights is unclear to me. The relationship between weights and $f_\\mathcal{M}$ for both linear and non-linear models should be specified.\n\n(p.3, `Note:) \n- Instead of using a separate section, I’d rather put these statements in the middle of `Problem Statement` for a clearer explanation. \n\n(p.4, `Two-stage Hierarchical Method`)\n- Why do we need to use two-stage method instead of single-stage method (joint optimization over $\\Theta_1$ and $\\Theta_2$)? The advantage of two-stage methods should be briefly mentioned when it first appears for readability. \n- How does the iterative update rule (4), (5) guarantee the optimization of (3)? It’s unclear to me due to the expectation in (4) and (5). My guess is that direct optimization of RHS of (3) is not possible and (4) and (5) might be either lower or upper bound of (3) due to Jensen’s inequality. \n\n(p.4, `Initialization`) `~in each learning task`\n- Do we care about multi-task learning or multiple reward weights only? I believe the latter case.\n\n(p.6, `Experiments`) `since almost only objectworld provides a tool that allows analysis and display the evolution procedure of the SIRL problem in a 2D heat map, we skip the typical invisible physics-based control tasks for the evaluation of our approach, i.e. cartpole Barto et al. (1983), mountain car Moore (1990), MuJoCo Todorov et al. (2012), and etc.`\n- I think this makes the contribution weaker. At least a few classic control tasks should have been considered. One way of evaluating the quality of rewards is retraining the agent with acquired reward, which is already widely used in the literature. \n\n(p.6, `Objectworld`) \n- One figure for illustration will enhance readability. \n\n(p.7, `Evaluation Procedure and Analysis`) `DSIRL`\n- DSIRL abbreviates Deep SIRL but wasn’t mentioned. \n\n(p.7, `Recovery Experiments`)\n- How many runs were used? How’s the mean and confidence interval of the empirical result? \n\n(p.8, `Robustness Experiments`)\n- I couldn’t understand how the robustness of reward is related to the proposed experiments. How the robustness is defined and its relation to the experiment should be clarified.  \n\n(p.8, `Hyperparameter Experiments`)\n- How is the range of hyperparameter search for all methods? Currently, only the results for SIRL and DSIRL are given. \n\n(p.8, `Conclusion`)\n- It seems like both succinctness and transferability were not discussed in the main part of the submission. \n\n### References\n- Levine et al., 2011, “Nonlinear inverse reinforcement learning with gaussian processes“\n- Fu et al., 2017, “Learning robust rewards with adversarial inverse reinforcement learning”\n- Ho et al., 2016, “Generative adversarial imitation learning”\n- Ziebart et al., 2008, “Maximum Entropy Inverse Reinforcement Learning”\n- Caffo et al., 2005, “Ascent-based Monte Carlo expectation-maximization”\n- Chan and Ledolter, 1995, “Monte Carlo em estimation for time series models involving counts“\n\n","sentences":[{"sentence_type":"2","sentence":"The readability of the submission is poor and needs to be improved.","rephrased":"The readability of the submission could be enhanced for better understanding."},{"sentence_type":"2","sentence":"There seems to be a minor contribution","rephrased":"The contribution of the work could be more clearly highlighted and elaborated upon."},{"sentence_type":"1","sentence":"I feel this statement is weird since we haven't defined the optimality of expert demonstrations.","rephrased":"The statement about the optimality of expert demonstrations could be clarified with a definition of 'optimality' in this context."},{"sentence_type":"1","sentence":"Definitions of these expressions seem ambiguous to me.","rephrased":"It would be helpful if the definitions of terms such as 'succinct', 'robust', and 'transferable' were more explicitly stated."},{"sentence_type":"1","sentence":"Again, ambiguous.","rephrased":"The term 'a global viewpoint' could benefit from further explanation to understand its relevance to the context."},{"sentence_type":"2","sentence":"The sentence seems abrupt. The terms like 'sub-optimal' and 'inconsistent' here are awkward.","rephrased":"The discussion on experts acting 'sub-optimally' or 'inconsistently' could be introduced more smoothly and the terms could be better integrated into the narrative."},{"sentence_type":"2","sentence":"I couldn't understand what the authors wanted to emphasize.","rephrased":"The authors' intended emphasis in this section is not entirely clear to me; further clarification would be beneficial."},{"sentence_type":"2","sentence":"I think this makes the contribution weaker.","rephrased":"Including classic control tasks in the evaluation could potentially strengthen the contribution of the work."},{"sentence_type":"2","sentence":"I couldn't understand how the robustness of reward is related to the proposed experiments.","rephrased":"The connection between the robustness of the reward and the proposed experiments could be more clearly articulated."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[726,793,"Confirmed"],[1408,1446,"Confirmed"],[2144,2198,"Not concerning"],[2242,2259,"Not concerning"],[10267,10310,"Not concerning"]],"Comments":[]}
{"id":"iadWG6QANxi","text":"Strengthes:\n* Simple search strategy for hierarchical policies allowing highly parallel implementation\n\nWeaknesses:\n* Quality of the evaluation of the proposed approach is below the standard of the community. (1) The comparison in Table 1 is rather unfair. The authors compared the performances of variants of the proposed approach after 100 or 600 million steps, with the performances of existing approaches after 10 million steps. (2) The two tested environments are similar, and do not support the generality of the proposed approach. It is also unclear whether these environments are representative for the environment said to be \"hard\" by the authors repeatedly in the introduction. (3) Ablation studies are missing.\n* Novelty is questionable. The search strategy is almost the same as [Salimans et al, 2017]. The only difference is that the fitnesses for the controller policy and for the primitive policy are different. The fitness of the primitive reward is rather similar to existing approaches except for a way to normalize it. The contribution of this proposed primitive reward is not evaluated in experiments, hence unclear. \n* Clarity of the statements should be improved. (1) F in Algorithm 1 is not explained in detail. (2) The authors repeatedly says \"challenging problems\" and \"hard problems\", but it is not clearly stated what kinds of difficult tasks the authors are targeting. (3) The authors claims that ES is invariant to delayed reward. But it is not clear what is meant by it. (4) The authors say that \"hard RL problems often have many large local minima\" and ES is advantageous for this perspective. This might be true for the standard ES, but for the one used in this paper, the authors set the noise std for the parameter search to be 0.02, meaning that this approach do not take into account so much global information of the objective function.","sentences":[{"sentence_type":"2","sentence":"Quality of the evaluation of the proposed approach is below the standard of the community.","rephrased":"The evaluation of the proposed approach could be strengthened to meet the community standards."},{"sentence_type":"2","sentence":"Novelty is questionable.","rephrased":"The novelty of the approach could be better highlighted and differentiated from existing work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[118,208,"Confirmed"],[724,748,"Confirmed"]],"Comments":[]}
{"id":"B1gpdP5K37","text":"This paper proposes a method for multi-document abstractive summarization. The model has two main components, one part is an autoencoder used to help learn encoded document representations which can be used to reconstruct the original documents, and a second component for the summarization step which also aims to ensure that the summary is similar to the original document. \n\nThe biggest problem with this paper is in its evaluation methodology. I don't really know what any of the three evaluation measures are actually measuring, and there is no human subject evaluation back them up.\n- Rating Accuracy seems to depend on the choice of CLF used, and at best says whether the summary conveys the same average opinion as the original reviews. This captures a small amount about the actual contents of the reviews. For example, it does not capture the distribution of opinions, or the actual contents that are conveyed.\n- Word Overlap with the original documents does not seem to be a good measure of quality for abstractive systems, as there could easily be abstractive summaries with low overlap that are nevertheless very good exactly because they aggregate information and generalize. It is certainly not appropriate to use to compare between extractive and abstractive systems.\n-There are many well-known problems with using log likelihood as a measure of fluency and grammaticality, such as biases around length, and frequency of the words.\nIt also seems that these evaluation measures would interact with the length of the summary being evaluated in ways which systems could game.\n\nOther points:\n- Multi-Lead-1: The lead baseline works very well in single-document news summarization. Since this model is being applied in a multi-document setting to something that is not news, it is hard to see how this baseline is justified.\n\n- Despite the fact that the model is only applied to product reviews, and there seem to be modelling decisions tailored to this domain, the paper title does not specify so, which in my opinion is a type of over-claiming.\n\nHaving a paper with poor evaluation measure may set a precedent that causes damage to an entire line of research. For this reason, I am not comfortable with recommending an accept.\n\n\n---\nThank you for responding to my comments and updating the paper. I have slightly raised my score to reflect this effort.\n\nThere are new claims in the results section that do not seem to be warranted given the human evaluation. The claim is that the human evaluation results validate the use of the automatic metrics. The new human evaluation results show that the proposed abstractive model performs on par with the extractive model in terms of conveying the overall sentiment and information (Table 2), whereas it substantially outperforms the extractive model on the automatic measures (Table 1). This seems to be evidence that the automatic measures do not correlate with human judgments, and should not be used as evaluation measures.\n\nI am also glad that the title was changed to reflect the scope of the experiments. I would now suggest comparing against previous work in opinion summarization which do not assume gold-standard summaries for training. Here are two representative papers:\n\nGanesan et al. Opinosis: A Graph-Based Approach to Abstractive Summarization of Highly Redundant Opinions. COLING 2010.\nCarenini et al. Multi-Document Summarization of Evaluative Text. Computational Intellgience 2012.","sentences":[{"sentence_type":"2","sentence":"I don't really know what any of the three evaluation measures are actually measuring, and there is no human subject evaluation back them up.","rephrased":"The paper could benefit from a clearer explanation of the three evaluation measures and from including human subject evaluations to support them."},{"sentence_type":"3","sentence":"Having a paper with poor evaluation measure may set a precedent that causes damage to an entire line of research.","rephrased":"It is important to ensure that the evaluation measures are robust to avoid setting a precedent that could potentially mislead future research in this area."},{"sentence_type":"1","sentence":"For this reason, I am not comfortable with recommending an accept.","rephrased":"Due to the concerns regarding the evaluation measures, I am hesitant to recommend acceptance at this stage."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[448,588,"Confirmed"],[2059,2172,"Confirmed"],[2173,2239,"Not concerning"]],"Comments":[]}
{"id":"HkxYmJqo2m","text":"In the vein of recent work on learning “ticking” behaviour for LSTMs such as Phased LSTM, this paper proposes to add additional data independent gates to LSTM units that are defined as Gaussian functions of time indices.\nThe performance of the modified g-LSTM is compared to LSTM on the Addition, sequential MNIST and sequential CIFAR-10 tasks. The authors argue that g-LSTM results in better performance and has faster convergence on these tasks. \n\nAdditionally, it is proposed that one can reduce the amount of computations performed by the network by adding a computation budget term to the optimized loss that encouraged the cells to update less often. Finally, a technique for gradually transitioning from a g-LSTM to an LSTM during training is proposed, with the objective of speeding up training over a regular LSTM.\n\nThe paper is well written and easy to understand in general. However, the main results of this paper are experimental, and I am not entirely convinced by the experiments that g-LSTM is an improvement over the LSTM baseline for certain scenarios.\n\nOne broad reason for my doubts is that the comparisons don’t seem to utilise proper hyperparameter tuning for the baseline LSTM. Network sizes, learning rates, decay schedules, initialisations etc. all appear to be fixed, so one can not be sure of the “real” performance or convergence behavior of the models. Biased gate initializations are not used, though they have been used successfully in past work to aid in long term memory.\n\nI should note that for long term memory problems such as those proposed by Hochreiter and Schmidhuber (1997), the proposed LSTM did not use a forget gate (or even BPTT) and used biased gate initialisations. However, these features are useful for more realistic tasks, and popular LSTM designs are biased towards them instead of toy problems.\n\nI would consider the addition problem and sequential MNIST and CIFAR-10 to be interesting and difficult toy tasks for initial validation of ideas (and more extensive hyperparameter searches). It is unclear if the proposed techniques will perform provide  improvements over a well-tuned baseline for some realistic tasks, or are they suitable only for toy problems. ","sentences":[{"sentence_type":"1","sentence":"However, the main results of this paper are experimental, and I am not entirely convinced by the experiments that g-LSTM is an improvement over the LSTM baseline for certain scenarios.","rephrased":"While the main results of this paper are experimental, I would like to see more evidence or additional experiments to fully ascertain the improvements of g-LSTM over the LSTM baseline in certain scenarios."},{"sentence_type":"2","sentence":"One broad reason for my doubts is that the comparisons don't seem to utilise proper hyperparameter tuning for the baseline LSTM.","rephrased":"One area of concern is whether the comparisons have utilized comprehensive hyperparameter tuning for the baseline LSTM, which could affect the validity of the results."},{"sentence_type":"2","sentence":"It is unclear if the proposed techniques will perform provide improvements over a well-tuned baseline for some realistic tasks, or are they suitable only for toy problems.","rephrased":"It would be beneficial to explore whether the proposed techniques can offer improvements over a well-tuned baseline for realistic tasks, beyond the initial validation on toy problems."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[886,1070,"Not concerning"]],"Comments":[]}
{"id":"B-gJKYKCWc","text":"The paper presents an architecture for reinforcement learning in the object manipulation setting. The main contribution is a network architecture called \"Linear Relation Network,\" which is essentially a relation network (RN) that receives an additional goal object. Thus, the authors propose to consider only relationships with the goal object. Thus, the overall computation complexity is $O(n)$ instead of $O(n^2)$, where $n$ is the number of objects. The authors show that their model generalizes better to testing environments with more objects than those of training. The paper presents an interesting contribution to the literature and is relevant to the workshop.\n\nMy detailed weakness comments are the following.\n\n1. What will happen if we just use a linear aggregation of object features instead of considering relationship between objects? Since there is only one goal object, I would imagine this method work works fine. See DeepSets as an example: https:\/\/arxiv.org\/abs\/1703.06114.\n2. Assuming one single goal object is definitely limited. For example, even if we only care about pushing one object to the target region, there might be cases where we may actually need to push away other objects that are blocking our path. The authors should be more fair when comparing their approach with existing literature, for example Li et al \"Towards practical multi-object manipulation using relational reinforcement learning.\" Exploring different design choices and see how they improves learning\/generalization is important but should be done in a more systematical manner.\n3. There have been a lot of work on reducing the quadratic computation complexity for relational architectures. For example, LinFormer https:\/\/arxiv.org\/pdf\/2006.04768.pdf.","sentences":[{"sentence_type":"2","sentence":"The authors should be more fair when comparing their approach with existing literature, for example Li et al \"Towards practical multi-object manipulation using relational reinforcement learning.\"","rephrased":"The authors could enhance their comparison with existing literature, such as the work by Li et al. \"Towards practical multi-object manipulation using relational reinforcement learning,\" to provide a more comprehensive evaluation of their approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1235,1430,"Not concerning"]],"Comments":[]}
{"id":"PpnE6pgidP","text":"Overall, the quality of the paper is fair. It is well-written, well-structured and easy to read for someone without knowledge on IVF and ART. The method is compared to five embryologists and results clearly shows that learning directly from the clinical outcome outperfoms embryologists by a large margin. The main weakness of the paper is in the methods section.\n\nThe methodological novelty seems insignificant. Plenty of works combine autoencoders with LSTMs. I suggest you either argue for the novelty or remove the claim from the paper.\n\nThe methods section lacks details for reproducing the work. These must be provided in a supplement to allow reproducability. If you want your work applied in clinics, this is much more important than improving the results.\n\nIn the methods section you describe training an autoencoder on unlabeled data, then training an LSTM using autoencoder embeding and embryologist grades. As I read it, UBar is the same LSTM just trained on clinical outcomes. You do not report results for the embryologist trained LSTM, so what do you use this LSTM for? If you dont use it, remove it from the section. If you do use it, you cannot argue that you learn from \"a small number of labeled samples\" as done in the final paragraph of the paper.\n\nIn the discussion you almost exclusively focus on the work by Tran et al and why comparing with that work is unfair. Instead, you should have made the comparison and highlighted the differences clearly. What is interesting is not who is better, but how, and how well, the task can be solved. \n\nYou argue that including embryologists decisions in the prediction is an easier task. I am not convinced. In your case, you train on data that has already been filtered to only include positive decisions by embryologists, otherwise the eggs would not have been implanted. It is not obvious how to best get around this issue, since the first embryologist screening probably has false negatives, but you need to take it into account.\n\nYour statement about AUCs and training sizes is either obviously correct or obviously wrong, depending on interpretation. The only way training size can influence AUC is by influencing the training of the model. It is quite well known that more training data, in general, results in improved performance of networks. This holds for all the popular performance measures. Having said that, if the model predictions does not change, then AUC does not change. Maybe you meant the size of the test set? In that case, it is the ratio of positive\/negative that is relevant. Regardless, trying to paint others work negatively by arguments to some general issue with established performance metrics is disingenuous. If there is an issue with Tran et al you should state it clearly, if not, you should accept their results.\n\nA mior nitpick:\nYou define all abbreviations except for UBar. It is fine that you give your method a name (although I personally dislike it), but a bit weird not to explain it.\n\nFinally, I would very much have liked to to see a frame from one of the videos. I am aware of the page limitation, so maybe MIDL should allow an extra page solely for an image of the raw data.","sentences":[{"sentence_type":"2","sentence":"The methodological novelty seems insignificant.","rephrased":"The methodological novelty could be better highlighted. It would be beneficial if you could further elaborate on how your approach differs from existing works that combine autoencoders with LSTMs."},{"sentence_type":"2","sentence":"If you dont use it, remove it from the section.","rephrased":"If the LSTM trained on embryologist grades is not utilized in the study, consider omitting it from the methods section to avoid confusion. If it is used, please clarify its role and contribution to the study."},{"sentence_type":"3","sentence":"Regardless, trying to paint others work negatively by arguments to some general issue with established performance metrics is disingenuous.","rephrased":"It's important to ensure that any critique of established performance metrics and comparisons with other work is presented in a constructive manner. If there are specific issues with the work of Tran et al., please articulate them clearly; otherwise, it would be more productive to acknowledge their results and focus on the contributions of your own work."},{"sentence_type":"1","sentence":"It is fine that you give your method a name (although I personally dislike it), but a bit weird not to explain it.","rephrased":"While it's acceptable to name your method, it would be helpful to include an explanation of the acronym UBar for consistency and clarity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[365,412,"Confirmed"],[1085,1132,"Confirmed"],[2564,2703,"Confirmed"],[2874,2988,"Maybe"]],"Comments":[]}
{"id":"HylngDnNnE","text":"The paper describes a domain acquisition approach that extends (Aineto et al. 2018). The underlying work takes partially observed plan sequences and a partial domain model (possibly empty) as input and creates a domain model through a construction of a planning problem. The presented work considers using a different representation for the partial domain model. In particular, using schematic mutex relations in place of pre\/post conditions. The approach exploits the mutexes in two ways. Firstly attempting to fill in the partially observed state information. Secondly in order to shape the chosen domain model. \n\nIn the context of domain model acquisition the direction of this work is refreshing. It is typical in this area to move between data inputs with different properties (even subtly), leaving meaningful analysis difficult or meaningless. This work fits in nicely as part of a more systematic investigation of how different input types can be exploited. \n\nThe paper is well presented and the results indicate that schematic mutexes provide considerable leverage for learning.\n\nA key consideration here is to what extent these mutexes are easier to specify than the domain model itself, which includes whether they are conceptually simpler than specifying the domain mechanics. I don't believe this point is really addressed (other than claiming it as \"easily deducible domain knowledge\"). This being the important topic of the paper, it seems there is interest in exploring it in the evaluation. For example, what happens if only x% of the mutexes are specified?\n\nThe other aspect that would be interesting to understand better is the scalability of this approach. Given the modest size of typical benchmark domain models and your use of 16GB RAM in the experiments, this is left unclear. \n\nI am surprised by the related work section, which appears to focus on domain model acquisition approaches that deal with noise. It is hardly surprising that these approaches require more evidence. Similarly it is unclear to what extent this new approach really brings anything new to general properties of completeness and correctness with respect to the acquired model.","sentences":[{"sentence_type":"2","sentence":"I don't believe this point is really addressed (other than claiming it as \"easily deducible domain knowledge\").","rephrased":"It would be beneficial for the paper to more thoroughly address the ease of specifying mutexes compared to the domain model, perhaps by expanding on the claim that it is \"easily deducible domain knowledge\"."},{"sentence_type":"2","sentence":"It is hardly surprising that these approaches require more evidence.","rephrased":"It would be expected that these approaches require more evidence, and it would be helpful to understand how this new approach compares in this regard."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1289,1400,"Confirmed"],[1931,1999,"Maybe"]],"Comments":[]}
{"id":"BJgkNLcAtr","text":"The submission describes an adaptive spiking neuron model that is based on the Laplace transform of the model output.\nThis reformulation allows to train a recurrent neural network of spiking neural network with good performances.\nThree tasks are proposed to assess the recurrent net, on synthetic data and real signal.\n\nI think this contribution could not be accepted for a methodological problem: the main idea is to use neuromorphic chips that use spiking neural networks with an approximation that is basically similar to an artificial neural network. The authors need to introduce a complex rescaling of the time step, repercussion on the computation. This point should be shown experimentally. The authors introduced a modification of the aI&F and are applying low pass filtering the spike trains. \n\nAs all the results are obtained on a python simulator, it is difficult to assess the interest and the applicability to real neuromorphic chips.\nAs pointed out by the authors, the main interest of these architectures are the lower energy consumption than CPU\/GPU-based architecture.\nUnfortunately, it is not possible to assess if the proposed neuron model is working on energy efficient architecture.\n\n\n[1] Nair, M. V. and Indiveri, G. (2019). An ultra-low power sigma-delta neuron circuit. In 2019 IEEE International Symposium on Circuits and Systems (ISCAS), pages 1–5.\n","sentences":[{"sentence_type":"2","sentence":"I think this contribution could not be accepted for a methodological problem","rephrased":"The contribution raises some methodological concerns that need to be addressed before it can be considered for acceptance."},{"sentence_type":"2","sentence":"Unfortunately, it is not possible to assess if the proposed neuron model is working on energy efficient architecture.","rephrased":"Further work is needed to assess whether the proposed neuron model operates efficiently on energy-efficient architectures."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[320,396,"Confirmed"],[1087,1204,"Maybe"]],"Comments":[]}
{"id":"bFp-4ZN2I7","text":"- Good summary of clinical problem in prostate cancer and need for \"hybrid\" ADC map with more structural information\n- Use of GANs to \"translate\" between ADC and T2 maps, but the exact logic underlying what the GAN is optimizing for is not well explained.\n- Impact of post-processing of T2w MRI is unclear.\n- No quantitative evaluation, hard to tell how effective the approach is.","sentences":[{"sentence_type":"2","sentence":"No quantitative evaluation, hard to tell how effective the approach is.","rephrased":"Including a quantitative evaluation could enhance the understanding of the approach's effectiveness."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[309,380,"Confirmed"]],"Comments":[]}
{"id":"iQmFiTg6Btg","text":"\nThere’s extensive work on scaling up PCA such as the randomized algorithm Halko et., al. (2010). In the prior work section, the authors argue that the existing randomized algorithms only guarantee a small approximation error, but not the accuracy of the computed singular values or space. I think the claim is not true as the accuracy of the singular values\/space follows from classic results, e.g., the \nHoffman-Wielandt bound, in matrix perturbation theory. \n\nThe threshold parameter epsilon in the proposed algorithm is introduced to specify the noise level. However, this parameter may not be very useful as data is typically standardized. I think it is helpful to establish the connection between the parameter with the rank of the algorithm output.\n\nThe presentation and the experiments could be improved. This paper lacks necessary evaluation on real-life datasets. The authors report numerical results of the proposed algorithm on synthetic data. For a fair evaluation, I think it would be helpful to include the state-of-the-art randomized algorithms as well as the robust PCA as baselines.","sentences":[{"sentence_type":"1","sentence":"I think the claim is not true as the accuracy of the singular values\/space follows from classic results, e.g., the Hoffman-Wielandt bound, in matrix perturbation theory.","rephrased":"While the authors suggest that existing randomized algorithms do not guarantee the accuracy of the computed singular values or space, it may be worth revisiting classic results such as the Hoffman-Wielandt bound in matrix perturbation theory, which could imply otherwise."},{"sentence_type":"2","sentence":"However, this parameter may not be very useful as data is typically standardized.","rephrased":"It would be beneficial to clarify the utility of the threshold parameter epsilon, especially considering that data is typically standardized, which might affect its relevance."},{"sentence_type":"2","sentence":"This paper lacks necessary evaluation on real-life datasets.","rephrased":"To strengthen the paper, it would be advantageous to include evaluations on real-life datasets in addition to the synthetic data already presented."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[290,460,"Not concerning"],[563,644,"Maybe"],[813,873,"Maybe"]],"Comments":[]}
{"id":"B1lCfqNOh7","text":"The paper proposes a class of Evolutionary-Neural hybrid agents (Evo-NAS) to take advantage of both evolutionary algorithms and reinforcement learning algorithms for efficient neural architecture search. \n\n1. Doesn't explain how exactly the mutation action is learned, and missing the explanation of how RL acts on its modification on NAS (Evo-NAS). \n2. Very poor explanation on LEARN TO COUNT experiment. The experiment contains difficult setups on a toy data, which makes it difficult to repeat. In figure 3, the paper says that the sample efficiency of the Evo-NAS strongly outperforms both the evolutionary and the neural agent. However, where the strength comes from is not discussed in detail. In figure 2, the paper claims that PQT outperforms Reinforce for both the Neural and the Evo-NAS agent. For the Evo-NAS agent, the gain is especially pronounced at the beginning of the experiment. Thus, the paper concludes that PQT can provide a stronger training signal than Reinforce. However, how much stronger training signal can obtain of the proposed method is not discussed. Because the experiments of 5.1 is setup on a toy data with complicated parameters. The conclusions based on this data set is not convincing. It would be better to add comparative results on the CIFAR and Imagenet data for convenient comparisons with state-of-the-art. \n3. Confusing notation and experimental setup. In 5.1, the sequence a is first defined as <a1, a2, .., an>. Then, after eq.2, the sequence a is given as a=<1, 2, ..., n>. It would be better to use different symbols here. ","sentences":[{"sentence_type":"2","sentence":"Very poor explanation on LEARN TO COUNT experiment.","rephrased":"The explanation of the LEARN TO COUNT experiment could be improved for clarity."},{"sentence_type":"2","sentence":"The conclusions based on this data set is not convincing.","rephrased":"The conclusions drawn from this dataset could be strengthened with additional evidence or comparative results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[354,405,"Confirmed"],[1165,1222,"Not concerning"]],"Comments":[]}
{"id":"iquh89P9Pja","text":"Summary of the paper: \nThe paper studies binary classification with pairwise comparisons as the supervision. Instead of the traditional pointwise supervision, the paper assumes only access to pairs of examples $x,x'$ where we believe that $p(y=1|x)\\geq p(y=1|x')$. The authors considers two kinds of methods. The first one considers x, x' be sampled from two different distributions, and uses the method from Unlabeled-Unlabeled (UU) classification to obtain an unbiased risk estimator. The second one is the RankPruning method, where a fraction of data with highest confidence is selected and is used to derive a URE on the selected samples. The paper proposes to add a moving-average regularization to RankPruning. The authors performed experiments on 2-class versions of standard benchmark datasets. In general RankPruning with regularization performs the best in most cases, but the first method is also competitive.\n\nReview: \nThe paper studies an important problem of learning classification from pairwise comparisons. I have some doubts though:\n\ta) The paper assumes a generative process of the pairs: Generally, it assumes a rejecting sampling process. If we sample $(x,x')$ with $y=-1,y'=+1$, then we reject it; otherwise we keep it. Why is this correct? Do we have data supporting this process? I may suggest other models: E.g., return $(x',x)$ if $y=-1,y'=+1$, and $(x,x')$ otherwise. Is this also plausible? How can we test what generation method is used?\n\tb) Another bigger problem is that the method ignores the PAIR nature of the problem; the method basically ignores the pairs and just treat list of $x, x'$ as from different distributions. We naturally loses the information that $p(y=1|x)\\geq p(y=1|x')$. Is this a good method? Can we use other methods to utilize the pair information, such as siamese networks? How does the performance compare?\n\tc) In general the paper lacks a bit novelty - the first method is an adaptation of UU estimator, and the second method is just adding a regularization to RankPruning.\n\nMinor Comments:\n\ta) Second paragraph in Sec 3 - the paragraph is a bit unclear to me. Can you state the generation process formally?\n\tb) Classification with pairwise comparisons is also considered in these works:\n\tXu, Y., Zhang, H., Miller, K., Singh, A., and Dubrawski, A. Noise-tolerant interactive learning from pairwise comparisons with near-minimal label complexity. NIPS2017.\n\tD. M. Kane, S. Lovett, S. Moran, and J. Zhang. Active classification with comparison queries. FOCS 2017.\nBoth papers use a small amount of labeled data; but they considers the pair information.","sentences":[{"sentence_type":"2","sentence":"In general the paper lacks a bit novelty - the first method is an adaptation of UU estimator, and the second method is just adding a regularization to RankPruning.","rephrased":"While the paper builds on existing methods, it would be beneficial to highlight more clearly the novel contributions that differentiate this work from previous adaptations of the UU estimator and enhancements to RankPruning."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1867,2030,"Maybe"]],"Comments":[]}
{"id":"r_dgZhZoD-c","text":"The paper discusses the relaxation the multivariate non-central hypergeometric distribution. This is the distribution whereby one has $N$ objects in $c$ classes, with $m_i$ objects of class $i$. From these, one then samples $n$ objects without replacement, where objects in class $i$ are sampled with weight $\\omega_i$. The authors reformulate this multivariate case as a sequence of $c$ bivariate cases. In step $i$, they assume the classes $\\lt i$ have been sampled, then condition on that result and sample the remaining from either class $i$ or the classes $\\gt i$. Each bivariate case is then a categorical over the number of samples in class $i$, which is relaxed via the Gumbel Soft-Max trick.\n\nFor the experiments, the paper considers the task of observing pairs of images, generated from a $d$ dimensional latent, whereby the latents differ in $k$ dimensions (sampled independently) and are equal on $d-k$ dimensions. The goal is to learn a VAE with an encoder that maps to a latent space that differs from the ground truth only via a permutation and element-wise diffeomorphism. For each pair, $k$ differs and is unknown, thus must be inferred by the encoder. The authors apply their method, in the bivariate case, with $d$ samples from $2d$ objects, with $d$ in class \"latents equal\" and $d$ in class \"latents differ\". The weights of the classes is a learned function of the encoder. Then a number $k$ is sampled in the class \"latents differ\", which are then heuristically matched to $k$ of the $d$ dimensions.\n\nThe relaxation strategy is makes sense to me. However, I find the application in the experiment very non-intuitive. Firstly, they only experiment with the bivariate case, while they propose a multi-class method. Secondly, why is this a hypergeometric problem in the first place? Why first predict a number $k$ and then with an unelegant heuristic map this to $k$ of the $d$ dimensions? A much more natural representation seems to me to just treat it as $d$ binary variables: whether the dimension is equal or not. The probabilities could then e.g. be computed learnably from the $\\gamma$ vector. This would be simpler and avoid the heuristic of post-hoc selection of the $k$ dimensions. In any case, I'm sure that one can find experiments in which the probabilistic problem is clearly a multivariate non-central hypergeometric distribution, which I'd recommend to evaluate the method on.\n\nFurthermore, there are some serious presentation issues. The multivariate non-central hypergeometric distribution itself is not defined in the main paper, only in the appendix. The $\\omega$ variables in equation 1 are not defined in the main paper. The variables $\\alpha_i$ are used in equation 2, but not defined. I'd recommend a big restructuring, in which first the mutivariate case is explained (including the PMF in the main paper), then the sequential sampling (including sec 2.3) and only then the relaxation.\n\nI weakly recommend acceptance of this paper because the general method seems sensible, but I suggest that the authors evaluate their method on more fitting problems and clarify the presentation for the final version.","sentences":[{"sentence_type":"1","sentence":"However, I find the application in the experiment very non-intuitive.","rephrased":"While the relaxation strategy is clear, the application in the experiment could be more intuitive."},{"sentence_type":"2","sentence":"Why first predict a number $k$ and then with an unelegant heuristic map this to $k$ of the $d$ dimensions?","rephrased":"It would be helpful to understand the rationale behind predicting a number $k$ and then mapping this to $k$ of the $d$ dimensions using the chosen heuristic."},{"sentence_type":"2","sentence":"Furthermore, there are some serious presentation issues.","rephrased":"Additionally, there are some areas in the presentation that could be improved for clarity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1569,1638,"Confirmed"],[1802,1908,"Confirmed"],[2412,2468,"Confirmed"]],"Comments":[]}
{"id":"SkecWJgtKV","text":"It is not clear how it is appropriate to the audience of the workshop because the data are properly labeled. Yet, the authors argue that there is noise in the data labeling. \n\n1\/ Introduction\nContext and goals are clearly described.\n\n2\/ The MELD algorithm\nClear.\nThen, they introduce Vertex Frequecy Clustering but the method is not detailed.\n\n3\/ Results\nIt seems good yet it's hard to judge because there is no comparison with other methods.\nAuthors used 'we' + citation which breaks double-blind review...\n\n\n","sentences":[{"sentence_type":"2","sentence":"It is not clear how it is appropriate to the audience of the workshop because the data are properly labeled.","rephrased":"The relevance to the workshop audience could be better articulated, especially considering the data are properly labeled."},{"sentence_type":"2","sentence":"Authors used 'we' + citation which breaks double-blind review...","rephrased":"Please ensure adherence to the double-blind review process by avoiding the use of 'we' in conjunction with citations."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,108,"Maybe"],[443,507,"Maybe"]],"Comments":[]}
{"id":"Hke_3RtehN","text":"This paper presents a domain-independent framework, ILM (incremental learning model), for incremental learning over multiple planning problems of a domain in PPDDL (without the use of past training data).\n\nILM learns from failure by checking if an action is in a list of state-action pairs which represents actions that have failed to execute. \n\nILM is evaluated on three benchmark domains, showing that learning from failure greatly reduces the number of failed executions leading to improved correctness and \"goal-directedness\".\n\nThe paper is moslty well written, ineteresting and fitting the workshop topic.\n\nSome suggestions\/questions:\n\n- Model in figure 1. I think it is a bit misleading, especially because of the inverse modeling of flat tire predicate. This probably comes from the IPC formulation, but would be way more intuitive if modeled with a Flattire() predicate instead of notFlattire(), having 0.25 probability that as an effect it gets true. \n\n- p3, Reliability of actions. Please gives 2 words of explanation for exposure and volatility when the first formula is presented. Notwithstanding they are more extensively defined later, it is needed to grasp the meaning of the formula (elaborate also more on the whole formula would also help). \n\n- Why \"In reinforcement learning, less reliable actions are preferred during exploration\"?\n\n","sentences":[{"sentence_type":"1","sentence":"The paper is moslty well written, ineteresting and fitting the workshop topic.","rephrased":"The paper is mostly well-written, interesting, and fits the workshop topic well."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[532,610,"Not concerning"]],"Comments":[]}
{"id":"bmfQrG7gw","text":"In this paper, the authors propose a two-stage deep learning method for producing slice-wise preditions for intracranial hemorrhage detetion. The paper is well written and easy to follow. The authors first train a 2D convolutional network to perform classification per slice using transfer learning. During this training process, the 6 adjacent slices are part of the same batch. Subsequently, a second CNN takes the predictions for each class for the 7 slices to produce a 7x6x1 tensor which is used to produce an updated prediction for the center slice. The method is validated on the RSNA Hemorrhage challenge and the CQ500 dataset. A score of 0.05341 on the RSNA challenge would have ranked 41 in the challenge.\n\nPro's:\n- Trained and validated on a large set. Also validated on an external dataset.\n- Compared a publicly available benchmark.\n\nCons: \n- I think this paper has little novelty.\n- A logical comparison would be to compare this approach with pseudo 3D approaches where multiple input slices are fed as extra channels. This is a common method which adds little computational overhead. A comparison with this baseline would have been very relevant. \n- A disadvantage of this approach is that it is not trained end-to-end. Why is this not possible? I do not see why not, and it is not explained in the paper.  The second stage could also be added using 1x1x7 convolutions? Also, the authors use batches of 16x7 so I would expect that it would fit in memory if the batch size is reduced.\n- It would have been good to report the performance without the second stage to see how much that adds to the performance.\n- From the paper, I understand that the authors only trained with the public training set of the RSNA challenge. Furthermore, performance is measured on the private test set. So, the public testing set was not used at all?","sentences":[{"sentence_type":"2","sentence":"I think this paper has little novelty.","rephrased":"The paper could benefit from highlighting its novel contributions more clearly, as they may not be immediately apparent."},{"sentence_type":"2","sentence":"Why is this not possible? I do not see why not, and it is not explained in the paper.","rephrased":"It would be helpful if the authors could provide further explanation as to why an end-to-end training approach was not possible or considered."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[856,894,"Maybe"],[1235,1320,"Confirmed"]],"Comments":[]}
{"id":"SygP9_2p2X","text":"The paper gives theorems concerning \"dual learning\" - that is, making\nuse of round-trip consistency in learning of translation and other\ntasks.\n\nThere are some interesting ideas here. Unfortunately, I think there\nare issues with clarity\/choice of notation and correctness (errors\nresulting from problems with the notation - or at least it's very\nhard to figure out if things are correct under some intepretation).\n\nMore specifically, I'm uneasy about the use of x^i and x^j as defined\nin section 2. In some cases x^j is a deterministic function of x^i, in\nsome cases it's a random variable, these cases are mixed. Section 2\nbecomes tangled up in this issue. It would be much better I think to\ndefine a function f_ij(x) for each (i,j) pair that maps a sentence\nx \\in S^i to its correct translation f_ij(x) \\in S^j.\n\nA critical problem with the paper is that Eq. 2 is I think incorrect.\nClearly,\n\nPr(T_ij(x_i) = f_ij(x_i), T_ji(f_ij(x_i)) = x_i)      [1]\n=\nPr(T_ij(x_i) = f_ij(x_i))                             [2]\n*\nPr(T_ji(f_ij(x_i)) = x_i) | T_ij(x_i) = f_ij(x_i))    [3]\n\nI think [1] is what is meant by the left-hand-side of Eq 2 in the paper -\nthough the use of x^j is ambiguous (this ambiguity is a real issue).\n\nIt can be verified that\n\nPr(T_ij(x_i) = f_ij(x_i)) = p_ij\n\nhowever\n\nPr(T_ji(f_ij(x_i)) = x_i) | T_ij(x_i) = f_ij(x_i)) \\neq p^r_ji\n\nThe definition of p^r_ji is that of a different quantity.\n\nThis problem unfortunately permeates the statement of theorem 1, and\nthe proof of theorem 1. It is probably fixable but without a\nsignificantly revised version of the paper a reader\/reviewer is\nbasically guessing what a corrected version of the paper would\nbe. Unfortunately I think publishing the paper with errors such as\nthis would be a problem.\n\nSome other points:\n\n[1] The theorem really does have to assume that there is a unique\ncorrect translation f_ij(x^i) for each sentence x^i. Having multiple\npossible translations breaks things. The authors say in section 2 \"In\npractice, we may select a threshold BLEU (Papineni et al., 2002a)\nscore, above which the translation is considered correct\": this seems\nto imply that the results apply when multiple translations (above\na certain BLEU score) are possible. But my understanding is that this\nwill completely break the results (or at least require a significant\nmodification of the theory).\n\n[2] A further problem with ambiguity\/notation is that T^d is never\nexplicitly defined. Presumably we always have T_ij^s(x^i) = T_ij(x^i) if\nT_ji(T_ij(x^i)) = x^i? That needs to be explicitly stated.\n\n[3] There may be something interesting in theorem 1 - putting aside point\n[1] above - but I am just really uneasy with this theorem and its proof\ngiven that it uses p^r_ji, and the issue with Eq. 2.\n\n[4] Another issue with the definition of p^r_ij: the notation\nP_{X^(j, r) ~ \\mu}(...) where the expression ... does not refer\nto X^{j, r} (instead it refers to x^j) is just really odd,\nand confusing.\n","sentences":[{"sentence_type":"2","sentence":"Unfortunately, I think there are issues with clarity\/choice of notation and correctness (errors resulting from problems with the notation - or at least it's very hard to figure out if things are correct under some intepretation).","rephrased":"I believe there are areas for improvement regarding clarity and choice of notation, as well as correctness. It may be challenging to determine the accuracy of the content due to these issues."},{"sentence_type":"2","sentence":"Unfortunately I think publishing the paper with errors such as this would be a problem.","rephrased":"Publishing the paper in its current form might lead to misunderstandings due to the errors present, and addressing these issues would be beneficial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[184,413,"Maybe"]],"Comments":[]}
{"id":"BJlHL35H9B","text":"The authors propose the adaptive thermostat Monte Carlo sampler for feedforward neural networks. The proposed approach dynamically adjust the amount of momentum and noisy applied to each model parameter during updates. ResNet++ (ResNet without batchnorm\/dropout but adding SELU, fixup and weight normalization) is introduced. Further, the authors claim that the need for hyperparameter setup is reduced provided that early stopping, stochastic regularization and carefully tuned learning rate schedules are not required.\n\nThe authors highlight some practical issues with the Nose-hoover thermostat, however, recognize its mathematical soundness. When ATMC is described (temperature stages), a motivation is provided but not justified theoretically.\n\nIn (10) and (11), \\gamma_1(), \\gamma_2(), \\eta_t and a are introduced without definition or further explanation.\n\nThe authors claim that the need for hyperparameter setup is reduced, however, in the experiments they use a cyclic step size with length n=50 (20 for ImageNet), a Laplace prior with parameter b=5, momentum noise with parameter 0.9, pre-conditioner parameter 0.0003 and c parameter 0.001. The impact of these choices on performance is not described. Further, the number of filters is doubled relative to ResNet-56 without explanation.\n\nThe calibration curves in Figure 3 are underwhelming. ATMC is better than SGD but not necessarily well calibrated. Also, note that x and y scales are heavily biased toward 1.\n\nIn summary, the proposed approach needs to be described in more detail and the experiments are not very satisfying given the claims made by the authors in the Introduction.\n\nMinor:\n- In (1) W is not defined.\n- In (1) the dimensionality of D, Q and \\Gamma is not defined but their elements are used.\n- In (2) m is only defined after (3), in fact, only called by its name, pre-conditioner, in Algorithm 1.\n- In Section 2.3 there is a reference to the step size, though not introduced until discretization later in Section 3.\n- In (7) \\beta() is a function of p, but not in other instances, e.g., (4), (10) and (11).\n- Move Algorithm 1 closer to definition.\n- In (13), d is not defined.","sentences":[{"sentence_type":"2","sentence":"The calibration curves in Figure 3 are underwhelming.","rephrased":"The calibration curves in Figure 3 could be improved to better demonstrate the effectiveness of ATMC."},{"sentence_type":"2","sentence":"In summary, the proposed approach needs to be described in more detail and the experiments are not very satisfying given the claims made by the authors in the Introduction.","rephrased":"In summary, the proposed approach would benefit from a more detailed description, and further experimentation could help substantiate the claims made in the Introduction."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1299,1352,"Confirmed"],[1475,1647,"Confirmed"]],"Comments":[]}
{"id":"p_8vbOFe4Gm","text":"\nUsing the same bar as NeurIPS, I continue to recommend rejecting this paper.\nSince the paper remained largely the same. My review remains largely the same.\nIt is also doubtful that these changes have satisfyingly address the other three\nreviews.\n\nThis paper proposes an iterative PBD solver which uses a neural network to guess\nthe constraint force and position updates before polishing with a conjugate\ngradient solver. The method utilizes a graph network architecture which makes it\nagnostic to the particular discretization allowing generalization (in theory)\nacross scenarios.\n\nSpeeding up simulations is an evergreen topic. A strength of this work is the\nproblem that it is tackling. The choice of methodology makes it mildly of\ninterest to the ICLR community. It is an application (without adaptation) of\ngraph networks. The result is mildly positive (though not earth shattering),\nindicating success of graph networks to some degree. I have not seen graph\nnetworks applied to rod simulation or elasticity simulation, although they have\nbeen applied to meshes in geometry processing (similar and more challenging\nscenario) and neural networks have been applied more generally to speeding up\nelasticity simulations (with what would be a trivial extension to rods). A\npossibly unique strength of this paper is the combination of rod simulation and\na convergent solver (i.e., just using the network as an initial guess in an\niterative solve). However, this is a really straight forward idea and the gains\nare again small. So, while this is a strength it is minor and possibly not\nexciting to the broader ML\/ICLR community.\n\nMy main criticism of this method have to do with three aspects of scaling: 1)\nthe network is applied at the inner most loop and message passing occurs by\niterating over edges (which I believe are based on the original connections).\nThis means that global information passing requires M = O(n) iterations. 2) the\nmethod operates only on the fine scale details (the input resolution). This runs\ncounter to multigrid literature which would suggest operating on all the\nresidual at all frequency levels. 3) the method shows a small number of small\nexamples (low resolution rods with one or two rods in a scene). PBD is often\nemployed in scenarios with millions of rod segments from thousands of rods\n(e.g., hair on a human head will have 100,000 rods each with hundreds\/thousands\nof segments). For a 1.5x to become impressive I would like to see this operating\nat scale.\n\nI worry that the network has simply memorized a mapping from global positions to\nguesses. Since the network has access to the raw positions, I would be surprised\nif it has learned rotation and translation invariance. Lack of this would be a\ngood indication that it's learning a spatial mapping. This would be a severe\nlimitation.\n\nThe exposition of main results is very confusing. If I understand this part of\nFigure 5 (and I doubt I do), then the pink curve below the red and black curves\nis indicating that using this method does not simply speed up the CG solve but\nsome how negatively affects the total runtime (I guess by confusing the outer\nloop down an incorrect path). So the gains by taking an aggressive initial guess\nare tempered a bit, though still resulting in a (quite modest) overall speed up\n<1.5x.\n\nThis modest speedup coupled with the small number of simple experimental\nscenarios worries me that these results will not generalize to a statistically\nsignificant speed up in general. \n\nCollisions appear as an afterthought. If the speedups were more significant, I\nwould happily excuse this as collisions can often be an extra systems effort.\nHowever, part of the \"glory\" of a PBD solver rather than an FEM+LCP type\nsimulation is that one can throw all sorts of constraints into the same system.\nSo, when this paper tacks on collisions outside the learning aspect of this work\nit calls the choice of PBD into question as perhaps needlessly inaccurate or an\n\"purely-out-of-convenience\" type choice rather than a scientifically motivated\none.\n\nIf I understand correctly, the paper always compares to a baseline of resetting\nthe position and multiplier updates to zero. Is this the best baseline? What\nabout using the previous iteration? Or other momentum based strategies? \n\nThe for-loop on line 8 of the pseudocode is misleading\/confusing\/incorrect. This\nimplies that updates for rods are conducted independently. But then line 9\nappears to accept as input and send as output coordinates and lagrange\nmultipliers for the entire system (rather than the rod i). What is the role of\nthe for loop of line 8 if line 9 does not depend on which rod is being\nconsidered? it would be better to write out the linear solve that is being\nconducted (e.g., with CG). The figure and text below confuses me further. Is the\ncorrection guess applied: a) once per time step, b) once per constraint\nlineariztaion (just before CG), or c) once per rod?\n\nThe revised paper (and perhaps rebuttal) should include a clarified pseudocode\nto understand what this method is actually proposing.\n\nThe effectiveness of the network depends on a parameter M which would appear to\nscale poorly with the resolution of the input shapes. Does M need to be adjusted\nfor higher resolution examples?\n\n\nWhat is the video showing? Training data created using the groundtruth\nsimulation? Results of this method at test time? If so what was the training\ndata used for each? This video did not really help supplement this submission. I\nwish that the video had included experiments that could be used to gain\nintuition about what's being learned and about the accuracy of the initial\nguess.\n\nFor example, the paper mentions many times that it is *not* replacing the time\nintegration\/constraint projection with an end-to-end trained network for\nrobustness reasons. Let's see it fail then!\n\nIn a future revision I would like to understand\n  - under what circumstances does end-to-end learning fail, but this method\n    succeeds.\n  - under what circumstances does simply using the previous frame's constraints\n    as an initial guess out perform this method?\n  \nIt'd be great to see a video where we also see an evolving plot per-frame (like\nFigure 6) showing the performance gains of applying this method rather than\nnaive initialization methods. This would be great to get match up whether the\ngains happen far from the rest state, in collision heavy scenarios, or the\nopposite etc.\n\nOn line 180, I did not understand how the set of input edges to the graph\nnetwork is defined. If inputs nodes are assigned to each rod segment, then input\nedges should connect two segments. Are only neighboring segments connected with\nthese edges? (e.g., the dual graph of the polyline representing the central axis\nof the rod). Or are all possible pairs of segments generated? Where are Young's\nand Torsion moduli stored? It's natural to store Young's modulus at segments but\nthis would correspond to nodes of the graph not edges.  \n\nThe graph network description (which gets at the core contribution of this\npaper) is poorly described. I read this section many times and via cross\nreferencing with [13] could finally understand with low confidence what is being\ndone.\n\nFigure 4 is very confusing. Is this figure showing that none of the hyper\nparameters matter except for MLP width? This is surprising to the point of\nindicating a bug\/overfitting.\n\nI do not understand Figure 5. What is the purple curve? the vanilla CG solver?\nThen wouldn't its speed up be 1x? Are these plots showing two different y-axis\nor two different examples (straight vs helix)? The caption is very confusing.\n\nThe paper does not accurately categorize past works when it writes \"Existing\nmethods enable learning these systems often in an end-to-end manner and with a\nfocus on replacing the entire integration procedure.\" Many fluids papers retain\npressure projection to ensure divergence free-ness and within elasticity\nsimulation, \n\nLatent-space Dynamics for Reduced Deformable Simulation\nLawson Fulton, Vismay Modi, David Duvenaud, David I.W. Levin, Alec Jacobson\n\ndoes not replace the time integration procedure.\n\nIn the future, I would appreciate a pdf in supplemental material with\nhighlighted changes. It is potentially rude to continuous reviewers to have to\nhunt for small changes (and then see that their reviews were largely ignored).\n","sentences":[{"sentence_type":"2","sentence":"Using the same bar as NeurIPS, I continue to recommend rejecting this paper.","rephrased":"While I appreciate the efforts made in revising the paper, my assessment aligns with the NeurIPS standard, and I maintain my recommendation for rejection."},{"sentence_type":"2","sentence":"It is also doubtful that these changes have satisfyingly address the other three reviews.","rephrased":"It remains unclear if the revisions have adequately addressed the concerns raised in the other three reviews."},{"sentence_type":"2","sentence":"However, this is a really straight forward idea and the gains are again small.","rephrased":"While the idea is straightforward, the incremental gains observed merit further discussion."},{"sentence_type":"2","sentence":"I worry that the network has simply memorized a mapping from global positions to guesses.","rephrased":"I am concerned about the possibility of the network having learned a direct mapping from global positions to guesses, which could limit its generalizability."},{"sentence_type":"2","sentence":"This modest speedup coupled with the small number of simple experimental scenarios worries me that these results will not generalize to a statistically significant speed up in general.","rephrased":"The modest speedup, when combined with the limited experimental scenarios, raises questions about the potential for these results to translate into a statistically significant improvement in general cases."},{"sentence_type":"2","sentence":"Collisions appear as an afterthought.","rephrased":"The treatment of collisions in the paper seems to be secondary and could benefit from more in-depth consideration."},{"sentence_type":"3","sentence":"So, when this paper tacks on collisions outside the learning aspect of this work it calls the choice of PBD into question as perhaps needlessly inaccurate or an \"purely-out-of-convenience\" type choice rather than a scientifically motivated one.","rephrased":"The integration of collisions outside the learning framework prompts a reevaluation of the choice of PBD, which could be seen as a convenience rather than a decision grounded in scientific rationale."},{"sentence_type":"2","sentence":"The for-loop on line 8 of the pseudocode is misleading\/confusing\/incorrect.","rephrased":"The for-loop on line 8 of the pseudocode could be clarified to avoid potential confusion."},{"sentence_type":"1","sentence":"Figure 4 is very confusing.","rephrased":"Figure 4 could be made clearer to enhance the reader's understanding."},{"sentence_type":"2","sentence":"This is surprising to the point of indicating a bug\/overfitting.","rephrased":"This result is unexpected and could suggest the need to investigate potential issues such as a bug or overfitting."},{"sentence_type":"1","sentence":"I do not understand Figure 5.","rephrased":"Figure 5 could benefit from additional explanation to aid in interpretation."},{"sentence_type":"3","sentence":"It is potentially rude to continuous reviewers to have to hunt for small changes (and then see that their reviews were largely ignored).","rephrased":"For the convenience of the reviewers, it would be helpful to provide a supplementary PDF highlighting the changes made in response to the reviews."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[1,77,"Confirmed"],[78,156,"Missed by Model"],[3499,3536,"Confirmed"],[4286,4361,"Maybe"],[7219,7246,"Not concerning"],[7399,7428,"Not concerning"]],"Comments":[]}
{"id":"SylZU8FPnQ","text":"The paper addresses the latent space distribution mismatch in VAEs and GANs. The authors try to solve the issue by optimal transport theory and the proposed method on the latent space yields better quality in the generated samples.\n\nTo me, the motivation is not very strong. In DCGAN, amazingly, latent space linear operations can carry over to the generated images. But it’s not something people are usually concerned with in GANs.  I understand that latent space operations can provide insights into how the trained generator works. But how can it improve the actual GAN training? Choosing Gaussian or uniform distribution for the latent variable is mainly for ease of computation and I am not sure if the motivation to match the distributions is very strong in GAN applications. Perhaps it more important in the context of VAEs.\n\nAt the first glance, the proposed form of transformation is not surprising. Though optimal transport is a very powerful theoretical tool, it serves more like an explanation or validation, rather than the motivation. I felt the theory part could be simper. \n\nIn the quantitative comparisons with other methods, all simulations seem to be in the context of GAN. The difference in 2-point cases (table 2) is not significant and the author only compares with linear interpolation but not SLERP. I would like to see more quantitative comparisons with other methods and also some empirical studies in the context of VAEs. ","sentences":[{"sentence_type":"2","sentence":"To me, the motivation is not very strong.","rephrased":"I believe the paper could benefit from a clearer articulation of the motivation behind the study."},{"sentence_type":"2","sentence":"At the first glance, the proposed form of transformation is not surprising.","rephrased":"Upon initial review, the proposed form of transformation appears to align with existing theories, which could be further elaborated to highlight its novelty."},{"sentence_type":"2","sentence":"I felt the theory part could be simper.","rephrased":"The theoretical framework could be streamlined for better clarity and accessibility."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[233,274,"Confirmed"],[833,908,"Confirmed"],[1049,1088,"Maybe"]],"Comments":[]}
{"id":"BdWe1G5c3Wq","text":"Summary:\nThis work builds on Van de Maele et al. [1] who introduce Cortical Column Networks [CCNs]. A CCN encodes an image patch containing an object into an object ID latent variable and a pose latent variable. The pose latent variable can be combined with an action to compute a transition which allows an object to be decoded with reference to a different viewpoint. An ensemble of CCNs is trained whereby each model in the ensemble is trained to encode one type of object. The CCNs are trained using a simulated dataset that consists of images of individual objects from different viewpoints. Random patches are used as negative examples for each object type. For a scene containing one or multiple objects, each CCN casts a vote towards the identity of an object. Votes are aggregated over space and time. Given an observation and a reference image, the authors use the CCNs to find the viewpoint of the reference image. Quantitatively, this performs favourably compared to PoseCNN. After taking a look at [1], my understanding is that the main extensions of this work are the consideration of multi-object scenes as well as the quantitative comparison to PoseCNN.\n\nClarity:\nThe paper reads reasonably well, though a clear statement of how this work relates to and differs from [1], which is cited in the paper, is missing and should be added.\n\nSignificance \/ originality \/ novelty:\nCCNs as introduced in [1] are fairly different to other object-centric models for scene understanding and it is interesting to have some more exploration and investigation of this approach. The paper is a rather incremental extension of [1], but the additional aspects introduced here (application to multi-object scenes and comparison to PoseCNN) are interesting.\n\nStrengths:\n- The paper is fairly clear.\n- The paper is relevant to the workshop.\n- The paper explores an interesting approach for object-centric scene representation learning.\n- The authors provide some interesting discussion in the conclusion section on the current limitations of this work as well as possible improvements.\n\nWeaknesses:\n- The work is a rather incremental extension of [1].\n- The quantitative analysis and discussion is quite minimal. It would be interesting if the authors could should some light on *why* CCNs perform better than PoseCNN. Otherwise, it is difficult to take much away from these results.\n\n[1] “Disentangling What and Where for 3D Object-Centric Representations Through Active Inference”, Van de Maele et al., 2021\n","sentences":[{"sentence_type":"2","sentence":"The paper is a rather incremental extension of [1].","rephrased":"While the paper builds upon the work in [1], elaborating on the specific advancements and contributions made beyond the original work would enhance the paper's impact."},{"sentence_type":"2","sentence":"It would be interesting if the authors could should some light on *why* CCNs perform better than PoseCNN. Otherwise, it is difficult to take much away from these results.","rephrased":"The authors could strengthen the paper by providing a deeper analysis of the reasons behind CCNs' improved performance over PoseCNN, which would offer more valuable insights from the results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1577,1752,"Maybe"],[2207,2377,"Maybe"]],"Comments":[]}
{"id":"SJlZfp6BF4","text":"This work investigates the connection between RL and variational inference on a toy task. Building upon the RVI  (Weber et al., 2015), off-the-shelf RL methods like policy gradient methods can be applied to the variational inference reformulated as RL. The authors attempted to apply this idea to learn a proposal distribution in an importance sampler. Based on RVI, they also proposed alternative objective that replaces the KL divergence with chi-square divergence. An inference problem in simple 1D random walk is used for evaluation. The proposed approach is shown to outperform simple MC baseline, but still worse than a hand-crafted baseline. And the objective using chi-square divergence isn't performing well. \n\nThe paper is relatively well-written and easy to follow. This work is an empirical investigation of RVI on a toy task, and proposes the use of chi-square divergence as an alternative to KL-divergence. \n\nAlthough the experiment is quite preliminary and the novelty is limited, this is an interesting work in progress and I recommend acceptance. I would suggest exploring some real inference tasks in graphical model as additional benchmark to make the experiments more solid. \n\nMinor issues:\nPage 1 paragraph 4 \"Variational inference (VI, Blei et al. (2006; 2017)) is an alternate technique\" --> \"alternative technique\"\nThe equation (6) should have \"x_T\" instead of \"x_t\". \n","sentences":[{"sentence_type":"1","sentence":"Based on RVI, they also proposed alternative objective that replaces the KL divergence with chi-square divergence.","rephrased":"Building on RVI, the authors proposed an innovative objective that utilizes chi-square divergence instead of KL divergence."},{"sentence_type":"2","sentence":"The proposed approach is shown to outperform simple MC baseline, but still worse than a hand-crafted baseline.","rephrased":"The proposed approach successfully outperforms the simple MC baseline, although it does not yet match the performance of a hand-crafted baseline."},{"sentence_type":"2","sentence":"And the objective using chi-square divergence isn't performing well.","rephrased":"However, there is room for improvement in the performance of the objective that employs chi-square divergence."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[353,467,"Not concerning"],[538,648,"Confirmed"],[649,717,"Not concerning"]],"Comments":[]}
{"id":"xaY90lmqYf","text":"This paper aims to improve image translation for the task of plague segmentation, by building an approach which can preserve small\/ subtle structures as well as global and intermediate structures. The approach makes use of UNIT (Liu et al., 2017), an image translation network with a single shared latent space, and a self-expressive loss (Ji et al., 2017), which helps with separating the subspaces and cross-domain translation. \nPros: \nThe authors explain the task and motivations well, and validate against another well known translation network, UNIT.\nThe results are promising, with improved performance compared to UNIT. A small decrease in performance is shown in comparison to training on real images, which is to be expected. \n\nCons:\nThe method can be more thoroughly validated, and a more detailed illustration of the network can be given.\n","sentences":[{"sentence_type":"1","sentence":"The method can be more thoroughly validated, and a more detailed illustration of the network can be given.","rephrased":"Further validation of the method would be beneficial, and additional details in the illustration of the network could enhance the clarity of the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[743,849,"Not concerning"]],"Comments":[]}
{"id":"ByeCx3AAFH","text":"This paper presents a formulation of graph generative models based on graph attention aimed at scalability of these methods.\n\nThe paper is generally written well and I like the overall theme of the paper, however, there are a few key issues with this work and I don't think the paper as it stands is ready for publication:\n\n1) The main motivation expressed in the paper is that graph generative models are generally not scalable and they identify three main areas: (a) graph size (i.e. num nodes); (b) data scalability (i.e. num training samples); (c) label scalability (i.e. num of node or edge types). However, the paper doesn't follow on why the proposed method actually addresses these issues. The derivation doesn't talk about scale until we reach section 3.5 and then we find out that actually the proposed model is O(n^3) in reality. Then there are approximations to make it scale. So for me there is a massive disconnect between the main motivation of the paper and the suggested model. Why not study approximation methods for already existing graph generator models?\n\n2) Following on the theme of scale, the only experimental result discussing this is the time column reported for the training time. So that partially addresses the data scalability. Other baselines as well have reasonable training times specially when it comes to large datasets (e.g. ZINC is that the largest dataset studied with 250K samples and GraphRNN is 2x slower and GraphRNN-S only about 20%). What I was looking for was when you really can train on real-world datasets that other methods basically can't be trained. The datasets chosen all are small hence there's not much issue with scale there. The question about the scalability w.r.t. other aspects (i.e. num nodes and num labels) has not been studied or reported.\n\n3) The approximations suggested in section 3.5 also don't seem to have much impact on the training time. These approximations were motivated by the scale while looking at the training times they barely make any difference. However, they make a big difference in performance metrics specially in smaller datasets. So the question that comes to mind is that what is the role of these approximations w.r.t. the quality of the models? Again this question needs further study.\n\n4) Comparing GraphRNN and GraphRNN-S's modifications with the results from the original paper, it seems they are performing much worse (e.g. deg for the original GraphRNN-S is 0.057 while the reported num here is 0.523 for Protein dataset). The same is true for other metrics. Why is that?\n\n5) As pointed out by an observer, it seems that there are nuances to generation of the graph needing seeds of arbitrary size to be provided, explained deep down in the appendix. If this is the case for generation then it should be discussed in the main part of the paper and contrasted with methods that can start from scratch.\n\n6) In the training configuration part of the appendix, A.7.2 it seems there are discrepancies in number of GPUs as well kinds of GPUs used for each method. When reporting training times in the main section, do you normalise against these?\n\n7) It seems that many hyperparameters mentioned in A.7.2 are chosen in an ad-hoc manner without proper model selection and seem to vary across each different versions of GRAM for each different dataset. How sensitive is the model to these hyperparameters? I suspect if the model was insensitive, you could've fixed them for many of these experiments, but seems that is not the case. So without proper model selection routines, the results may not be representative of what the model discussed.\n\nMinor comment: The model suggested has some similarities to DEFactor model from Assouel et al 2019 in terms of formulation of the problem for labelled graphs (nodes as a matrix and adj as a tensor), though the underlying models are very different, that paper as well targets arbitrary size graph generation and efficiency w.r.t. model parameters.","sentences":[{"sentence_type":"2","sentence":"I don't think the paper as it stands is ready for publication:","rephrased":"I believe the paper requires further revision before it is ready for publication:"},{"sentence_type":"2","sentence":"So for me there is a massive disconnect between the main motivation of the paper and the suggested model.","rephrased":"There appears to be a significant gap between the main motivation of the paper and the proposed model that needs to be addressed."},{"sentence_type":"1","sentence":"Why not study approximation methods for already existing graph generator models?","rephrased":"It may be beneficial to explore approximation methods for existing graph generator models as well."},{"sentence_type":"1","sentence":"The datasets chosen all are small hence there's not much issue with scale there.","rephrased":"The datasets selected are relatively small, which may not fully demonstrate the scalability challenges."},{"sentence_type":"1","sentence":"The approximations suggested in section 3.5 also don't seem to have much impact on the training time.","rephrased":"The impact of the approximations suggested in section 3.5 on training time appears to be minimal and could be further examined."},{"sentence_type":"1","sentence":"So the question that comes to mind is that what is the role of these approximations w.r.t. the quality of the models?","rephrased":"It would be informative to clarify the role of these approximations in relation to the quality of the models."},{"sentence_type":"1","sentence":"Why is that?","rephrased":"Could you please provide an explanation for this discrepancy?"},{"sentence_type":"2","sentence":"It seems that many hyperparameters mentioned in A.7.2 are chosen in an ad-hoc manner without proper model selection and seem to vary across each different versions of GRAM for each different dataset.","rephrased":"The selection of hyperparameters as described in A.7.2 appears to be somewhat arbitrary and varies for different versions of GRAM across datasets; a more systematic approach to model selection may be beneficial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[260,322,"Not concerning"],[889,994,"Confirmed"],[995,1075,"Maybe"],[1602,1682,"Not concerning"],[1809,1910,"Not concerning"],[2119,2236,"Not concerning"],[2556,2568,"Not concerning"],[3142,3341,"Maybe"]],"Comments":[]}
{"id":"UQKvmxbtLe","text":"This work primarily builds on the idea introduced in Heinrich (2019), namely PDDNet, which itself borrows the correlation layer from FlowNet. The main difference is the use of a non-learned keypoint extractor in order to keep the computational burden in check, the feature dimensionality reduction, and a different graph-based smoothness regularization approach due to the non-regular sampling of keypoints. For feature dimensionality reduction, a simple PCA was employed for this proof-of-concept. Given the closely related work of PDDNet, it is surprising that authors have not compared their adaptation to this method! I would consider it mandatory to demonstrate the benefit of regular vs. non-regular control point distribution. No information at all is provided on how the displacement embeddings are used to predict the final displacement fields. It is very promising work, and I am looking forward to a future conference \/ journal article on the approach.","sentences":[{"sentence_type":"2","sentence":"Given the closely related work of PDDNet, it is surprising that authors have not compared their adaptation to this method!","rephrased":"Considering the closely related work of PDDNet, it would be beneficial for the authors to include a comparison of their adaptation with this method."},{"sentence_type":"2","sentence":"No information at all is provided on how the displacement embeddings are used to predict the final displacement fields.","rephrased":"The paper would be strengthened by providing details on how the displacement embeddings contribute to the prediction of the final displacement fields."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[499,621,"Confirmed"],[734,853,"Confirmed"]],"Comments":[]}
{"id":"365Nmpe6ZG-","text":"1. In Introduction , the authors states that \"Compared with unimodal learning, multimodal learning can effectively utilize the multimodal data to achieve better performance.\", actually in some cases multimodal data must be utilized properly to make multimodal learning more effective  than unimodal learning. For e.g., researchers have found that the best unimodal model can outperform its multimodal counterpart in this paper: \"W. Wang, et al. What Makes Training Multi-modal Classification Networks Hard?\" The authors should try to make the statements more accurate.\n\n2. The author have mentioned in Page 4 that \"In the following, we will show that we use empirical distribution to implement these underlying marginal distribution in our algorithm.\", but the reviewer could not find any descriptions in the following paragraphs.\n\n3. In experiments on eNTERFACES’05, the condition with 100% missing rate should be considered, which could be helpful to demonstrate whether the left 5% data in 95%-missing case is indeed used for the task or just because the other complete modality of data.\n\n4. The authors mentioned several different methods dealing with missing modality in related works, but no experiments to compare the performances between the proposed methods and the mentioned framework. At the same time, the comparative methods in this submission are less persuasive.","sentences":[{"sentence_type":"1","sentence":"The authors should try to make the statements more accurate.","rephrased":"The authors may consider refining their statements for accuracy, taking into account situations where multimodal learning needs to be properly utilized to be more effective than unimodal learning."},{"sentence_type":"2","sentence":"The author have mentioned in Page 4 that \"In the following, we will show that we use empirical distribution to implement these underlying marginal distribution in our algorithm.\", but the reviewer could not find any descriptions in the following paragraphs.","rephrased":"It would be helpful if the authors could clarify where the empirical distribution is discussed in the algorithm, as it was not immediately apparent in the subsequent paragraphs."},{"sentence_type":"2","sentence":"At the same time, the comparative methods in this submission are less persuasive.","rephrased":"The authors might consider strengthening the comparative analysis to enhance the persuasiveness of the methods presented in this submission."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[508,568,"Not concerning"],[573,830,"Not concerning"],[1296,1377,"Not concerning"]],"Comments":[]}
{"id":"qovkXs5ewmG","text":"This paper proposes an alternative way to conduct hard attention. Specifically, it estimates the expected information gain (EIG) of attending various regions and at each timestep chooses the region with the maximum EIG. The proposed method is tested on image classification.\n\nIssues:\n1. what do you mean \"achieving explainability\" in the title? I don't quite get it. The visualization in Fig.5 shows only that the region selected in each timestep indeed has the maximum EIG. But how to interpret the explainability from the glimpse sequence is still confusing. I can hardly perceive the sequence using my knowledge. \n2. why the proposed method needs three building blocks is not well explained, especially the partial VAE. \n3. what is the data used to train the  partial VAE?\n4. no ablation study is conducted on these building blocks, such as the normalizing flow module in the partial VAE.\n5. I think image classification is not the best task to demonstrate the effectiveness of hard attention method. As shown in the experiments, simply using a standard CNN that takes the whole image as the input obtains the best result.\n","sentences":[{"sentence_type":"2","sentence":"I can hardly perceive the sequence using my knowledge.","rephrased":"The sequence of glimpses and their relation to explainability could be made clearer, as it is currently challenging to understand how they contribute to the overall interpretability of the model."},{"sentence_type":"2","sentence":"I think image classification is not the best task to demonstrate the effectiveness of hard attention method.","rephrased":"It may be beneficial to explore additional tasks beyond image classification to fully demonstrate the potential of the hard attention method."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[561,615,"Confirmed"],[895,1003,"Not concerning"]],"Comments":[]}
{"id":"R1W6Xgdrite","text":"Strong points:\n* A novel approach on how to analyze various gradient estimators.\n* Interesting new theoretical insights into various flavors of the STE gradient approximation.\n* Detailed derivations in the appendix.\n\nWeak points:\n* No experimental results, even not on MNIST or a toy example to show that the theoretical findings correlate with empirical observations.\n* The straight through estimator (STE, identity function) is know to be a biased estimator. In the paper this discussion is not coming back, but I think it would be interesting to discuss whether the other estimators (ReLU, cReLU) are biased and whether one is more biased than the other. Is there a trade-off to be made between being more biased vs having a higher chance to converge to a local minimum?\n* The optimization problem defined in 2.1 (eq 1 & 2) is non-convex. For a non-convex optimization problem it is unclear to me based on the manuscript how the gradients in stationary points are important and increase the chance to get to the true global minimum (page 5, below eq 23). Some further explanation on the reasoning could be helpful to understand for the reader and to verify that these claims are true.\n* A discussion on whether or not this analysis also holds for 1) weight quantization and 2) multi bit quantization would be interesting. Especially for the latter case it is common practice that the gradient is clipped due to the clipping in quantization (STE is applied to the rounding operation, thus the gradient of the full quantization operation is clipped due to the gradient of the clipping, see Esser et al. 2019).\n* The clarity of the paper could improve and there are some misconceptions:\n    * The straight through estimator is clearly defined in literature (see Bengio et al. 2013) as back propagation through a function as it would have been the identity function (thus gradient of 1 in the backwards path). However, in the manuscript any approximate gradient is defined as a STE gradient. This misuse of terminology makes it extra difficult and confusing to understand the work, especially since it is of theoretical nature. (“In this paper, we refer to the proxy of the gradient as the STE gradient.”)\n    * It is a bit confusing that sigma is defined as step function. But based on the text (binary activations) and later equations it seems that it is a sign function. Would be good to be clear and maybe mathematically describe the exact function.\n\n","sentences":[{"sentence_type":"2","sentence":"No experimental results, even not on MNIST or a toy example to show that the theoretical findings correlate with empirical observations.","rephrased":"Including experimental results, such as those on MNIST or a toy example, could strengthen the paper by demonstrating how the theoretical findings correlate with empirical observations."},{"sentence_type":"2","sentence":"The clarity of the paper could improve and there are some misconceptions:","rephrased":"Enhancing the clarity of the paper and addressing certain misconceptions could make the theoretical concepts more accessible to the reader:"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[232,368,"Confirmed"],[1613,1686,"Maybe"]],"Comments":[]}
{"id":"iF90kNhX0n8","text":"**Summary of the Paper:**\nIn this paper, the authors extend NS-CL by an image manipulation task. The result is what they refer to as **NeuroSIM**, a model which uses visual representations, semantic parsing, and symbolic operations to allow for changes in a given source image in accordance with the input instruction text. In comparison to the TIM-GAN baseline, NeuroSIM performs better using a small number of training examples but does not improve significantly when trained on larger datasets, in which case TIM-GAN has the best results.\n\n**Strengths:**\nThis paper clearly fits the topic of this workshop well, as it utilizes a neuro-symbolic approach in order to apply image manipulation. I like the underlying idea of the paper of extending NS-CL in such a way that the input image is not only looked at (to answer questions) but actively changed. As a personal thought (this is not claimed by the authors), this approach might possibly even be see as a step towards causality, going from only observing an image to *intervening* on it. The paper makes the differences to NS-CL and other related work very clear while still introducing the underlying concepts in sufficient detail. I also really like the examples given for some functions within NeuroSIM, which make understanding easier and faster. The figures are well made and helpful.\n\n**Weaknesses\/Possible Improvements:**\nI would have liked to see at least some more experiments going beyond the comparison of metrics with the two baselines. For NS-CL, the authors show generalization abilities of their model in different aspects. With that being (as I see it) one of the big advantages of using symbolic models, I would have liked to see at least one experiment exploring this direction (see the NS-CL paper). Speaking of the results, I feel like the authors chose to focus a bit too much on the advantageous parts of their approach. They show that NeuroSIM performs better than TIM-GAN even on a relatively small ($\\beta = 5.4k$) dataset (a good result worth highlighting), mention the almost-equal performance on a larger ($\\beta = 20k$) dataset (a fair assessment) but fail to mention that NeuroSIM has worse results than TIM-GAN when trained with an even larger ($\\beta = 54k$) dataset. Based on their experiments, NeuroSIM does not improve noticeably with larger datasets, indicating that from a specific dataset size on, TIM-GAN seems to be the preferable model (judging by FID and recall metrics). This also makes me question the meaningfulness of Table 2, where results are only calculated for a small dataset. Does NeuroSIM still come out on top when using larger datasets here? The same applies for the qualitative assessment, where the dataset size is not even mentioned. What dataset size is used here? NeuroSIM appears to produce better images here but would this still be true if the best TIM-GAN model was used (and if that was used, why not mention it)? Overall, I find the results and its discussion lacking and slightly biased towards the desirable results. Instead of discussing NeuroSIM by highlighting the beneficial properties (requiring less data, generalization abilities), the disadvantages of the model go unmentioned.\n\nI do find the paper generally well-written and also like the use and design of figures. Nonetheless, it would have benefited from a lot more polishing. None of the following points is a significant problem in and of itself but they add up to leave a bad impression (some points might be slightly subjective, but most points simply are mistakes):\n\n- The abstract seems too long for a 5 page paper. In my opinion, there is too much detail here, taking up space which could be used later (for example in the experiment section)\n- Line 61: \"s\" missing for \"task\" (change \"task\" to \"tasks\"), also what are the \"two cases\"?\n- Lines 122 to 126: The order\/wording of sentences is confusing. An example is introduced before the definition.\n- Line 134: unnecessary comma\n- Equation 4: What is $D$? Discriminator? Should be mentioned. And what is the concept $c$ here?\n- Table 1: It would be nice to highlight (**bold**) the best results per datset size\/metric.\n- Lines 149, 152: each missing a dot (full stop)\n- Line 170: missing comma on line end\n- Lines 172-173: Where is 6)? Why is it skipped?\n- Generally, the punctuation surrounding equations does not seem right to me, in its current form it disrupts the reading flow\n\nNote, that I did not specifically pay attention to spelling or punctuation errors, so going over the entire paper again could be beneficial.\nI wonder why NeuroSIM despite the used losses visibly changes the appearance of other objects a bit (see the appendix). Should the corresponding loss be weighted more strongly?\n\n**Review Summary:**\nOverall, I see this paper as introducing a good idea in a nice, easy to understand way with results showing that it can work. However, a lacking experiment section and a general feeling of \"unpolishedness\" leave a bad impression. I decided to **barely recommend accepting** this paper despite its many flaws, since I like the underlying idea and methodology and since all of my personal complaints are fixable and do not harm the basic concept. I do so in good faith, expecting that the authors will decide to polish the paper for the final version and hope to see at least some changes made to the experiments section.","sentences":[{"sentence_type":"2","sentence":"Overall, I find the results and its discussion lacking and slightly biased towards the desirable results.","rephrased":"While the results are promising, I encourage a more balanced discussion that also acknowledges the limitations of the approach, particularly in scenarios with larger datasets."},{"sentence_type":"2","sentence":"Nonetheless, it would have benefited from a lot more polishing.","rephrased":"The paper could be further improved with additional refinement and attention to detail."},{"sentence_type":"2","sentence":"None of the following points is a significant problem in and of itself but they add up to leave a bad impression","rephrased":"While individually these points may not be significant, collectively they suggest areas where the paper could be improved for a stronger overall presentation."},{"sentence_type":"2","sentence":"Overall, I see this paper as introducing a good idea in a nice, easy to understand way with results showing that it can work. However, a lacking experiment section and a general feeling of \"unpolishedness\" leave a bad impression.","rephrased":"The paper presents a compelling idea and is generally accessible, but would benefit from a more comprehensive experiment section and additional polishing to enhance the overall quality."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2934,3039,"Confirmed"],[3298,3361,"Confirmed"],[3362,3474,"Confirmed"],[4764,4993,"Not concerning"]],"Comments":[]}
{"id":"Byx38-Gl24","text":"This paper proposes a new formalism for decentralised HTN planning based around the idea of object-centric knowledge graphs, where objects are treated as first-class citizens in the representation. Each object can be associated with a set of capabilities which connects attributes of an object to particular tasks. The formalism also enables causal and inhibitory relationships between objects to be modelled. A special type of probability, called the leak probability, specifies the probability that an object will appear in a plan even when none of its causes occur in the world, enabling the model to work with incomplete causal models with unknown objects. This formalism is described in the context of the ARCADE decentralised planning framework. Initial work on a late-binding mechanism is also mentioned, with preliminary results for the SHOP2 planner.\n\nThe idea of an object-centric representation for planning is certainly an interesting one, and one that offers certain advantages as the authors point out. However, I do have some concerns about the paper, especially with respect to clarifying certain aspects of the formalism that is being proposed. The writing in some sections of the paper could also be improved for clarity, and there are a number of relevant related works that could be added to the paper.\n\nComments and suggestions:\n\n- In the Introduction, the authors seem to be motivated by two points: (1) traditional logic-based formalisms present certain problems, e.g., the need to solve the model alignment problem for distributed planning agents, and (2) object-centric representations offer a more natural model with certain inherent advantages. I think the authors have done a good job of justifying (2) but I'm less convinced about (1), which I don't see much discussion about in the paper. For instance, looking at the knowledge graph representation in Figure 1, which contains some fragments of logic-like representations, doesn't this raise some of the same problems discussed in the Introduction. E.g., how can we guarantee that even object labels are the same across a set of agents?\n\n- I wasn't quite clear how domain designers actually specify object-centric knowledge graphs. There's a brief description near the end of page 2, and the description of Figure 1 is fairly good, however, some additional information about the actual formalism, its syntax, restrictions, etc. would be helpful for the reader. Given the criticism of traditional logic-based formalisms in the Introduction, this would also help clarify the approach.\n\n- I didn't see any direct mention of the concept of affordance in the paper, although the authors certain mention ideas that are quire similar. In particular, the definition of \"capabilities\", which define attributes of objects that are useful for tasks, appears to be quite close to some representations of affordance.\n\n- The contributions listed in the Introduction mention preliminary experimental results from an abstracted military air operations domain but this domain really isn't mentioned in the paper.\n\n- It might be useful to mention the idea of late binding earlier in the paper, e.g., in the Introduction as one of the potential advantages of the approach. The first time we see it mentioned is right at the end of the paper, along with the experimental results. Maybe separate the Discussion from the Conclusions so it appears in the main body of the paper, rather than just tacked on at the end.\n\n- In terms of related work, the authors may want to look at some of the work from the EU PACO-PLUS project (http:\/\/paco-plus.org\/) which explored object-centric representations through the idea of Object-Action Complexes (OACs). See, e.g., the papers below which have some connections to planning:\nKrueger et al. (2011), Object-Action Complexes: Grounded Abstractions of Sensory Motor Processes. RAS 59(10):740-757, doi:10.1016\/j.robot.2011.05.009. Geib et al. (2006), Object Action Complexes as an Interface for Planning and Robot Control. Humanoids 2006 Workshop: Towards Cognitive Humanoid Robots.\n\nAlso, in terms of the connection between object-centric representations and human communication, the authors should look at the paper:\nM. Steedman (2002). Plans, Affordances, and Combinatory Grammar. Linguistics and Philosophy, 25(5-6):723-753.\n","sentences":[{"sentence_type":"1","sentence":"However, I do have some concerns about the paper, especially with respect to clarifying certain aspects of the formalism that is being proposed.","rephrased":"I would like to suggest some areas for clarification regarding certain aspects of the formalism that is being proposed."},{"sentence_type":"1","sentence":"The writing in some sections of the paper could also be improved for clarity,","rephrased":"Enhancing the clarity in some sections of the paper could further strengthen the presentation."},{"sentence_type":"1","sentence":"I think the authors have done a good job of justifying (2) but I'm less convinced about (1), which I don't see much discussion about in the paper.","rephrased":"While the authors have effectively justified point (2), I would appreciate more discussion and justification regarding point (1)."},{"sentence_type":"1","sentence":"I didn't see any direct mention of the concept of affordance in the paper, although the authors certain mention ideas that are quire similar.","rephrased":"It would be beneficial to include a direct mention of the concept of affordance in the paper, as it seems closely related to the ideas presented."},{"sentence_type":"1","sentence":"The contributions listed in the Introduction mention preliminary experimental results from an abstracted military air operations domain but this domain really isn't mentioned in the paper.","rephrased":"I noticed that the Introduction mentions preliminary experimental results from an abstracted military air operations domain; it would be helpful to elaborate on this domain within the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1017,1161,"Not concerning"],[1162,1239,"Not concerning"],[1672,1818,"Not concerning"],[2566,2707,"Not concerning"],[2887,3075,"Not concerning"]],"Comments":[]}
{"id":"VHah7OCUlF","text":"This paper tests the hypothesis that a dual-domain cascade of U-nets outperforms single-domain cascades. The results suggest that this is the case. The paper is straight forward, well-structured and the aims, methods and results and discussion are interesting, informative and clearly presented.\n\nMinor comments:\nurl Link to Ronneberger’s unet paper is broken.\n","sentences":[{"sentence_type":"1","sentence":"url Link to Ronneberger’s unet paper is broken.","rephrased":"Please note that the link to Ronneberger's U-net paper appears to be broken and may need to be updated."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[313,360,"Not concerning"]],"Comments":[]}
{"id":"rJgOwFa1oB","text":"This paper presents a computational model of motivation for Q learning and relates it to biological models of motivation. Motivation is presented to the agent as a component of its inputs, and is encoded in a vectorised reward function where each component of the reward is weighted. This approach is explored in three domains: a modified four-room domain where each room represents a different reward in the reward vector, a route planning problem, and a pavlovian conditioning example where neuronal activations are compared to mice undergoing a similar conditioning.\n\nReview Summary:\nI am uncertain of the neuroscientific contributions of this paper. From a machine learning perspective, this paper has insufficient details to assess both the experimental contributions and proposed formulation of motivation. It is unclear from the discussion of biological forms of motivation, and from the experimental elaboration of these ideas, that the proposed model of motivation is a novel contribution. For these reasons, I suggest a reject.\n\nThe Four Rooms Experiment:\n\nIn the four-rooms problem, the agent is provided with a one-hot encoding representing which cell it the agent is located in within the grid-world. The reward given to the agent is a combination of the reward signal from the environment (a one-hot vector where the activation is dependent on the room occupied by the agent) and the motivation vector, which is a weighting of the rooms. One agent is given access to the weighting vector mu in its state vector: the motivation is concatenated to the position, encoding the weighting of the rooms at any given time-step. The non-motivated agent does not have access to mu in its state, although its reward is weighted as the motivated agent’s is. The issue with this example is that the non-motivated agent does not have access to the information required to learn a value-function suitable to solve this problem. By not giving the motivation vector to non-motivated agent, the problem has become a partially observable problem, and the comparison is now between a partially observable and fully observable setting, rather than a commentary on the difference between learning with and without motivation.\n\nIn places, the claims made go beyond the results presented. How do we know that the non-motivated network is engaging in a \"non-motivated delay binge\"? We certainly can see that the agent acquires an average reward of 1, but it is not evident from this detail alone that the agent is engaging in the behaviour that the paper claims. \n\nMoreover, the network was trained 41 times for different values of the motivation parameter theta. Counting out the points in figure 2, it would suggest that the sweep was over 41 values of theta, which leaves me wondering if the results represent a single independent trial, or whether the results are averaged over multiple trials. Looking at the top-right hand corner I see a single yellow dot (non-motivated agent) presented in line with blue (motivated agent) suggesting that the point is possibly an outlier. Given this outlier, I’m led believe that the graph represents a single independent trial. A single trial is insufficient to draw conclusions about the behaviour of an agent. \n\nThe Path Routing Experiment:\n\nIn the second experiment, where a population of agents is presented in fig 5, it is claimed that on 82% of the trials, the agent was able to find the shortest path. Looking at the figure itself, at the final depicted iteration, all of the points are presented in a different colour and labelled “shortest path”. The graph suggests that 100% of the agents found the shortest path. The claim is made that for the remaining 18% of the agents, the agents found close to the shortest path—a point not evident in the figures presented.\n\n\nPavlovian Conditioning Experiment:\n\nIn the third experiment, shouldn’t Q(s) be V(s)? In this setting, the agent is not learning the value of a state action pair, but rather the value of a state. Moreover, the value is described as Q(t), where t is the time-step in the trial; however, elsewhere in the text it is mentioned that the state is not simply t, but contains also the motivation value mu.  \n\nThe third experiment does not have enough detail to interpret the results. It is unclear how many trials there were for both of the prediction settings. It is unclear whether the problem described is a continuing problem or a terminating prediction problem—i.e., whether after the conditioned stimulus and unconditioned stimulus are presented to the agent, does the time-step (and thus the state) reset to 0, or does time continue incrementing? If it is a terminating prediction problem, it is unclear whether the conditioned stimulus and unconditioned stimulus were delivered on the same time-steps for each independent trial. If I am interpreting the state-construction correctly, the state is incrementing by one on each time-step; this problem is effectively a Markov Reward Process where the agent transitions from one state to the next until time stops with no ability to transition to previous states.\n\nIn both the terminating and continuing cases, the choice of inputs is unusual. What was the motivation for using the time-step as part of the state construction?\n\nHow is the conditioned stimulus formulated in this setting? It is mentioned that it is a function of time, but there are no additional details.\n\nFrom reading the text, it is unclear whether fig 7b\/c presents activations over multiple independent trials or a single trial.\n\nGeneral Thoughts on Framing:\n\nThis paper introduces non-standard terms without defining them first. For example, TD error is introduced as Reward Prediction Error, or RPE: a term that is not typically used in the Reinforcement Learning literature. To my understanding, there is a hypothesis about RPE in the brain in the cognitive science community; however, the connection between this idea in the cognitive science literature and its relation to RL methods is not immediately clear.\n\nTemporal Difference learning is incorrectly referred to as \"Time Difference\" learning (pg 2). \n\nNotes on technical details:\n\n- The discounting function gamma should be 0<= gamma <=1, rather than just <=1.\n\n- discounting not only prevents the sum of future rewards from diverging, but also plays an important role in determining the behaviour of an agent---i.e., the preference for short-term versus long-term rewards.\n\n- pg 2 \"the motivation is a slowly changing variable, that is not affected substantially by an average action\" -- it is not clear from the context what an average action is. \n\n- Why is the reward r(s|a), as opposed to r(s,a)?\n\nNotes on paper structure:\n\n- There are some odd choices in the structure of this paper. For instance, the second section---before the mathematical framing of the paper has been presented---is the results section. \n\n- In some sentences, citations are added where no claim is being made; it is not clear what the relevance of the citation is, or what the citation is supporting. E.g., “We chose to use a recurrent neural network (RNN) as a basis for our model” following with a citation for Sutton & Barto, 1987.\n\n- In some sentences, citations are not added where substantial claims are being made. E.g, “The recurrent network structure in this Pavlovian conditioning is compatible with the conventional models of working memory”. This claim is made, but it is never made clear what the conventional computational models of working memory are, or how they fit into the computational approaches proposed.\n\n- Unfortunately, a number of readers in the machine learning community might be unfamiliar with pavlovian conditioning and classical conditioning. Taking the time to unpack these ideas and contextualise them for the audience might help readers understand the paper and its relevance.\n\n- Figure 7B may benefit from displaying not just the predicted values V(s), but a plot of the prediction over time in comparison to the true expected return.\n","sentences":[{"sentence_type":"1","sentence":"I am uncertain of the neuroscientific contributions of this paper.","rephrased":"The neuroscientific contributions of this paper could be further clarified."},{"sentence_type":"2","sentence":"For these reasons, I suggest a reject.","rephrased":"Due to the concerns outlined, I would recommend further revision before considering acceptance."},{"sentence_type":"1","sentence":"The issue with this example is that the non-motivated agent does not have access to the information required to learn a value-function suitable to solve this problem.","rephrased":"It would be beneficial to ensure that the non-motivated agent has access to the necessary information to learn a value-function that could solve the problem."},{"sentence_type":"1","sentence":"In places, the claims made go beyond the results presented.","rephrased":"There are instances where the claims could be better supported by the results presented."},{"sentence_type":"1","sentence":"Given this outlier, I'm led believe that the graph represents a single independent trial.","rephrased":"The presence of an outlier suggests the possibility that the graph may represent a single independent trial, which could be clarified."},{"sentence_type":"2","sentence":"A single trial is insufficient to draw conclusions about the behaviour of an agent.","rephrased":"Drawing robust conclusions about the behaviour of an agent typically requires multiple trials."},{"sentence_type":"1","sentence":"The third experiment does not have enough detail to interpret the results.","rephrased":"Providing additional detail in the third experiment would help in interpreting the results more clearly."},{"sentence_type":"1","sentence":"Temporal Difference learning is incorrectly referred to as \"Time Difference\" learning (pg 2).","rephrased":"There appears to be a typographical error on page 2 where 'Temporal Difference learning' is referred to as 'Time Difference' learning."},{"sentence_type":"1","sentence":"Unfortunately, a number of readers in the machine learning community might be unfamiliar with pavlovian conditioning and classical conditioning.","rephrased":"It may be helpful to provide some background on Pavlovian and classical conditioning for readers who might be less familiar with these concepts."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[587,653,"Not concerning"],[999,1037,"Confirmed"],[1760,1926,"Not concerning"],[2219,2278,"Not concerning"],[3159,3242,"Not concerning"],[4208,4282,"Not concerning"],[6040,6133,"Not concerning"],[7592,7736,"Not concerning"]],"Comments":[]}
{"id":"Meg_dkWWJCP","text":"# Summary\n\nThis paper investigates the incorporation auditory events into reinforcement learning. Specifically, it proposes a new algorithm that uses event prediction as an intrinsic reward. This algorithm has two phases. In the first phase, an agent is given a small number of episodes to gather diverse auditory data. This phase has two pieces that work in conjunction: 1) As it learns, the agent clusters the sound embeddings it has observed using K-means. 2) To encourage the agent to find diverse auditory data, it is rewarded for reaching states that emit sounds that are far away from its existing cluster centers. In the second  phase (which dominates the first in terms of number of episodes consumed), a new agent is trained to predict the cluster center to which the next auditory event will belong. It is rewarded according to how incorrect its prediction is, thereby encouraging the agent to explore states for which it has difficulty predicting the auditory event.\n\nThe paper performs experiments in Atari, Habitat and TDW. It compares against strong vision-based intrinsic reward baselines. It also performs experiments comparing its proposed methodology to ablations with the aim of determining 1) whether it suffices to predict sound features instead of auditory events, 2) whether a two-stage exploration strategy is necessary, 3) whether it is necessary to perform active exploration in the first phase, and 4) whether event classification is necessary.\n\n# Writing\n\nThis submission does not read as that of a paper ready for publication. Its organization, unnecessary use of the passive voice, singular-plural inconsistencies, tense mixing, and muddled descriptions weaken its value. Below is a (non-exhaustive!) list of issues.\n\n- Abstract\n\n“We first conduct an in-depth” \n\nThere needs to be a transition from the method description for this “first” to fit here.\n\n- Introduction\n\nWhy is Deep Reinforcement Learning all caps?\n\n“algorithms aim to learn a policy of an agent to maximize its cumulative rewards by interacting with environments”\n\nsingular\/plural\n\n“domains, such as video game”\n\nGame should be plural\n\n“While these results are remarkable, one of the critical constraints is the prerequisite of carefully engineered dense reward signals, which are not always accessible.”\n\nIs Go a good example of this? AlphaZero accomplishes the same task without carefully engineered dense reward signals.\n\n“For example, curiosity-driven intrinsic reward based on prediction error of current (Burda et al., 2018b) or future state (Pathak et al., 2017) on the latent feature spaces have shown promising results.”\n\nThis sentence is ordered awkwardly. As written, “have” refers to “curiosity-driven intrinsic reward”, which is singular. “on the latent feature spaces” doesn’t work here.\n\n“visual state is high-dimensional” -> states are\n\n“speech or other nonverbal but audible signals” -> speech or other audible signals OR speech or nonverbal, audible signals\n\nUsing “other” here makes it read as if speech is a member of “nonverbal but audible signals”\n\n“However, it is just as much in physics.”\n\n ?\n\n“A naive strategy would be” -> A naive strategy is\n\n“In the beginning”\n\nDoes this mean in the first phase?\n\n“The state that has the wrong prediction is rewarded and encouraged to be visited more.”\n\nPassive voice makes this hard to parse. The agent is the one making predictions and receiving rewards.\n\n“understand our audio-driven exploration works well under what circumstances”\n\nSome words are missing here\n\n“can encourage interest action that involved physical interaction”\n\nNeeds fixing\n\n- Related Work\n\n“By leveraging audio-visual correspondences in videos, it can help to learn powerful audio and visual representations through self-supervised learning”\n\nIt can help to learn? -> It can learn?\n\n“Reinforcement Learning (RL)”\n\nAcronym has already been introduced.\n\n“makes use of the bootstraps for deep exploration”\n\nbootstraps -> bootstrap\n\n“Here, we mainly focus on the problem of using intrinsic rewards to drive explorations.”\n\nWhy is exploration plural?\n\n“The most widely used intrinsic motivation could be roughly divided into two families.” could -> can\n\nThe works discussed in the ensuing sentences are already listed and cited in the previous sentences. If you are going to discuss as if you had not already just mentioned them, it is better to exclude them from the previous sentences.\nAlso, maybe you should add “approaches” or “methods” somewhere in this sentence.\n\n“Burda et al. (2018b) employs the prediction errors of a self-state feature extracted from a fixed and random initialized network and encourage the agent to visit more previous unseen states.” previous -> previously\n\nWhat is a self-state feature? Burda does not use that term and there is no explanation here.\nThe end of the sentence doesn’t make sense. What is the subject of “encourage”?\n\n“Another one is the curiosity-based approach (Stadie et al., 2015; Pathak et al., 2017; Haber et al., 2018; Burda et al., 2018a), which is formulated as the uncertainty in predicting the consequences of the agent’s actions.”\n\n-The paper previously said that there were two families so “another one” should be “The other” or something else signifying that this is referring back to the two families comment.\n\n-The paper described family one as a set of approaches (plural) but family two as an approach “singular”.\n\n-The end of the sentence needs fixing.\n\n“The agent is then encouraged to improve its knowledge about the environment dynamics” then -> thereby\n\nFigure 1 would be more clear if it did not use time indexing for the stage 1 section.\n\n“There are numerous works to explore”\n\nthat explore?\n\n“More recently, Dhiraj et al. (2020) collected a large sound-action-vision dataset using Tilt-bolt and demonstrates sound signals could provide valuable information for find-grained object recognition”\n\n-Dhiraj et al. is plural so demonstrates should be demonstrate.\n\n-could provide -> can provide\n\n-find-grained -> fine-grained\n\n“More related to us” us -> our work OR this work\n\n“which have shown that the sound signals could provide useful supervisions for imitation learning and reinforcement learning in Atari games.” \n\n-could -> can\n\n-unnecessary passive voice\n\n\nThroughout the Sounds and Actions paragraph, the paper repeatedly switches between describing papers in past tense and present tense.\n\n“And then we elaborate on the pipeline of self-supervised exploration through auditory event predictions.” And then -> Then\n\nThere is nothing wrong (in general) with starting a sentence with the word “And” but this is not an appropriate place for it.\n\n“a standard Markov Decision Process (MDP), defined as (S, A, r, T , µ, γ). S, A and µ(s) : S → [0, 1] denote”\n\nas -> by\n\nIt is bad form to start a sentence with a symbol.\n\n“The transition function T (s 0 |s, a) : S × A × S → [0, 1] defines the transition probability to next-step state s’ if the agent takes action a at current state s.”\n\nThe transition function defines this transition probability whether or not the agent executes a at s.\n\n“The goal of training reinforcement learning is to learn an optimal policy π ∗ that can maximize the expected rewards under the discount factor γ as”\n\nThis is the goal of reinforcement learning not the goal of training reinforcement learning.\n\nThe sentence doesn’t work. It reads “The goal is to learn an optimal policy that is an optimal policy.” Either modify to “The goal is to learn an optimal that is an optimal policy.” or “The goal is to learn an optimal policy. An optimal policy is …” \n\n“The agent chooses an action a from a policy π(a|s)” from -> according to\n\n“Intrinsic Rewards for Exploration”\n\n This paragraph is repeating information that was already written\n\n“Designing intrinsic rewards for exploration has been widely used to resolve the sparse reward issues in the deep RL communities”\n\n-Unnecessary passive voice\n\n-What deep RL communities? Isn’t there just one? If there are more than one, what are they?\n\n“transits to the next state with visual observation sv,t+1 and sound effect ss,t+1. “\n\ntransits -> transitions\n\nstate with -> state, receiving\n\n“We hypothesize that the agents, through this process, could learn the underlying causal structure of the physical world and use that to make predictions about what will happen next, and as well as plan actions to achieve their goals.”\n\n-“and as well as” is redundant\n\n“To better capture the statistic of the raw auditory data”\n\nWhat statistic?\n\n“For the task of auditory event predictions, perhaps the most straightforward option is to directly regress the sound features Φ(ss,t+1) given the feature embeddings of the image observation sv,t and agent’s actions at”\n\nThe paper said this already\n\n“Nevertheless, we find that not very effective. We hypothesize that the main reasons are: 1) the mean squared error (MSE) loss used for regression is satisfied with “blurry” predictions. This might not capture the full distribution over possible sounds and a categorical distribution over clusters; 2) the MSE loss does not accurately reflect how well an agent understands these auditory events. Therefore, we choose instead to define explicit auditory events categories and formulate this auditory event prediction problem as a classification task, similar to (Owens et al., 2016b).”\n\n-Nevertheless is not appropriate here.\n\n-The paper runs this experiment and discusses the results later in the paper. Its confusing to discuss it both as a choice and as an ablation.\n\n\n“Our AEP framework”\n\nWhile the acronym can be deduced from the section header, it is still good practice to write it explicitly.\n\n“We need to”\n\nThis is a design choice, not a need.\n\n“And then”\n\nAnd is not appropriate here.\n\n“takes input as the embedding of visual observation and action and predicts which auditory event will happen next.”\n\nneeds fixing\n\n“then utilized” -> used\n\n“to explore those auditory events with more uncertainty”\n\nthose is unnecessary here\n\n“We will elaborate on the details of these two phases below.”\n\nGet rid of “will”\n\n“The agents start to collect audio data by interacting with the environment”\n\nThey start to isn’t good phrasing here. \n\n“During this exploration, the number of clusters will grow”\n\nfix tense\n\n“After the number of the clusters is saturated”\n\nThe description of the sound clustering process is muddled. It does not defined saturated until after it has used it in context.\n\n“To be noted, the number of cluster K is determined automatically in our experiments. In practice, we define K ∈ [5, 30] for clustering at each time step and use the silhouette score to automatically decide the best K, which is a measure of how similar a sound embedding to its own cluster compared to other clusters.”\n\nDo “To be noted” or “In practice” have any added value here?\n\n“we believe it is “saturated””\n\nThe paper is defining saturation, it is not a belief.\n\n“We visualize the corresponding visual states in two games (Frostbite and Assault) that belong to the same sound clusters, and it can be observed that each cluster always contains identical or similar auditory events”\n\n-Unnecessary passive voice\n\n-Always is a pretty strong claim. Can we deduce that from this visualization?\n\n“Since we have already explicitly defined the auditory event categories, the prediction problem can then be easily formulated as a classification task”\n\n-Don’t need “already”\n\n-Don’t need “then”\n\n“It will reward the agent at that stage and encourage it to visit more such states since it is uncertain about this scenario”\n\n-Use present tense tense\n\n-at that state?\n\n“In practice, we do find that the agent can learn to avoid dying scenarios in the games since that gives a similar sound effect it has already encountered many times and can predict very well.”\n\n-we do find -> we find\n\n-dying scenarios?\n\n- Experiments\n\n“And then”\n\nAnd is not appropriate here\n\n“Our primary goal is to investigate whether we could use auditory event prediction as intrinsic rewards to help RL exploration.”\n\nThis statement is repeated many times in the paper and has no added value to this section.\n\n“also supports an audio API to provide”\n\nto provide -> that provides\n\n“We use 20 familiar video games”\n\nIs familiar needed here?\n\n“We follow the standard setting in (Pathak et al., 2017; Burda et al., 2018b), where an agent can use external rewards as an evaluation metric to quantify the performance of the exploration strategy. This is because doing well on extrinsic rewards usually requires having explored thoroughly.”\n\n-Passive voice is excessive in multiple places here\n\n-incorrect use of interrogatives\n\n“the the” typo\n\n“Table 1: Categorical results”\n\nThese are not results\n\n“could simulate”\n\ncan simulate\n\n“physic simulation platform” physics\n\n“Figure 7 ,”comma misplaced\n\n“The agent is required to execute actions to interact with objects of different materials and shapes.”\n\nThe agent interacts with objects of different materials and shapes.\n\n“When two objects collide, the environment could generate collision sound based on the physical properties of objects”\n\ncould generate collision sound?\n\n“We would like to compare”\n\nWe compare\n\n“we choose PPO algorithm”\n\neither choose the PPO algorithm or choose PPO\n\n“The PyTorch implementation”\n\nwhich?\n\n“the open-source toolbox 1”\n\n-which?\n\n-footnote shouldn’t have space\n\n“As for the auditory prediction network”\n\nDon’t need “as”\n\n“our model use 10K interactions” fix\n\n“previous vision-only intrinsic motivation modules”\n\ndon’t need previous here\n\n“We would like to provide an in-depth understanding of under what circumstances our algorithm works well.”\n\nYou would like to or you do?\n\n“event-driven sounds which emitted when agents” fix\n\n“action-driven sounds which emitted when agents” fix\n\n“None of the category accounts for the majority” fix\n\n“Since the sound is more observable effects of action” fix\n\n“games dominant with event-driven” fix\n\n“These are also reasonable”\n\nNothing for “These” to refer to\n\n“Sometimes sound events will occur independently of the agent’s decisions and do not differentiate between different policies”\n\ndifferentiate is not the right word here\n\nThe phrase “ablated study” is used repeatedly. Use “ablation study” instead?\n\n“We further carry out additional experiments”\n\nfurther unnecessary\n\n“One main contribution of our paper is to use auditory event prediction as an intrinsic reward.”\n\nRepeated without added value\n\n“In Figure 6, using only 16K exploration steps, our agent has already explored all unique states (211 states)” fix\n\n“These results demonstrate that our agent explores environments more quickly and fully, showing the potential ability of exploring the real world.”\n\nDo they? This is a strong claim\n\n“less than 195 unique states” fewer\n\n“These results demonstrate that our agent explores environments more quickly and fully, showing the potential ability of exploring the real world.”\n\nDo they? Again, a strong claim.\n\nThere is a sub-header “Setup” of Section 4.4 Experiments on TDW. There is also a TDW sub-header of Section 4.1 Setup.\n\n“The action space consists of moving to eight directions and stop. An action is repeated 4 times on each frame.”fix\n\n“previous vision-based modules”\n\ndon’t need previous\n\n“could not” -> did not\n\n“the 3D photo-realistic world, in which a physical event happens.”needs fix\n\n“Instead, our auditory event prediction driven exploration will lead agents”\n\nIn constrast, … exploration leads agents\n\n“(See SHE in Figure 8)” see\n\n“We will reward an agent” We reward an agent\n\n“We also want to understand if it is necessary to use audios” audios?\n\n“is powerful for agents to build a causal model of the physical world” fix\n\n- Comments on Organization\n\n-I think it would make more sense to group the question-based analysis together. IE, the ablation studies and the discussions.\n\n-I think whether to use clustering classification or feature prediction should be discussed consistently throughout the paper. As it currently stands, sometimes it is presented as a design choice, sometimes with the claim that the latter is worse (without supporting evidence), and sometimes as a question to be answered by an ablation study.\n\n- Other comments\n\n“As compared to visual cues, sounds are often more directly or easily observable causal effects of actions and interactions.”\n\nIs this obvious?\n\n# Causality?\n\nThe paper makes a number of comments about its method learning causal structure. To me, these seem like big claims. The proposed algorithm has no mechanism that tests counterfactuals or, as far as I can tell, any other mechanism for estimating causation, so I see no reason why it would learn anything beyond correlative relationships. Given this fact, in my opinion, if the paper wants to make claims about the fact that its method is learning causal structure, it should back these claims up with experiments.\n\n# Experimental Evaluation\n\nThe paper makes very definitive claims (see writing section) about the effectiveness of its method compared to the baselines. In my opinion, there are a number of issues with these claims. First, the paper gives no information (that I could find) about how it tuned the baselines or whether they tuned them at all. Second, for the Atari results, the paper states that it used three random seeds. For the other experiments, it does not say how many seeds it used (or at least I could not find where it said so). Both of these facts make it difficult to know how seriously to take the claims of superior performance.\n\n\n# Related work\n\nThe paper cites many references in its related work section. Yet, I feel that it tells us almost nothing about what it is most important for us to know about:\n\n\"More related to us are the papers from Aytar et al. (2018) and Omidshafiei et al. (2018), which have shown that the sound signals could provide useful supervisions for imitation learning and reinforcement learning in Atari games. Concurrent to our work, Dean et al. (2020) uses novel associations of audio and visual signals as intrinsic rewards to guide RL exploration. Different from them, we use auditory event predictions as intrinsic rewards to drive RL explorations.\"\n\nWe are only given a couple of sentences of information about these papers. Additionally, I am not sure that is consistent that the paper claims that Dean is concurrent, but at the same time, designed its experiments to follow Dean “Following (Dean et al., 2020), we use the the apartment 0 in Replica scene (Straub et al., 2019) with the Habitat simulator for experiments.”\n\n# Choice of baselines\n\nThe paper appears to be concerned with claiming superior performance over vision-based intrinsic methods, yet it is not clear to me that having superior performance is necessary for the proposed method to have added value, given that the two methods make use of disjointed information for prediction targets. I do not mean to say that these experiments do not have added value—certainly it is nice to see the proposed algorithm compared to existing algorithms—but maybe the adversarial narrative is not the right choice? I understand that the paper is claiming that sounds give the agent better information for intrinsic exploration but, in my opinion, convincing evidence for that claim would require extensive experiments on a wide array of intrinsic methods using both sound and vision and many environments.\n\n# Broader Scope Question\n\nCan a paradigm requiring an initial exploration stage to collect diverse sounds be effective in environments in which some sound events require a large amount learning to discover?\n\n# Closing Thoughts\n\nThis seems like promising work, but in my opinion it is not ready for publication. Both the quality of writing and the issues with seeds\/tuning independently merit rejection. There are also other issues discussed above.","sentences":[{"sentence_type":"2","sentence":"This submission does not read as that of a paper ready for publication.","rephrased":"The submission could benefit from further revisions to reach a publication-ready standard."},{"sentence_type":"1","sentence":"The state that has the wrong prediction is rewarded and encouraged to be visited more.","rephrased":"The agent is rewarded for states where its predictions are incorrect, which encourages revisiting these states for better learning."},{"sentence_type":"1","sentence":"The paper makes very definitive claims (see writing section) about the effectiveness of its method compared to the baselines.","rephrased":"The paper presents strong claims about the effectiveness of its method compared to the baselines, which could be substantiated with additional evidence or discussion."},{"sentence_type":"2","sentence":"This seems like promising work, but in my opinion it is not ready for publication.","rephrased":"This work shows promise, and with further refinement, it could reach a level suitable for publication."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1485,1556,"Confirmed"],[3224,3310,"Not concerning"],[16897,17022,"Not concerning"],[19605,19687,"Not concerning"]],"Comments":[]}
{"id":"rygLWwJ6Yr","text":"This paper proposes an algorithm that learns to synthesize tools for the task of reaching. The main idea is to first use unsupervised segmentation algorithm to decompose an image of a set of tools into individual objects; then, with a trained feasibility model, search through the latent space of encoded tools to 'imagine' new ones for reaching. \n\nThis paper has clear strengths and weaknesses. It's studying an important problem from a cognitive perspective; it also proposes a novel model for the task, building upon SOTA models. However, the current problem formulation and experiment setup are not well justified, and the experiments are quite limited. I lean toward rejection.\n\nMost importantly, while this paper argues for the importance of an object-centric representation, it conducts most of its search in the pixel space (both as input to the model, and as the output of the imagination). This leads to some unnatural and unphysical results: in the teaser figure, it's true that the final, imagined tool reaches the target; however, the tool itself shouldn't be able to pass the gap\/hole on the wall, due to its angular shape. Objects, in essence, have shapes and physical occupancy. Without modeling physics, it's unclear how useful the object-centric representation is.\n\nImagination is done by searching over the latent space, which limits the model's generalization power to novel tools or new configurations. This is revealed in the results on case H, where the model doesn't work at all.\n\nThe experimental results, as just mentioned, are not very impressive, especially given the simplified setup. There are no results on other tasks except reaching. In addition, comparisons with published methods are missing. For example, what if I just train a Pix2Pix from the inputs to successful reaches? That sounds like a reasonable baseline and should be compared with.\n\nDue to all these limitations, I lean toward rejection.","sentences":[{"sentence_type":"2","sentence":"The experimental results, as just mentioned, are not very impressive, especially given the simplified setup.","rephrased":"The experimental results could be strengthened, particularly considering the simplified setup, to better demonstrate the efficacy of the proposed approach."},{"sentence_type":"2","sentence":"This leads to some unnatural and unphysical results: in the teaser figure, it's true that the final, imagined tool reaches the target; however, the tool itself shouldn't be able to pass the gap\/hole on the wall, due to its angular shape.","rephrased":"This approach sometimes leads to results that may not seem physically plausible, such as in the teaser figure where the imagined tool reaches the target despite its angular shape, which suggests a need for incorporating physical constraints into the model."},{"sentence_type":"2","sentence":"Imagination is done by searching over the latent space, which limits the model's generalization power to novel tools or new configurations. This is revealed in the results on case H, where the model doesn't work at all.","rephrased":"The reliance on searching over the latent space may constrain the model's ability to generalize to novel tools or configurations, as evidenced by the results in case H, which indicate room for improvement in the model's robustness."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[900,1137,"Not concerning"],[1284,1503,"Maybe"],[1505,1613,"Confirmed"]],"Comments":[]}
{"id":"8G_c9zooDa","text":"This paper considers federated learning for edge devices with multiple wireless edge servers. The paper proposes FedMes to leverage devices in overlapping areas covered by multiple edge servers. In particular, in FedMes, if a device is in the coverage area of multiple edge servers, the device receives current models from all the edge servers covering it. Each device uses a (weighted) average of the models it receives as a starting point, and performs local updates (using SGD). A device broadcasts the updated model to multiple edge servers that cover the device. The key idea is that these devices in the overlapping coverage area act as ‘bridges’, and communication between edge servers is not required (until the final averaging step). The authors carry out experiments to evaluate FedMes, and compare against hierarchical federated learning of (Liu et al., 2019).\n\nStrong points:\n\n1. How the broadcast wireless nature can be leveraged in federated learning is a practically motivated question, and the proposed algorithm is quite simple. \n\n2. The paper is well-written and easy to follow.\n\nMajor concerns:\n\n1. The main premise of the paper is that communication with the central cloud server located at the higher tier of edge servers is costly and incurs significant delay. (One of the selling points of FedMes is that it does not require any backhaul traffic.) However, the authors do not provide much evidence for this premise. In fact, the bottleneck in wireless networks is typically the communication between edge devices and edge servers, and the backhaul communication is usually cheap and fast. It is not even clear why a central cloud server is required since edge servers can talk with each other periodically, and simply average the models. It will be important to give an evidence that communicating with a cloud server or between edge servers incurs large delay. \n\n2. The paper only presents experimental evaluation, and the experiments make several simplifying assumptions. For instance, the latency with the cloud is modeled with simple one-round delay parameter t_c, and the one-round delay between a device and edge server is assumed to be 1. Further, the devices in overlapping coverage areas are assumed to be very symmetric. These assumptions do not seem to be practical, and it is difficult to assess the usefulness of FedMes over hierarchical FL. FedMes may perform better in these somewhat ideal conditions, but it would be important to consider practical aspects.\n\nSpecifically, (Liu et al., 2019) compute latency using a wireless model. Also, they consider various values of E and T_cloud. It will be useful to consider various values in the experiments for the fairness of comparisons. (Abad et al., 2020) also analyze end-to-end latency by considering the properties of the wireless nature. Overall, it will be important to consider similar models for latency other than taking a simplistic approach of one-round delay t_c.\n\nConsidering the above points, the contribution and novelty seem to be fairly limited. It will be helpful if authors can consider a more practical latency model, and\/or provide more evidence for the values and assumptions used in experimental evaluations.\n\nOther suggestions:\n\n1. The authors cite latency sensitive applications, e.g., smart cars, to motivate faster training time. It will be helpful to clearly distinguish between training time and inference time. For instance, the 100 milliseconds latency considered in (Mao et al., 2017) is for training or inference? \n\n2. In Fig. 2 and 3, what are the units of $t_c$ and the running time? When $t_c$ (delay between cloud and device) is increased, clearly FL and hierarchical FL will be slower. It will be important to give evidence for how these values are chosen. Also, what about the case when ES can talk with each other over backhaul; does it incur similar delay as talking to a cloud server? \n\n3. In experiments, it is assumed that adjacent edge servers select the same set of devices from the overlapping area by cooperating with each other. It will be helpful to comment on the impact of this cooperation on latency as compared to sharing the (possibly compressed) models between edge servers. \n\n4. Considering the same devices in the coverage area of an edge server throughout the training process does not seem to be practical. Would it be possible to extend the experiments to consider the case when the devices in the coverage area of an edge server follow some practically motivated distribution?  \n\n============= Post-Rebuttal Comments ===============\nThanks to authors for their response and efforts in updating the manuscript. Some of my concerns were addressed. However, I still think that the novelty is fairly limited. For example, additional experiments in Fig. 5 produce quite intuitive results in the sense that any scheme that yields smaller t_c will have higher accuracy at a specific time slot. FedMes reduces t_c with the assumption that it is faster to communicate between edge servers. Systems-level experiments to thoroughly study the effect on t_c will greatly improve the contributions. ","sentences":[{"sentence_type":"2","sentence":"Considering the above points, the contribution and novelty seem to be fairly limited.","rephrased":"Considering the above points, enhancing the contribution and novelty of the approach could further strengthen the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2961,3046,"Confirmed"]],"Comments":[]}
{"id":"M1VZYDBzGDr","text":"One of my main concern is that the baseline Prompt is too weak.   \n1. According to ablation study in Table 1, the main gains are contributed to the continue training P(r|ins) and P(ins|r) on top of extra corpora (Wikipedia and Bookcorpus). However, the baseline prompt is not conducted with continue training at all. \n\n2. There is a clear gap between the inference and training for the baseline prompt. \nDuring the training, LM is trained on natural sentences, but only some of them satisfy the pattern \"if ... then ...\". In addition, since r_p is not a natrual sentence, a prompt \"if r_p then <mask>\" is not a natural sentence during inference. As a result, such a gap in baseline leads to weak performance. \n\nTherefore, to make the baseline prompt more plausible, firstly, it should collect a set of such sentences \"if sent1 then sent2\" and remove entities from sent1 and sent2. Then it continues to train LM on top of this dataset. \n\n\n","sentences":[{"sentence_type":"2","sentence":"One of my main concern is that the baseline Prompt is too weak.","rephrased":"One of my main concerns is that the baseline prompt could be strengthened."},{"sentence_type":"2","sentence":"During the training, LM is trained on natural sentences, but only some of them satisfy the pattern \"if ... then ...\". In addition, since r_p is not a natrual sentence, a prompt \"if r_p then <mask>\" is not a natural sentence during inference. As a result, such a gap in baseline leads to weak performance.","rephrased":"During training, the language model is trained on natural sentences, but not all follow the \"if ... then ...\" pattern. Moreover, since r_p does not form a natural sentence, the prompt \"if r_p then <mask>\" may not reflect natural language use during inference, which could be a factor in the observed performance gap."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,63,"Confirmed"],[404,708,"Not concerning"]],"Comments":[]}
{"id":"TCJmIOll5xb","text":"**Summary of the Paper**\n\nRecent works Indicate that **large language models** (LLM) are incapable of inferring meaning as they do not have any reference object to relate the text to, citing examples such as the octopus test. The paper refutes this stating this to be a singular perspective of meaning and introduces another perspective -Conceptual Role Theory -  where the meaning of a word is rather associated with the context of the words surrounding it thus rendering large language models capable of inferring meaning.  \n\n**Main Review**\n\n**Pros**\n\n- The paper is very well written and easy to follow. The authors motivate the problem by providing sufficient details of the current literature and their singular viewpoint. Furthermore, the authors provide sufficient details of the theoretical background such as Conceptual Learning Theory among others -needed to understand the thesis - which makes the paper self sufficient. \n-  The paper does not claim that LLM's can learn human level concepts but rather claim that reference should not play a role in determining meaning which is appropriate. \n\n**Cons**\n\n- The section \"Communicative Intentions\" of the paper states that the internal states of LLM's capture rich, causal and structural information. While rich and structural have been proven to exist, causal is still an open avenue. An example I would like to cite is the paper  'Attention is not explanation' where they demonstrate that there exists a set of counterfactual attention weights which produce the same output as the learned weights do. \n- While the paper provides examples of discovering conceptual roles in the context of learning in several large models such as Alphafold, I would have liked to see the example of an LLM which would have affirmed my understanding of the section w.r.t to LLM's\n\n**Typos**\n\nLine 231 posses --> possess\n\n**Summary of the Review**\n\nOverall, the paper is an interesting read and easy to follow. It is also well motivated and sufficient details are provided to make the paper self sufficient. Certain statements such as LLM's capture causal structure can be further revised based on other papers referenced in this review. Some minor typos could be removed \n\n\n\n\n","sentences":[{"sentence_type":"1","sentence":"The paper does not claim that LLM's can learn human level concepts but rather claim that reference should not play a role in determining meaning which is appropriate.","rephrased":"The paper appropriately focuses on the argument that reference should not be the sole factor in determining meaning, rather than claiming that LLMs can learn human-level concepts."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[937,1103,"Not concerning"]],"Comments":[]}
{"id":"BzMxOpdypb5","text":"**Summary**: The authors propose minimization of conditional mutual information as a method for learning disentangled representations which generalize more favorably to test distributions with shifts in correlation of the ground truth generative factors. They provide a convincing theoretical argument for the proposed idea based on an analysis of the simple 2-dimensional setting, and further validate this argument with strong empirical results on toy tasks. They further introduce a more general architecture-agnostic training algorithm based on latent-space shuffling which could allow for attribute-conditional mutual information minimization in more realistic settings. They then demonstrate preliminary positive results with this algorithm on a modified version of the Celeb-A dataset where they artificially introduce correlation between attributes.\n\n**Strong points**: \n- The approach is well motivated and I believe the preliminary analysis beginning from the low-dimensional linear setting should be highly valued especially the context of this  workshop.\n- The extended related work section is thorough and greatly appreciated. \n- The paper is well written.\n\n**Suggestions for minor improvements**:\n- At the top of page 2, the authors appear to claim that Locatello et al. (2019b) states unsupervised disentanglement is not possible due to frequent violations of the assumption of independence of the source variables. However, from my understanding, the main argument of Locatello et al. (2019b) relates to the identifiability of ‘disentangled’ representations when no supervision is provided (even in the case of fully independent generative factors). I agree that correlated source variables further makes this identification more challenging, but the specific framing of this sentence appears incorrect. I would be happy to hear the authors comments on this if I am misunderstanding. \n- It is somewhat disappointing to use an identity mixing matrix in the toy examples. Is there a reason why this analysis could not be done with randomly initialized matrices? \n\nOverall, the paper makes interesting points in regards to standard mutual information minimization for disentanglement and gives strong evidence that attribute-conditional mutual information minimization may be a promising path forward for generalization under correlation shifts. I believe it would make a good addition to the workshop and thus recommend acceptance.\n","sentences":[{"sentence_type":"2","sentence":"It is somewhat disappointing to use an identity mixing matrix in the toy examples.","rephrased":"While the use of an identity mixing matrix in the toy examples is understandable, exploring the effects with randomly initialized matrices could potentially strengthen the analysis."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1903,1985,"Maybe"]],"Comments":[]}
{"id":"SeLeOC5bbv","text":"The paper is well written and interesting to read. The experimental setup is made very clear and results are nicely portrayed, alone the motivation for wbMRI synthesis does not convey completely from the very beginning. I really appreciate the combination of PGAN\/StyleGAN and Schlegl's anomaly detection approach. I also really like the study of simulated tumor intensity, radius and the impact on anomaly detection, although these preliminary results are not earth-shattering.\n\n\nPros:\n- well written and clearly motivated\n\nCons:\n- Given the rare nature of cancer in pediatrics, can you comment on the clinical relevance of this field of study? Do you see potential elsewhere?\n- Cancer regions are only simulated, a set of real cancer testing data would have been nice (is such data available? Again, I think this relates to the clinical relevance)\n- Anomaly detection: which model did you exactly use for anomaly detection?\n- DCGAN: I really wonder how you were able to obtain such compelling results using DCGAN. It would be great if you could provide details on the training\n- Anomaly detection: Do you also have visual results of a less hyper-intense, simulated tumor?\n- Anomaly detection: Is the accuracy evaluated on a pixel-level, or on a level of connected components?\n- Where exactly did the StyleGAN2 fail, as the radiologist was still able to correctly identify 70% of the generated images as fake.\n\nMinor:\n- Introduction: How the synthesis of such wbMRI would play together with anomaly detection is not completely obvious from the very beginning, I'd suggest some rephrasing for the introduction.","sentences":[{"sentence_type":"2","sentence":"although these preliminary results are not earth-shattering.","rephrased":"although these preliminary results may not be groundbreaking, they provide a valuable foundation for further research."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[418,478,"Confirmed"]],"Comments":[]}
{"id":"Hyg0GawAqB","text":"In this article, the authors propose a single image super-resolution network that can generate high-resolution images from the corresponding C-JPG images. The method contains two main parts, namely a JPG recovering step, which recovers the information from low-quality JPG images, and an SR generation step, which generates SR images from the images achieved by the recovering step. Moreover, the authors leverage a cycle loss to generate better results.\nThe main contribution of this work is only the integration of existing models. The authors claimed that the proposed method is lossless, while there is no evidence to demonstrate it. The authors should show more evidence about the JPG recovering step, like how much information it can recover. Moreover, the SR generation step only incorporates s-LWSR without any improvement. It makes SR in this manuscript more like an application for the JPG recovering method rather than a contribution to the SISR field. \nIn the experimental section, Figure 5 makes readers confused. Does the image entitled “s-LWSR(Training)” mean the “STRAIGHT TRAINING” described in section 4.2.1? If yes, is there any perceptual difference between the result of s-LWSR and the result of ours? It is suggested that the authors should reorganize the results and provide more instructions. In Table 1, the results derived from s-LWSR32(C-JPG) and the proposed are very similar. The authors should more convincingly show the advantages of the proposed method. From the results, I observe that the SR images of the proposed model are blurry and lack much information about textures. At the same time, there are some other SISR studies, especially GAN based models like ESR-GAN, which show visual quality with more realistic and natural textures. I hope the authors can conduct more comparisons with these methods.\nThere are still some issues as follows:\n1.\tThe authors should carefully check the format of the references in the whole article. For instance, in section 4.1, almost all references are in the wrong format. The same mistake happens in the caption of Figure 6. Please check the full article before submission.\n2.\t(Page 1, line 2 from bottom) Please add a reference to “bicubic”.\n3.\t(Section 3, line 1) Please add a full stop after “Challenge Formulation”.\n4.\t(Figure 2) Please enlarge the arrow of the red lines. They are hard to read right now.\n5.\t(Figure 4) The figure seems to miss the skip connect of the former five layers, which should be a part of the input added to the latter four layers (Li et al., 2019). In addition, please enlarge the arrow of the blue lines.\n6.\t(Section 4.2.1, line 4) “Both of the PSNR …” Does figure 5 can reflect this? Please add data instruction.\n","sentences":[{"sentence_type":"2","sentence":"The main contribution of this work is only the integration of existing models.","rephrased":"The primary contribution of this work appears to be the integration of existing models, which could be further elaborated to highlight its novelty and impact."},{"sentence_type":"2","sentence":"It makes SR in this manuscript more like an application for the JPG recovering method rather than a contribution to the SISR field.","rephrased":"The manuscript could benefit from a clearer demonstration of how the SR approach contributes to the SISR field beyond its application to the JPG recovering method."},{"sentence_type":"2","sentence":"From the results, I observe that the SR images of the proposed model are blurry and lack much information about textures.","rephrased":"The results suggest that there may be room for improvement in the clarity and texture detail of the SR images produced by the proposed model."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[455,533,"Maybe"],[832,963,"Confirmed"],[1486,1607,"Not concerning"]],"Comments":[]}
{"id":"ZN9_weGPcd","text":"The methodology introduced within the paper is clear, simple and concise. The authors propose combining N=4 sine wave frequencies to apply a continuous transformation function that modifies the gray values of the training dataset. The transformation preserves edge gray-value information and is effective in assisting vertebral body segmentation.\n\nCons: The authors fail to acknowledge or mention whether this transformation is applicable to other modalities (for example: T1-weighted MRI input data, or CT to MRI detection) and other less-bony structures. \n\nPotential impact: Preliminary results demonstrate that the transformation enhances and preserves, the vertebral body edges that leads to good cross-modality segmentation. I think the introduced transformation has potential use and impact for generalizing datasets during training where structures being segmented have edges to guide localization\/segementation. It would be interesting to see whether the introduced transformation can assist with cross-modality whole-vertebra and intervertebral disc segmentation, where there is low bone\/tissue image intensity contrast.\n","sentences":[{"sentence_type":"2","sentence":"The authors fail to acknowledge or mention whether this transformation is applicable to other modalities (for example: T1-weighted MRI input data, or CT to MRI detection) and other less-bony structures.","rephrased":"The authors could further strengthen the paper by discussing the applicability of this transformation to other modalities, such as T1-weighted MRI input data, or CT to MRI detection, and its effectiveness on less-bony structures."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[354,556,"Confirmed"]],"Comments":[]}
{"id":"HyxXpukrjH","text":"Description:\n\nThe information bottleneck (IB) is an information theoretic principle for optimizing a mapping (encoding, e.g. clustering) of an input, to trade off two kinds of mutual information: minimize mutual information between the original input and the mapped version (to compress the input), and maximize mutual information between the mapped input and an output variable. It is related to a minimization of an (expected) Kullback-Leibler divergence betwen conditional distributions of an output variable.\n\nIn this paper, instead of the original IB, authors consider a previously presented dual problem of Felice and Ay, where the Kullback-Leibler divergence is minimized in the reverse direction: from the conditional distribution of output given encoding, p(y|hat x), to the conditional distribution given the original input, p(y|x).\nThe \"dual problem\" itself has a more complicated form than the original IB, authors claim this is \"a good approximation\" of the original bottleneck formulation, and aim to prove various \"interesting properties\" of it. \n\n- An iterative algorithm (Algorithm 1) similar to the original IB algorithm but with a few more steps is provided.\n\n- A theorem about critical points where cardinality of the representation changes is given, similar to the IB critical points, and another theorem about difference of curves on an information plane between the IB and dual-IB solutions.\n\n- Authors also show that if the true conditional distribution of outputs given inputs has an exponential-family form, the dual-IB decoder also has a form in the same family, which is said to reduce computational complexity of the algorithm.\n\n\n\nEvaluation:\n\nThis is an entirely theory-based paper; although an algorithm is given, it is not instantiated for any concrete representation learning task, and no experiments at all are demonstrated.\n\nOverall, I feel the motivation is not clear and strong enough. The abstract does not illustrate the importance of the mentioned \"interesting properties\" well enough for concrete tasks. Reading the paper, the clearest motivations seem to be improving computational complexity, and having a clearer connection to output prediction in cases where the predictor may be sub-optimal. However, authors do not quantify these well:\n\n- The computational complexity improvement is not made clear (quantified) in a concrete IB optimization task: it seems it is only for exponential families, and even for them only affects one part of the algorithm, reducing its complexity from dim(X) to d; the impact of this is not tried out in any experiment.\n\n- For output prediction, authors motivate that dual-IB could have a more direct connection e.g. \"due to finite sample, in which it can be very different from the one obtained from the full distribution\"). Authors further claim that the dual-IB formulation can \"improve the generalization error when trained on small samples since the predicted label is the one used in practice\". However, this is not tested at all: no prediction experiments, no quantification of generalization error, and no comparisons are done, thus the impact of the clearer connection to output prediction is not tested at all, and no clear theorems are given about it either.\n\nThe property that the algorithm \"preserves exponential form of the original data distribution, if one exists\" is interesting in principle, but it is unclear if any real data would anyway precisely have such a distribution; what happens if the data is not exactly in an exponential family?\n\nIn its current state the paper, although based on an interesting direction, in my opinion does not make a sufficient impact to be accepted to ICLR.\n\nOther comments:\n\n\"Application to deep learning\" mentioned in Section 1.5 is only a sincle sentence in the conclusions.\n\nThere have been some other suggested alternative IB formulations, for example the Deterministic IB of Strouse and Schwab (Neural Computation 2017) which also claim improved computational efficiency. How does the method compare to those?\n\nSection 1.5 claims the algorithm \"preserves the low dimensional sufficient statistics of the data\": it is not clear what \"preserves\" means here, certainly it seems the decoder in Theorem 7 uses the same kinds of sufficient statistics as in the original data, but it is not clear that hat(x) would somehow preserve the same values of the sufficient statistics.\n","sentences":[{"sentence_type":"2","sentence":"Overall, I feel the motivation is not clear and strong enough.","rephrased":"The motivation could be articulated more clearly and strongly to convey its significance."},{"sentence_type":"2","sentence":"In its current state the paper, although based on an interesting direction, in my opinion does not make a sufficient impact to be accepted to ICLR.","rephrased":"While the paper takes an interesting direction, further work is needed to demonstrate a significant impact for consideration in ICLR."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1860,1922,"Confirmed"],[3536,3683,"Confirmed"]],"Comments":[]}
{"id":"HyxNF2Jr2Q","text":"The paper proposes an alignment of two manifolds that is performed in a low-dimensional parameter space corresponding to a low-pass \"filtering\" of the Graph Fourier transform obtained from the underlying data graphs for the two manifolds. The numerical results show the quality of the alignment for some toy image datasets and a biological dataset.\n\nThe derivation of the technical details of the approach is not clear - see the comments below on Pages 5,6 and 9 in particular. The paper is not clear enough for acceptance at this point.\n\nDetailed comments:\n\nPage 2: Grammar error \"that is invariant batch effects\". When denoising is discussed, can you explain whether this is denoising or simply regularization? When is the selected subspace a good approximation for the \"signal subspace\"?\nPage 3: Should X^(S) be X^(s)? When W and W(s) are defined, do they also rely on a neighborhood graph? It appears that in the definition of psi_j the eigenvectors phi_j should be obtained from W, not P (which is how they are defined earlier in the page).\nPage 4: There is an abuse of notation on f, used both as a linear function on X(s) and an element of X(s).\nPage 5: Typos \"exlpained\", \"along the along the\". It is not clear what applying a window to eigenvalues means, or what the notation g_xi(lambda) means. The construction of the filters described here needs to be more explicit. h_xi is undefined. How is H in (1) defined when i = 1?\nPage 6: M should be M(s1,s2). Typesetting error in Lambdabar(s). Which matrix is referred to in \"the laplacian eigenvalues of each view\"? What is the source and target of the embedding E? How is the embedding applied to data x(s1), x(s2)?\nPage 7: Figure 1a appears to have an error in the orientation of one of the blue \"3\"s. The text on the arrow between the manifold embeddings does not agree with the notation in the paper. In Figure 1b, it is not clear which image is the original point and which images are the neighbors, or why some images are smaller than others. Results for the other algorithms are missing (why no comparison?). Typo \"Wang&Mahadevan\". Can you be more specific as to why that algorithm was \"unable to recover k-neighborhoods\" in certain cases?\nPage 8: Why no comparison with Wang & Mahadevan in Figure 2?\nPage 9: There is little description as to how manifold learning is applied in the biological data example. What is the ambient dimensionality and the dimension of the manifolds? How are the \"abundances\" extracted from the data? \n\"Which we explore in 4\" -> \"Which we explore in Fig. 4\"","sentences":[{"sentence_type":"2","sentence":"The paper is not clear enough for acceptance at this point.","rephrased":"The paper would benefit from additional clarity in several sections before it could be considered for acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[478,537,"Confirmed"]],"Comments":[]}
{"id":"G5NgQiUwgiA","text":"Strengths:\n1. This paper proposed a two-stage pipeline that could generate the facial details of any target expressions and render it realistically using just one input image.\n2. A detail hallucination network was proposed and trained. \n3. The Augmented Wrinkle Loss and Detailed Shading Loss were proposed to train the rendering network.\n4. The authors evaluated the method quantitatively and qualitatively, also compared it with the DECA method. \n5. The authors further showed that the rendered results are view consistent, proving the effectiveness of the rendering network. \n6. Ablation studies are done to show the effectiveness of the two novel losses.\nWeaknesses:\n1. The readability of this paper can still be improved. For example, a pipeline figure would help in explaining the overall picture of the proposed method; alpha_s is not in the input of Equation (2) although it appears in Fig 2. \n2. The figures in this paper could be improved to show the details clearly. For example, in Fig 5, it seems that the lighting\/shading of the two subjects' results are quite different, making it hard to see the facial details. The same problem also exists for Fig 4&6. Also,I would suggest the authors to show the zoom-in details in the rectangles as in Fig 1 rather than ask the readers to zoom in for details.\n3. The proposed method in this paper is not well-supported by experiments. First, it seems that the image quality of the rendered view is much more blurry than the input image and also the previous work [Chen et al. 2019]. Second, since the proposed method is built on [Chen et al. 2019], it would be fair to include this work for comparison as well reconstructed on the expression of the input image. Lastly, there're no evaluations of the usage of the age prediction network and FaceID embeddings. It would be interesting to know that age information make the proposed method outperforms the others in generating results for people across different ages, etc. ","sentences":[{"sentence_type":"2","sentence":"The proposed method in this paper is not well-supported by experiments.","rephrased":"The experimental support for the proposed method could be strengthened by including additional comparative analyses and clarity in the rendered view quality."},{"sentence_type":"1","sentence":"Lastly, there're no evaluations of the usage of the age prediction network and FaceID embeddings.","rephrased":"Including evaluations of the age prediction network and FaceID embeddings could provide valuable insights into the performance of the proposed method across different ages."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1316,1387,"Not concerning"],[1715,1812,"Not concerning"]],"Comments":[]}
{"id":"E76rpEHeXU","text":"**Summary**: This paper tackles two important issues of concept-based models: interpretability and concept leakage. Both issues arise from a lack of a widely accepted definition, resulting in an inability to concretely quantify the problem. The paper proposes to define interpretability in terms of alignment, where the goal is to learn a representation for which each variable monotonically maps to a generative factor of the data. They propose GlanceNet, a new type of concept-based model that learns the representation using a VAE architecture. Concept leakage is addressed by rejecting samples that are too far away from labels in the latent space or if the reconstruction loss is too high. GlanceNets are shown empirically to have better alignment and resistance to leakage compared to the competitor, CBNM.\n\n**Strengths**:\n1. The problem is clearly motivated, and a solution could indeed be quite useful from the perspective of explainable AI. I particularly like the approach of working with causal assumptions, which perhaps could be expanded more formally. The connection with disentanglement representation learning is also quite interesting.\n\n2. The GlanceNet architecture and optimization appears to be an interesting novel approach to this problem. The experimental results are not overly extensive, but they are quite convincing.\n\n**Weaknesses**:\n1. The goal of setting concrete definitions for interpretability and concept leakage seems to fall short here. While Sec. 3 attempts to define these concepts for this problem setting, it is still not clear how these properties can be measured and why these definitions capture the issue at hand. There is also a lack of theoretical results, which would help rigorously ground these concepts.\n\n2. Despite the positive experimental results, it is unclear if the approach is sound. Even under perfect training of GlanceNet, is it guaranteed that the generative factors will be recovered? Also, why does the rejection approach work for solving concept leakage? The cited paper, Mahinpei et al. (2021) seems to suggest that many approaches to avoiding concept leakages do not work, including adding latent capacity and decorrelating factors, which this paper appears to do as well. Theoretical results would help here.\n\n3. In general, the presentation of the paper could be improved for clarity purposes. Most prominently, the work builds on several cited sources which are often leveraged without context (for example the MNIST experiment in Mahinpei et al. (2021) or the open-set recognition strategy of Locatello et al. (2020)). Providing some background on these components and how they relate to this paper could help the reader follow better. Additionally, this paper would benefit from having examples in Sec. 1 or 2 to illustrate the issues with interpretability and concept leakage, and also in Sec. 3 to explain the intuition of each of the solutions described in the paper.\n\nIn general, I think the ideas presented in this paper offer interesting insight into the issues of concept-based models and would be a great contribution to the workshop.","sentences":[{"sentence_type":"2","sentence":"The goal of setting concrete definitions for interpretability and concept leakage seems to fall short here.","rephrased":"The paper makes a commendable attempt at setting concrete definitions for interpretability and concept leakage, though further clarification could enhance understanding."},{"sentence_type":"2","sentence":"Despite the positive experimental results, it is unclear if the approach is sound.","rephrased":"While the experimental results are promising, further discussion on the soundness of the approach would be beneficial."},{"sentence_type":"1","sentence":"In general, the presentation of the paper could be improved for clarity purposes.","rephrased":"Enhancing the clarity of the paper's presentation, particularly in providing context for cited sources, could further strengthen the work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1364,1471,"Maybe"],[1757,1839,"Confirmed"],[2279,2360,"Confirmed"]],"Comments":[]}
{"id":"BklYXrfv2N","text":"The paper follows up on one of Fox et al's proposals for XAIP, answering questions of the type \"why does the plan have property A rather than property B?\". It assumes the contrastive answer generating a plan with property B for comparison, and it focusses specifically on the sub-problem of designing a compiled planning problem whose solution will be such a plan.\n\nThis is completey fine, and highly relevant to XAIP. I think the paper should be accepted.\n\nI have two major comments though:\n\n1. Imho, the approach of generating a plan with property B for comparison has severe limitations. First, the plan may differ from the previous one in arbitrary ways unrelated to A vs B. Second, the plan may satisfy B in trivial ways not relevant to answering the question (e.g., as mentioned by Fox et al, if A and B are applying a particular action in the current state, tjen the new plan may undo action B and use again action A afterwards). These issues do not by any means disvalidate the approach. But I think they need to be at least mentioned.\n\n2. I find it awkward and scientifically unsaisfactory to address this problem as a long list of individual questions. First, this pretends that the qestions have no interreltion, which is clearly not so, isiuble also in the similarities between the compiltions offered. Second, it leaves open all the other questions which might be asked. The authors acknowledge this, but do not offer a solution. How will we ever be able to address the problem in a way that can be reasonably argued to be exhaustive? Why, the rather obvious answer given my own background is to define a question *language* instead of individual questions. Some fragment of logics with temporal elements that allows to state the things the authors want stated here. This would lift the discussion from one about long lists of questions (awkward, infeasible) to one about expressiveness of languages (elegant, compact, standard in CS). This seems rather obvious to me and I wonder why the authors did not consider it, or did not choose to discuss it. Perhaps such an approach would be difficult from an explanation\/cognitive point of view? In any case, I do think that at least a brief discussion of this possibility should be given in the paper.","sentences":[{"sentence_type":"2","sentence":"Imho, the approach of generating a plan with property B for comparison has severe limitations.","rephrased":"In my opinion, while the approach of generating a plan with property B for comparison is innovative, it may have some limitations that could be addressed."},{"sentence_type":"2","sentence":"I find it awkward and scientifically unsaisfactory to address this problem as a long list of individual questions.","rephrased":"I believe that addressing this problem through a long list of individual questions may not be the most scientifically robust method."},{"sentence_type":"1","sentence":"This would lift the discussion from one about long lists of questions (awkward, infeasible) to one about expressiveness of languages (elegant, compact, standard in CS).","rephrased":"Adopting a question language could transition the discussion from a focus on extensive lists of questions to an emphasis on the expressiveness of languages, which is a standard approach in computer science."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[496,590,"Maybe"],[1048,1162,"Maybe"],[1780,1948,"Not concerning"],[1949,2063,"Missed Maybe"]],"Comments":[]}
{"id":"S1eXfcYpOV","text":"Summary: The paper proposes a framework to relax the functional dependency (FD) discovery problem as a structure learning problem by focusing on the dependency between pairs of records. Graphical lasso is applied to obtain the sparse inverse covariance matrix, resulting in an approximate solution to the FD discovery problem. The proposed method is compared with prominent FD discovery methods such as PYRO and RFI, showing much higher precision and recall on a synthetic dataset. On a real dataset of data cleaning, the proposed method outperforms HoloClean, which uses manually written FDs.\n\nStrengths:\n1. The relaxation of the FD discovery problem to structure learning in elegant.\n2. The empirical performance on synthetic and real datasets are impressive.\n\nWeakness:\nLack of theoretical guarantee: perhaps there's a way to get error bound on B_hat from the error bound for Glasso?\n","sentences":[{"sentence_type":"1","sentence":"Lack of theoretical guarantee: perhaps there's a way to get error bound on B_hat from the error bound for Glasso?","rephrased":"Exploration of theoretical guarantees: It would be beneficial to investigate if an error bound on B_hat could be derived from the error bound for Glasso to strengthen the framework."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[773,886,"Not concerning"]],"Comments":[]}
{"id":"BJxg_FwwqB","text":"This paper proposes to detect inputs that are from a slightly shifted distribution (eg images of houses in CA instead of KY) or from a very shifted distribution (eg imagenet images) by fitting a density model to the last layer h(x) of an MLP trained with squared error, and using the likelhiood score p(h(x)) as a metric. This is a reasonable idea. However, it is not novel eg Aigrain'19 did essentially the same thing for classification models. (The difference between classification and regression is a trivial change to the loss function, and does not change the fundamental idea.)\n\nIn addition to lack of novelty, the experimental methodology is very weak. First, the toy 2d example is too trivial to be informative, since there is essentiallly no overlap between the two distributions of features, p(x) and q(x) - even a density model on input space could detect this. More importantly, the results on the two image datasets are suspect. First, it seems that using the predictive variance sigma(x) as the reliability metric (the \"var\" method) - which is totally standard approach known as 'heteroskedastic regression'. - works very well in several cases. I suspect when it fails it is due to  implementation problems (eg trying to predict sigma instead of log(sigma)). Also ensembles are known to be very robust to distribtution shift (see eg Ovadia'19), so  I am surprised at their poor performance. Another problem is that the datasets used are not standard, so it is impossible to compare to other papers. Finally, no error bars are reported, so it is hard to know if any of the results are statistically significant. \n\n\n\nJ. Aigrain and M. Detyniecki, “Detecting Adversarial Examples and Other Misclassifications in Neural Networks by Introspection,” in ICML Workshop on Uncertainty and Robustness in Deep Learning, 2019 [Online]. Available: http:\/\/arxiv.org\/abs\/1905.09186\n\n\nY. Ovadia et al., “Can You Trust Your Model’s Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift,” arXiv [stat.ML], 06-Jun-2019 [Online]. Available: http:\/\/arxiv.org\/abs\/1906.02530\n\n\n\n","sentences":[{"sentence_type":"2","sentence":"However, it is not novel eg Aigrain'19 did essentially the same thing for classification models.","rephrased":"While the idea has merit, it appears similar to the approach taken by Aigrain'19 for classification models, suggesting that the novelty might be limited."},{"sentence_type":"2","sentence":"In addition to lack of novelty, the experimental methodology is very weak.","rephrased":"In addition to the concerns about novelty, there are opportunities to strengthen the experimental methodology."},{"sentence_type":"2","sentence":"First, the toy 2d example is too trivial to be informative, since there is essentiallly no overlap between the two distributions of features, p(x) and q(x) - even a density model on input space could detect this.","rephrased":"The toy 2D example could be improved to better demonstrate the method's effectiveness, as the current lack of overlap between the distributions p(x) and q(x) makes the detection task less challenging."},{"sentence_type":"1","sentence":"I suspect when it fails it is due to  implementation problems (eg trying to predict sigma instead of log(sigma)).","rephrased":"The instances where it fails may be attributed to potential implementation issues, such as predicting sigma instead of log(sigma), which could be further investigated."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[349,445,"Confirmed"],[586,660,"Confirmed"],[661,873,"Confirmed"],[1160,1273,"Confirmed"]],"Comments":[]}
{"id":"ivoC0Wu6fmM","text":"This submission addresses (I believe...) the problem of finding empty regions in pointsets in a specific setup.\n\nThe presented technique relies on a voxelization of the input pointset, and defines a hollow voxel as \"a voxel that is closed to the upper area in y-axis (has voxels above itself) and connects with the outer area in x-axis or z-axis\". The set of hollow regions is depicted in Fig 2b in blue. The hollow regions are then partitioned into connected components, that finally define the hollow bodies. Each hollow body is then characterized by volume, \"normal line\" (I do not understand the definition of the normal line as described in the manuscript but I assume, based on Fig6, that it could be the direction of smallest variance given by the PCA passing through the center of mass?) and \"depth ratio\" (I did not understand this definition either...). The characteristics of the hollow bodies are not really used in the present work, but \"could be used for further research\".\n\nI am actually not entirely sure of what is described in the manuscript, because I have extreme difficulties in making sense of the phrasing... However, if the authors address the consistent volumetrization of pointsets (or consistent in\/out segmentation), there are a number of existing techniques that the authors could compare to. For example:\nA Global Parity Measure for Incomplete Point Cloud Data, Seversky and Yin, Pacific Graphics 2012 (does not assume that the input pointset contains normals).\n\nMaybe there are extremely specific constraints that guide the proposed approach, which make the technique not possible to compare to existing work, but then I did not understand them... (and it may be partly my fault).\n\nI believe that given the current state of the manuscript in terms of clarity of exposition, this submission should be rejected. I encourage the authors to proof-read the manuscript before submitting it again.","sentences":[{"sentence_type":"2","sentence":"I am actually not entirely sure of what is described in the manuscript, because I have extreme difficulties in making sense of the phrasing...","rephrased":"The manuscript could benefit from clearer phrasing to enhance understanding of the described methods and results."},{"sentence_type":"2","sentence":"I believe that given the current state of the manuscript in terms of clarity of exposition, this submission should be rejected.","rephrased":"Improving the clarity of the manuscript could strengthen the submission and potentially make it suitable for acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[989,1131,"Confirmed"],[1713,1840,"Confirmed"]],"Comments":[]}
{"id":"zrCbyRb7obD","text":"It is important to handle Large scale packing problem with continuous action space. The authors expand the tree by using methods of heuristics, which reduces the action space to limited number of leaf nodes (actions). Then reinforcement learning is incorporated to optimize packing efficiency. As a result, the method reduces the size of action space which leads to better learning results.\n\nHowever, there are some suggestions to improve the paper:\n1. The method reduces the action space to discrete nodes via heuristic search, while after heuristic search, the packing action space is not fully covered because the heuristics only select part of action space. In fact, It is a trend-off between complexity and optimality. In addition, the complexity of the tree search will grow exponentially when lots of items have to be packed, which threaten the scalability of the proposed method. Worse, a large number of leaf node would makes the attention network computationally heavy since it is quadratic related to the number of nodes.\n2. After determine the candidate points, the original heuristics select the placement point of new item by its own heuristic rules. Here, the authors replace the heuristic candidate points selection with DRL. But they do not compare with recent heuristics to show whether the DRL is indeed superior than these heuristic rules.\n3. The dataset is too naive, which only discretizes each edge to 10, while conventional methods have much more resolution. In their continuous setting, their results degrade, but there is no explanation about this. The authors claim that the method works on continuous solution space, but they do not define the continuous solution space. Clearly, it is different from the continuous action space in reinforcement learning. In fact, the method works on discrete action space.\n4. I think Section 4.4 should be modified. The distribution of adding a uniform random disturbance to each point of another uniform distribution is almost uniform. This is not the proper way to evaluate generalization.\n\nThere are some specific points: \n1. The author did not mention how many bins are used in the problem settings, which should be clearly state.\n2. In the second paragraph of introduction, the authors said online packing ‘imposes additional constraints and difficulty’. but it is clear that offline packing is more complex than the its online variety since it includes the item selection step before the ‘online packing’ step. In the next sentence, the authors said ‘Learning-based approaches usually perform better than heuristic methods, especially under various complicated constraints’. Why Learning-based approaches perform better under various complicated constraints?\n3. In equation 1, the right side use a capital S，I didn’t understand this, should this be a lowercase s? \n4. In the first paragraph of page 3,  ‘The flaw of their work is the heightmap (frontier) state representation like Zhang et al. (2021) is still used, while the underlying interactions that exist in packed items are missed’. what does the ‘underlying interactions’ mean?\n5. In Section 3.1, the authors use \\pi(L_t|L_t,n_t) to denote policy, but the policy is \\pi(a|s) in RL. Therefore, people may be confused between the state and action when reading. This notion is very misleading. The same problem exists in the following text.\n","sentences":[{"sentence_type":"2","sentence":"Worse, a large number of leaf node would makes the attention network computationally heavy since it is quadratic related to the number of nodes.","rephrased":"Additionally, the computational load of the attention network may increase significantly with a large number of leaf nodes, as it is quadratically related to the number of nodes."},{"sentence_type":"2","sentence":"The dataset is too naive, which only discretizes each edge to 10, while conventional methods have much more resolution.","rephrased":"The dataset could be improved by increasing the resolution beyond the current discretization of each edge to 10, to better align with the higher resolution used in conventional methods."},{"sentence_type":"2","sentence":"I think Section 4.4 should be modified. The distribution of adding a uniform random disturbance to each point of another uniform distribution is almost uniform. This is not the proper way to evaluate generalization.","rephrased":"Section 4.4 could benefit from a revision. The method of adding a uniform random disturbance to each point of another uniform distribution may not effectively evaluate generalization and alternative approaches could be considered."},{"sentence_type":"1","sentence":"The author did not mention how many bins are used in the problem settings, which should be clearly state.","rephrased":"It would be helpful if the authors could specify the number of bins used in the problem settings for clarity."},{"sentence_type":"1","sentence":"but it is clear that offline packing is more complex than the its online variety since it includes the item selection step before the \n\nonline packing step.","rephrased":"It may be beneficial to discuss how offline packing could be considered more complex than online packing due to the additional item selection step that precedes the packing process."},{"sentence_type":"1","sentence":"Why Learning-based approaches perform better under various complicated constraints?","rephrased":"It would be informative if the authors could provide evidence or a rationale for why learning-based approaches are considered to perform better under various complicated constraints."},{"sentence_type":"2","sentence":"The flaw of their work is the heightmap (frontier) state representation like Zhang et al. (2021) is still used, while the underlying interactions that exist in packed items are missed.","rephrased":"A potential area for improvement in their work is the continued use of the heightmap (frontier) state representation, similar to Zhang et al. (2021), which may not fully capture the underlying interactions among packed items."},{"sentence_type":"2","sentence":"This notion is very misleading. The same problem exists in the following text.","rephrased":"This notation could be clearer to avoid potential confusion. A similar issue is observed in subsequent sections of the text."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[888,1032,"Not concerning"],[1363,1482,"Confirmed"],[1839,2054,"Maybe"],[2092,2197,"Not concerning"],[2644,2727,"Not concerning"],[3286,3364,"Confirmed"]],"Comments":[]}
{"id":"rkgfxIgOh7","text":"This paper tries to address the\"pretend-to-share\" problem by designing the gradient passing schemes in which the gradient updates to specific parameters of tasks are passed to the shared parameters. Besides, the authors summarize existing multitask learning algorithms in a framework called Parameters Read-Write Networks (PRAWN). \n\nPros:\n- The view of putting existing multi-task learning algorithms in a read-write framework is quite intriguing and inspiring.\n\nCons:\n- Motivation: The whole paper is assumed to address the \"pretend-to-share\" problem, while the authors never provide any evidence that such problem really exists for any other algorithm. It seems to be an assumption without any support.\n- Method:  \n   - Though the read-write framework is very interesting, the authors do not clearly present it, so that the readers can be totally get lost. For example, what do you mean by writing {\\Theta^{*r}_k - \\theta^{swr}_k}? In the line of structural read-op, where are \\theta_3 and \\theta_4  in the column of the constituent para. ? What do you mean by writing the equation (4)? How do you define g() in equation (8)? This is a research paper which should be as clear as possible for the readers to reproduce the results, rather than a proposal only with such abstract and general functions defined. \n   - In the list-wise communication scheme, you define the task relationship in equation (11). The problem is how do you evaluate the effectiveness of such definition, since massive works in multitask learning pursue to learn the task relationship automatically to guarantee the effectiveness instead of such heuristic definition. \n- Related works: The authors do not clearly and correctly illustrate the connections between this work and meta-learning\/domain adaptation. To my best knowledge, meta-learning, including MAML (Finn et al. 2017), can obviously solve both in-task setting and out-task setting. In some sense, I think this work is almost equivalent to MAML. \n- Experiments: \n   - First, several state-of-the-art baselines including MAML and cross-stitch networks should be compared. Specifically, for the text classification dataset, there have been a lot of domain adaptation works discovering the transferable pivots (shared features) and non-pivots (specific features), which the authors should be aware of and compare in Table 3.  \n   - The Figure 5 is not clear to me, and so is the discussion. The authors try to explain that the updating direction of shared parameters for PGP-SR is an integration of two private updating directions. I tried hard to understand, but still think that Figure 5(a) is even better than Figure 5(b). The updating direction of the shared parameters is almost the same as the cyan line.\n- Presentation: there are so many grammatical errors and typos. For example,\n   - In the introduction, \"...datasets, range from natural\" -> \"...datasets, ranging from natural\"\n  - In the related work, \"and they propose address it with adversarial\" -> \"and they propose to address it with adversarial\"\n - In the beginning of Section 4, \" an general\" -> \"a general\"","sentences":[{"sentence_type":"2","sentence":"The whole paper is assumed to address the \"pretend-to-share\" problem, while the authors never provide any evidence that such problem really exists for any other algorithm. It seems to be an assumption without any support.","rephrased":"The paper sets out to address the \"pretend-to-share\" problem; however, it would be beneficial if the authors could provide evidence or references to support the existence of this problem in other algorithms."},{"sentence_type":"2","sentence":"Though the read-write framework is very interesting, the authors do not clearly present it, so that the readers can be totally get lost.","rephrased":"While the read-write framework is intriguing, the presentation could be clearer to prevent confusion and aid the reader's understanding."},{"sentence_type":"2","sentence":"This is a research paper which should be as clear as possible for the readers to reproduce the results, rather than a proposal only with such abstract and general functions defined.","rephrased":"For the benefit of reproducibility, it would be helpful if the paper could provide more detailed explanations of the abstract and general functions."},{"sentence_type":"2","sentence":"The problem is how do you evaluate the effectiveness of such definition, since massive works in multitask learning pursue to learn the task relationship automatically to guarantee the effectiveness instead of such heuristic definition.","rephrased":"It would be informative if the paper could discuss the methods used to evaluate the effectiveness of the task relationship definition, especially in comparison to approaches that learn this relationship automatically."},{"sentence_type":"2","sentence":"To my best knowledge, meta-learning, including MAML (Finn et al. 2017), can obviously solve both in-task setting and out-task setting. In some sense, I think this work is almost equivalent to MAML.","rephrased":"It would be helpful if the authors could clarify how this work differs from and contributes beyond existing meta-learning approaches like MAML, which also address in-task and out-task settings."},{"sentence_type":"1","sentence":"I tried hard to understand, but still think that Figure 5(a) is even better than Figure 5(b).","rephrased":"I found it challenging to understand the rationale behind Figure 5; perhaps further clarification or a more detailed explanation could enhance the figure's effectiveness."},{"sentence_type":"2","sentence":"there are so many grammatical errors and typos.","rephrased":"The paper would benefit from a thorough proofreading to correct the grammatical errors and typos present."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[483,704,"Confirmed"],[722,858,"Confirmed"],[1128,1309,"Confirmed"],[1406,1641,"Maybe"],[1783,1980,"Confirmed"],[2564,2657,"Confirmed"],[2759,2806,"Confirmed"]],"Comments":[]}
{"id":"WEhU5rVlMw","text":"### Strengths \n\nThe problem that the paper tackles, analysing latent concepts captured in BERT, is challenging and needed to understand the model. It is well in line with the trend of model and representation interpretation. \n\nThe proposed solution to the problem requires carefully manually annotation which was carried out thoughtfully. The innovation is that there are several syntactic and semantics aspects taken into account, including hierarchy nature of those concepts. \n\nThe analyses presented in the paper do lead to several findings about the knowledge of BERT, thus they back the claims risen in the paper.\n\n\n### Weaknesses \n\nThe paper doesn't go any further beyond 1000 clusters \/ concepts, which doesn't seem to have as wide coverage as e.g. wikipedia. Hence, one would question about the used clustering method, especially whether it is good enough to discover a wide range of concepts \/ clusters. \n\nThe methodology proposed in the paper requires expensive manual annotation. This leads to the problem of replication. Besides, although the BCD dataset has some potential, it is limited to only BERT. It does't seem useful when other models are examined. \n\nI found the BCD development (section 7.1) problematic. Although clusters were manually annotated, it is unclear how accurate an instance is assigned to a specific cluster. For instance, although annotators intuitively agreed that cluster A with N instances properly present concept \"animal\", how many instances among the N instances actually belong to concept \"animal\"?\n\n\n\n\n","sentences":[{"sentence_type":"2","sentence":"The paper doesn't go any further beyond 1000 clusters \/ concepts, which doesn't seem to have as wide coverage as e.g. wikipedia.","rephrased":"The paper's analysis is limited to 1000 clusters\/concepts, which may not provide as comprehensive coverage as larger datasets like Wikipedia. Expanding the scope could enhance the study's applicability."},{"sentence_type":"1","sentence":"This leads to the problem of replication.","rephrased":"This approach may pose challenges for replication, which is an important aspect to consider for future research."},{"sentence_type":"2","sentence":"It does't seem useful when other models are examined.","rephrased":"The utility of the BCD dataset might be more limited when considering its application to models other than BERT."},{"sentence_type":"1","sentence":"I found the BCD development (section 7.1) problematic.","rephrased":"The BCD development described in section 7.1 could benefit from a clearer explanation of the methodology for assigning instances to clusters."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[638,766,"Confirmed"],[991,1032,"Not concerning"],[1115,1168,"Confirmed"],[1171,1225,"Maybe"]],"Comments":[]}
{"id":"HAxxHOTBzz5","text":"The paper focuses on an interesting problem of learning causal models from high-dimensional unstructured data with interventions, the authors provided indentifiability proofs for such a setting with weak supervision signals (only the pair of data before and after intervention is given, the intervention itself can be unknown). Here are my comments for the paper. \n\n1. The paper focuses on an very interesting and important problem. The authors provided identifiability proofs for such a setting with only weak supervision signals, the intervention itself can be unknown, this is an very interesting result.\n\n2. However, given such strong and interesting theoretical proofs, the experiment seems to be a bit pale in comparison. The experiment is only conducted on a 2D toy setting, and my main concern is that the causal graph in the experiment is fixed and not learned, and learning the causal graph structure is one of the most important (and challenging) aspect of causal learning.\n\nI understand that this might be prelimary work, however, I do feel that this should be described properly in the introduction and abstract. From the way it currently reads, it seems as if the authors have both theoretical and experimental results indicating that a SCM can be fully learned from high-dimensional unstructured data. This is a little misleading. It would be nice if the authors could update the paper to reflect the experimental results. \n\nThat being said, I think the theoretical results are intriguing. I would be excited to see further results, especially experimental results showing that a SCM can be learned from high dimensional data.","sentences":[{"sentence_type":"2","sentence":"The experiment seems to be a bit pale in comparison.","rephrased":"While the theoretical proofs are strong, the experimental section could benefit from more robust and varied settings to better illustrate the applicability of the theoretical results."},{"sentence_type":"1","sentence":"I do feel that this should be described properly in the introduction and abstract.","rephrased":"It would be helpful if the scope of the preliminary work was clearly outlined in the introduction and abstract to accurately set the expectations for the theoretical and experimental results."},{"sentence_type":"2","sentence":"This is a little misleading.","rephrased":"There is a potential for misunderstanding the extent of the experimental results as currently presented in the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1043,1125,"Not concerning"],[1317,1345,"Not concerning"]],"Comments":[]}
{"id":"Syghzj69j4","text":"I am not familiar with the problem of spacecraft constellations, however, it looks like an important problem, and the paper proposed a communication module to optimize the schedule of communication. The authors compare the algorithm in two settings: distributed one and centralized one. The results show the distributed approach can achieve 16% more values than the centralized one, with a price of 4% less GP observed.  \n\nThe presentation of the paper can be improved. I understand that it is an application paper. Nevertheless, the scheduling algorithm  and the results should be described in more detail. The subsections of Nature Run for Observing Simulations and Orbital Mechanics and Attitude Control are rather long, and readers could get lost in those details without right background. I suggest to shorten these sections, but add more details in the algorithm.  Given the current descriptions, I don't understand how the DP based algorithm works. The summarized algorithm needs to be elaborated. For instance, what are commBundles(), tSrc_c, satsWoverlappingFOR(sat)? It will be very helpful if authors can add some descriptions for each for loop in the algorithm to state what loops are doing.  In addition, authors mentioned the DP algorithm is validated by an IP model. The IP model is not formulated in the paper, and there are no details about experiments. How many instances were run? how large are the instances?  and, can the proposed algorithm handle instances with overlapping areas?\n\nIn the result section, it is not explained what is cumulative value. In addition, the robustness of the algorithm is not discussed. It is not clear what the performance would be for different instances. It will be good if authors can add some discussions there. ","sentences":[{"sentence_type":"2","sentence":"The subsections of Nature Run for Observing Simulations and Orbital Mechanics and Attitude Control are rather long, and readers could get lost in those details without right background.","rephrased":"The subsections on Nature Run for Observing Simulations and Orbital Mechanics and Attitude Control are quite detailed. It may be beneficial to streamline these sections to ensure they are accessible to readers with varying levels of background knowledge."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[608,793,"Not concerning"]],"Comments":[]}
{"id":"wdhNqmDEu2S","text":"This paper proposes the AIME framework - Action Inference by Maximizing Evidence - a 2 step approach to train reinforcement learning agents where the agent first learns a world model from actions and observations, and then imitates the behavior of an expert based on a set of observations.\n\nThe theoretical and implementation aspects of the methodology are crisply motivated and explained. The proposed approach is tested on multiple representative environments. The choice of baselines and experimental setup is meticulously documented. The results clearly showcase the generalizability and efficacy of the approach. The authors discuss interesting observations and outline potential future directions.\n\nThe paper is concise and written in a simple and understandable manner. The authors also compare their approach against related work in the fields of imitation learning and reusing pretrained components and succinctly outline the unique contributions of the paper.\n\nThe proposal is interesting and evokes comparisons to transfer learning techniques that have proven incredibly effective in sequence modeling research, where a pretrained model learns general rules about the domain and the knowledge can be transferred in a few-shot manner to downstream tasks. The authors discuss these similarities and present the gaps in current RL research on corresponding ideas in the related works section. I’d encourage the authors to continue exploring these themes!\n","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"k4LmsCHVohi","text":"review:\nThis paper addresses the effects of gradient descent methods onto compositionality and compositional generalization of models. The authors claim that the optimization process imposes the models to deviate compositionality, which is defined with conditional independence among random variables of input, predicted output and the ground-truth. Since compositionality is one of important features of human intelligence, it has been interested widely in the field of AI\/ML such as vision, language, neuro-symbolic approaches, common sense reasoning, disentangled representation, and the emergence conditions of compositionality. As it has been not much focused on the relationship with optimizers, it is fresh and interesting. However, it is not easy to figure out the position of this paper from two reasons: (1) the definitions on compositionality in this paper are not so compatible with recent related works, which mostly consider certain structures in models [ICLR19, JAIR20] or representative problems such as visual reasoning [CVPR17] and Raven progressive matrices [PNAS17]. (2) The authors do not consider quantitative approaches such as compositionality [ICLR19] or compositional generalization [ICLR20]. \n\nIn this paper, the main claim is very broad argument. To verify this claim, the authors provide supports of both theoretical and experimental aspects. Theoretically, they try to show that reducing loss values in the optimization process induces utilizing other input variables including useful information based on mutual information. Experimentally, they show the gaps between several settings of accuracy curves with the MNIST dataset (vision) and the SCAN dataset (language). With both aspects, theoretical steps are vague and weak, and the experimental results are little persuasive and convincing.\nSome steps in theoretical derivation seem to be wrong.\nI recommend ‘trivial and wrong’ for this paper.\n\nPros:\nThey deal with the relationship among compositionality, compositional generalization and gradient descent. It is interesting and novel question as far as I know.\n\nConcerns:\n-\tIt is not clear the assumptions on models is covered in the main claim. Some arguments have readers guess the claim only on neural networks. Currently, it is not explicit. What if a model is naïve Bayes classifier which assumes conditional independence? Does it have compositional generalization? If the classifier is trained with gradient descent, the key argument of the paper has counterexamples, which becomes wrong.\n-\tTheorem 1 should show more clearly Markov chain structure among X, Y and Z. X -> Y -> Z (as written in Cover 1999 p.34)\n-\tWhat is the relationship between Y and X in Proposition 1? \n-\tThe proof in Proposition 2 seems not valid. Is the Markov chain among Y hat, X, and Y still valid? Without any constraints of X and Y, the equation in the middle of Proposition 2 seems not an identity (consider joint probability models with discrete values), and the derivation process is not trivial. The validity of this result is a factor that also affects subsequent verification.\n-\tThere is no quantitative analysis with measurable cases as mentioned above.\n\n\n[CVPR17] Johnson et al., CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning, CVPR 2017.\n\n[PNAS17] Duncan et al., Complexity and compositionality in fluid intelligence, PNAS 2018.\n\n[ICLR19] Jacob Andreas, Measuring compositionality in representation learning, ICLR 2019.\n\n[ICLR20] Keysers et al., Measuring compositional generalization: a comprehensive method on realistic data, ICLR 2020.\n\n[JAIR20] Hupkes et al., Compositionality decomposed: how do neural networks generalise?], JAIR 2020.","sentences":[{"sentence_type":"2","sentence":"Theoretical steps are vague and weak, and the experimental results are little persuasive and convincing.","rephrased":"The theoretical steps could be articulated more clearly, and the experimental results would benefit from additional evidence to enhance their persuasiveness."},{"sentence_type":"2","sentence":"Some steps in theoretical derivation seem to be wrong.","rephrased":"There appear to be some inaccuracies in the theoretical derivation that need to be addressed."},{"sentence_type":"3","sentence":"I recommend \ntrivial and wrong\n for this paper.","rephrased":"I would suggest that the paper requires significant revisions to strengthen its arguments and address the concerns raised."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[1824,1878,"Not concerning"]],"Comments":[]}
{"id":"O4i2dKYWGf","text":"In this paper's introduction, the challenge of obtaining reliable COVID-19 data is explained due to the need for target data and costly tests. To address this issue, the authors suggest utilizing an indirect survey method that involves a fixed number of participants. They also propose the NSUM method to estimate various epidemic indicators. However, I have noticed that the NSUM method for constructing a contact network in COVID-19 cases has been utilized before but is not mentioned in the related works.\n\nThe methodology used in the paper is reliable. The survey gathered data from 15 contacts of 1000 participants concerning various COVID-19 indicators. However, the paper did not specify how the participants were selected or if their contacts were mutually exclusive. For instance, if the participants were hospital staff, their contacts would differ from those who work remotely. The paper clearly explained the data preprocessing, utilizing inconsistency filters and univariate outlier detection to eliminate anomalies while accounting for skewed data. Nevertheless, the NSUM method was not extensively discussed.\n\nIn the methodology section, the researchers assessed their findings in the UK and Australia by contrasting them with the official results on the OWID platform. Although the mortality rate differed significantly, Cronbach’s alpha score was high, indicating strong internal consistency. Notably, the vaccination rate result closely matched the actual value. In my opinion, the sample size should have been larger as the filters have significantly decreased the number of sample surveys available.\n\nThe paper is well-organized, with each section thoroughly explained. However, I noticed that the methodology of NSUM is missing, which plays a vital role in constructing the network graph and producing the results. I also came across some related works that utilize NSUM from survey data in COVID-19 cases, which were not included in the relevant work section. Although the problem they were addressing is undoubtedly significant, I remain somewhat skeptical about the novelty of this work.\n\nThis paper does not heavily rely on mathematical formulas or algorithms, making it less technical in nature. However, the equations presented in the paper seem to be accurate to my understanding.\n\nTo summarize, the paper is well-written and presents a clear problem definition. However, the methodology could use further development, and there is a lack of reference to recent work on the same problem.","sentences":[{"sentence_type":"2","sentence":"Although the problem they were addressing is undoubtedly significant, I remain somewhat skeptical about the novelty of this work.","rephrased":"While the problem addressed is significant, it would be beneficial to see how this work builds upon and differentiates from existing research to better understand its novelty."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1982,2111,"Maybe"]],"Comments":[]}
{"id":"DopuMlxYb5g","text":"The paper introduced a training mechanism that includes auxiliary forward flow and supervision from the very training of the very large model into the training of the tiny nets, this training mechanism improves the classification and object detection performance of tiny nets on several large datasets. The paper does not provide evidence that if a small sub-network of the larger network which is equivalent to the tiny network in network sizes will provide the same results as shown in the paper, in other words, does the auxiliary training necessary?","sentences":[{"sentence_type":"2","sentence":"The paper does not provide evidence that if a small sub-network of the larger network which is equivalent to the tiny network in network sizes will provide the same results as shown in the paper, in other words, does the auxiliary training necessary?","rephrased":"The paper could be strengthened by providing evidence or a comparison to show whether a small sub-network of the larger network, equivalent in size to the tiny network, would yield similar results. It would be helpful to clarify the necessity of the auxiliary training in this context."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[303,553,"Not concerning"]],"Comments":[]}
{"id":"H1ge8bKu2m","text":"In this paper, the authors investigate the collapse of deep and shallow network to a constant function under the following setting:\n1. Very shallow networks, width ~ 10\n2. ReLU activation function.  \n3. Symmetric weights and biases initialization.  \n4. Vanilla feed forward networks.  \n\nThe main take-home message is: don't use neural networks (NNs) that are both deep and shallow.  \n\nThe theoretical analysis is built on the observation: \n1. Every neuron (after applying ReLU) is equal to zero with probability 1\/2. \n2. For narrow network and for any fixed input, there is a high chance that all neurons in a particular hidden layer are all zero. All neurons after that layer are all zero if zero-bias initialization is used.  \n3. The authors conclude that derivatives of all parameters vanish but the bias of the last layer.\n4. As a result, the network collapse to its mean (median) if mean squared loss (L1 loss) is used because only the bias of the last layer is being updated during training. \n\nPros.\n1. I think the phenomenon that shallow and deep NNs collapse to a constant is very interesting. \n2. The authors provide empirical and theoretical insights in favor of wider networks: have a better chance to avoid vanishing gradients.  \n3. For shallow networks, it might be better not to use ReLU.  \n\nCons:\n1.The analysis works in a very limited setting, works for ReLU but not other activations: tanh, erf, SELU etc. \n2. Very shallow networks are not popular in practice. Width>=100 is popular for fully-connected layers. \n3. The phenomenon observed by the paper can easily be addressed using any of the following trick: \n   3.1. Non-symmetric initialization  (set the mean to be non-zero). \n   3.2 . wider networks. \n4. Most of the analysis (and theorems)  are about one single input. In another word, distribution of the inputs have not been taken into account.  \n5. I don't think the author provides a completely rigorous justification for the collapse phenomenon.  \n\nOther comments. \n1. Eq (2) in page 4 is not trivially correct. The expectation operator (w.r.p. to lower layers) is moved into the activation function phi, justification is needed for this step.  \n2. Theorem 4: when the Lebesgue measure of $\\Omega$ is NOT finite, it is unclear how to define a uniform probability distribution on it.  \n3. Theorem 4: the integrability assumption on y should depend on the loss: for L2 loss (L1 loss), squared (absolutely) integrable  should be used. They are not the same.  ","sentences":[{"sentence_type":"2","sentence":"The main take-home message is: don't use neural networks (NNs) that are both deep and shallow.","rephrased":"The main take-home message is that neural networks (NNs) with both deep and shallow characteristics may not perform optimally under certain conditions."},{"sentence_type":"2","sentence":"I don't think the author provides a completely rigorous justification for the collapse phenomenon.","rephrased":"It would be beneficial if the author could provide a more rigorous justification for the collapse phenomenon."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[287,381,"Confirmed"],[1875,1973,"Maybe"]],"Comments":[]}
{"id":"milTQ2cdsOz","text":"Contextual MNL is a recent hotly studied topic. \n\nMy biggest concern is the lack of comparison with an existing work. I want to bring one paper into attention: A Tractable Online Learning Algorithm for the Multinomial Logit Contextual Bandit. The main difference between two papers is whether different choices share the same parameters. However, the analyses are very similar in two settings and the analysis is similar to the generalized linear bandits. Moreover, regarding the regret bound, the improvement is also similar: it improves the constant term from \\kappa to \\sqrt{\\kappa} and it meanwhile pushes the constant term into a second order term. Can you clarify \n\n1) The technical difficulty\/contribution of this paper (e.g. how it differs from the existing work);\n\n2) What's the connection between two constants (kappa in your paper and kappa in their paper)?\n\n3) What is the regret lower bound? Is the regret optimal with respect to the order of K? I saw the short comments in line 275-285, but can you provide a rigorous argument for that conclusion?\n\nThe writting is good, but the contribution needs to be clearly emphasized.\n\nMinor: 1) The notation \\bar{\\theta}_* can be simplified to \\theta_*;\n\n2) Please define \\otimes before formula (8);\n\n\n","sentences":[{"sentence_type":"1","sentence":"The writting is good, but the contribution needs to be clearly emphasized.","rephrased":"The writing is of high quality. To enhance the paper further, I suggest more clearly emphasizing the unique contributions of your work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1063,1137,"Not concerning"]],"Comments":[]}
{"id":"SKUxjlVuCWc","text":"This paper works on building an automated evaluation toolkit for unsupervised\/weekly supervised visual concept discovery. Specifically, the  proposed method (SOLaCE) evaluates visual concepts discovered by image classification models trained on higher-level classification tasks. For example, the model is trained on classifying scenes and the model automatically discovers different object types.\n\nThe proposed approach is well-motivated, as stated in the introduction section, \"meaningful visual concepts have concise descriptions in natural language.\" Thus, the paper proposes to leverage pre-trained visual-language models (CLIP) to score proposed concepts. The paper has also presented a human study on how their automatic evaluation agrees with human judgement. Overall the model is well-presented, relevant to the theme of the workshop, and can be a good contribution to the workshop.\n\nBelow I listed a few weaknesses of the paper.\n\n1. The authors have primarily motivated the work by discussing generally \"language descriptions,\" however, as shown in Table 1 (also stated by the author in their results analysis paragraphs), the JVL model (CLIP-based) actually performs worse than the simple object-detection based model.\n2. The concepts used for training the Visual Genome model may not align well with the AVA dataset the authors used. Also, most of the visualizations of the results are presented on scene365. The authors are encouraged to analyze more results on the AVA dataset.\n3. The authors have stated that the \"CLIP model is more general,\" however there is no experimental support for that (e.g., application to domains with more concepts).\n4. The paper has referred to cognitive science arguments (human XXXXXX) in various places. It could be better if the authors can cite relevant papers and draw explicit connections between their arguments and results documented in cog-sci studies.\n","sentences":[{"sentence_type":"2","sentence":"The authors have primarily motivated the work by discussing generally \"language descriptions,\" however, as shown in Table 1 (also stated by the author in their results analysis paragraphs), the JVL model (CLIP-based) actually performs worse than the simple object-detection based model.","rephrased":"While the authors have emphasized the use of \"language descriptions\" to motivate their work, Table 1 indicates that the JVL model (CLIP-based) may not outperform the simpler object-detection based model. It would be beneficial if the authors could further explore and discuss these results."},{"sentence_type":"2","sentence":"The authors have stated that the \"CLIP model is more general,\" however there is no experimental support for that (e.g., application to domains with more concepts).","rephrased":"The authors claim that the \"CLIP model is more general\"; to strengthen this assertion, it would be helpful to include experimental evidence, such as its application to domains with a broader range of concepts."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[943,1229,"Not concerning"],[1495,1658,"Not concerning"]],"Comments":[]}
{"id":"L10dcWpSgth","text":"The paper is focused on how model-based RL algorithms benefit adversarial imitation learning. Experiments show that the result is promising compared to the baseline. In this review, we list the strengths and weaknesses of the work.\n\nThe topic fits the guideline of Reincarcinating RL. The background and the related work parts are detailed and help illustrate the innovative insight of the work. The method part is well illustrated with detailed proof and formula. The experiment comparing the method with the baseline VMAIL looks promising, but there can be more baseline experiments and maybe extend to other environments.\n\nIn summary, the paper works well in the Franka kitchen domain compared with one baseline method and illustrates the efficiency of offline learning algorithms on adversarial imitation learning.","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"SJgQWfJvKV","text":"This paper introduces a structure learning framework for functional dependency (FD) discovery. The authors model the distribution of FDs over pairs of records by capturing dependencies of attribute-values in a graph structure.\n\nThe authors compare their approach to manually-specified dependencies and automated state-of-the-art methods from the database and data mining community.\n\nI’ve included a list of strong points and points of confusion\/questions below:\n+ Figure 1 showing autoregression matrix shows incrementally verifies hypotheses in structure learning approach.\n+ Empirical results support strong improvements over baselines.\n- The authors describe the key result: “to model the distribution that FDs impose over pairs of records instead of the joint distribution over the attribute-values of the input dataset”. Could you further explore the theoretical\/empirical improvement here? This would strengthen the motivation of the approach.\n- What were the trade-offs considered in database\/data mining communities-- what are the conceptual limitations from these communities that the authors were able to overcome?\n- Additional datasets -- how does the method perform on other datasets with different error\/data repairing characteristics (i.e. mentioned in the HoloClean paper, or others)?\n\nThe paper is well-written, and could be strengthened additional exploration to strengthen choice and comparison to baselines.The paper w ould be a reasonable fit for the workshop, under the challenges introduced via: “Representations to enforce structured prior knowledge (e.g. invariances, logic constraints).”","sentences":[{"sentence_type":"1","sentence":"The paper is well-written, and could be strengthened additional exploration to strengthen choice and comparison to baselines.","rephrased":"The paper is well-written. Further exploration and additional comparisons to baselines could enhance the strength of the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1301,1426,"Not concerning"]],"Comments":[]}
{"id":"B1etdm5itr","text":"Summary:  This paper studies alternative priors for VAEs, comparing Normal distributions (diagonal and full covariance) against Student-t’s (diagonal and full covariance).   In particular, the paper is concerned with posterior collapse---i.e. posterior remains at the prior, limiting the model’s ability to reconstruct the data.  Experiments are performed on a synthetic 2D dataset, ‘Gaussian ovals,’ and on OMNIGLOT.  Results primarily take the form of visualizations of the reconstructed data and MSE \/ SSIM numbers. \n\nPros:  Systematic study and investigation of alternative priors for deep generative models is an under-studied area.  Moreover, heavy-tailed priors such as the student-t---while widely successful for robust regression---have not been explored as extensively for latent variable models, to the best of my knowledge.  This paper makes some steps towards solving these open problems.  \n\nCons:  I have two primary critiques of the paper: (i) the experimental hypothesis is unclear, (ii) no engagement with the results of Mathieu et al. [ICML 2019], who also study Student-t priors for reconstruction (and disentanglement).  \n\nRegarding (i), the paper seems to be testing two hypotheses simultaneously: the effect of diagonal vs full covariance matrices and exponential-tailed vs heavy-tailed priors.  The latter seems more crucial for purposes of reconstruction according to Figure 3 (since the diagonal St-t has good reconstruction).  Yet a proper study of the effect of tails vs reconstruction would report results as the degree of freedom parameter is gradually increased (as this controls the tails directly).  No careful ablation study of this sort is performed.  For comparison, see Figure 2 of Mathieu et al. [ICML 2019].  Moreover, the text simply calls the student-t a “weakly informative prior,” but it needs to be much more specific about what characteristics of the student-t are crucial.  If all we require is something “weakly informative,” why aren’t alternatives like a diffuse Gaussian or uniform also considered?\n\nRegarding (ii), Mathieu et al. [ICML 2019] also study priors formed by products of student-t marginals, but their work is not cited.  Mathieu et al. [ICML 2019] also show that, due to student-t’s not being rotationally invariant (unlike the diagonal Gaussian), they improve disentanglement with only a minor degradation of reconstruction.  As this work also studies reconstruction in student-t VAEs, it should include some discussion of Mathieu et al. [ICML 2019]’s results---if not direct engagement with their hypotheses.       \n\nFinal Evaluation:  While I like the general motivation for this work, there are no clear experimental hypotheses being tested in the experiments.  \n\nMathieu, E., Rainforth, T., Narayanaswamy, S. and Teh, Y.W., 2018. Disentangling Disentanglement in Variational Autoencoders. ICML 2019.","sentences":[{"sentence_type":"2","sentence":"While I like the general motivation for this work, there are no clear experimental hypotheses being tested in the experiments.","rephrased":"Although the motivation behind this work is commendable, it would be beneficial to articulate the experimental hypotheses more clearly in the experiments."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1632,1683,"Maybe"],[2600,2726,"Maybe"]],"Comments":[]}
{"id":"BkxgKFy5hQ","text":"This paper applied an object detection network, like SSD, for optical character detection and recognition. This paper doesn't give any new contributions and has no potential values.\n\nweakness:\n1. the paper is lack of novelty and the motivation is weak. I even can't find any contribution to OCR or object detection.\n\n2. the paper is written badly so that I can't follow easily. In addition, the figures and tables are not always explained in the main body, which makes the experimental results confusing.\n\n3. There are no titles in the figures and tables in this paper\n\n4. the authors don't confirm the superiority of the proposed method to others.\n\nminor comments\n1. what's the meaning of Target mAP in the table?\n2. It seems that Some figures are cropped from TensorBoard, with some extra shadows.","sentences":[{"sentence_type":"3","sentence":"This paper doesn't give any new contributions and has no potential values.","rephrased":"The paper could benefit from a clearer articulation of its contributions and potential impact in the field."},{"sentence_type":"2","sentence":"the paper is lack of novelty and the motivation is weak. I even can't find any contribution to OCR or object detection.","rephrased":"The paper would be strengthened by more explicitly stating its novel contributions to OCR and object detection, as well as by providing a stronger motivation for the research."},{"sentence_type":"2","sentence":"the paper is written badly so that I can't follow easily.","rephrased":"Improving the clarity of the writing would help readers follow the methodology and arguments more easily."},{"sentence_type":"1","sentence":"the authors don't confirm the superiority of the proposed method to others.","rephrased":"The authors could enhance the paper by providing a comparison that demonstrates the superiority of the proposed method over existing ones."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[107,180,"Confirmed"],[196,315,"Confirmed"],[320,377,"Confirmed"],[573,648,"Maybe"]],"Comments":[]}
{"id":"rkgBtXVhFr","text":"In this paper, the authors propose a reinforcement learning method for multi-robot scheduling problems. They state the method's scalable performance and transferability. My major concerns are as follows.\n\n1. The paper is not easy to read. In my understanding, multi-robot scheduling is a very important problem and is very similar to many scheduling problems in complex platforms such as the dispatch system for ride sharing and package delivery. However, I did see any real application in this paper. It is very difficult to understand how this proposed method works and what is the benefit under non trivial environment.\n\n2. The experiments (2~8 robots, 20~50 tasks) cannot support the scalable performance or large problems very well. How about thousands and millions of robots\/tasks, e.g. routing planning or dispatching for vehicles in a ride sharing platform?  \n\n3. It is not convincing without comparison with necessary baseline methods.\n\n4. There is no in-depth analyses for the transferability.\n\n5. There are many typos, such as the missing figure citation with Figure ??.   \n","sentences":[{"sentence_type":"2","sentence":"However, I did see any real application in this paper.","rephrased":"However, I did not see any clear real-world applications detailed in this paper."},{"sentence_type":"2","sentence":"It is very difficult to understand how this proposed method works and what is the benefit under non trivial environment.","rephrased":"It would be helpful to clarify how this proposed method works and to elaborate on its benefits in a non-trivial environment."},{"sentence_type":"1","sentence":"It is not convincing without comparison with necessary baseline methods.","rephrased":"Including a comparison with necessary baseline methods would strengthen the paper's convincingness."},{"sentence_type":"1","sentence":"There are many typos, such as the missing figure citation with Figure ??.","rephrased":"Addressing the typos, such as the missing figure citation with Figure ??, would improve the paper's readability."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[447,501,"Confirmed"],[502,622,"Not concerning"],[872,944,"Not concerning"],[1008,1081,"Not concerning"]],"Comments":[]}
{"id":"gLpL2k8NQ0r","text":"It is nice to have an illustrative example to clarify ideas at the beginning of the paper, but is the example presented in introduction useful for the purpose? Model uncertainty refers to the uncertainty associated to not knowing the transition probabilities. And the transition uncertainty refers to the inherent stochasticity. It is not clear how the situations presented in the example correspond to those uncertainties. It rather makes things more confusing.\n\nIn line 121, V is defined as \\min_\\pi CVAR(G), where G is defined in terms of reward, not cost. Should this be maximised instead, as shown in equation (4)?\n\nWhat is the definition of a node? Do you aggregate\/discretize to define a state and\/or node? What is the impact of such process?\n\nRA-BAMCP is an online algorithm which involves computing posteriors at each node of the tree in realtime. Using Beta\/Dirichlet distribution, as done in the paper, provides a closed form approach to compute posteriors. But what happens when a closed form approach is not avaialable for a distribution? Does it scale? How about some empirical analysis?\n\nOne main claim in the paper is to apply CVaR over both the model and transition uncertainties. What difference this makes compared to general robust and\/or risk averse methods studied in the literature? This is an important question to address, both theoretically and empirically. The paper misses this point. The empirical evaluation may show the difference more clearly by addressing only model uncertainty, only transition uncertainty and then addressing both types of uncertainties. Also, it can be interesting to compare against general robust, soft-robust and risk-averse methods available in the literature.\n\nAs the paper uses many different concepts like SG, MCTS, OFU\/UCRL, GP and so on, the paper feels highly convoluted to read. In my opinion, the paper is not well written. A reorganization of the contents focusing readability and clarity may help.","sentences":[{"sentence_type":"2","sentence":"It rather makes things more confusing.","rephrased":"It would be helpful if the example could be clarified further to better illustrate the concepts of model and transition uncertainties."},{"sentence_type":"3","sentence":"In my opinion, the paper is not well written.","rephrased":"The paper could benefit from a reorganization to enhance readability and clarity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[424,461,"Not concerning"],[1843,1888,"Maybe"]],"Comments":[]}
{"id":"RtA_NlDGoLB","text":"This paper solve the class-imbalanced problem from two aspects:\n1. pairwise adversarial training and generate the samples on the interpolated line from a source sample to a target sample of the same class. And samples from the minority class will have larger chance.\n2. Align the conditional feature distributions of source and target domains by explicitly matching the centroids of two domains.\n\nHowever, my major concerns are as follows:\n1. During the data generating process, the pseudo-labels of the target data are still not accurate. Won't there still exist error accumulation?\n2. The improvements of the experimental results are not obvious.","sentences":[{"sentence_type":"2","sentence":"The improvements of the experimental results are not obvious.","rephrased":"It would be helpful to clarify how the experimental results demonstrate significant improvements over existing methods."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[587,648,"Maybe"]],"Comments":[]}
{"id":"HgZg_wgnAb9","text":"This paper proposes a method to automatically score the quality of “visual concepts” extracted by unsupervised methods (usually in the form of a set of images and associated activation maps).\n\nThis is done by combining a network which produces labels for activated image regions, as well as a scoring function. The paper assesses a few ways to produce labels (Faster R-CNN to generate object bounding boxes; CLIP to directly compute language-visual consistency scores), as well as a few scoring functions, and they show that these correlate well with human judgments.\n\nAlthough this targets a very specific problem, I found the paper easy to follow and making clear decisions throughout, so it might be of interest to the workshop’s attendees.\n\nQuestions and comments:\n1. Did you directly use the single word labels for CLIP as it appears in Figure 2? Did you explore more advanced prompt hacking? I would have expected this to have quite a strong effect, considering what the community has been exploring recently (see also DALL-E re-ranking and co)\n2. Wouldn’t the BAM require the gammas to be calibrated\/normalized over the whole “data” in order for the max to be well-behaved?\n3. Instead of Table 1 with Pearson’s correlation scores, I would have preferred to see the raw scatter plots and judge for myself how correlated the scores and human ratings would have been (I do not trust the linearity assumption and these are too easily overconfident).\n   1. Could you add these to the Appendix perhaps?\n4. The fact that the CLIP results depend on yet another way to extract activation maps is slightly unfortunate, especially as the authors mention that the Grad-CAM activation quality might be causing issues.\n   1. Are there particular avenues to fix that issues or alternative scores which would bypass this issue?","sentences":[{"sentence_type":"2","sentence":"I do not trust the linearity assumption and these are too easily overconfident.","rephrased":"I am cautious about the linearity assumption, and it would be beneficial to provide additional evidence to support the robustness of these findings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"S1lolYlnt4","text":"The paper proposes a method that learns a regression model with a few samples.\n\nPros:\n- It is an interesting application.\n- Original work and clearly explained. Mathematically sound.\n- It outperforms other methods.\n\nCons:\n- Just a few examples in the results section. Part of the results were attached as appendices. Looking at the results, my question would be how the different models compared in Tables 1 and 2 perform in the different regression data sets. Only one model is compared for each regression data set.\n","sentences":[{"sentence_type":"1","sentence":"Just a few examples in the results section.","rephrased":"The results section could be enhanced by including more examples."},{"sentence_type":"1","sentence":"Part of the results were attached as appendices.","rephrased":"Incorporating more results within the main text rather than in the appendices could improve the paper's readability."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[224,267,"Not concerning"],[268,316,"Not concerning"]],"Comments":[]}
{"id":"SJlR4YwSFE","text":"The authors derive a REINFORCE estimator based on sampling without replacement (building on the recent work of Kool et al.) and show improvements over existing techniques on structured prediction.\n\nThe paper is well-written and the experiments are informative. The paper could be improved by theoretically quantifying the improvement gain from sampling w\/ replacement. This would help to understand why the benefits of sampling without replacement diminish with larger instances and larger k.","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"HfzjntfCR60","text":"Strengths:\nThe paper seems to introduce a new dataset that could be very useful to the community.  \n\nWeaknesses:\nThe paper is generally poorly written.  Even the main claims are hard to decipher, right from the abstract.  But the entire introduction provides no clear\/coherent overview\/findings or motivation.  The remainder of the paper continues the same way.  This is a pity, since it seems like the authors have some interesting results to present.  They are too unclear for me to be secure in restating them.\nA new dataset is introduced  (winogradversarial), over which the main evidence of the claims of the paper are obtained, without any description of its contents beyond a couple examples and an extremely obscure description of the purpose of its examples.","sentences":[{"sentence_type":"2","sentence":"The paper is generally poorly written.","rephrased":"The paper could benefit from clearer writing to enhance the presentation of the main claims."},{"sentence_type":"2","sentence":"Even the main claims are hard to decipher, right from the abstract.","rephrased":"The main claims could be articulated more clearly, starting from the abstract."},{"sentence_type":"2","sentence":"But the entire introduction provides no clear\/coherent overview\/findings or motivation.","rephrased":"The introduction would benefit from a more coherent overview and clearer presentation of the findings and motivation."},{"sentence_type":"2","sentence":"The remainder of the paper continues the same way.","rephrased":"Improving the clarity and coherence in the subsequent sections would be beneficial as well."},{"sentence_type":"2","sentence":"They are too unclear for me to be secure in restating them.","rephrased":"Clarifying these results would give the reader more confidence in understanding and restating them."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[113,151,"Maybe"],[153,220,"Not concerning"],[222,309,"Confirmed"],[311,361,"Maybe"],[363,378,"Confirmed"],[454,513,"Not concerning"]],"Comments":[]}
{"id":"rkB5-TcgG","text":"This paper proposes a new character encoding scheme for use with character-convolutional language models. This is a poor quality paper, is unclear in the results (what metric is even reported in Table 6), and has little significance (though this may highlight the opportunity to revisit the encoding scheme for characters).","sentences":[{"sentence_type":"2","sentence":"This is a poor quality paper, is unclear in the results (what metric is even reported in Table 6), and has little significance (though this may highlight the opportunity to revisit the encoding scheme for characters).","rephrased":"The paper could benefit from clearer results, particularly in Table 6 where the reported metric is not specified, and a more compelling argument for its significance, which could also underscore the potential to revisit the encoding scheme for characters."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[106,323,"Confirmed"]],"Comments":[]}
{"id":"BygheOf79r","text":"In this paper, the authors proposed two methods of Nesterov Iterative Fast Gradient Sign Method (NI-FGSM) and Scale-Invariant attack Method (SIM) to improve the transferability of adversarial examples. Empirical results on ImageNet dataset demonstrate its effectiveness. In general, the paper is clearly written and easy to follow but I still have several concerns:\n1.\tAlthough the method is easy to understand, the authors are expected to clarify why the methods can improve the transferability. The authors are expected to make more theoretical analysis.\n2.\tThe authors are expected to make more comprehensive comparisons with the recent methods in adversarial attacks, e.g, PGD, and C&W even if some methods are designed for white-box attack. \n3.\tThe authors are expected to make more evaluations on the models with defense mechanism, and numerous important methods are missing. Without this, the authors cannot claim its effectiveness since only experiments on NIPS2017 is not enough.    \n","sentences":[{"sentence_type":"2","sentence":"Without this, the authors cannot claim its effectiveness since only experiments on NIPS2017 is not enough.","rephrased":"To strengthen the claim of effectiveness, it would be beneficial for the authors to include more evaluations, particularly on models with defense mechanisms, as relying solely on experiments from NIPS2017 may not provide a comprehensive validation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[882,988,"Not concerning"]],"Comments":[]}
{"id":"rkgGwTlF27","text":"The primary contribution of this work is a dataset for action following through dialogue.  The authors collect a comparatively small dataset in terms of language but one which contains real images and dialogue. \n\nThere are a number of aspects of the proposed approach which I found hard to follow\/justify.  First off, I was unclear on the details of the collected data (e.g. average action sequence length, dialogue length, lexical types\/tokens, etc).  There's a claim of 62 acts which sums both dialogue and actions with averages of 8 and 9 dialogue acts for tourist\/guide implying 45 move actions?  on a 4x4 grid?  Is it safe therefore to assume that the example dialogue is therefore atypical? It's very hard to figure out based on the number of steps across the different tables what the model should be aiming for.  Also, in 2.3 does the claim that they \"successfully complete the task\" mean in the 76.74% of cases where they succeed or did they succeed in 100% of cases and then a new human eval was run afterwards which performed worse?\n\nThe primary modeling result appears to be the success of emergent language and the bold claim that humans are bad at localizing.  This doesn't feel intuitively true from the example dialogue, but the NLG system samples to appear to be quite bad which makes me worried that it's not so much that humans are bad localizers but that the model's NLU\/NLG system is quite weak and maybe there's a problem with the data-collection procedure.  Additional justification and analysis would be appreciated.\n\nAs I understand the paper right now:\n1. Humans talking to one another do very well on the task and achieve success very quickly. \n2. Emergent language can do better at the task though their approach is very sub-optimal (requiring 2-3x the number of steps).\n3. The currently proposed NLU\/NLG mechanisms are very weak and cannot produce or correctly interpret actual language.\n\nThere are many moving pieces in this paper (e.g. extracting text from images vs detections), there doesn't seem to be any pretraining of the decoder, etc which makes it very hard for me to understand what's going wrong.  The results in this paper, don't convince me that emergent language is better than natural language or that agents are better communicators than humans, but that the data-collection methodology was faulty leading to lots of failures. \n\nI haven't touched on the MASC aspect and how this compares to existing work on interpretable spatial relations and questions as to why various architectural choices were made though the paper would obviously benefit from that discussion as well.\n\nI found this paper very confusing to read.  It relies heavily on 11 pages of appendices (where it puts all of the related work) and still fails to clearly explain its contributions or justify its claims.  \n\nMinor: URLs intermittently anonymized page 12 vs 19","sentences":[{"sentence_type":"2","sentence":"This doesn't feel intuitively true from the example dialogue, but the NLG system samples to appear to be quite bad which makes me worried that it's not so much that humans are bad localizers but that the model's NLU\/NLG system is quite weak and maybe there's a problem with the data-collection procedure.","rephrased":"While the example dialogue suggests that humans are capable localizers, the NLG system's performance raises concerns. It would be helpful to see further analysis to determine if the observed issues stem from the NLU\/NLG system's capabilities or from the data-collection procedure."},{"sentence_type":"2","sentence":"The results in this paper, don't convince me that emergent language is better than natural language or that agents are better communicators than humans, but that the data-collection methodology was faulty leading to lots of failures.","rephrased":"The paper could provide more evidence to support the superiority of emergent language over natural language and the communicative abilities of agents versus humans. Clarifying the data-collection methodology could help address the observed failures and strengthen the argument."},{"sentence_type":"1","sentence":"I found this paper very confusing to read.","rephrased":"The paper could benefit from a clearer presentation of its contributions and a more structured organization to enhance readability."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1175,1479,"Confirmed"],[2139,2372,"Not concerning"],[2622,2664,"Not concerning"]],"Comments":[]}
{"id":"5dVUIF7UUsi","text":"##########################################################################\n\nSummary:\nThis paper offers an interesting approach to scaling bootstrapping which is applicable to many machine learning problems. While it is not a perfect method, I think a paper providing a thorough evaluation of this approach and the previous ones is worthy of publication, if done properly.\n \n\n##########################################################################\n\nReasons for score: \nFor the most part, the paper is written clearly but some of the crucial comparisons against previous approaches (see below) are missing. I am slightly leaning toward reject since the paper probably needs more work. While the algorithm is novel, it is unclear how much benefit it would offer above previous approaches. I am open to adjusting this score in the rebuttal stage, pending the authors' responses.\n\n\n##########################################################################\n\nPros: \n\n \n1. The paper addresses an interesting computational problem applicable to many models in machine learning. The algorithm is simple to implement and to understand.\n\n2. Experiments cover interesting machine learning use cases, e.g. contextual bandit, reinforcement learning, confidence interval estimation.\n \n\n##########################################################################\n\nCons: \n\n \n1. It is unclear how much benefit the new methodology offers over the previous ones, e.g. in terms of model accuracy improvement.\nIt is presumed that the iterative nature of the algorithm incurs many model updates and model loss evaluations in the inner loop.\n\n2. Comparison against previous approaches except for vanilla bootstrap are largely missing. It would be beneficial to comment on how this method compares against m-out-of-n bootstrap and bag-of-little bootstraps. The authors mention that both of these methods are inherently slower (page 9, Section 6). However, these methods are highly parallelizable algorithms and they are worthy of discussion (unlike the iterative algorithm proposed in this paper).\n\n3. As stated in the appendix, the motivation of the paper is not to decrease the training cost but reduce the memory cost and the computational cost for inference. How much compression can be achieved in terms of memory? It seems the study on establishing the relationship between optimal m and n is for future work but it is a bit unclear from the experiments at least empirically.\n \n4. How big is the dataset (n) in the experiments? Any comment on how the proposed method performs for ensemble tree methods, as the experiments discuss primarily neural networks? Please also comment on the dimensionality of theta in each experiment setting.\n\n5. On a related above: how would the initialization of theta work for a tree based method?\n\n##########################################################################\n\nQuestions during rebuttal period: \n\n \nPlease provide clarifications for the points in the previous section.\n\n \n\n#########################################################################\n\nSome typos: \n\n- page 19: bootstrap partical -> bootstrap particle\n","sentences":[{"sentence_type":"2","sentence":"I am slightly leaning toward reject since the paper probably needs more work.","rephrased":"I believe the paper could benefit from further development, particularly in the areas highlighted."},{"sentence_type":"2","sentence":"It would be beneficial to comment on how this method compares against m-out-of-n bootstrap and bag-of-little bootstraps. The authors mention that both of these methods are inherently slower (page 9, Section 6). However, these methods are highly parallelizable algorithms and they are worthy of discussion (unlike the iterative algorithm proposed in this paper).","rephrased":"A comparison with m-out-of-n bootstrap and bag-of-little bootstraps would be valuable, especially considering their parallelizability, which the authors could discuss in relation to their proposed iterative algorithm."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[608,685,"Not concerning"],[1713,2074,"Not concerning"]],"Comments":[]}
{"id":"rxewWlBcWc","text":"This paper suggests that by changing cosine-similarity SimCLR-like contrastive learning losses with L1-losses, a decomposition of the learned latent spaces along different data augmentations can be achieved. First, the paper provides some theoretical guarantees for such block-identifiability under some rather special assumptions. Second, the effect of using L1-contrastive losses is being empirically investigated under a simple linear toy experiment as well as an experiment involving the stylized MNIST dataset. \n\nPros:\n- The paper is well written and easy to follow.\n- The presented experiments, analysis and evaluations are reasonable and solid, supporting the main claim of the paper.\n- Discussion of theoretical background and related recent works.\n- Interesting empirical results on the MNIST experiment, especially the clear decompositions of the learned latent spaces.\n\nWeaknesses\/Suggestions\n- Regarding the MNIST experiments, I would have appreciated to see some further justification in choosing a latent feature map and the generalized group-lasso objective. Why did you decide for that and not for a standard 128-dimensional latent space (which seems sufficient for MNIST) and a standard L1 loss as in the original SimCLR implementation?\n- While I agree that it is interesting to see the improved downstream prediction of the augmentation features, the SimCLR model is only slightly worse while being better at the digit prediction. I would be curious to see how this changes when using a 2-layer or 3-layer MLP as prediction model that might be better at inferring this information from the SimCLR representation.\n- I think it would be great to see some experiments, which show some practical benefits of the obtained representations with such decomposed structure,  i.e. the representations’ robustness and OoD generalization abilities compared to the performance of the SimCLR model.\n\n\nMinor:\nThe table seems to have two captions: “Table 1” and “Table 2”","sentences":[{"sentence_type":"1","sentence":"Why did you decide for that and not for a standard 128-dimensional latent space (which seems sufficient for MNIST) and a standard L1 loss as in the original SimCLR implementation?","rephrased":"Could you provide the rationale behind choosing a specific latent feature map and the generalized group-lasso objective over a standard 128-dimensional latent space and a standard L1 loss, as used in the original SimCLR implementation?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1074,1253,"Not concerning"]],"Comments":[]}
{"id":"SJxFuRgyiV","text":"The paper essentially is an EPSRC project proposal, somewhat reshaped (so far as I can tell) into a workshop submission.\n\nThis strikes me as unusual (this is the first time I see a project proposal turned into a paper), and there are no concrete results to discuss. However the ideas and approach could be useful & interesting for discussion at the workshop so I'm fine with that. \n\nProposal summary in my words: address instruction-giving problems involving the interpretation of, and dynamic reacton to, human signals such as facial expressions. Conduct cognitive sciene experiments to determine the relevant human aspects and metrics; use epistemic planning to generate instructions taking other agents' knowledge into account.\n\nThis strikes me as an interesting instruction-giving project. What's not qiute so clear to me is, what is the link to XAI?\n\nOne can call an \"instruction\" an \"explanation\", and the paper\/proposal frequently does so. But does that mean that instruction giving is explainable AI? My understanding of XAI is that what we're trying to explain are the decisions taken by an AI system. In instruction giving (in general, and in this paper in particular), instead an AI system explains some third artifact X (external to the AI system) to a human. This seems to be a quite different problem. The strongest connection I can see is that both ultimately require communication with human users, incurring (potentially?) similar cognitive considerations on that side.\n\nIn short, the paper proposes to use planning techniques for generating explanations (i.e., instructions) of something outside the planner; as opposed to explaining the decisions of the planner itself. I hence find the link to XAIP, and hence the workshop, a bit tenuous.\n\nIt could be interesting to discuss these things at the workshop though, so I'm not adverse to including the paper. If included, I'd appreciate if the authors could discuss the above points, in the paper and their presentation.\n\nSmall point: In the motivating example in the introduction, it did not become clear to me what the role\/importance is of \"After reaching a place where they can see they are almost back to the starting point\" (one could take a break in a cafe at any point on a tour).\n","sentences":[{"sentence_type":"2","sentence":"The paper essentially is an EPSRC project proposal, somewhat reshaped (so far as I can tell) into a workshop submission.","rephrased":"The paper appears to be derived from an EPSRC project proposal and has been adapted for a workshop submission."},{"sentence_type":"2","sentence":"This strikes me as unusual (this is the first time I see a project proposal turned into a paper), and there are no concrete results to discuss.","rephrased":"It is uncommon to see a project proposal adapted into a paper format without concrete results, which presents a unique case for discussion."},{"sentence_type":"2","sentence":"In short, the paper proposes to use planning techniques for generating explanations (i.e., instructions) of something outside the planner; as opposed to explaining the decisions of the planner itself. I hence find the link to XAIP, and hence the workshop, a bit tenuous.","rephrased":"The paper proposes using planning techniques to generate explanations of external elements, which is a different approach from explaining the planner's own decisions. Clarifying the connection to XAIP and the workshop's theme would strengthen the paper's relevance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,120,"Not concerning"],[122,265,"Confirmed"],[1488,1758,"Not concerning"]],"Comments":[]}
{"id":"HkgvPwh-3E","text":"The paper is about learning action models by exploiting observations of states for executed plans and also using state axioms providing additional knowledge about the domain. The paper is clearly relevant to KEPS and there is novel though a bit incremental contribution. State axioms are known from planning for some time and the authors suggest using their specific version - mutexes (called schematic mutexes in the paper) - in action-model learning using compilation to planning. The preliminary experiments show that it brings some advantage over the “classical” approach, in particular when some intermediate states are observed. I think it is an interesting approach as it goes in the direction of exploiting more knowledge, that is frequently available, rather than using brute force with a large number of training data (which is not always available).\n\nSome specific comments:\n\nThe idea of using state axioms can be applied in other action-model learning approaches, correct? Specifically, it seems that ARMS is ready for this approach as the domain constraints can be directly encoded in the SAT formula. Maybe, it would be even easier to encode the constraints there than to do it in PDDL (see the next comment).\n\nThe authors show how to encode schematic mutexes for the compilation-based approach. It is not fully clear how complicated encoding other types of state axioms will be. Some discussion of generality of the proposed approach would be useful. \n\nAs I understand some of the mutex constraints are resolved in preprocessing while others are encoded in the compiled model. It is enough if everything is encoded in the compiled model so resolving some mutexes in pre-processing only speeds-up the process, correct? If yes, the empirical results can also demonstrate how much it helps.\n\nWhy actions are not assumed among observations? The compilation-based approach supports partially observed states and actions. Is there any specific reason to omit actions in this setting?\n\nThe section on background uses a bit non-standard model of planning, where the state is described as a complete set of valid literals (so predicates that are not true in the state are explicitly included in a negated version). Then, one must be careful in defining the transition function, specifically, the complement of effects. This is not a set complement but a logical complement, which is not fully clear from the text. Also, using conditional effects brings a danger if different conditional effects are contradictory. Then, based on the included definition, we may obtain an inconsistent state as it may contain some predicate in both positive and negative version (from two different effects with satisfied conditions).\n\nWhen introducing schematic mutexes to the compilation approach (Figure 4), it looks like they are used to generate a failure during planning. Would not be better to prevent such a failure rather than just wait for it? The whole compilation-based approach resembles the generate-and-test approach (generate the model and then verify it) so it would be interesting to look for something more efficient. Actually, runtimes are never reported in the paper so we do not know how practically efficient the approach is.\n\nThe system is using a SAT-based planner, which removes many obvious symmetries when generating the action model. The authors claim in the text that the planning horizon is bound to 2 (for programming any action model). It is a correct claim (though might be hard to grasp by the reader who is not aware of details of the compilation approach), but it may be also a bit misleading as we need additional layers to encode the observed plan (yes, this is not for programming the model but for evaluating it, but we need more layers). So I do not fully understand the discussion on bias to find shorter plans as the bias is still there (the systems tries to minimise the number of actions that explain given observations).\n\nThe authors use a good number of domains in experiments. For each domain, they define some set of schematic mutexes, but the reader does not know how they look. It is expected, that quality of this extra domain knowledge will influence efficiency so the empirical results are always biased by what extra knowledge is provided. As the extra knowledge has a compact form (set of mutexes), it might be useful to study how the results are influenced by enlarging this set. Right now the comparison is between zero and all knowledge.","sentences":[{"sentence_type":"1","sentence":"The paper is clearly relevant to KEPS and there is novel though a bit incremental contribution.","rephrased":"The paper is clearly relevant to KEPS and makes a novel contribution, albeit incremental, which is valuable in advancing the field."},{"sentence_type":"1","sentence":"Why actions are not assumed among observations? The compilation-based approach supports partially observed states and actions. Is there any specific reason to omit actions in this setting?","rephrased":"Could you please clarify why actions were not included among observations? Since the compilation-based approach supports partially observed states and actions, understanding the rationale for omitting actions in this setting would be helpful."},{"sentence_type":"1","sentence":"The section on background uses a bit non-standard model of planning, where the state is described as a complete set of valid literals (so predicates that are not true in the state are explicitly included in a negated version).","rephrased":"The section on background introduces a model of planning that diverges from the standard by describing the state as a complete set of valid literals, including explicitly negated predicates for those not true in the state. This is an interesting choice that could benefit from further explanation."},{"sentence_type":"1","sentence":"Would not be better to prevent such a failure rather than just wait for it?","rephrased":"It might be more advantageous to explore methods of preventing such failures in advance rather than waiting for them to occur."},{"sentence_type":"2","sentence":"Actually, runtimes are never reported in the paper so we do not know how practically efficient the approach is.","rephrased":"Including runtime data in the paper would provide valuable insights into the practical efficiency of the approach."},{"sentence_type":"1","sentence":"The authors claim in the text that the planning horizon is bound to 2 (for programming any action model). It is a correct claim (though might be hard to grasp by the reader who is not aware of details of the compilation approach), but it may be also a bit misleading as we need additional layers to encode the observed plan (yes, this is not for programming the model but for evaluating it, but we need more layers).","rephrased":"The authors' claim that the planning horizon is bound to 2 for programming any action model is technically correct, but it could be clarified for readers less familiar with the compilation approach. Additionally, it would be helpful to discuss the need for additional layers to encode the observed plan, which is not for programming the model but for evaluating it."},{"sentence_type":"1","sentence":"So I do not fully understand the discussion on bias to find shorter plans as the bias is still there (the systems tries to minimise the number of actions that explain given observations).","rephrased":"The discussion on the bias towards finding shorter plans could be expanded upon, as it seems that there is still an inherent bias in the system to minimize the number of actions that explain given observations."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[175,270,"Not concerning"],[1804,1992,"Not concerning"],[1994,2220,"Not concerning"],[2866,2941,"Not concerning"],[3125,3236,"Not concerning"],[3351,3767,"Not concerning"],[3768,3955,"Not concerning"]],"Comments":[]}
{"id":"Hkec2hOaYB","text":"This paper introduces a corpus-based approach to build sentiment lexicon for Amharic. In order to save time and costs for the resource-limited language, the lexicon is generated from an Amharic news corpus by the following steps: manually preparing polarized seed words lists (strongly positive and strongly negative), calculating the co-occurrence of target word in its context via Positive Point-wise Mutual Information (PPMI) method, measuring the similarity between target words and seed words by cosine distance, iterating with the threshold 100 and 200. The PPMI lexicon is stemmed and evaluated from aspects of subjectivity detection, coverage, agreement and sentiment classification. Three other lexicons: Manual developed by manual, SOCAL and SWN developed by bilingual dictionary, are used as benchmark to compare with the PPMI lexicon. In sentiment classification experiment the PPMI lexicon did not show a superior performance. All the four lexicons have similar accuracy, between 42.16% ~ 48.87%.  Only when the four are combined together the result is improved to 83.51%. \n\nWhile this paper presents an economical and practical method to generate a sentiment lexicon for resource-limited language it is not acceptable in it's current state to ICRL. The following points should be improved or clarified. \n(1) The generalizability to any language needs to be shown. What are the lessons learned for any resource-limited language?\n(2) The fit to ICLR is not perfect. I would expect a stronger focus on representation learning.\n(3)\tThe conclusion is not well proved. Especially about the claim that their method is “with almost minimal costs and time”. PPMI lexicon might cost less than Manual lexicon, but SWN and SOCAL (Neshir Alemneh et al., 2019) are automatically generated by English-Amharic dictionary, not manually. Their generation costs and time are not told and can not be compared here. \n(4)\tThe paper is incorrectly structured. The part “4 RESULTS AND DISCUSSION” presents neither results nor discussion. Part 4.1 shows seed words which should belongs to part 3. Part 4.2 shows stemming which should belong either to part 3 or to part 5. Therefore, it is better to make a restructure. \n(5)\tThe contents following “Discussion:” in part 5 are not discussion.  Moreover, there is almost no discussion in this paper. \n(6)\tIn part 5.4 Table 4, why there is result of PPMI in column “2500 Amharic Comments” but no result in column “20 million Amharic tokens”? Are the 2500 comments stemmed? \n(7)\tIn part 5.6, why negation handling is adopted in part 5.6?\n\nMinor comments:\n(1)\tGrammatical problems such as: Page 3 last paragraph: “Amharic is highly morphological language both inflectional and derivational morphology is complex.” \n(2)\tPage 6 last paragraph: “We will evaluate in three ways: external to lexicon and internal to lexicon.” It should be two ways. \n(3)\tThe number of facebook comments varies: it is 2800 in part 5.3, 2500 in 5.4 including Table 4, and 2821 in 5.6.  \n","sentences":[{"sentence_type":"2","sentence":"While this paper presents an economical and practical method to generate a sentiment lexicon for resource-limited language it is not acceptable in it's current state to ICRL.","rephrased":"While this paper presents an economical and practical method to generate a sentiment lexicon for resource-limited languages, there are areas that need improvement to meet the standards of ICRL."},{"sentence_type":"1","sentence":"The conclusion is not well proved. Especially about the claim that their method is \\","rephrased":"The conclusion could be strengthened, particularly the claim regarding the cost-effectiveness and time efficiency of the method."},{"sentence_type":"2","sentence":"The paper is incorrectly structured.","rephrased":"The structure of the paper could be improved for better clarity and flow."},{"sentence_type":"2","sentence":"Moreover, there is almost no discussion in this paper.","rephrased":"It would be beneficial to include more comprehensive discussions to enhance the paper's depth."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1088,1262,"Not concerning"],[1914,1950,"Not concerning"],[2281,2335,"Confirmed"]],"Comments":[]}
{"id":"SySnNRUxz","text":"Summary: The paper proposed a two-dimensional approach to lifelong learning, in the context of multi-task learning. It receives instances in an online setting, where both the prediction model and the relationship between the tasks are learnt using a online kernel based approach. It also proposed to use budgeting techniques to overcome computational costs. In general, the paper is poorly written, with many notation mistakes and inconsistencies. The idea does not seem to be novel, technical novelty is low, and the execution in experiments does not seem to be reliable. \n\nQuality: No obvious mistakes in the proposed method, but has very low novelty (as most methods follows existing studies in especially for online kernel learning). Many mistakes in the presentation and experiments.  \n\nOriginality: The ideas do not seem to be novel, and are mostly (trivially) using existing work as different components of the proposed technique. \n\nClarity: The paper makes many mistakes, and is difficult to read. [N] is elsewhere denoted as \\mathbb{N}. The main equation of Algorithm 2 merges into Algorithm 3. Many claims are made without justification (e.g. 2.2. “Cavallanti 2012 is not suitable for lifelong learning”… why?; “simple removal scheme … highest confidence” – what is the meaning of highest confidence?), etc. The removal strategy is not at all well explained – the objective function details and solving it are not discussed. \n\nSignificance: There is no theoretical guarantee on the performance, despite the author’s claiming this as a goal in the introduction itself (“goal of lifelong learner … computation”). The experiments are not reliable. Perceptron obtains a better performance than PA algorithms – which is very odd. Moreover, many of the multi-task baselines obtain a worse performance than a simple perceptron (which does not account for multi-task relationships). \n","sentences":[{"sentence_type":"2","sentence":"In general, the paper is poorly written, with many notation mistakes and inconsistencies.","rephrased":"The paper could benefit from a thorough review to correct notation mistakes and inconsistencies to enhance its overall clarity."},{"sentence_type":"2","sentence":"The idea does not seem to be novel, technical novelty is low, and the execution in experiments does not seem to be reliable.","rephrased":"The paper could more clearly highlight the novel aspects of the approach, and the experimental execution may require further validation to ensure reliability."},{"sentence_type":"2","sentence":"The paper makes many mistakes, and is difficult to read.","rephrased":"The paper would benefit from additional editing to correct errors and improve readability."},{"sentence_type":"2","sentence":"The experiments are not reliable.","rephrased":"The experimental results could be strengthened with additional replication or more rigorous validation methods."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[358,447,"Confirmed"],[448,572,"Confirmed"],[949,1005,"Not concerning"],[1621,1654,"Confirmed"]],"Comments":[]}
{"id":"Syl3tBeAtH","text":"The paper aims to explain the regularization and generalization effects of data augmentation commonly used in training Neural Networks. \nIt suggests a novel measure of \"rugosity\" that measures a function's diversion from being locally linear and explores the connection between data augmentation and the decrease in rugosity.\nIt further suggests the explicit use of rugosity measure as a regularization during training to replace need for data augmentation.\nThe paper is very well written and both the positive and negative findings are clearly presented and discussed. \nCons:\n- The main contribution of the paper, in my view, is the suggestion of using rugosity as a explicit regularization for training Neural Networks. Nevertheless, all the results in the paper show a negative impact of this on the test accuracy which is contradicting to the proposition. \nThis result has been discussed in section 5 but without much evidence to the explanations mentioned. The connection is very interesting but I believe further work is needed to explain those negative results on test accuracy. \n- The difference in finding (Table 1) between the CNN and ResNet networks can be more discussed. \n- Additional tasks (like regression) or even toy examples can be useful in further explaining the connection between rugosity and generalization to test data. \n ","sentences":[{"sentence_type":"2","sentence":"Nevertheless, all the results in the paper show a negative impact of this on the test accuracy which is contradicting to the proposition.","rephrased":"However, the results presented in the paper suggest that using rugosity as an explicit regularization does not consistently improve test accuracy, which seems to be at odds with the initial hypothesis. This warrants further investigation to understand the discrepancy."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[722,859,"Not concerning"]],"Comments":[]}
{"id":"r1Kg9atxz","text":"The authors extend the approach proposed in the  \"Reverse Curriculum Learning for Reinforcement Learning\" paper by adding a discriminator that gives a bonus reward to a state based on how likely it thinks the current policy is to reach the goal from said state. The discriminator is a potentially interesting mechanism to approximate multi-step backups in sparse-reward environments. \n\nThe approach of this paper seems severely severely limited by the assumptions made by the authors, mainly assuming a deterministic environment, known goal states and the ability to sample anywhere in the state space. Some of these assumptions may be reasonable in domains such as robotics, but they seem very restrictive in the domains like the games considered in the paper.\n\n\nAdditional Comments:\n\n-The authors demonstrate some benefits of using Tendency rewards, but made little attempt to explain why it leads to accelerated learning. Results are pure performance results.\n\n-The authors should probably structure the tendency reward as potential based instead of using the Gaussian kernel hack they introduce in section 4.2\n\n- Presentation: There are several mistakes and formatting issues in References\n\n- Assumption 2 transformations -> transitions?\n\n-Need to add assumption 3: advance knowledge of goal state\n\n- the use of gamma as  a scale factor in equation 2 is confusion, it was already introduced as the discount factor ( which is default notation in RL). It also isn't clear what the notation r_f denotes (is it the same as r^f in appendix?).\n\n-It is nice to see that the authors compare their method with alternative approaches. Unfortunately, the proposed method does not seem to offer many benefits. \n","sentences":[{"sentence_type":"2","sentence":"The approach of this paper seems severely severely limited by the assumptions made by the authors, mainly assuming a deterministic environment, known goal states and the ability to sample anywhere in the state space.","rephrased":"The approach of this paper could be further strengthened by addressing the assumptions made by the authors, such as the deterministic environment, known goal states, and the ability to sample anywhere in the state space."},{"sentence_type":"2","sentence":"-The authors demonstrate some benefits of using Tendency rewards, but made little attempt to explain why it leads to accelerated learning. Results are pure performance results.","rephrased":"While the authors demonstrate the benefits of using Tendency rewards, a more detailed explanation of the underlying reasons for accelerated learning would enhance the understanding of the results."},{"sentence_type":"2","sentence":"-It is nice to see that the authors compare their method with alternative approaches. Unfortunately, the proposed method does not seem to offer many benefits.","rephrased":"It is commendable that the authors compare their method with alternative approaches. Further discussion on the unique advantages of the proposed method could help in highlighting its potential benefits."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[386,602,"Confirmed"],[786,962,"Not concerning"],[1543,1701,"Not concerning"]],"Comments":[]}
{"id":"HJeBukc62m","text":"The current paper proposes using Graph Convolutional Networks (GCN) to explicitly represent and use relational data in dialog modeling, as well an attention mechanism for combining information from multiple sources (dialog history, knowledge base, current utterance). The work assumes that the knowledge base associated with the dialog task has en entity-to-entity-relationship format and can be naturally expressed as a graph. The dependency tree of dialog utterances can also be expressed as a graph, and the dialog history as a set of graphs. To utilize this structure, the proposed method uses GCNs whose lowest layer embeddings are initialized with the entity embeddings or via outputs of standard RNN-like models. The main claim is that the proposed model outperforms the current state-of-the-art on a goal-oriented dialog task.\n\nThe idea of explicitly modeling the relational structure via GCNs is interesting. However, the use of GCNs independently per sentence and per knowledge-base is a bit disappointing, since it does not couple these sources of information in a structured way. Instead, from my current understanding, the approach merely obtains better representations for each of these sources of information, in the same way it is done in the related language tasks. For instance, have you considered passing information across the trees in the history as well? Or aligning the parsed query elements with the KB elements?\n\nThe results are very good. That said, a source of concern is that the model is only evaluated as a whole, without showing which modification brought the improvements. The comparison between using\/not using RNNs to initiate the first GCN layer is promising, but why not compare to using only RNN also? Why not compare the various encoders within an established framework (e.g. without the newly introduced attention mechanism)? Finally, the attention mechanism, stated as a contribution, is not motivated well.\n\nClarity:\nThe notation is described well, but it's not terribly intuitive (the query embedding is denoted by c, the history embedding by a, etc.), making section 4.4. hard to follow. A figure would have made things easier to follow, esp. due to the complexity of the model. A clearer parallel with previous methods would also improve the paper: is the proposed approach adding GCN on top of an established pipeline? Why not?\n\nMore discussion on code-mixed language, e.g. in section 4.6, would also improve clarity a bit (make the paper more self-contained). While the concept is clear from the context, it would be helpful to describe the level of structure in the mixed language. For instance, can dependency trees not be obtained code-mixed languages? Is there any research in this direction? (or is the concept very new?) Maybe I am just missing the background here, but it seems helpful in order to asses how appropriate the selected heuristic (based on the co-occurence matrix) is.\n\nRelevant Reference:\nLearning Graphical State Transitions, Johnson, ICLR 2017 also uses graph representations in question answering, though in a somewhat different setting.\n\nTypos:\nSection 4: \"a model with following components\"\nSection 5: \"the various hyperparameters that we conisdered\"","sentences":[{"sentence_type":"2","sentence":"The idea of explicitly modeling the relational structure via GCNs is interesting. However, the use of GCNs independently per sentence and per knowledge-base is a bit disappointing, since it does not couple these sources of information in a structured way.","rephrased":"The concept of explicitly modeling the relational structure using GCNs is intriguing. It would be beneficial to explore how these GCNs could be applied not just independently per sentence and per knowledge-base, but in a manner that more tightly integrates these information sources."},{"sentence_type":"2","sentence":"The notation is described well, but it's not terribly intuitive (the query embedding is denoted by c, the history embedding by a, etc.), making section 4.4. hard to follow.","rephrased":"While the notation is adequately described, enhancing its intuitiveness could improve the readability of section 4.4. For example, using more descriptive labels for the query and history embeddings might help."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[836,1091,"Not concerning"],[1959,2131,"Maybe"]],"Comments":[]}
{"id":"BfgZzBeRbc","text":"### Summary\n\nThe focus of this work is on systematic generalization in RL, which is here used to refer to generalizing universal causal relations (such as laws of physics) learned from interacting with a few environment to approximately solve any task in any other environment without further interactions. This is made tractable through a set of structural assumptions about the shared causal structure that explains a significant portion of the transition dynamics in these reward-free environments. When using a causal transition model (obtained by estimating a Bayesian network from a mixture of the environments) to infer the common dynamics, then it can be employed by a planning oracle to provide an approximately optimal policy for a latent environment and a given reward function.\n\nHere it is shown that this simple recipe allows achieving any desired planning error up to an unavoidable term inherent to the setting. An analysis of the sample complexity of this approach is provided, which is polynomial in all relevant quantities of the problem.\n\n### Review\n\nUnfortunately, I am not an expert in RL theory, which makes it difficult for me to evaluate the main contribution, which is Theorem 4.2, and consequently any of the claims above. Given my unfamiliarity, it seems unreasonable to expect me to review the lengthy derivation in the appendix for a workshop. I apologize to the authors for my lack of feedback, insights, or comments, especially since the work appears both relevant and interesting. ","sentences":[{"sentence_type":"1","sentence":"Unfortunately, I am not an expert in RL theory, which makes it difficult for me to evaluate the main contribution, which is Theorem 4.2, and consequently any of the claims above.","rephrased":"While I am not a specialist in RL theory, I will do my best to evaluate the main contribution, which is Theorem 4.2, and the claims presented."},{"sentence_type":"2","sentence":"Given my unfamiliarity, it seems unreasonable to expect me to review the lengthy derivation in the appendix for a workshop.","rephrased":"Given my limited expertise in this area, I find it challenging to thoroughly review the extensive derivation in the appendix for a workshop setting."},{"sentence_type":"1","sentence":"I apologize to the authors for my lack of feedback, insights, or comments, especially since the work appears both relevant and interesting.","rephrased":"I regret that I may not be able to provide detailed feedback, insights, or comments due to my limited familiarity with the field, despite the work being relevant and interesting."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1070,1248,"Not concerning"],[1249,1372,"Maybe"],[1373,1512,"Not concerning"]],"Comments":[]}
{"id":"6EYpDkO1oy","text":"This paper proposed a few deep learning models to solve the fungi image classification problem. As stated in the paper, it is the first paper that focuses on using image classification help the diagnosis of fungal infections. The paper lacks detailed information about the implementation and model training process, which is very important to draw the conclusion mentioned in the paper.\n\npro: This paper proposes to use deep learning for fungi microscopic images classification. The problem is interesting and impactful.\nThe authors provide visualization of random clusters generate by the bag-of-word approach, as well as analysis from a microbiologist perspective.\n\ncons: There are several key points missing in the paper.\n1) How the patch are generated from the fungi images and how many total number are used for training?\n2) How is each model trained? Without a detailed training setting, it is hard to understand why inceptionV3 performs worse than AlexNet, or why the bag-of-words with InceptionV3 performs much worse than InceptionV3 itself.","sentences":[{"sentence_type":"2","sentence":"Without a detailed training setting, it is hard to understand why inceptionV3 performs worse than AlexNet, or why the bag-of-words with InceptionV3 performs much worse than InceptionV3 itself.","rephrased":"To fully understand the comparative performance, including why InceptionV3 might perform worse than AlexNet or why the bag-of-words with InceptionV3 underperforms compared to InceptionV3 alone, a detailed training setting description would be beneficial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[857,1049,"Not concerning"]],"Comments":[]}
{"id":"Ske4TVOCY4","text":"The paper introduces a task of online metalearning, where the agent is doing few shot learning online -- every task is seen only once.\n\nI am not an expert in online learning, but the paper seems to be sound. The experimentation looks thorough. The results are promising, but I would like to see some dataset closer to real world.\n\nA minor point -- graphs are very hard to read, please use vector images","sentences":[{"sentence_type":"1","sentence":"A minor point -- graphs are very hard to read, please use vector images","rephrased":"A minor suggestion for improvement -- to enhance the readability of the graphs, consider using vector images."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[331,402,"Not concerning"]],"Comments":[]}
{"id":"Byxeg0D3KH","text":"This paper presents a VAE model. The authors consider time series data and claim that in this situation it is better to model the transformations in the latents instead of each datum independently. The setup is reasonable and seems novel, but since it stops at image registration, which is a well-known existing model I cannot qualify the paper as novel. The paper is mostly clear, some claims are not backed up by experiments and the experiments are lacking. As I motivate below I find the current content more at a workshop level than a conference paper. \n\nMajor issues:\n* This paper can become a conference paper in two ways in my opinion. 1) It either needs to show that richer modeling has benefits (if anything it would seem from fig 5 that this is not the case). A way towards that would be to take data where there are no simple transformations that we can introduce and show that it discovers reasonable ones. And 2) show on some highly varying temporal domain that this is better than differences of z. \n* on page 2 \" the initial assumption that the time-series must be stationary can be fulfilled\" -- The data doesn't have to comply with our standards of stationarity. A more sensible formulation is we add these additional constraints to our model which are correct if the data is stationary. \n* On page 3 \"to make sure that the latent space can be interpreted\". This is a very strong claim, it implies that if we do this the latent space will always be interpretable, which I think is false and definitely not backed up by experiments.\n* The conditions on \\dot{z} are interesting and potentially useful and they should be explored in experiments. Putting them in or not does it really make the sense that we think it should make ? Ideally in a setup where the data is not trivial.\n* I am not sure what insight a reader can possibly get from figure 3. \n* Given the final image-registration setup I find that the following citations are necessary: \njaderberg et al. Spatial transformer networks, Shu et al. Deforming auto-encoders: unsupervised disentangling of shape and appearance. \nMinor issues:\n* the authors should number all equations. \n* In their first equation (not numbered) the indices go beyond N+1. ","sentences":[{"sentence_type":"2","sentence":"since it stops at image registration, which is a well-known existing model I cannot qualify the paper as novel.","rephrased":"While the paper builds upon the concept of image registration, which is an established model, further innovation would be necessary to clearly distinguish the paper's novelty."},{"sentence_type":"2","sentence":"As I motivate below I find the current content more at a workshop level than a conference paper.","rephrased":"In my view, the current content seems more suited for a workshop presentation rather than a conference paper, as detailed below."},{"sentence_type":"2","sentence":"I am not sure what insight a reader can possibly get from figure 3.","rephrased":"It would be beneficial to clarify the insights that a reader is expected to gain from Figure 3."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[243,354,"Maybe"],[460,556,"Not concerning"],[1375,1547,"Missed Maybe"],[1796,1863,"Confirmed"]],"Comments":[]}
{"id":"ByecO2R6j7","text":"The paper proposes performing Thompson Sampling (TS) using a Bayesian Linear Regressor (BLR) as the action-value function the inputs of which are parameterized as a deterministic neural net. The authors provide a regret bound for the BLR part of their method and provide a comparison against Double Deep Q-Learning (DDQL) on a series of computer games.\n\nStrengths:\n  * The paper presents some strong experimental results.\n\nWeaknesses:\n  * The novelty of the method falls a little short for a full-scale conference paper. After all, it is only a special case of [3] where the random weights are restricted to the top-most layer and the posterior is naturally calculated in closed form. Note that [3] also reports a proof-of-concept experiment on a Thompson Sampling setting.\n\n  * Related to the point above, the paper should have definitely provided a comparison against [3]. It is hard to conclude much from the fact that the proposed method outperforms DDQN, which is by design not meant for sample efficiency and effective exploration. A DDQN with Dropout applied on multiple layers and Thompson Sampling followed as the policy would indeed be both a trivial design and a competitive baseline. Now the authors can argue what they provide on top of this design and how impactful it is.\n\n  * If the main concern is sample efficiency, another highly relevant vein of research is model-based reinforcement learning. The paper should have provided a clear differentiation from the state of the art in this field as well.\n\n  * Key citations to very closely related prior work are missing, for instance [1,2].\n\n  * I have hard time to buy the disclaimers provided for Table 2. What is wrong with reporting results on the evaluation phase? Is that not what actually counts? \n\n  * The appendix includes some material, such as critical experimental results, that are prerequisite for a reviewer to make a decision about its faith. To my take, this is not the Appendices are meant for. As the reviewers do not have to read the Appendices at all, all material required for a decision has to be in the body text. Therefore I deem all such essential material as invalid and make my decision without investigating them.\n\nMinor:\n  * The paper has excessively many typos and misspellings. This both gives negative signals about its level of maturity and calls for a detailed proofread.\n\n[1] R. Dearden et al., Bayesian Q-learning, AAAI, 1998\n\n[2] N. Tziortziotis et al., Linear Bayesian Reinforcement Learning, IJCAI, 2013\n\n[3] Y. Gal, Z. Ghahramani, Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning, ICML, 2016","sentences":[{"sentence_type":"2","sentence":"The novelty of the method falls a little short for a full-scale conference paper.","rephrased":"While the method shows promise, it would benefit from further development to establish its novelty for a full-scale conference paper."},{"sentence_type":"2","sentence":"I have hard time to buy the disclaimers provided for Table 2.","rephrased":"The disclaimers provided for Table 2 could be clarified to better support the results presented."},{"sentence_type":"3","sentence":"Therefore I deem all such essential material as invalid and make my decision without investigating them.","rephrased":"It is important that all essential material is included in the main text, as reviewers may not consider the appendices, which could affect the evaluation of the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[439,520,"Maybe"],[1610,1671,"Confirmed"],[2102,2206,"Confirmed"],[2274,2369,"Missed Maybe"]],"Comments":[]}
{"id":"ZZkHkhXAYDs","text":"The definitions of Node Smoothing Level and Graph Smoothing Level compare the representations of the same node across different EP steps. However, the oversmoothing problem is across nodes. Considering the deviations, the performance of DGMLP appears to be comparable to the state-of-the-art. It is claimed that DGMLP can support large transformation depth D_t. But Fig6 (b) only shows a very stable accuracy as D_t increases. It would be more convincing if the performance of DGMLP improves with a larger D_t. Otherwise, why bother to increase D_t? Larger D_t means more parameters, and hence may need to train models longer (and with better training settings). Is it possible that large D_t leads to undertrain of GNN? The proposed node-adaptive weighting mechanism is interesting. It could helpful to see experiments that validate the importance of the node-adaptive weighting mechanism. ","sentences":[{"sentence_type":"2","sentence":"But Fig6 (b) only shows a very stable accuracy as D_t increases. It would be more convincing if the performance of DGMLP improves with a larger D_t. Otherwise, why bother to increase D_t?","rephrased":"While Figure 6(b) demonstrates stable accuracy with increasing D_t, it would strengthen the argument if the performance of DGMLP improved with a larger D_t. Could you please elaborate on the benefits of increasing D_t?"},{"sentence_type":"1","sentence":"Larger D_t means more parameters, and hence may need to train models longer (and with better training settings). Is it possible that large D_t leads to undertrain of GNN?","rephrased":"A larger D_t implies more parameters, which might require longer training times or more optimized training settings. Could there be a risk that a large D_t might result in the undertraining of the GNN?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[362,549,"Not concerning"],[550,720,"Not concerning"]],"Comments":[]}
{"id":"Bk-tLaKlz","text":"This paper introduces a convolutional autoencoder for irregular graphs, specifically surfaces in the form of discrete meshes in 3D. The underlying technique that is used to operate on the irregular graph is spectral decomposition, which enables convolutions in the spectral domain. \n\nThe spectral convolution methods have been applied to mesh data structures for about 5 years now, as stated in the paper as well [Bruna et al. 2013], [Defferrard et al. 2016], [Bronstein et al. 2017], [Li et al. 2017] ... The paper states that it builds upon the formulation in [Defferrard et al. 2016] as explained in section 3. \n\nGiven the facts above, I am having a hard time to understand the novelty of this paper? Is it the \"Mesh Upsampling\" operation defined at the end of page 4? If that is the case, it is not demonstrated in the paper that it actually works. The main reason is that the original face mesh graph that goes into the convolution\/downsampling\n operations is topologically preserved through the upconvolutions. This means that the upsampling operation is not really upsampling a \"true\" graph\/mesh. The topology is already known, the upsampling just predicts a function on this topology. \n\n The choice of the face domain is also suspicious, since all faces are topologically the same graph (even though there are geometric variations). Convolutions\/downsampling-convolutions\/upsampling that are demonstrated in the paper basically boil down to function prediction on the same exact global graph. Face topologies are so regular that they can even be represented with a height map like geometry encoding in the image plane (See [1'] below). \n\n To demonstrate the \"mesh\/graph generation\" capability truly, the authors need to experiment on novel topology generation. As is, the paper does not bear enough novelty on top of [Defferrard et al. 2016], or is not demonstrating it even if there exists any.\n\n[1'] Z. Shu, E. Yumer, S. Hadap, K. Sunkavalli, E. Shechtman, D. Samaras. Neural Face Editing with Intrinsic Image Disentangling. CVPR 2017\n\nMINOR: \nFirst paragraph of Section 3: \n- The definition of a mesh (F=(V,E,A)) is not correct: Both E and A essentially define the same connectivity. Base your definition on F=(V,E) or F=(V,A). Since you are using A later in the section, probably the latter makes more sense for you.\n\n","sentences":[{"sentence_type":"2","sentence":"Given the facts above, I am having a hard time to understand the novelty of this paper?","rephrased":"Could you please clarify the novel contributions of this paper, as they are not immediately apparent from the current text?"},{"sentence_type":"2","sentence":"If that is the case, it is not demonstrated in the paper that it actually works.","rephrased":"It would be beneficial if the paper could include evidence or experiments demonstrating the effectiveness of the 'Mesh Upsampling' operation."},{"sentence_type":"2","sentence":"The choice of the face domain is also suspicious, since all faces are topologically the same graph (even though there are geometric variations).","rephrased":"The selection of the face domain raises some questions, as all faces share a common topological graph structure despite geometric variations."},{"sentence_type":"2","sentence":"As is, the paper does not bear enough novelty on top of [Defferrard et al. 2016], or is not demonstrating it even if there exists any.","rephrased":"The paper could more explicitly highlight its novel contributions, particularly in relation to [Defferrard et al. 2016], to strengthen the demonstration of its novelty."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[616,703,"Confirmed"],[772,852,"Confirmed"],[1196,1340,"Not concerning"],[1769,1903,"Confirmed"]],"Comments":[]}
{"id":"S1gTl83L6X","text":"This paper considers the problem of recovering the lowest layer of a deep neural network whose architecture is ReLU or sign function followed by a polynomial. This paper relies on three assumptions: 1) the lowest layer has a high threshold (\\Omleg(\\sqrt{d})), 2) the polynomial has 1\/poly(d) lower bouned and O(1) upper bounded linear terms and is monotone 3) the input is Gaussian. Under these assumptions, this paper shows it is possible to learn the lowest layer in precision \\eps in poly(1\/eps, d) time.\n\nThe proposed algorithm has two steps. The first step is based on the landscape design approach proposed by Ge et al. (2017) and the second step is based on checking the correlation. \n\nProvably learning a neural network is a major problem in theoretical machine learning. The assumptions made in this paper are fine for me and I think this paper indeed has some new interesting observation. My major concern is the writing. There are several components of the algorithm. However, it is hard to digest the intuition behind each component and how the assumptions are used. I suggest authors providing a high-level and non-technical description of the whole algorithm at the beginning. If authors can significantly improve the writing, I am happy to re-evaluate my comments and increase my rating.","sentences":[{"sentence_type":"1","sentence":"My major concern is the writing.","rephrased":"My primary suggestion is to improve the clarity of the writing."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[899,931,"Not concerning"]],"Comments":[]}
{"id":"L9mAra0G8Wm","text":"The authors tackle the challenging problem of in-context adaptation and exploration without using gradient-based updates. They approach this challenge by training partial models in a supervised manner using a Transformer architecture that are used as the hypothesis space in the inference process. Their results show that using the pre-trained partial models facilitate adaptation and lead to good policies even excluding relevant information from the environment.\n\nStrengths:\n\n1. The problem of in-context adaptation and exploration is challenging and significant advances in the methods used for this problem are needed in the literature.\n2. The idea of learning general knowledge in the form of an inference process over partial models is very interesting, and representing the partial models as graphs that can be approximated using neural networks (Transformers or Graph Neural Networks) is an interesting and promising approach.\n3. The results show that the trained partial models can lead to rewarding policies that can be effectively used with posterior sampling.\n\nWeaknesses:\n\n1. Even the problem is challenging and the idea is interesting, the clarity of the paper could be improved with more Figures and Diagrams that helps the reader to understand the available training data, which policies are trained, how the trained policies are used, and how the posterior sampling works.\n2. The partial models are trained in a supervised manner using data from a random policy (which is ok depending on the environment). In the conclusion, the authors discuss that a future work is to learn partial model representation without supervision signals, but the reviewer thinks that an in-depth discussion comparing the partial models with other model-based methodologies, intrinsic rewards, and reward prediction, might be needed.\n3. The paper might be at the edge of the workshop’s scope. There is not an in-depth discussion regarding the reuse of data collected by previous policies that can be used to train the partial models or the reuse of world models.\n\nOverall, the reviewer’s opinion is that the work has merit and tackle an important and challenging problem. Even the paper tackles a problem relevant for the workshop theme, the reviewer thinks that additional discussion might improve the clarity of the paper and its contributions.","sentences":[{"sentence_type":"1","sentence":"Even the problem is challenging and the idea is interesting, the clarity of the paper could be improved with more Figures and Diagrams that helps the reader to understand the available training data, which policies are trained, how the trained policies are used, and how the posterior sampling works.","rephrased":"While the problem is challenging and the idea is interesting, enhancing the paper's clarity with additional Figures and Diagrams could help readers better understand the training data, the policies being trained, their application, and the posterior sampling process."},{"sentence_type":"1","sentence":"The reviewer thinks that additional discussion might improve the clarity of the paper and its contributions.","rephrased":"The paper could benefit from further discussion to enhance its clarity and highlight its contributions more effectively."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1089,1389,"Not concerning"]],"Comments":[]}
{"id":"HyxE-hwBtE","text":"This paper explores whether decomposing an agent-oriented structure prediction task into sub-agents and an aggregator improves performance on query reformulation tasks.  The paper considers both decomposing on random sub-sets of the data (bagging), and partitioning into semantically similar classes.  The results show that decomposing into sub-agents improves performance.\n\nThe method is applied to 2 tasks - document retrieval (on 3 datasets), and question answering.  One of the main results is that the same level of performance can be achieved with much less compute.\n\nThe basic idea is elegant, but I have 3 concerns. First, I found that some aspects were really unclear.  Second, it wasn’t clear but I inferred that the results were created from a single run, which limits how much can be concluded.  Finally, it wasn’t clear whether the method would generalize to other tasks.\n\n* Clarity.  I was unclear on the following:\n\n- Fig 1: why is there 1 search box in Fig 1b, but N+1 search boxes in Fig 1c?  If the idea is that the search in Fig 1b is doing a single search by simultaneously receiving all queries, that wasn’t at all clear.\n\n- Sec 3.4, “the aggregator receives as input q_0…”: q_0 is not an input into the aggregator in Fig 1.  Should q_0 be a_0? \n- Sec 4.3, “other metrics … resulted in similar or slightly worse performance than Recall@40.”  Does this mean that the proposed method is strongest only when evaluated under certain metrics? \n- Table 1: I was unclear on how RL-10-Ensemble and RL-10-Full differ, since the descriptions in the text (Sec 4.4 and 4.5) are nearly identical. \n* Experimental procedure.  Were the results the product of a single run, or the results of averaging many runs?  I might have missed it but I inferred they were from a single run.  As a result, readers won’t know what the variance of the methods are, and whether the relative orderings of the methods are reliable. \n\n* Generality.  Query re-writing is a very specific task, and both experiments here relied on an external search engine.  I’m worried that the method may be “fit” to specific properties of the task — for example, in the current setting, all actions can effectively be executed to produce search results; in other settings, this isn’t possible.  Moreover, because of the search engine, producing a diversity of responses seems to be important; in other settings, having a diverse set of outputs may be less important.  The results would be more impactful if other types of tasks were considered — even more text generation tasks, like dialog response generation, paraphrasing, translation, etc.  \n","sentences":[{"sentence_type":"1","sentence":"First, I found that some aspects were really unclear.","rephrased":"First, I believe some aspects could be clarified further."},{"sentence_type":"2","sentence":"Second, it wasn't clear but I inferred that the results were created from a single run, which limits how much can be concluded.","rephrased":"Second, it would be helpful to clarify if the results were obtained from multiple runs or a single run, as this has implications for the robustness of the conclusions."},{"sentence_type":"1","sentence":"Finally, it wasn't clear whether the method would generalize to other tasks.","rephrased":"Finally, it would be beneficial to discuss the potential for the method to generalize to other tasks."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[624,677,"Not concerning"]],"Comments":[]}
{"id":"SkgLM7m_FN","text":"This paper presents a unified framework for transfer learning and learning with (large amounts of) noisily-labeled (source) data. The authors assume the source and target classifiers share the same “representation layers” and only differ by the “classification layers”.  They then jointly learn these layers as well as the source example weights. Specifically, the authors formulate the problem as a bilevel optimization problem and design the learning process such that the exterior level minimizes the target loss only through the source weights.  As a result, the target classifier can only control\/adjust the features representation by adjusting the source example weights. Finally, the authors prove that under certain conditions this bilevel optimization procedure will converge and empirically show it helps learning. \n\nOverall the paper is in good shape. I would like to see more (empirical) analysis on the convergence condition and understand how likely the condition at the end of page 9 will be satisfied. Also, some hyper-parameter sensitively analysis on lambda_{a} and lambda_{p} will be interesting. Finally, there are some minor mistakes (listed below) that need to be fixed:\n1. in the equation (1), change min to argmin\n2. in page 8 appendix A line 5, “A summer of SOSELETO algorithm appears in (Algorithm) 1”\n3. in page 10 Appendix E line 2, Section “???”","sentences":[{"sentence_type":"1","sentence":"Finally, there are some minor mistakes (listed below) that need to be fixed:","rephrased":"Additionally, I have identified a few minor areas for correction (listed below):"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1116,1192,"Not concerning"]],"Comments":[]}
{"id":"SJgISm7mYS","text":"The authors show that CNNs are somewhat able to compress entire videos within their parameters that can be reconstructed by an autoregressive process. This is an interesting idea that has been explored in a different context before (e.g., Deep Image Prior, Ulyanov et al. 2017). There is also plenty of work in the area of exploiting NNs for video compression\/encoding (see [1] for instance). However, a bit unusual is the choice of compressing a video into network parameters, which is quite an expensive process using backprop. I could not find any motivation for why this would be a good idea, potentially because the paper does not state any explicit goal\/contribution. In any case the authors show merely some mediocre qualitative results. There are no comparisons to prior work and no empirical results. The combination of methods also seems a bit arbitrary.\n\nTherefore this paper has no valuable contribution in its current form and I vote for rejection.\n\nMajor issues\n- No empirical results\n- No comparison to any baseline or prior work\n- Confusing: the paper has almost no structure, e.g., there are almost no sections at all. Symbols are not used consitently (e.g., functions f and g).\n\nQuestions\n- What's the goal of employing normalizing flows in this paper?\n\n[1] Image and Video Compression with Neural Networks: A Review. Ma et al. 2019.\n","sentences":[{"sentence_type":"3","sentence":"Therefore this paper has no valuable contribution in its current form and I vote for rejection.","rephrased":"Given the current version of the paper, I believe it would benefit from a clearer articulation of its contributions and a more robust comparison with existing work before it can be considered for acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[866,961,"Confirmed"],[1047,1168,"Missed by Model"]],"Comments":[]}
{"id":"ZsdnpcKgZB","text":"The method is reasonable, but the paper is very short\/vague and the method not tested with real data.  Short papers are allowed to use up to 3 pages excluding references, but this paper only used a fraction of that space.  The paper could have been much stronger if it used the full space allotment.\n\nI wish the paper would have spent more time explaining why Eq. (1) was chosen given many other possibilities, since the form of Eq. (1) is not intuitive.  Since this is a standard superresolution problem, so the lack of any comparison against other superresolution methods is an important omission.","sentences":[{"sentence_type":"2","sentence":"The paper is very short\/vague and the method not tested with real data.","rephrased":"While the paper is concise, providing more details and testing the method with real data could enhance its robustness."},{"sentence_type":"1","sentence":"The paper could have been much stronger if it used the full space allotment.","rephrased":"Utilizing the full space allotment could allow for a more comprehensive discussion and potentially strengthen the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[223,299,"Not concerning"]],"Comments":[]}
{"id":"rkx9eFq6tH","text":"Overview:\nThis paper introduces a model for image-based facial 3D reconstruction. The proposed model is an encoder-decoder architecture that is trained in semi-supervised way to map images to sets of vectors representing identity (which encodes albedo and geometry), pose, expression and lighting. The encoder is a standard image CNN, whereas the decoders for geometry and albedo rely on spectral graph CNNs (similar to e.g. COMA, Ranjan’18). \nThe main contribution of the work with respect to the existing methods is the use of additional loss terms that enable semi-supervised training and learning somewhat more disentangled representations. Authors report quantitative results on MICC Florence, with marginal improvements over the baselines (the choice of the baselines is reasonable).\n\nDecision:\nThe overall architecture is very similar to existing works such as COMA (Ranjan’18) and (Tran’19), including the specific architecture for geometry decoders, and thus the contributions are primarily in the newly added loss terms. \nI also find the promise of “disentangled” representation a bit over-stated, as the albedo and base geometry still seem to be encoded in the same “identity” vector (see related question below).\nThe numerical improvements seem fairly modest with respect to (Tran’19). In addition, there is no numerical ablation study that would demonstrate the actual utility of the main contributions (such as adversarial loss): there are qualitative results but they are not very convincing. \nThus, the final rating “weak reject”.\n\nAdditional comments \/ typos:\n\n* I am not fully following the argument about sharing identity for albedo and shape on p2: “albedo and face shape are decoded ...”. Would it not be more beneficial to have a fully decoupled representation between the albedo and the facial geometry? I do not see how albedo information would be useful for encoding face geometry and vise-versa. \n* Authors claim that one of the main drawbacks e.g. of (Train’19) is the fact that they train on data generated from linear 3DMM. This is indeed the case, but it does not seem like here the authors fully overcome this issue: they do have additional weakly-supervised data, but they still strongly rely on linear 3DMM supervision (p6, “pairwise shape loss”, “adversarial loss”), and do not seem to provide experimental evidence that the model will work without it.\n* In particular, the “adversarial training” actually corresponds to learning the distribution of the linear 3DMM. Would it not mean that ultimately the model will be limited to learning only linear ? Could you please elaborate on this?\n* p3: “allows ene-to-end … training”\n* p3: “framework to exact … representations“.\n* p8: “evaluation matric”\n\nUpdate:\nAuthors did not provide any response, thus I keep my rating.\n\n\n\n\n","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[],"Comments":[]}
{"id":"t5bx0EOFKe4","text":"========================\n\nPaper Summary:\n\nThis paper proposed to prune heads of multi-head attention in BERT to achieve regularization for tasks with a smaller dataset. Existing pruning papers on transformers focus on compression (model size) with a smaller loss in accuracy but this work claims that pruning can actually improve accuracy in some cases. The authors use DQN to learn a policy to prune attention head layer by layer. They demonstrate improvements on 4 small tasks from GLUE.\n\n========================\n\nReview\n\nThe central idea of this paper is interesting, but the experiment is not convincing enough. Whether we actually need to prune large pretrained transformer for regularization itself is debatable because researchers have found that over-parameterized deep neural language models, for example GPT-3, is good at few shot learning. This paper needs much stronger experiments to support their claim.\n\nPros:\n- The proposed method is interesting. Use pruning to improve performance is a new thing, at least with transformers and BERT.\n\nCons:\n- This work is limited to small tasks. No results are demonstrated on larger datasets.\n- Experiment is weak. The authors may improve this by running all tasks in GLUE, perhaps with a smaller training split to fit the authors’ setting. Also, it might make more sense to experiment on BERT-large or other larger, more powerful pretrained transformers to demonstrate the proposed idea can regularize over-parameterized networks.\n- Lack of comparison with other regularization techniques, for example those mentioned in related work.\n- The training overhead of this method is not discussed. It involves repeated finetuning after each layer is pruned. It will benefit the readers to measure the time needed for training AUBER.\n\n==========================\n\nOther Questions\n\n- Is Table 2 a fair comparison with other baselines? In AUBER, model is finetuned after each layer is pruned. It is not clear if this finetuning is done for other heuristic-based pruning. This might need another ablation experiment.\n- Why not directly use the whole value embedding V as the input to the DQN? Theorem 1 is also somewhat heuristic.\n- It is not clear how the training data is sampled in Algorithm 1 to train the DQN model. Does s contain all training examples? Also, in line 29, what data does the model see to decide pruning?\n\n=================================\n\nMinor Issues\n\n- Please fix the citation format (citep\/citet in latex).\n- Perhaps Figure 1 can be improved. In my opinion, the current figure does not help the readers understand the method.\n","sentences":[{"sentence_type":"2","sentence":"The experiment is not convincing enough.","rephrased":"The experimental results could be strengthened to better support the claims."},{"sentence_type":"2","sentence":"Experiment is weak.","rephrased":"The experimental design could be improved to provide more robust evidence for the claims."},{"sentence_type":"1","sentence":"The training overhead of this method is not discussed.","rephrased":"It would be beneficial to include a discussion on the training overhead of this method."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1148,1167,"Maybe"],[1591,1645,"Not concerning"]],"Comments":[]}
{"id":"zEOEGS8HVpW","text":"Summary:\nThis paper proposed to decentralize FL by using multiple edge servers (ES), each only covering a subset of user devices, and utilize devices in the overlapped region of ESs to assist model aggregation, which saves the need to communicate with higher tier ESs. This decentralized architecture for FL hopefully can be more communication-efficient than a cloud-based or a hierarchical FL framework, with comparable model performance.\n\nThis paper has its merits in leveraging devices in overlapped ES cells to assist model aggregation, which could be a practical FL setting in the near future given the advance of 5G techniques. Experimental results on several benchmarks revealed the efficacy of this approach compared with a hierarchical FL baseline. However, the nonnegligible pitfalls of this paper are 1) the novelty is limited, 2) the challenge that they aim to address is unclear, and 3) their algorithm objective is not well formulated. Moreover, as a purely empirical study, its experiment designs are quite simple, missing comparisons with more state-of-the-art baselines, which further weakens their contribution. \n\nPros:\n+ The idea of leveraging overlapped ESs to decentralize FL is legitimate.\n+ This paper shows promising experimental results compared with Hierarchical FL which requires more communication rounds.\n\nCons:\n- Although following an interesting direction, the novelty of their proposed algorithm is limited, and the challenge of this setting is not clearly described. I feel it is a straightforward extension of FedAvg and Hierarchical FL to a decentralized scenario.\n- Performance gain over the prior art (*hierarchical* FL) is marginal when multiple clouds are adopted ($T_{cloud}=5$).\n- Important baselines, such as cloud-based FL (FedAvg), and local training (without FL), are missing.\n  - 1) The main focus of this paper is to decentralize FL to improve communication efficiency, but the tradeoff between performance and communication efficiency is not shown in the paper.\n  - 2) Since the task of binary classification is quite simple, it is likely that each local device can perform well without using information from other devices, so I consider it necessary to comparing with local training. \n- The argument that FedMes is more communication-efficient than cloud-based FL is doubtful. FedMes actually requires more communication rounds, since critical users in the overlapped region need to communicate with multiple servers. Another argument in the paper that the communication can be done by broadcasting applies to cloud-based FL as well. A theoretical or empirical analysis of communication efficiency is needed.\n- Unclear objective: the proposed algorithm is designed to optimize Eq(1). However, since there is no higher-tier central server to aggregate the models from ESs, it is doubtful whether Algorithm 1 truly aligns with the optimization of Eq(1). A different objective, such as those adopted by personalized FL, where multiple sets of weights are learned rather than a single set, seems to fit this scenario more than the canonical FL objective.\n- The weight design in Eq(9) is more like engineering efforts than theoretically motivated.\n- Robustness of the proposed algorithm: Although I agree with the argument that \"even users in the non-overlapped region can help training in other ESs\". However, their contributions heavily depend on the participants of users in overlapped regions, and their hyper-parameter choice in Eq(9). An unresolved question is, when the number of users in overlapped regions is quite small, does their effects on other ESs reduce greatly as well? As shown in Figure 4, when there is no overlap, the performance is worse than all other baselines. The current experiment setting of using ratio 1:2 for overlapped versus non-overlapped users can be too enthusiastic. What if only 10% of users are in the overlapped regions? A sensitivity analysis of this ratio would be very interesting to see.\n\nMinor:\n- The definition of  $t_c$(as the one-round delay) should be more clearly elaborated.\n- Eq(6) - Eq(7): weighted average requires each user in the overlapped region knows the total number of training samples for its corresponding ESs, is this assumption practical? In cloud-based FL, only the central cloud knows the number of training samples for each device.\n- Eq(4): it would be better to use a different notation instead of $k$ for the second equation on the RHS to avoid confusion.","sentences":[{"sentence_type":"2","sentence":"However, the nonnegligible pitfalls of this paper are 1) the novelty is limited, 2) the challenge that they aim to address is unclear, and 3) their algorithm objective is not well formulated.","rephrased":"While the paper presents interesting ideas, there are areas that could be strengthened, such as 1) further clarifying the novelty of the approach, 2) more explicitly stating the challenges being addressed, and 3) refining the formulation of the algorithm's objective."},{"sentence_type":"2","sentence":"Moreover, as a purely empirical study, its experiment designs are quite simple, missing comparisons with more state-of-the-art baselines, which further weakens their contribution.","rephrased":"Additionally, the study could benefit from more complex experimental designs and comparisons with current state-of-the-art baselines to strengthen the contribution."},{"sentence_type":"2","sentence":"I feel it is a straightforward extension of FedAvg and Hierarchical FL to a decentralized scenario.","rephrased":"The proposed algorithm appears to be an extension of FedAvg and Hierarchical FL to a decentralized scenario, and it would be beneficial to highlight the distinct advancements beyond these existing methods."},{"sentence_type":"1","sentence":"The argument that FedMes is more communication-efficient than cloud-based FL is doubtful.","rephrased":"The claim that FedMes is more communication-efficient than cloud-based FL could be supported by additional theoretical or empirical analysis to strengthen its validity."},{"sentence_type":"2","sentence":"The weight design in Eq(9) is more like engineering efforts than theoretically motivated.","rephrased":"The weight design in Eq(9) could be further improved by providing a stronger theoretical motivation or justification."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[758,949,"Maybe"],[950,1129,"Maybe"],[1500,1599,"Not concerning"],[2237,2326,"Not concerning"],[3103,3192,"Not concerning"]],"Comments":[]}
{"id":"7DhN5cIhdl","text":"**Summary**: This paper experiments on several state-of-the-art pre-trained language models to see if they can predict unexpected counterfactual consequences arising from hypothetical situations. This is accomplished by providing a text prompt that begins by establishing a hypothetical premise (inconsistent with reality), then comparing the model’s likelihood outputs of two possible continuations, one consistent with reality and the other consistent with the hypothetical world. The result is compared with baselines of either using reality as the premise or by having no contextual premise. Additional experiments are performed to evaluate the effects of cue words. Results show that, when accounting for cue words, GPT-3 is the only model that shows significant understanding of counterfactual situations, but results are largely random in all cases.\n\n**Strengths**: \n1. This paper presents an unusually novel idea which offers valuable insight into the evaluation of large language models. The unique experimental results are very revealing about the true nature of such models and provide much needed critical analysis.\n\n2. The several examples added in the paper greatly contributed to the readability of the paper. Although the ideas of “counterfactual conditionals” are complicated and not easily defined, the examples provided strong intuition of what to expect in each experimental setting.\n\n3. The experiments are very extensive and well thought-out.\n\n**Weaknesses**:\n1. The paper is quite subjective. The idea of a “counterfactual conditional” is not rigorously defined and relies on humans to decide whether a conditional in text is considered factual or counterfactual. As such, data points in the dataset are handcrafted by humans and are subjectively determined by humans to be appropriate for this task. Then the evaluation of the models may not have a clear meaning.\n\n2. Even in the experiments in which the effects of lexical cues are considered, success of a model at differentiating between the two cases does not seem to necessarily imply any knowledge of counterfactual logic. Perhaps a powerful language model could simply understand lexical cues more precisely. For example, seeing the word “if” makes the condition more hypothetical (and should therefore be ignored), and seeing the phrase “in reality” implies a true continuation.\n\n3. Generally, counterfactual information is impossible to obtain because one cannot observe two realities at once. Hence, there will be a lack of counterfactual data in the training data for these large language models. Then, there may be little confidence that the language models will be correct, even if they achieve perfect results on the experiments in the paper. For example, we can hypothesize that cats would eat carrots if they were vegetarian, but perhaps they would hate carrots too. In other cases, it may not even be clear that the result would be different in the hypothesized world compared to the real world.\n\nIn general, although the weaknesses listed above should be considered as heavy limitations of this work, I think the ideas presented in this paper offer interesting insight into language models and would be a great contribution to the workshop.\n","sentences":[{"sentence_type":"2","sentence":"Then the evaluation of the models may not have a clear meaning.","rephrased":"Clarifying the evaluation criteria for the models could enhance the interpretability of the results."},{"sentence_type":"1","sentence":"Generally, counterfactual information is impossible to obtain because one cannot observe two realities at once.","rephrased":"Obtaining counterfactual information is inherently challenging due to the inability to observe multiple realities simultaneously."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1824,1887,"Not concerning"],[2365,2476,"Not concerning"]],"Comments":[]}
{"id":"zPfiii-GXy","text":"This paper proposes a Transformer-based imitation learning method for solving complex robotic control tasks. The paper is clearly written and understandable. There are several illustrations that can help with understanding the proposed method. The proposed method named CoTPC outperforms several other BC methods by significant margins. It manages to do so by encoding knowledge about the multiple intermediate subgoals that need to be reached so that the ultimate task can be solved. Below are the strengths and weaknesses of the paper:\n\nStrengths: \n\n1)  The Key State concept for dealing with complex continuous control problems which include many intermediate subproblems is interesting and allows for knowledge about the multi-step nature of the problem to be incorporated into a BC method.\n\n2) The experimental results are very good compared to the other methods and the other baselines are recent successful BC methods.\n\n3) The examples and the illustrations that are provided help with demonstrating the necessity for using key states in these problems.\n\n\nWeaknesses: \n\n1) One of the methods used as a baseline for the experimental comparisons is the Decision Transformer (DT) approach which is an offline RL method, not a BC one. It requires return inputs to properly function. The DT implementation used in this paper ignores reward tokens and this can possibly hurt performance significantly. Including DT as a baseline might be unfair. \n\n2) The addition of other Control benchmarks would have been helpful to paint a clearer picture on the differences in performance.\n\n3) It is stated that ChatGPT is used for automating the process of producing the subgoals needed for each task. This seems completely unnecessary as there are only 4 problems each with very few intermediate steps. However, this is a very minor detail and does not change the assessment overall.\n\n\nQuestion:\n\nCould the key state approach be problematic in some environments? The states are continuous-valued and there could be possibly infinite different choices for a key state at each intermediate step. \n\nThe contributions are marginally significant or novel as it is not a major overhaul of transformer-based BC (or offline RL) methods.\n\nOverall, I am leaning towards acceptance.","sentences":[{"sentence_type":"2","sentence":"The contributions are marginally significant or novel as it is not a major overhaul of transformer-based BC (or offline RL) methods.","rephrased":"While the contributions build upon existing transformer-based BC (or offline RL) methods, the novelty and significance could be further highlighted to emphasize the advancements made."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1692,1792,"Missed Maybe"],[2087,2219,"Not concerning"]],"Comments":[]}
{"id":"SygIGxKzcE","text":"This paper presents a different perspective in understanding posterior collapse in VAEs by studying the connection between probabilistic PCA (pPCA) and linear VAEs. In previous work, it is widely acknowledged that the KL-term plays an important role in posterior collapse. However, in this paper, the authors show theoretically that even the marginal log-likelihood itself could have spurious local optima and for linear VAEs, the ELBO does not add any additional optima to the pPCA model. Experimental results on posterior collapse in non-linear VAEs provide evidence to the analysis. \n\nThe analysis in this paper presents a complementary view in helping us better understand posterior collapse. One thing which is not clear to me in the current analysis is how posterior collapse can happen to pPCA if it has the same spurious local optima. Another minor comment is on the MNIST dataset, given the data is practically binary, I wonder if that would also contribute to the preference of having a smaller \\sigma. Finally, it would be interesting if the authors could also comment on VAEs with other observational model rather than Gaussian (e.g., Multinomial, as in Krishnan et al. 2018, On the challenges of learning with inference networks on sparse, high-dimensional data). ","sentences":[{"sentence_type":"1","sentence":"One thing which is not clear to me in the current analysis is how posterior collapse can happen to pPCA if it has the same spurious local optima.","rephrased":"Could you please clarify how posterior collapse occurs in pPCA despite the presence of the same spurious local optima as highlighted in the analysis?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[697,842,"Not concerning"]],"Comments":[]}
{"id":"S1lgvje0Yr","text":"This paper proposes a neural topic model that aim to discover topics by minimizing a version of the PLSA loss. According to PLSA, a document is presented as a mixture of topics, while a topic is a probability distribution over words, with documents and words assumed independent given topics. Thanks to this assumption, each of these probability distributions (word|topic, topic|document, and word|document) can essentially be expressed as a matrix multiplication of the other two, and EM is usually adopted for the optimization. This paper proposes to embed these relationships in a neural network and then optimize the model using SGD.\n\nI believe the paper should be rejected because: 1) most aspects of this paper are a little dated 2) novelty is little 3) experimental section is very limited and unconvincing.\n\nTo elaborate on the experimental section:\n- Only LDA has been presented as baseline. There's plenty of neural topic models to compare against (you mentioned some in your related work section) but no comparison with any of those is presented. If the concern is their training time on large datasets, they should be at least presented as comparison for the smaller datasets. For the large datasets there's other approaches that would scale and should be presented as baselines: 1) train on a sample of the dataset 2) co-occurrence based topic methods on sliding windows of text are extremely fast (eg see \"A Biterm Topic Model\", \"A Practical Algorithm for Topic Modeling with Provable Guarantees\", and \"A Reduction for Efficient LDA Topic Reconstruction\" which could fit your scenario with large datasets where topics most likely have small overlap with each other and are almost separable by anchor words.)\n- Even regarding just LDA: what hyper-parameters \\alpha and \\beta did you set for LDA? Tuning \\beta to a small value might have an impact for large datasets.\n- Metrics: only perplexity is presented and metrics but it's well known that perplexity on its own is quite limited and often is not correlated to human judgment. Consider adding topic coherence measures as well.\n- The section on continuous document embeddings is confusing and the explanation should be improved and the formalism tightened.\n\n\nOther (did not impact the score):\n- Biases: you're adding biases to your probability estimation equations. This is not in line  with the PLSA assumption. What happens if no biases are used?\n\nThe paper has several typos and grammatical errors, e.g.:\n- page 2, L#1: networks -> network\n- page 4, sec 3.2: set unobserved -> set of unobserved\n- page 5, sec 5: pratise -> practice\n- several places: it's -> its\n","sentences":[{"sentence_type":"2","sentence":"I believe the paper should be rejected because: 1) most aspects of this paper are a little dated 2) novelty is little 3) experimental section is very limited and unconvincing.","rephrased":"The paper might benefit from further development in the following areas: 1) updating some of the methodologies to reflect current research trends, 2) enhancing the novelty of the approach, and 3) expanding the experimental section to provide more robust and convincing results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[639,814,"Maybe"],[901,1057,"Missed Maybe"]],"Comments":[]}
{"id":"HJZM5e9eM","text":"Summary\n\nThis article considers neural networks over time-series, defined as a succession of convolutions and fully-connected layers with Leaky ReLU activations. The authors provide relatively general conditions for transformations described by such networks to admit a Lipschitz-continuous inverse. They extend these results to the case where the first layer is a convolution with irregular sampling. Finally, they show that the first convolutional filters can be chosen so as to represent a discrete wavelet transform, and provide some numerical experiments.\n\n\nMain remarks\n\nWhile the introduction seemed promising, and I enjoyed the writing style, I was disappointed with this article.\n\n(1) There are many mistakes in the mathematical statements. First, in Theorem 1.1, I do not think that phi_L \\circ ... \\circ phi_1 \\circ F is a non-linear frame, because I do not see why it should be of the form of Definition 1.2 (what would be the functions psi_n?). For the same reason, I also do not understand Theorem 1.2. In Proof 1.4, the line of equalities after « Also with the Plancherel formula » is, in my opinion, not true, because the L^2 norm of a product of functions is not the product of the L^2 norms of the functions. It also seems to me that Theorem 1.3, from [Benedetto, 1992], is incorrect: it is not the limit of t_n\/n that must be larger than 2R, but the limit of N_n\/n (with N_n the number of t_i's that belong to the interval [-n;n]), and there must probably be a compatibility condition between (t_n)_n and R_1, not only between (t_n)_n and R. In Proposition 1.6, I think that the equality should be a strict inequality. Additionally, I do not say that Proof 2.1 is not true, but the fact that the undersampling by a factor 2 does not prevent the operator from being a frame should be justified.\n\n(2) The authors do not justify, in the introduction, why admitting a continuous inverse should be a crucial criterion of quality for the representation described by a neural network. Additionally, the existence of this continous inverse relies on the fact that the non-linearity that is used is a Leaky ReLU, which looks a bit like \"cheating\" to me, because the Lipschitz constant of the inverse of a Leaky ReLU, although finite, is large, so it seems to me that cascading several layers with Leaky ReLUs could encode a transformation with strictly positive, but still very poor frame bounds.\n\n(3) I also do not understand why having \"orthogonal outputs\", as in Section 2, is really desirable; I think that it should be better justified. Also, there are probably other ways to achieve orthogonality than using wavelets in the first layer, so the fact that wavelets achieve orthogonality does not really justify why using wavelets in the first layer is a good choice, compared to other filters.\n\n(4) I had understood in the introduction that the authors would explain how to define a (good) deep representation for data of the form (x_n)_{n\\in\\N}, where each x_n would be the value of a time series at instant t_n, with the t_n non-uniformly spaced. But all the representations considered in the article seem to be applicable to functions in L^2(\\R) only (like in Theorem 1.4 and Theorem 2.2), and not to sequences (x_n)_{n\\in\\N}. There is something that I did not get here.\n\n\nMinor remarks\n\n- Fourth paragraph, third line: \"this generalization frames\"?\n- Last paragraph before \"Contributions & Organization\": \"that that\".\n- Paragraph about notations: it seems to me that what is defined as l^2(R) is denoted as l^2(Z) after the introduction.\n- Last line of this paragraph: R^d_1 should be R^{d_1}, and R^d_2 R^{d_2}.\n- I think \"smooth\" could be replaced by \"continuous\" (smoothness implies a notion of differentiability).\n- Paragraph before Proposition 1.1: \\sqrt{s} is not defined, and \"is supported\" should be \"are supported\".\n- Theorem 1.1: the f_k should be phi_k.\n- Definition 1.4: \"piece-linear\" -> \"piecewise linear\"?\n- Lemma 1.2 and Proof 1.4: there are indices missing to \\tilde h and \\tilde g.\n- Proof 1.4: \"and finally\" -> \"And finally\".\n- Proof 1.5: I do not understand the grammatical structure of the second sentence.\n- Proposition 1.4: the definition of a RNN is the same as definition 1.2 (except for the frame bounds); I do not see why such transformations should model RNNs.\n- Paragraph before Proposition 1.5: \"in,formation\".\n- Proposition 1.6: it should be said on which space the frame is injective.\n- On page 8, \"Lipschitz\" is erroneously written (twice).\n- Proposition 1.7: \"ProjW,l\"?\n- Definition 2.1: in the \"nested\" property, I think that the inclusion should be the other way around.\n- Before Theorem 2.1, the sentence \"Such Riesz basis is proven\" is unclear to me.\n- Theorem 2.1: \"filters convolution filters\".\n- I think the architecture described in Theorem 2.2 could be clarified; I am not exactly sure where all the arrows start from.\n- First line of Subsection 2.3: \". is always\" -> \"is always\".\n- First paragraph of Subsection 3.2: \"the the\".\n- Paragraph 3.2: could the previous algorithms developed for this dataset be described in slightly more detail? I also do not understand the meaning of \"must solely leverage the temporal structure\".\n- I think that the section about numerical experiments could be slightly rewritten, so that the architecture used in each experiment is clearer. In Paragraph 3.2 in particular, I did not get why the architecture presented in Figure 6 has far fewer parameters than the one in Figure 5; it would help if the authors clearly precised how many parameters each layer contains.\n- Conclusion: \"we can to\" -> \"we can\".\n- Definition 4.1: p_v(s) -> p_v(t).","sentences":[{"sentence_type":"2","sentence":"While the introduction seemed promising, and I enjoyed the writing style, I was disappointed with this article.","rephrased":"Although the introduction was engaging and the writing style was enjoyable, I believe there are several areas in the article that could be improved."},{"sentence_type":"2","sentence":"Additionally, the existence of this continous inverse relies on the fact that the non-linearity that is used is a Leaky ReLU, which looks a bit like \"cheating\" to me, because the Lipschitz constant of the inverse of a Leaky ReLU, although finite, is large, so it seems to me that cascading several layers with Leaky ReLUs could encode a transformation with strictly positive, but still very poor frame bounds.","rephrased":"Furthermore, the reliance on Leaky ReLU for the existence of a continuous inverse raises some concerns. While the Lipschitz constant of the inverse is finite, its magnitude suggests that using multiple layers of Leaky ReLUs might result in transformations with positive but suboptimal frame bounds."},{"sentence_type":"1","sentence":"I also do not understand why having \"orthogonal outputs\", as in Section 2, is really desirable; I think that it should be better justified.","rephrased":"The significance of having 'orthogonal outputs' as mentioned in Section 2 could be more clearly articulated to underscore its importance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[577,688,"Confirmed"],[750,956,"Missed Maybe"],[958,1226,"Missed Maybe"],[1638,1811,"Missed Maybe"],[1997,2406,"Not concerning"],[2412,2551,"Maybe"]],"Comments":[]}
{"id":"iAxDsbcJZXQ","text":"I think the descriptions about the core PKCAM module are unclear and seem to be incorrect. As shown on Page 4,  Y=W\\widetilde(X) and thus Y should be a feature vector with the dimension of RC_0. However, the authors claim that Y is a feature vector with dimension of C_0. Do I miss something? Besides, the authors state to split the function f() into two functions f_1() and f_2(). However, I can not find the definition of f_2(). \n\nThe authors split the PKCAN module into a summation followed by a linear mapping. It can indeed reduce the complexity. But why such simplicity works? More analysis should be provided.\n\nThe authors claim that the module can be easily integrated into different network architectures. However, they merely conduct experiments with the Reset series as baselines. I think the experiments with other architecture s such as mobile net should also be provided. Or the experiments can not support the statements.\n\nMore recent works [1, 2] also adopt channel and spatial attention for feature enhancement. These works should also be included for analysis and comparisons.\n\nI think the work is somewhat a draft for the current version. There are many reference errors throughout the paper, e.g., fig. ?? on Page 3 and fig. ?? on Page 7.\n[1] Hou et al., Coordinate Attention for Efficient Mobile Network Design Coordinate Attention, in CVPR, 2021.\n[2] Zhang et al., ResNeSt: Split-Attention Networks, in arXiv 2020.","sentences":[{"sentence_type":"2","sentence":"I think the work is somewhat a draft for the current version.","rephrased":"The current version of the work appears to be in an early stage and could benefit from further refinement."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,89,"Missed Maybe"],[886,935,"Missed Maybe"],[1096,1157,"Not concerning"]],"Comments":[]}
{"id":"hh9ZWMzN15L","text":"**Originality:**\n\n(positive) The paper has the technical contribution of proposing the novel problem of combinatorial construction and formulating a GNN+RL pipeline for addressing the task. Also, the authors make contributions at 1) designing the action space to make it not growing with the increasing number of bricks during assembly, by defining the action space as a tuple of <pivot brick, offset>; 2) training a neural network to predict if an action is valid or not, to reduce the growing checking time if not using the network.\n\n(negative) However, I have some major concerns regarding the claimed contributions. Firstly, it is weird to claim \"combinatorial construction\" as the novel formulation proposed in this paper, as this is a general term and many previous works [19, 38] are also essentially solving the combinatorial part assembly problem. Secondly, I don't understand the necessity of training a network to predict invalid actions. If checking for O(|A_off|t^2) for an accurate answer is too computationally heavy, can you simply maintain a voxel-grid logging the brick occupancy and adding a new brick is simply a O(1)-time checking?\n\n**Quality:**\n\n(positive) The method design is reasonable, easy to read, and well-stated. The paper conducts a lot of experiments over different datasets. \n\n(negative) I have many concerns regarding the experiments: 1) it seems weird to do the MNIST experiment as MNIST images are 2D shapes. Why using 3D bricks for reconstruction is an interesting task? Also, it seems that you will remove one dimension and only use a 1x2 or 1x4 2D brick to doing a 2D reconstruction, right? 2) The qualitative result for the Table shape in Fig.  6 is pretty bad. Considering that this is the only result shown for Table in the main paper, is this representing your best result? Can you achieve better results than this? Actually, this may slightly exaggerate my concern why using 2x4 bricks as the only primitive is a good choice, given such bad reconstruction quality for real ModelNet shapes? 3) Can you compare to [19, 38] as these two published papers are so related to the task in this work? In my opinion, it should be not impossible to convert them to work with image conditions. Also since your method also uses 3D ground-truth to provide rewards in Eq. 1,  I think the task settings (input\/output\/supervision\/goal) in this paper are quite similar to [19, 38]. I thus think that a fair comparison is necessary to prove the improvement of the proposed method. 4) In table 1, it's weird to put \"AVN\" as a term for comparison. Do previous works not consider invalid overlapping at all? I don't think this is a big point to claim difference. \n\n**Clarity:**\n\nthe paper is overall well-written and easy-to-read. However, the comparison to [19, 38] is not clearly described, in Sec 1\/2\/5. \n\n**Significance:**\n\noverall, I think the claimed contributions are not strong to meet NeurIPS bar, or not well-proven to be necessary. Besides, necessary detailed discussions and experimental comparisons to significantly similar works [19, 38] are missing.\n\n","sentences":[{"sentence_type":"2","sentence":"Firstly, it is weird to claim \"combinatorial construction\" as the novel formulation proposed in this paper, as this is a general term and many previous works [19, 38] are also essentially solving the combinatorial part assembly problem.","rephrased":"Firstly, the term \"combinatorial construction\" seems to be a general concept that has been addressed in various forms by previous works [19, 38]. Could you clarify how the formulation proposed in this paper differs significantly from these prior approaches?"},{"sentence_type":"3","sentence":"The qualitative result for the Table shape in Fig.  6 is pretty bad.","rephrased":"The qualitative result for the Table shape in Figure 6 appears to be suboptimal."},{"sentence_type":"2","sentence":"Actually, this may slightly exaggerate my concern why using 2x4 bricks as the only primitive is a good choice, given such bad reconstruction quality for real ModelNet shapes?","rephrased":"This leads me to question the rationale behind using 2x4 bricks as the sole primitive, especially considering the reconstruction quality for real ModelNet shapes shown."},{"sentence_type":"2","sentence":"overall, I think the claimed contributions are not strong to meet NeurIPS bar, or not well-proven to be necessary.","rephrased":"Overall, I believe that the contributions, as presented, may not sufficiently meet the NeurIPS criteria, or their necessity has not been convincingly demonstrated."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[620,856,"Confirmed"],[1633,1701,"Confirmed"],[1859,2033,"Confirmed"],[2509,2628,"Missed by Model"],[2850,2964,"Maybe"]],"Comments":[]}
{"id":"PSTTIdq8EOf","text":"This paper proposes adding regularization terms to encourage diversity of the layer outputs in order to improve the generalization performance. The proposed idea is an extension of Cogswell's work with different regularization terms. In addition, the authors performed detailed generalization analysis based on the Rademacher complexity. The appearance of the term related to the layer output diversity in the generalization bound provides theoretical support for the proposed idea.\n\nThe main weakness of this paper, in my humble opinion, is the lack of important details or rigor in the experiments presented. For example, the authors didn't mention how the hyperparameter selection was conducted, what optimizer (and its parameters) was used, how many runs per result and the confidence interval, whether any test was done to establish statistical significance, why state-of-the-art architecture was not used for the image classification tasks, etc. Without these important details and rigorous comparison, it's hard to have high confidence in the reproducibility of the results.\n\nDetails:\n1) Intro section. The line of work in \"double descent\" shows that overparameterization doesn't necessarily lead to overfitting. For completeness, it'll be good to mention this line of work and qualify the claim on overfitting.\n2) End of section 2. The authors claim that the proposed diversity term induces \"within-layer\" feedback. The regularization term is computed on the outputs of a layer, which do depend on the parameters of the lower layers. So when backpropagation happens, it will affect the parameters of the lower layers. Therefore, \"within-layer\" feedback doesn't sound accurate to me.\n3) Section 3.1, last bullet point. Should $\\tau$ be introduced here?  Otherwise, where does the $\\tau$ later used in Lemma 3.5, Lemma 3.6 and Theorem 3.7 come from?\n4) Section 5. The proposed regularization terms don't seem cheap to compute for large networks with wide layers. It'll be helpful to measure the training cost increase.","sentences":[{"sentence_type":"2","sentence":"The main weakness of this paper, in my humble opinion, is the lack of important details or rigor in the experiments presented.","rephrased":"One area where the paper could be strengthened is in providing more detailed and rigorous experimental information."},{"sentence_type":"2","sentence":"Without these important details and rigorous comparison, it's hard to have high confidence in the reproducibility of the results.","rephrased":"Including these important details and a rigorous comparison would enhance confidence in the reproducibility of the results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[484,610,"Not concerning"],[952,1081,"Not concerning"],[1626,1689,"Missed by Model"]],"Comments":[]}
{"id":"y22A7C2ixK","text":"Summary:\nThe authors attempt to learn sparse DAGs that explain observational data. In contrast with prior work that considers relaxing the set of graphs to a real space, the authors propose to learn a distribution over graphs via backprop methods on discrete sets. This distribution is learned jointly with a model (here considered linear) that generates the data according to the graph.\nThe loss objective is reconstruction and L1 and NOTEARS regulizers for sparsity and acyclicity.\nFor optimizing the distribution over graphs, the authors consider the straight through estimator and the Implicit-MLE method.\n\nStrength:\n- Gives some insight into which methods do and do not work for this problem.\n\nWeaknesses:\n- The contribution is marginal. The authors experimented with some pre-existing discrete backprop methods on a problem that has previously been addressed by relaxation methods.\n- The proposed method performs worse than the relaxation methods.\n- The authors don't really motivate why relaxation methods are an insufficient\/undesirable solution to the problem.\n- Many important details relegated to the appendix, making the paper hard to read.\n\nConclusion:\nI recommend a borderline accept for this paper. Even though it has some flaws, it may still be interesting for the community to learn which approaches do and do not work on this problem.","sentences":[{"sentence_type":"2","sentence":"The contribution is marginal.","rephrased":"The contribution, while incremental, adds to the existing body of work."},{"sentence_type":"2","sentence":"The proposed method performs worse than the relaxation methods.","rephrased":"The proposed method does not yet outperform the existing relaxation methods in terms of performance."},{"sentence_type":"2","sentence":"The authors don't really motivate why relaxation methods are an insufficient\/undesirable solution to the problem.","rephrased":"The authors could provide a stronger motivation for preferring their method over relaxation methods."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[713,742,"Not concerning"],[890,953,"Not concerning"],[956,1069,"Not concerning"]],"Comments":[]}
{"id":"S1gWju1DFV","text":"Summary: the authors present a simple extension of VAEs (and CoordConv VAEs) and demonstrate through a variety of experiments that the proposed tiling and (1x1) coord-conv solution produces a more disentangled representation. The presentation of detailed ablation studies is helpful in understanding exactly what benefits are brought by 1x1 convolutions vs. upsampling The empirical results are strong and promising, but a few points should be addressed in the final version. \n\nMajor:\n  - The results comparing Spatial Broadcast VAEs to CoordConv VAEs is a pretty critical result and should be moved into the main text from the appendix. Note that this should be present for all experiments, including the ones demonstrating the rate-distortion curves. In addition it would be interesting to contrast the CoordConv VAE with a few upsample layers, followed by 1x1 convolutions (as in the Spatial Broadcast VAE) to see if the effect is mainly from tiling or from the lack of upsampling blocks.\n  - A simple evaluation of disentanglement would be to use a linear classifier on the (mean) posterior sample after the training of the VAE. This would provide a more informative evaluation of (linear) separation in the latent space. This has been done in Associative Compressive Networks by Alex Graves for example. \n\nMinor:\n  - Figure labeling (i.e. a, b) missing on figure 3.\n  - Consistency between letter figure labeling and left\/right.\n  - A4: what is the condition for termination of training? Early Stopping? If so what are the hyper-parameters used there?","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"HkxeVLCAYE","text":"The authors tackle the problem of passage ranking (i.e. given a query, rank the relevance of set of passages to this query), and propose using an interesting combination of two existing approaches: BERT, which has achieved state-of-the-art result on many similar NLP problems, and the weak supervision framework proposed by Ratner et al. (2016). The authors show that this combination obtains results that are better than the current fully supervised state-of-the-art.\n\nOverall, although the different components of this system are not novel, this work seems to have a good contribution as an application paper since the results look good, and the topic is also very relevant to this workshop. However, my most major concern is the comparison with other similar approaches (in terms of methods and results). Specifically, there seems to be a related paper that is not properly discussed, nor fully compared with in terms of results (see my comments below).\n\nStrengths:\n- the problem is very relevant to this workshop.\n- the results look good.\n- the explanations are generally clear and easy to follow.\n\n\nMajor weaknesses:\n- it sounds from the authors' description that the work of Nogueira & Cho (2019)  is very similar, and yet this paper doesn't discuss the similarities in enough detail. For instance \"Nogueira & Cho (2019) does not have an MLP module\" -- so what does it have instead?  Also, do they also do weakly supervised training?\n- why are the results of Nogueira & Cho (2019) not reported in the table (except for one number in the footnote)?\n- the citation for the most similar work is incomplete, it only says \"Rodrigo Nogueira and Kyunghyun Cho. Passage Re-ranking with BERT. 2019.\", with no information where to find it.\n- it's unclear from this paper whether there are other weakly supervised approaches on these datasets, other than the traditional ranking scores the authors used as baseline. If the aren't, that should be specified. If there are, they should be compared and reported in the table too.\n\nMinor issues:\n- authors refer to BM25 scores without ever explaining what they are (e.g. \"models trained on labels solely generated from BM25 scores\"), which can be an issue for anyone who hasn't specifically worked in information retrieval.\n- there are a few grammatical mistakes.\n- why did the authors chose the hidden state of the CLS token as the embedding that is used as input to the MLP?\n- what is s_ij in the \"Supervised Training\" paragraph of section 2?","sentences":[{"sentence_type":"2","sentence":"it sounds from the authors' description that the work of Nogueira & Cho (2019)  is very similar, and yet this paper doesn't discuss the similarities in enough detail.","rephrased":"The authors may want to consider a more detailed comparison with the work of Nogueira & Cho (2019), as their approach appears to be quite similar."},{"sentence_type":"2","sentence":"why are the results of Nogueira & Cho (2019) not reported in the table (except for one number in the footnote)?","rephrased":"It would be beneficial to include the results of Nogueira & Cho (2019) in the table for a comprehensive comparison, as currently only one number is mentioned in the footnote."},{"sentence_type":"1","sentence":"the citation for the most similar work is incomplete, it only says \"Rodrigo Nogueira and Kyunghyun Cho. Passage Re-ranking with BERT. 2019.\", with no information where to find it.","rephrased":"Please provide a complete citation for the work of Nogueira & Cho (2019), including where it can be found, to assist readers in locating it."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1124,1290,"Not concerning"],[1442,1553,"Not concerning"],[1556,1735,"Not concerning"]],"Comments":[]}
{"id":"JF3IaHcgkSd","text":"##########################################################################\n\nSummary:\n\nThis paper proposes a new method and two algorithms for solving kernel k-means. The contribution is that the algorithms converge to the optimal solution. The downsides are 1) the method is not better than a simple baseline (i.e., random features + distributed power method) and 2) the main theorem (Theorem 3) is wrong.\n\n\n##########################################################################\n\nReasons for score:\n\nI vote for rejection for two reasons. First, the proposed method appears not useful. The same problem can be solved in a much simpler and faster way. Second, the main theorem, Theorem 3, is wrong.\n\n\n##########################################################################\n\nPros:\n\n+ This paper develops a new method of distributed kernel k-means. The method is new, although I do not find it very useful.\n\n+ This paper proves that two algorithms can correctly solve the trace-norm regularized problem in Section 4.1.\n\n\n##########################################################################\n\nCons:\n\n1. First and foremost, I do not see a good reason for using the proposed algorithm. The goal of the algorithm is to find the top singular vectors of the random features, $A$.\n\n    - The solution to the trace norm regularized problem, $Z^*$, has the same singular vectors as K. By finding $Z^*$, you can find the eigenvectors of $K$.\n\n    - However, the same goal could be achieved in an easier and less expensive way, i.e., random features + distributed power method. Random features are naturally distributed among the clients. Their truncated SVD could be found by the distributed power method or Krylov subspace methods. Truncated SVD is easier than solved the proposed trace norm regularized problem because the latter uses SVS which repeatedly performs SVD.\n\n2. I am very surprised that Theorem 3 does not reply on $D$ (the number of random features). So I checked some of the proofs. I found Theorem 3, which is the main theorem, is wrong.\n\n    - $Z^*$ has the same top eigenvectors as $\\xi$. But $Z^*$ may not have the same as $K$.\n\n    - The proof of Theorem 3 relies on that $Z^*$ has the same eigenvectors as $K$. This is wrong.\n\n\n3. The description of the algorithm is difficult to follow. I’d suggest splitting algorithm description into 3 paragraphs: 1) Client-side computation, 2) server-side computation, and 3) communications.\n\n\n\n\n\nTypos:\n\n17th page: \"The following two lemmas will be used in the proof of Theorem 4.” Do you mean Theorem 3?\n\n##########################################################################\n\nUpdates after discussing with the authors\n\n1. The paper is not very clearly written, and I had misunderstandings. Some of my comments above are not right.\n\n2. However, I will not change my rating. I found the convergence rates stated in the paper are misleading. The paper claims $O(1\/T)$ convergence rate. In fact, this is WRONG. The authors assume the Frobenius and trace norms of $n\\times n$ matrices are CONSTANTS. This is not possible. The norms are $O(n)$. Simple arguments can show $|| \\xi ||_F = G$ is $O(n)$.\n\n3. Based on the right assumption that $|| \\xi ||_F = G = O(n)$, the required number of iterations is $T = O(n^2)$. The algorithm is not communication-efficient. It is more expensive than communicating the $n\\times n$ kernel matrices.\n\n4. After reading my comments, the authors changed their notation from $G$ to $\\gamma$, $C$, $G$, and $H$. They are also Frobenius and trace norms of $n\\times n$ matrices. The authors assume $\\gamma$, $C$, $G$ and $H$ are constants. This is WRONG. They are $O(n)$. \n\n    - For example, if they use the bound of Rahimi and Recht,  then $|| \\xi - K ||_F^2 = G^2$ is $O(n^2)$.  A bound as good as $|| \\xi - K ||_F^2 = O(n)$ would surprise me; if the authors know such a bound, please let me know. \n\n    - Let me strengthen my point again: IT IS WRONG TO ASSUME MATRIX NORMS ARE CONSTANTS! If the authors can prove they are constants, they need to show me the proofs. If they cannot, they should assume Frobenius norm and trace norm are $O(n)$.\n\n\n\n","sentences":[{"sentence_type":"2","sentence":"First, the proposed method appears not useful.","rephrased":"First, the utility of the proposed method is not clear when compared to simpler existing solutions."},{"sentence_type":"2","sentence":"The method is new, although I do not find it very useful.","rephrased":"The method is novel, but its practical advantages over existing methods are not evident."},{"sentence_type":"2","sentence":"First and foremost, I do not see a good reason for using the proposed algorithm.","rephrased":"First and foremost, the justification for using the proposed algorithm over simpler alternatives is not adequately addressed."},{"sentence_type":"1","sentence":"I am very surprised that Theorem 3 does not reply on $D$ (the number of random features).","rephrased":"It is unexpected that Theorem 3 does not depend on $D$ (the number of random features), which warrants further clarification."},{"sentence_type":"3","sentence":"Let me strengthen my point again: IT IS WRONG TO ASSUME MATRIX NORMS ARE CONSTANTS!","rephrased":"To emphasize my point, it is incorrect to assume that matrix norms are constants without proper justification."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[542,588,"Confirmed"],[852,909,"Confirmed"],[1110,1190,"Maybe"],[1874,1963,"Not concerning"],[3060,3080,"Missed Maybe"],[3627,3640,"Missed by Model"],[3896,3979,"Confirmed"]],"Comments":[]}
{"id":"WYdzxYS1_Tt","text":"The paper describes a two-stage generative image model: first, a GAN is trained to output low-resolution images, and another model to then perform single-image superresolution on the results of the first model. The claim is that the resulting model is slightly better than BigGAN-512 using half the compute requirements, in terms of FID. Two variants are described: one that generates in the wavelet decomposition domain (-W), and another that operates in pixel space (-P).\n\nThe idea of applying SISR to a GAN output seems potentially novel and useful, but as it stands, I find the paper convoluted and lacking a clear message. I cannot recommend acceptance at this point.\n\nThe main issues I see are the following:\n\n1. I suspect much of the image processing is performed incorrectly, casting doubt on the validity of the -P model and rendering the comparison to the wavelet case moot.\n2. Results are only reported in numeric form as FID and IS.\n3. The argumentation about the properties of the wavelet decomposition seem vague and without clear technical counterparts in the (well-developed) literature on wavelets and image processing.\n4. Simultaneous lack of details and overall verbosity; I find it difficult to find the big picture from this paper even after hours of trying.\n\n\n1. I believe the bilinear downsampling, the basis of the -P variant, is implemented incorrectly. This is visible as clear aliasing in the supplemental Figure 2, rightmost “pixel-space” column. To verify, I extracted the dog and sailboat images from the PDF and applied bilinear downsampling in Matlab – which uses proper pre-filtering before downsampling to remove aliases, unlike for instance the bilinear grid_sample operation in PyTorch – and get a significantly different result; one that does not have the signature aliasing artifacts that remain in the images shown. If, on the other hand, I explicitly turn off antialiasing, the result quite closely matches the right-hand column. To be clear, this a rudimentary mistake in image processing (which is surprisingly prevalent in the ML and vision literature).\n\nThis makes me suspect all results of the -P variants are not to be trusted: teaching a GAN to generate aliased images, and then another model to up-res those aliased images, seems like a task that is fundamentally harder than if the aliasing wasn’t there. Hence the worse results are not unexpected.\n\nIn particular: I find the conclusions drawn from the results in Table 1 all potentially invalid.  On the other hand, using pretrained samplers, the pixel space versions appear to actually do a little *better* (in terms of FID) than the wavelet ones in Table 2. Comparing the results in the appendix does not appear to reveal large differences.\n\n\n2. It is well known that metrics like FID and IS do not capture the notion of the quality of a GAN well. They are useful in drawing a picture of how the model performs. While some metrics that better correlate with result quality are known, a satisfactory one hardly exists, so visual inspection and analysis of the results cannot be skipped. I do not approve of pushing them to the appendix.\n\n3. Example: \"The functional prior imposed by our deterministic encoder leads to a highly structured representation space made up of low frequency TL patches of images.” What does this mean, precisely? The repeated application of the wavelet approximation coefficient filter followed by decimation by 2 is equivalent to a particular linear downsampling operation applied to the original image; a poor one at that, because the kinds of critically sampled wavelets employed here are known for their aliasing issues (which has long ago led to a preference of using overcomplete bases). Similar language about the “structuredness” of the wavelet representation can be found near Figure 2, where the pixel-space comparison is, I believe, incorrect, as I detail above.\n\n4. What precisely is going on with Equation 2? IWT(…) would appear to be a reconstruction operation that combines the approximation and detail coefficients into an image of 2x the size, in pixel space; then addition of f(W^l_1,1) seems to add hallucinated detail on top. Does f do anything random or is it deterministic? And more pressingly, how is this actually different from the pixel-space version..?\n\nI do not understand the paragraph 3.1.2 “U-Net decoder”. Why “does [it] not take full advantage of the compression that wavelet space modeling brings about”? \n\n","sentences":[{"sentence_type":"2","sentence":"I cannot recommend acceptance at this point.","rephrased":"I believe further revisions are necessary before I can recommend acceptance."},{"sentence_type":"2","sentence":"I suspect much of the image processing is performed incorrectly, casting doubt on the validity of the -P model and rendering the comparison to the wavelet case moot.","rephrased":"There are concerns regarding the image processing methods used, which may affect the validity of the -P model and the comparison with the wavelet case. Further clarification and validation are needed."},{"sentence_type":"2","sentence":"Simultaneous lack of details and overall verbosity; I find it difficult to find the big picture from this paper even after hours of trying.","rephrased":"The paper could benefit from a clearer presentation of the main concepts and a more concise explanation to help readers grasp the big picture more easily."},{"sentence_type":"2","sentence":"This makes me suspect all results of the -P variants are not to be trusted: teaching a GAN to generate aliased images, and then another model to up-res those aliased images, seems like a task that is fundamentally harder than if the aliasing wasn't there.","rephrased":"The presence of aliasing in the -P variant results raises concerns about their reliability. It would be beneficial to address this issue to ensure the robustness of the model's performance."},{"sentence_type":"2","sentence":"I do not approve of pushing them to the appendix.","rephrased":"I would recommend including the metrics like FID and IS in the main text rather than the appendix to provide a more comprehensive evaluation of the model's performance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[628,672,"Not concerning"],[719,884,"Not concerning"],[1140,1279,"Confirmed"],[2098,2172,"Missed by Model"],[2399,2494,"Missed by Model"],[3088,3137,"Not concerning"]],"Comments":[]}
{"id":"9e3A3rYtvNP","text":"Strength\n    The paper introduces new condition TGM for value deposition MARL,and the reviewer thinks that this condition should continue to be discussed in the value deposition method. The experiment for ablation study shows their claim well, and the performance of the proposed method GVR is shown to be outperformed than the state-of-the-art value decomposition methods in various experimental environments.\n\n    Weaknesses\n    1. In the paper, the authors used true $Q$ function and joint $Q$ value function, but reviewer doesn't find the definition of joint $Q$ value function. What is the difference between joint $Q$ value function and true $Q$ function?.\n    \n    2. In the equation (3), the authors expressed the utility function as true $Q$ function. If joint $Q$-value function is used for equation (3) instead of true $Q$ function, then the equation is true. However, the author use true $Q$ function and reviewer doesn't understand how to derive the equation (3). Some more explanations are needed\n    \n    3. In Appendix D and E, the authors prove their claim, but I couldn't follow the process of proof. How can the author express the utility function as equation (13) in appendix D? The reviewer doesn't understand how mapping $f$ occurs. Therefore, more explanation is needed to understand equations 13 and 18\n    \n    4. Finally, the authors madeThe author proposes a new additional condition for value decomposition in MARL, True-Global-Max (TGM) condition, which is reasonable in some respects, but the reviewer believe that in the proof of the author's claim, there are lots of explanation to understand. Thus, if the author can solve the above mentioned questions, the reviewer will raise the score. target of critic $V(s)$ as equation (9), but there is no explanation of why that can happen. You need explanation of reason for target of critic.","sentences":[{"sentence_type":"2","sentence":"but I couldn't follow the process of proof.","rephrased":"The process of the proof was not clear to me, and I would appreciate further clarification to follow the author's reasoning."},{"sentence_type":"2","sentence":"but the reviewer believe that in the proof of the author's claim, there are lots of explanation to understand.","rephrased":"I believe that the proof of the author's claim could benefit from a more detailed explanation to enhance understanding."},{"sentence_type":"2","sentence":"You need explanation of reason for target of critic.","rephrased":"It would be helpful if the authors could provide an explanation for the rationale behind the target of the critic."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1075,1118,"Not concerning"],[1515,1625,"Not concerning"],[1815,1867,"Not concerning"]],"Comments":[]}
{"id":"SJeeDkc227","text":"This paper presents an approach to multi-modal imitation learning by using a variational auto-encoder to embed demonstrated trajectories into a structured latent space that captures the multi-modal structure. This is done through a stochastic neural network with a bi-directional LSTM and mean pooling architecture that predicts the mean and log-variance of the latent state. This is followed by a state and action\/policy decoder (both LSTMs) that recursively generate trajectories from latent space samples. The entire model is trained by optimising the ELBO on a set of pre-specified expert demonstrations. At test time, samples are generated from the latent space and recursively decoded to generate state and action trajectories. The method is tested on three low-dimensional continuous control tasks and is able to learn structured latent spaces capturing the modes in the training data as well as generating good trajectory reconstructions.\n\nLearning from multi-modal demonstration data is an important sub-area in imitation learning. As the paper pointed out, there has been a lot of recent work in this area. A lot of the ideas in this paper are similar to those proposed in prior work -- the network for embedding the trajectory is similar to the ones from Wang et al & Co-Reyes et al with the major difference being in the structure of the action decoder (and what inputs to encoder). Also, prior work has dealt with problems that are high-dimensional (Wang et al) and has shown results when operating directly on visual data (InfoGAIL). Comparatively, the results in this paper are on toy problems. \n\nAs there is no direct comparison to prior work provided in the paper, it is hard to quantify how much better the proposed approach is in comparison to prior work. For example, the \"2D Circle Example\" was taken from the InfoGAIL paper. It would have been good to use that as a baseline example to compare those two methods and highlight the advantages of the proposed approach -- did it require less data? fewer environment interactions? etc. \n\nThe results on the Zombie Attack Scenario seem poor. Specifically, in the avoid scenario, the approach seems to fail almost half the time. It would be good if the authors spend more time on this -- again, a comparison to prior work would establish some baselines and give us a good idea of the expected performance on this scenario. The videos show a single representative example for the \"Attack\" and \"Avoid\" scenarios. More examples including failures need to be included so that the distribution of results can be captured. \n\nThere is little in terms of generalisation or ablation studies in the paper. For example, in the Zombie Attack Scenario one could generate data with different zombie behaviours and measure performance on held out behaviours. Similarly, as an ablation, the authors could look at directly predicting actions instead of states & actions (states could be generated through a pre-trained dynamics model).\n\nFigure 6. is hard to parse and could be explained better. No details are provided on the network architecture (number\/size of the LSTM\/fully connected layers), number of demonstrations used, training algorithm, hyper-parameters etc. \n\nFew typos in the paper: \n  Page 6 - between the animation links 'avoiding' 'region'\n  Fig 7 caption - the zombie but are not in attacking range -> but the zombies are not in the attacking range,\n\nRelevant citations that can be added:\n1) Hausman, K., Chebotar, Y., Schaal, S., Sukhatme, G., & Lim, J. J. (2017). Multi-modal imitation learning from unstructured demonstrations using generative adversarial nets. In Advances in Neural Information Processing Systems (pp. 1235-1245).\n2) Tamar, A., Rohanimanesh, K., Chow, Y., Vigorito, C., Goodrich, B., Kahane, M., & Pridmore, D. (2018). Imitation Learning from Visual Data with Multiple Intentions.\n\nOverall, I find the paper to be incremental and lacking good experimental results and comparisons. The strengths of the paper are not clear and need to be explained and evaluated well. Substantial work is needed to significantly improve the paper before it can be accepted.","sentences":[{"sentence_type":"2","sentence":"Comparatively, the results in this paper are on toy problems.","rephrased":"While the results in this paper are demonstrated on low-dimensional continuous control tasks, it would be beneficial to see how the approach scales to more complex problems."},{"sentence_type":"2","sentence":"The results on the Zombie Attack Scenario seem poor.","rephrased":"The results on the Zombie Attack Scenario suggest there is room for improvement, particularly in the 'avoid' scenario."},{"sentence_type":"3","sentence":"Overall, I find the paper to be incremental and lacking good experimental results and comparisons.","rephrased":"Overall, the paper could be strengthened by providing more robust experimental results and detailed comparisons with prior work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1548,1609,"Confirmed"],[2056,2108,"Not concerning"],[2109,2194,"Missed Maybe"],[3869,3967,"Not concerning"]],"Comments":[]}
{"id":"H4uvtWh_DxW","text":"The paper integrates known techniques such as variational inference and nested importance sampling in an interesting way. The sequential nature of the transformation from a simple sampling density to a complex distribution reminds me of diffusion-based generative models and I would be interested in seeing if this kind of important sampling approach can be useful in that context.\n\nHowever, the proposed approach is rather complicated and the paper fails to show convincing use cases where this complexity is needed. The most obvious use case for the approach is to learn paths for annealed importance sampling. If this were the goal of the authors, the paper should have covered the theory of annealed importance sampling in greater details and compared the new approach with the existing alternatives. The experiment section should have accordingly been focused on comparing the relative performance of different AIS paths in a wide range of relevant inference problems. \n\nIn general, the presentation of the method is too generic. The authors do not commit to any specific transformation operators. The result is a very large family of possible methods, each with very different performances and characteristics. It is really difficult therefore to evaluate the proposed method. \n\nThe experiments are unfocused ad non-systematic. The experiment with multimodal densities is relevant. However, the set of baselines is rather idiosyncratic and it does not represent the current state-of-the-art in density estimation. The experiment with state-space models is interesting but It si in my opinion outside the main scope of the paper. Application of the method to a Bayesian filtering setting introduces several additional complexities that need to be addressed in the body of the paper. I would suggest to cover the filtering application in an independent follow up work. ","sentences":[{"sentence_type":"2","sentence":"However, the proposed approach is rather complicated and the paper fails to show convincing use cases where this complexity is needed.","rephrased":"However, the proposed approach is quite complex, and it would be beneficial for the paper to demonstrate more clearly the scenarios where this complexity adds value."},{"sentence_type":"2","sentence":"It is really difficult therefore to evaluate the proposed method.","rephrased":"Therefore, it would be helpful if the authors could provide more specific examples or case studies to facilitate the evaluation of the proposed method."},{"sentence_type":"2","sentence":"The experiments are unfocused ad non-systematic.","rephrased":"The experiments could benefit from a more focused and systematic approach to enhance their relevance and impact."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[383,517,"Confirmed"],[1217,1282,"Not concerning"],[1285,1333,"Confirmed"],[1388,1518,"Missed by Model"]],"Comments":[]}
{"id":"C7IeCiHt2xm","text":"This paper proposes unifying language reasoning with actions into a single policy. The authors utilize captions in offline training data and propose using captions as well as actions and observations to construct a model that is trained to predict both actions and text captions. The paper presents results showing that this model trained to predict both captions and actions performs better in the BabyAI environment. The paper's strengths include suggesting an interesting modification to existing language-conditioned RL methods and positive initial results. However, the paper's experiments section is not very significant. While initial results appear positive, it would be helpful to see this method tested on more environments. The novelty of this paper is also questionable. The authors do not provide technical analysis as to the differences between their work and the work proposed by Li et al. that they reference in their Related Works section. The method section lacks technical details and theoretical justification that is arguably necessary when studying their proposed architecture, both in sections 4.1 and 4.2.","sentences":[{"sentence_type":"2","sentence":"The paper's experiments section is not very significant.","rephrased":"The paper could benefit from a more comprehensive experiments section to strengthen its findings."},{"sentence_type":"2","sentence":"The novelty of this paper is also questionable.","rephrased":"The paper would be improved by a clearer delineation of its novel contributions, especially in comparison to the work of Li et al."},{"sentence_type":"2","sentence":"The method section lacks technical details and theoretical justification that is arguably necessary when studying their proposed architecture, both in sections 4.1 and 4.2.","rephrased":"The method section would benefit from additional technical details and theoretical justification to fully understand the proposed architecture, particularly in sections 4.1 and 4.2."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[561,626,"Missed by Model"],[735,782,"Confirmed"],[957,1129,"Not concerning"]],"Comments":[]}
{"id":"TbetNRIrCwQ","text":"The paper proposes embedding ferns as an alternative to convolutional layers for deep learning architectures. It departs from standard random ferns and variants in that it is a drop-in replacement and allows for end-to-end training of architectures.\n\nThe abstract is well structured and relatively easy to follow, and overall it can be interesting for MIDL.\n\nWhat is gained from moving from a convolutional layer to a fern? Ultimately it looks like the computational complexity of the proposed layer, and the memory footprint is going to be similar to that of a standard convolutional layer. There are $c_{out}\\times \\text{#ferns} \\times 2^{depth}$ trainable parameters (plus the fixed ones) where a convolutional layer would have at worst, $c_{out}\\times c_{in}\\times k^2$.\nIt is not clear whether there are settings of the depth and number of ferns such that the number of parameters, computational complexity and\/or memory usage will be reduced by an order of magnitude at little cost in performance, since even a depth of $3$ leads to similar number of parameters as a $3\\times 3$ kernel.\n\nIn terms of operations, floating point multiplications from convolutions are replaced by $\\Vert \\, \\cdot \\Vert^2$, which expands one way or the other to similar floating point multiplication or squaring, plus the $tanh$.\n\nWhat is the energy consumption gain attributable to? Also why not report other metrics that relate to computational\/memory complexity?","sentences":[{"sentence_type":"1","sentence":"Ultimately it looks like the computational complexity of the proposed layer, and the memory footprint is going to be similar to that of a standard convolutional layer.","rephrased":"Could you provide more details on how the computational complexity and memory footprint of the proposed layer compare to a standard convolutional layer?"},{"sentence_type":"2","sentence":"It is not clear whether there are settings of the depth and number of ferns such that the number of parameters, computational complexity and\/or memory usage will be reduced by an order of magnitude at little cost in performance, since even a depth of 3 leads to similar number of parameters as a 3x3 kernel.","rephrased":"It would be helpful if the paper could explore whether certain settings of the depth and number of ferns could significantly reduce the number of parameters, computational complexity, and\/or memory usage without substantially impacting performance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[424,591,"Not concerning"]],"Comments":[]}
{"id":"Oe2P2CXCcPD","text":"The authors propose using pre-trained large language models (LLMs) to hypothesize an abstract world model for embodied RL agents. The RL agent uses this abstract world model to guide its exploration. The method, DECKARD, operates in two phases: 1) the Dream phase, where the LLM suggests subgoals, and 2) the Wake phase, where the agent verifies or corrects its model based on its experience. Unlike other LLM for RL papers, this work uses LLMs only to propose a world model but uses its own grounded experience to learn from. The authors present this work in the context of item crafting in Minecraft and they use OpenAI Codex as the pre-trained LLM.\n\nThe writing is very clear and the limitations of the method are discussed. The method is simple and effective. Large language models take tremendous computing and data resources to train; the potentially valuable knowledge in them about what information to inquire about and how to complete tasks can benefit RL agents. This makes this paper a relevant submission for this workshop.\n","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"H1lHgrse9S","text":"The paper considers the problem of training black box models for improved interpretability, and  proposes to penalize black-box models at training time using two regularizers that correspond to fidelity and stability explanation metrics. As computing the regularizers exactly is computationally intensive they propose two approximating algorithm. In addition, as the one for fidelity is still prohibitive, a randomized variant is proposed. Connections are established between the regularizers and the model's Lipschitz constant or total variation. A generalization bound is presented for local linear explanations. The proposed approach is evaluated on a variety of datasets. \n\nThe paper deals with an important problem and the exposition is clear.  While regularizing deep learning models is a pertinent  direction, I feel the paper makes a couple of overstatements, and overall I am not fully convinced by the approach and empirical evaluation, as outlined below.\n\n- The paper states \"recent approaches that claim to overcome this apparent trade-off between prediction accuracy and explanation quality are in fact by-design proposals that impose certain constants on the underlying model families they consider\" and that they are addressing this shortcoming. But in fact, the proposed regularizations do exactly the same: they impose certain constraints. Indeed the regularizers encourages models with lower Lipschitz constant or with small total variation across neighborhoods.\n\n- I also find that it is unsurprising that regularizing via fidelity or stability will lead to models with better fidelity\/stability so it's an artificial way to yield \"improved interpretability\" and this is more of an issue because fidelity and stability are kind of proxy metrics to evaluate interpretability.\n\n- It would be important to investigate further the difference between regularization and explanation neighborhoods. This might not be a bad thing which in fact help with generalization. \n\n- Proposition 1 supports algorithm 2, but it is not a given at all that Algorithm 1 will have smaller local variances across neightborhoods and hence might generalize well.  It would be important to proceed with an empirical study of the local variance across neighborhoods for Algorithm 1.\n \n- Computational complexity remains an issue as ExpO-1D-fidelity is performing much worse.\n\n- Comparison against alternative approaches beyond SENN are lacking (e.g. Lee et al 2019, Wang and Rudin,2015 etc).\n \n Overall I feel that more work is needed to convincingly demonstrate the importante of the proposed approach.\n ","sentences":[{"sentence_type":"2","sentence":"While regularizing deep learning models is a pertinent  direction, I feel the paper makes a couple of overstatements, and overall I am not fully convinced by the approach and empirical evaluation, as outlined below.","rephrased":"While the direction of regularizing deep learning models is pertinent, there are aspects of the paper, such as some claims and the empirical evaluation, that could be further strengthened to enhance the paper's convincingness."},{"sentence_type":"2","sentence":"I also find that it is unsurprising that regularizing via fidelity or stability will lead to models with better fidelity\/stability so it's an artificial way to yield \"improved interpretability\" and this is more of an issue because fidelity and stability are kind of proxy metrics to evaluate interpretability.","rephrased":"It would be beneficial for the paper to address the potential concern that regularizing via fidelity or stability, while expected to improve these metrics, may not necessarily translate to genuinely improved interpretability, especially considering that fidelity and stability are proxy metrics."},{"sentence_type":"1","sentence":"Overall I feel that more work is needed to convincingly demonstrate the importante of the proposed approach.","rephrased":"In conclusion, further work could help to more robustly demonstrate the significance and impact of the proposed approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[750,965,"Confirmed"],[1484,1793,"Not concerning"],[2486,2594,"Not concerning"]],"Comments":[]}
{"id":"S1xc36r03Q","text":"---Below is based on the original paper---\nThis paper presents a framework that allows the agent to learn from its observations, but never follows through on the motivation of experimentation---taking actions mainly for the purpose of learning an improved dynamics model. All of their experiments merely take actions that are best according to the usual model-based or model-free methods, and show that their consistency constraint allows them to learn a better dynamics model, which is not at all surprising. They do not even allow for the type of experimentation that has been done in reinforcement learning for as long as it has been around, which is to allow exploration by artificially increasing the reward for the first few times that each state is visited. That would be a good baseline against which to compare their method.\n\nOverall:\nPros:\n1. Clear writing\n2. Good motivation description.\n\nCons:\n1. Failed to connect presented work with the motivation.\n2. No comparison against known methods for exploration.\n\n\n----Below is based on the revision---\n\nThanks to the reviewers for making the paper much clearer. I have no particular issues on the items that are in the paper. However, subsections 7.2.1 and 7.2.2 are missing.","sentences":[{"sentence_type":"2","sentence":"They do not even allow for the type of experimentation that has been done in reinforcement learning for as long as it has been around, which is to allow exploration by artificially increasing the reward for the first few times that each state is visited.","rephrased":"It would be beneficial if the authors considered including traditional experimentation methods in reinforcement learning, such as exploration by artificially increasing the reward for initial visits to each state, to provide a comprehensive comparison with their method."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[510,764,"Confirmed"]],"Comments":[]}
{"id":"ryxRUPb83X","text":"Authors extends stacked hourglass network with inception-resnet-A mudules and a multi-scale approach for human pose estimation in still RGB images. Given a RGB image, a pre-processing module generates feature maps in different scales which are fed into a set of serial stack hourglass modules each responsible for a different scale. Authors propose an incremental adaptive weighting formulation for each stack-scale-joint. They evaluate proposed architecture on LSP and MPII datasets.\n\npositive:\n- Having an adaptive weight strategy is a necessary procedure in multi-loss functions where cross-validation or manual tuning of fixed weights are expensive. While the weights are functions of the loss, it is not analyzed and evaluated thoroughly, e.g. evolution of weights for each joint-stack-scale. Even it is not given in the section 5.2.1. So it is hard to judge effectiveness of the proposed loss. \n\nnegative:\n- In general experiments section is the most weakness of the paper. I comment some points in the following:\na) Multi-scale image processing is not a novel idea in computer vision and specifically in human pose estimation. The authors have not compared their methods with most recent papers in the literature and I believe the results are not state-of-the-art (see [1] for instance which is a multi-scale approach).\nb) What is the effect of each scale in the results and for each joint? This must be analyzed and shown visually or numerically.\n\n- The number citations is not enough.\n\n- The writing must be improved.\n\noverall:\nRegarding mentioned comments, I believe the paper needs a huge extra effort (both analytically and numerically) to be adequate for publication. Therefore, I recommend rejection.\n\n\n[1] Yang, W., Li, S., Ouyang, W., Li, H., Wang, X.: Learning feature pyramids for human pose estimation. In: ICCV. (2017)","sentences":[{"sentence_type":"2","sentence":"In general experiments section is the most weakness of the paper.","rephrased":"The experiments section could benefit from further development to strengthen the paper."},{"sentence_type":"2","sentence":"I believe the results are not state-of-the-art.","rephrased":"The results could be compared with more recent state-of-the-art methods to better position the paper within the current research landscape."},{"sentence_type":"1","sentence":"The number citations is not enough.","rephrased":"Including additional citations could provide a more comprehensive background and context for the study."},{"sentence_type":"1","sentence":"The writing must be improved.","rephrased":"Improving the clarity and structure of the writing would enhance the overall presentation of the research."},{"sentence_type":"2","sentence":"I recommend rejection.","rephrased":"Given the areas identified for improvement, I suggest major revisions before considering the paper for publication."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[914,979,"Not concerning"],[1134,1325,"Missed Maybe"],[1458,1493,"Not concerning"],[1497,1526,"Not concerning"],[1692,1714,"Not concerning"]],"Comments":[]}
{"id":"ry7VxCKlM","text":"In this paper, the authors consider non-sequential (in the sense that many hyperparameter evaluations are done simultaneously) and uninformed (in the sense that the hyperparameter evaluations are chosen independent of the validation errors observed) hyperparameter search using determinantal point processes (DPPs). DPPs are probability distributions over subsets of a ground set with the property that subsets with more \"diverse\" elements have higher probability. Diverse here is defined using some similarity metric, often a kernel. Under the RBF kernel, the more diverse a set of vectors is, the closer the kernel matrix becomes to the identity matrix, and thus the larger the determinant (and therefore probability under the DPP) grows. The authors propose to do hyperparameter tuning by sampling a set of hyperparameter evaluations from a DPP with the RBF kernel.\n\nOverall, I have a couple of concerns about novelty as well as the experimental evaluation for the authors to address. As the authors rightly point out, sampling hyperparameter values from a DPP is equivalent to sampling proportional to the posterior uncertainy of a Gaussian process, effectively leading to a pure exploration algorithm. As the authors additionally point out, such methods have been considered before, including methods that directly propose to batch Bayesian optimization by choosing a single exploitative point and sampling the remainder of the batch from a DPP (e.g., [Kathuria et al., 2016]). The default procedure for parallel BayesOpt used by SMAC [R2] is (I believe) also to choose a purely explorative batch. I am unconvinced by the argument that \"while this can lead to easy parallelization within one iteration of Bayesian optimization, the overall algorithms are still sequential.\" These methods can typically be expanded to arbitrarily large batches and fully utilize all parallel hardware. Most implementations of batch Bayesian optimization in practice (SMAC and Spearmint as examples) will even start new jobs immediately as jobs finish -- these implementations do not wait for the entire batch to finish typically.\n\nAdditionally, while there has been some work extending GP-based BayesOpt to tree-based parameters [R3], at a minimum SMAC in particular is known well suited to the tree-based parameter search considered by the authors. I am not sure that I agree that TPE is state-of-the-art on these problems: SMAC typically does much better in my experience. \n\nUltimately, my concern is that--considering these tools are open source and relatively stable software at this point--if DPP-only based hyperparameter optimization is truly better than the parallelization approach of SMAC, it should be straightforward enough to download SMAC and demonstrate this. If the argument that BayesOpt is somehow \"still sequential\" is true, then k-DPP-RBF should outperform these tools in terms of wall clock time to perform optimization, correct?\n\n[R1] Kathuria, Tarun and Deshpande, Amit and Kohli, Pushmeet. Batched Gaussian Process Bandit Optimization via Determinantal Point Processes, 2016.\n\n[R2] Several papers, see: http:\/\/www.cs.ubc.ca\/labs\/beta\/Projects\/SMAC\/\n\n[R3] Jenatton, R., Archambeau, C., González, J. and Seeger, M., 2017, July. Bayesian Optimization with Tree-structured Dependencies. In International Conference on Machine Learning (pp. 1655-1664).","sentences":[{"sentence_type":"2","sentence":"I am not sure that I agree that TPE is state-of-the-art on these problems: SMAC typically does much better in my experience.","rephrased":"While TPE is considered state-of-the-art for these problems, it may be beneficial to compare its performance with SMAC, which has shown promising results in similar contexts based on my experience."},{"sentence_type":"2","sentence":"Ultimately, my concern is that--considering these tools are open source and relatively stable software at this point--if DPP-only based hyperparameter optimization is truly better than the parallelization approach of SMAC, it should be straightforward enough to download SMAC and demonstrate this.","rephrased":"Given that these tools are open source and stable, it would be constructive to provide empirical evidence of the superiority of DPP-based hyperparameter optimization over the parallelization approach of SMAC, if applicable."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1603,1778,"Missed Maybe"],[2337,2461,"Not concerning"],[2464,2761,"Not concerning"]],"Comments":[]}
{"id":"8m58lHxobZD","text":"The paper aims to improve contrastive learning for text representation by tackling two challenges: (1) The conventional mutual-information (MI) based objective can results in unstable training due to the sensitivity of KL to changes of representation; (2) contrastive learning could require a large number of negative samples, which is inefficient. For (1), the paper replaces the KL loss with Wasserstain distance; while for (2), the paper selects top-K most difficult negative samples (defined as the nearest neiborhors to the current representations).\n\nThe contrastive learning loss is then used to augment the standard task-specific loss to enhance learning and enable semi-supervised training. Experiments on benchmarks for text classification (GLUE), retrieval, and language modeling show the proposed method improve over standard supervised\/semi-supervised learning.\n\nThe proposed method is intuitive and simple, largely stitching together previous successful techniques (e.g., Wasserstein distance for robustness, hard negative samples, momentum update).\nSection 2.2 gives a nice summary of several core challenges of contrastive learning.\n\nQuestions \/ weaknesses:\n\n1) In section 2.2, is it necessary to introduce v? -- Constrative learning is usually seen as maximizing the MI between input w and representation u, i.e., MI(w, u). Why here MI(v, u), e.g., Eq.(4), is used?\n\n2) I'm a bit surprised that the experiments do not include any comparison with previous contrastive learning methods, but only compared with models without contrastive learning. \nSimilarly, the ablation study only compares results of negative sample sizes (K). It's necessary to include more comparsions to show how much improvement each of the two proposed techniques (Wasserstein distance, hard negative samples) reaches. \n\n3) The caption of Table.2 says \"Results for QNLI, MRPC, and QQP are in the Supplementary Material (SM). \". Yet those results are not included in the suppementary.","sentences":[{"sentence_type":"2","sentence":"The proposed method is intuitive and simple, largely stitching together previous successful techniques (e.g., Wasserstein distance for robustness, hard negative samples, momentum update).","rephrased":"The proposed method builds on established techniques such as Wasserstein distance for robustness, hard negative samples, and momentum update, presenting an intuitive and straightforward approach."},{"sentence_type":"1","sentence":"I'm a bit surprised that the experiments do not include any comparison with previous contrastive learning methods, but only compared with models without contrastive learning.","rephrased":"It would be beneficial for the study to include comparisons with previous contrastive learning methods in addition to models without contrastive learning to better contextualize the results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[875,1062,"Not concerning"],[1386,1560,"Not concerning"]],"Comments":[]}
{"id":"g6-vZf-8_rX","text":"This work focuses on a super interesting idea of combining program synthesis with neural optimization. Specifically suggesting a novel algorithm that combines transforming explicit code into neural weights and transferring these back into code. Thus, representing a very interesting neuro-symbolic approach. The brief experiments provide a good proof of principle. Overall, I believe there are several relevant points within this work concerning this workshop that should contribute to fruitful discussions and exchange of ideas. \nHaving said this I found the paper a little difficult to understand which I attribute to the overall structure of the work. E.g. a clearer introduction and final conclusion and a stronger distinction between motivation, related works and how they differ from this approach would be beneficial. But also smoother transitions between the sections would be beneficial, especially as the page limit still allows for this.","sentences":[{"sentence_type":"1","sentence":"Having said this I found the paper a little difficult to understand which I attribute to the overall structure of the work.","rephrased":"While the paper presents a compelling concept, I believe that improving the overall structure could enhance its clarity and accessibility."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[531,654,"Not concerning"]],"Comments":[]}
{"id":"rHWFzG7L-5","text":"The paper proposes to place a Bayesian prior on the distribution generated by a deep network instead of the traditional approach in Bayesian deep learning, where the prior is placed on the weights.\n\nThe choice of short paper makes the presentation extremely dense, and it is thus very hard to thoroughly evaluate the paper. This goes for both the mathematical developments, and for the correctness of statements such as \"the regularization caused by these prior is not able to calibrate the network output, nor do these priors explicitly make the model under-confident on the OOD samples.\".\n\nHowever, setting the readability aside, I believe the idea pursued in the paper - to define the prior on the output distribution - has merits. The authors develop the variational framework for training the network, define an evaluation criteria (the ECE measure), and validate the model experimentally on skin lesion classification.\n\nOverall, though the paper would certainly benefit from more pages to elaborate on all aspects of the model, and though I cannot fully validate its correctness, I find the paper has potential merit and would be an interesting read for the MIDL audience.","sentences":[{"sentence_type":"2","sentence":"The choice of short paper makes the presentation extremely dense, and it is thus very hard to thoroughly evaluate the paper.","rephrased":"While the concise nature of the paper makes the presentation quite dense, a more detailed exposition could facilitate a more thorough evaluation."},{"sentence_type":"1","sentence":"Overall, though the paper would certainly benefit from more pages to elaborate on all aspects of the model, and though I cannot fully validate its correctness, I find the paper has potential merit and would be an interesting read for the MIDL audience.","rephrased":"Overall, the paper could be enhanced by additional pages to further elaborate on the model's aspects. Despite the limitations in fully validating its correctness, the paper presents promising ideas that could interest the MIDL audience."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[199,323,"Confirmed"],[926,1178,"Not concerning"]],"Comments":[]}
{"id":"pWngULBdEg","text":"The authors propose a recurrent CNN architecture with a new loss inspired from the  mumford shah  \/ chan-vese functional. Doing so, the network learns to maximize the separation between  foreground and  background in a fully unsupervised fashion. With few modifications, the approach is also adapted to the supervised case where segmentation labels are available.  The authors validate the approach on simulated phantom SPECT data. \nThe paper is technically sound and convincing. The idea of bringing the ACWE formalism to deep learning based segmentation is refreshing and in itself is a sufficient contribution to the field that is worth being communicated to the community. \n\nOn the negative side, the validation on simulated data is not very impressive.  Visual results seem to suggest that foreground to background separation is quite easy for this data with almost uniform black background. There are also too many typos for a 3 page paper (avaiable, prposed,..) One could also wonder how well the supervised ACWE loss compare to conventional segmentation losses. ","sentences":[{"sentence_type":"2","sentence":"On the negative side, the validation on simulated data is not very impressive.","rephrased":"While the validation on simulated data provides a good starting point, it would be beneficial to see more complex datasets to fully assess the model's capabilities."},{"sentence_type":"2","sentence":"There are also too many typos for a 3 page paper (avaiable, prposed,..)","rephrased":"The paper would benefit from a thorough proofreading to correct the typos present, which is especially important given the brevity of the manuscript."},{"sentence_type":"1","sentence":"One could also wonder how well the supervised ACWE loss compare to conventional segmentation losses.","rephrased":"It would be informative to include a comparison of the supervised ACWE loss with conventional segmentation losses to highlight the advantages of the proposed method."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[679,757,"Confirmed"],[897,968,"Not concerning"],[969,1069,"Not concerning"]],"Comments":[]}
{"id":"rklPBJyfcr","text":"The study analyzes NFL data to mitigate injuries of NFL players. Methods such as K-NN, XGBoost, and SVM are used for the analysis and predictive modeling.\nAlthough the research is important for NFL and sports industries, there are several problems as an ICLR paper: \nFirst, it is not formatted correctly. I guess using single column, the content may be overlength. Second, the methods used in the paper are conventional and there is no novelty from the algorithmic perspective. Third, the findings is useful within the sports industry, but does not conveys much insight for the ICLR community.\n","sentences":[{"sentence_type":"1","sentence":"First, it is not formatted correctly. I guess using single column, the content may be overlength.","rephrased":"Firstly, please ensure the paper adheres to the ICLR formatting guidelines, as the current single-column format may lead to concerns about content length."},{"sentence_type":"2","sentence":"Second, the methods used in the paper are conventional and there is no novelty from the algorithmic perspective.","rephrased":"Secondly, while the methods used are well-established, it would be beneficial to highlight any novel aspects of their application or to consider incorporating more innovative algorithmic approaches."},{"sentence_type":"2","sentence":"Third, the findings is useful within the sports industry, but does not conveys much insight for the ICLR community.","rephrased":"Thirdly, the findings are certainly valuable for the sports industry; however, it would be advantageous to draw connections to broader computational research themes that resonate with the ICLR community."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[267,364,"Not concerning"],[365,477,"Confirmed"],[478,593,"Not concerning"]],"Comments":[]}
{"id":"Iyir3x3oAJH","text":"The problem is highly relevant, and the promise of having a means of reducing the computational complexity of causal (interventional) queries by obtaining sufficiently close but tractable approximations is very exciting.\n\nHowever unfortunately the paper is extremely vague and implicit about the actual proposed methodology. After spending 5 pages describing known background, theory and other approaches, all in great clarity with some nice examples, the actual description of the contribution itself (p6) is surprisingly vague and without sufficient details to properly assess what is actually proposed or how to reproduce the results (see detailed comments below). \nIn fact, I am unsure whether the goal suggested at the beginning of the paper (‘here is a method that allows to compute interventional distributions from observational data + causal graph using an approximation based on tractable models’) is actually what the paper is about, or whether the main purpose of the paper is  to show that in principle SPNs could be used as tractable approximators of interventional distributions. If the first then I did not find it in the paper, if the second then it is hardly a surprising conclusion. \n\nI am willing to entertain the notion I missed or misunderstood the main contribution of the paper (hence reduced confidence), but all things considered I doubt the paper is suitable for NeurIPS in its current form.\n\noriginality: novel suggestion, though unclear about the details \nquality: poor: there is simply not enough detail to properly assess what is actually proposed and to what extent it makes sense or solves the initial problem statement\nclarity: very clear on background, existing work and general examples (p1-5), but completely unclear when it gets to the actual contribution of the paper\nsignificance: due to the lack of details the paper is unlikely to have significant impact in its current form\n\ndetailed comments:\np1.6 ‘subsuming’ suggests you claim to do it better\np1.23: ‘difficult to scale’ => why would they be? there are CBNs containing thousands to even millions of variables\np1.27: ‘weaving in the notion of interpretability’ => poetic but too vague\np2.36: ‘.. since a bipartite graph ..’ => bit sudden if you are not familiar with that ref.\np2.fig1: explain what the intervention ‘setting lung cancer to B(1\/2)’ means\np2.43: ‘dream of tractable causal models is not insurmountable’ => yes but at what cost ? in general it has to be at best an approximation of the true interventional quantities right?\np2.57: ‘the inductive bias’ => perhaps introduce this first\np2.61-63: point 3. this is far too cryptic at this stage\np3.69: define CSPN before using acronym\np3.105: ‘causal mechanisms do not change through intervention’ => this is not what is meant by the assumption of ‘invariant causal mechanisms’: for example there are interventions corresponding to mechanism change, e.g. adding a catalyst to stimulate\/enable a particular chemical reaction\np4.117: SCMs also allow non-recursive interactions (feedback); in addition not al variables need to be observed\np4.section 3.1: this insight is laudable but is standard common knowledge in the field of causal inference dating back at least to Reichenbach (1931) and before\np4.146: ‘curating’ is perhaps a bit much for generating data from such a tiny toy model …\np5,Fig2: ‘.. conditions on the mutilated causal graph ..’ => please explain better\nalso: figure is a tad small for such a crucial example => try to maximise (space permitting)\n\np5.173: so far we spent 5 pages without introducing anything new …\np6.176: move prefixed bold sentence ‘Definition of iSPN’ to line 184: now this paragraph is very confusing when you think you are finally getting to the ‘meat’ of the paper but then still end up just discussing other work first again\n\np6.185: ‘.. as inout the (mutilated) causal graph..’ => which one is it? the causal graph or the mutilated graph or both? (to be clear: you need both, or at least the original causal graph + target node of intervention)\nidem: this definition (based on an adjacency matrix) does not seem to leave any room for possible unobserved confounders that were deemed so crucial to handle in p4.133?\np6.188, Def.1: this definition should be improved. at the moment there is nothing ‘interventional’ about this definition (even though you may intend to use it as such later). \nalso: ‘shared parameters’ => shared between what?\n\np6.191: being able to ‘answer’ a causal query is meaningless if you cannot provide guarantees about the outcome … and so far we have not seen anything that argues how or why it should be\np6.193: ‘The shared parameters allow for information flow during learning between the conditions and estimated densities’ => sounds great but I have no idea what it means as you have not explained any details yet\n\np6.294, Prop.1: ‘ .. with data D generated from the intervened SCM ..’ => ??? The problem is: we have data D from an unintervened system, and a corresponding causal graph … from this can we predict what will happen when we have intervene on Xi. If you assume you have data corresponding to this intervention the whole problem goes away. Or is this what you suggest to do in the paper: learn the structural equations from the data, set intervened equation to constant X_i = a, and sample new data from this modified system so you can then do standard inference on it given the intervened graph?\n\np6.217+: this is just so vague I have no idea what you are trying to say. Seriously, what does ‘freeing the investigation of iSPN from independent research around hidden confounding’ mean or why should we care?\n\np7.225: ok: here you are apparently learning the iSPN directly from the interventional data … if that is what the paper is about, then I’m afraid it has little new insights to offer … if not then please make sure to describe in detail exactly what you do.\n\np7-9: given that I still have no idea what you actually do or try to do I cannot assess the relevance or validity of the results presented here. This may be due to my lack of understanding (hence reduced confidence), but  tbh I don’t think that is the case here.","sentences":[{"sentence_type":"2","sentence":"However unfortunately the paper is extremely vague and implicit about the actual proposed methodology.","rephrased":"However, the paper could benefit from a more explicit and detailed description of the proposed methodology."},{"sentence_type":"2","sentence":"I doubt the paper is suitable for NeurIPS in its current form.","rephrased":"I believe the paper may require substantial revisions to meet the standards of NeurIPS."},{"sentence_type":"2","sentence":"quality: poor: there is simply not enough detail to properly assess what is actually proposed and to what extent it makes sense or solves the initial problem statement","rephrased":"Quality: The paper would benefit from additional detail to fully assess the proposed solution and its effectiveness in addressing the initial problem statement."},{"sentence_type":"2","sentence":"significance: due to the lack of details the paper is unlikely to have significant impact in its current form","rephrased":"Significance: Providing more details could enhance the paper's potential impact in the field."},{"sentence_type":"2","sentence":"p5.173: so far we spent 5 pages without introducing anything new \n","rephrased":"It would be beneficial if the paper could introduce its novel contributions earlier, as the first five pages primarily review existing knowledge."},{"sentence_type":"2","sentence":"p6.217+: this is just so vague I have no idea what you are trying to say.","rephrased":"The section starting at p6.217 could be clarified to better convey the intended message."},{"sentence_type":"2","sentence":"p7-9: given that I still have no idea what you actually do or try to do I cannot assess the relevance or validity of the results presented here.","rephrased":"The methods and objectives between pages 7-9 could be articulated more clearly to enable an assessment of the results' relevance and validity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[222,324,"Confirmed"],[1356,1418,"Confirmed"],[1485,1652,"Not concerning"],[1807,1916,"Not concerning"],[4262,4384,"Missed by Model"],[4446,4624,"Missed by Model"],[5434,5507,"Confirmed"],[5508,5643,"Missed by Model"],[5903,6047,"Confirmed"]],"Comments":[]}
{"id":"IsihpgDCLMN","text":"The paper presents good writing style and is easy to follow. It devotes however the whole 9 pages to written explanations and a few numeric tables of results, relegating fundamental information such as part of the algorithm and the entire results plots to the appendix. That is right, there is not a single figure in the paper. This is exacerbated by the experimental results being presented as 6 (six!) purely numerical tables accounting for roughly 3 full pages, with minimal discussion and almost absent captioning, which makes the experimental evaluation unnecessarily hard to assess. The contributions presented are themselves limited, which does not support this choice of presentation. Before I can vouch for its publication, I would require the authors to present the results in a more readable way which does not rely on Appendix material for interpretation or reproducibility.\nFrom a more technical perspective, the paper offers limited support for its arguments. Its main contributions are (i) a rule-based tree simplification method including both algebraic and pruning techniques, and (ii) an archive-based restart strategy.\nHowever, neither contribution is compared in the experimental results against the current state of the art, but only against standard GP. This offers a limited insight on its relative advantage, but no clear perspective to the method's actual applicability and utility.\n\nMain questions that need to be addressed by the authors (in the paper and with experimental results) prior to considering this work ready for publication:\n- What is the practical, empirical difference between the literature method of simplification with removal and the proposed substitution with an operation-neutral constant? I.e., what is the difference between removing a sub-tree from a node with e.g. a multiplication operator, and substituting it with a constant-one (1) leaf?\n- The pruning procedure accepts an arbitrary 15% degradation in fitness on the simplified tree, before looping on itself. In your experiments, is the 15% degradation a global budget over successive loops (i.e. the final simplified tree cannot be worse than 15% on the original tree) or a per-loop limit (which leads to a compounding effect as the solution can worsen by 15% per iteration)?\n- Can you highlight and discuss the performance degradation as depicted above across the Results tables? How did you come up with 15%? Is this hyperparameter robust to small variations?\n- Only aggregated final performance is presented, which limits our understanding of the learning process over time. Please include a standard plot of performance improvement over time for all methods.\n- A budget of 500'000 individuals is significant, especially on a low-dimensional benchmark of limited complexity, and with a mutation rate of 30%. How do the standard GP and your contribution fare against random guessing? I would expect a baseline of generating 500'000 individuals, and include the performance of the best-so-far over time in the comparison.\n- Figures 1 and 2 (Appendix) lack any discussion or interpretation. For example, what is happening with Nguyen 5 and 6 in Figure 2? Why the high variance for everyone but 0 for SubTreeInit? The paper lacks a proper discussion at this stage.\n- How does this technique stand against standard restart strategies? What about niching, as each run could be considered as a niche for the final restarted run? They are entirely missing from the literature review. Moreover, the global consensus on evaluating restart strategies is to maintain a standard useful budget of individual evaluation constant for all method, with the restart being able to reset as many times as seen fit. Instead the current experiments only restart once, and for \"fairness\" doubles the available fitness evaluations from 500'000 to 1'000'000 evaluations. What if the standard GP reaches convergence by 400'000? How would this be fair?\n- Building on that, it is clearly stated (Section 4.2) that the limit for convergence is 25'000 evaluations without improvement: assuming this means early termination if convergence is detected (as usual), what is the budget actually used by GP vs. the proposed contribution over the 50 runs?\n\nMinor points:\n- It is part of the authors' responsibilities to recognize which results are most compelling for their arguments and present those in a more digestible form. The corresponding plots from the Appendix should be moved to the main text. The full results tables could instead be moved to the Appendix.\n- In Section 5.2, I would relax the claim of \"it is evident that [...] improves the overall results\" from a qualitative statement to a quantitative statement (measured performance increase).\n- In Section 5.3 you mention \"a single constant node that is obtained after simplification\". Section 3.3 however states the minimal heights for trees being 2 after simplification. I believe this may be a misunderstanding, but it shows how the exposition is perceived as unnecessarily complicate, and a requirement for all data required for reproducibility to be found in a single place in a clear format (which I propose being another requirement for acceptance).","sentences":[{"sentence_type":"2","sentence":"The contributions presented are themselves limited, which does not support this choice of presentation.","rephrased":"While the contributions are modest, a clearer presentation could enhance their perceived value and support their significance."},{"sentence_type":"2","sentence":"However, neither contribution is compared in the experimental results against the current state of the art, but only against standard GP. This offers a limited insight on its relative advantage, but no clear perspective to the method's actual applicability and utility.","rephrased":"To provide a comprehensive evaluation, it would be beneficial if the contributions were compared with the current state of the art in addition to standard GP, thereby offering a clearer perspective on the method's applicability and utility."},{"sentence_type":"2","sentence":"The paper lacks a proper discussion at this stage.","rephrased":"The paper would benefit from a more thorough discussion at this stage to clarify the results and their implications."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[270,327,"Missed Maybe"],[589,692,"Not concerning"],[1138,1407,"Not concerning"],[3220,3270,"Maybe"]],"Comments":[]}
{"id":"Kl_QO5GxJqm","text":"Summary:\nThe authors propose a method for latent domain learning, where input data come from different domains and the domain labels are unknown. The proposed method consists of two parts: dynamic residual adapter and weighted domain transfer. The dynamic residual adapter acts as a mixture of expert layer. And the weighted domain transfer which augments the dataset by interpolating between different input pairs. Empirical results show that when combined together, the proposed method perform better than training a regular model.\n\nPros:\n1. Latent domain discovery is a very interesting topic. \n2. Empirical results show that the method brings improvement to minority domains.\n\nCons:\n1. Maybe I missed something, but I don't there are new insights in the paper. The proposed dynamic residual adapter is just an instance of MoE [1] with adapters, which I think should be a baseline in the experiments.\n2. \"Section 3.4 Weighted Domain Transfer\" is not well-motivated and very confusing. Here you want to interpolate between x_i and x_j. But why do you compute the difference between the input x_i and the feature \\mu_i in equation 3? Are they comparable with each other? What is the goal that you want to achieve here?\n\nOther comments:\n1. I think the introduction describes the problem too much, leaving it no space to expand your idea and intuition. For example, you start describing your idea at the very last paragraph.\n2. When creating the augmented examples, can you leverage the gate information that you produced from the MoE?\n3. It will be more helpful to understand the DRA component if you can provide PCA over the original activations.\n\n\n[1] OUTRAGEOUSLY LARGE NEURAL NETWORKS: THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER","sentences":[{"sentence_type":"2","sentence":"Maybe I missed something, but I don't there are new insights in the paper.","rephrased":"I may have overlooked something, but it seems that the paper could benefit from highlighting more novel insights, particularly in relation to the dynamic residual adapter."},{"sentence_type":"2","sentence":"\"Section 3.4 Weighted Domain Transfer\" is not well-motivated and very confusing.","rephrased":"The motivation behind 'Section 3.4 Weighted Domain Transfer' could be made clearer, and the section might benefit from additional explanation to avoid confusion."},{"sentence_type":"1","sentence":"I think the introduction describes the problem too much, leaving it no space to expand your idea and intuition.","rephrased":"The introduction could be more concise, allowing more space to elaborate on your ideas and the underlying intuition of your approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[690,764,"Confirmed"],[907,987,"Confirmed"],[1240,1351,"Maybe"]],"Comments":[]}
{"id":"H1yqn7qlM","text":"Summary\nThis paper proposes a prototype matching network (PMN) to model transcription factor (TF) binding motifs and TF-TF interactions for large scale transcription factor binding site prediction task. They utilize the idea of having a support set of prototypes (motif-like features) and an LSTM from the few shot learning framework to develop this prototype matching network. The input is genomic sequences from 14% of the human genome, each sequence in the dataset is bound by at least one TF. First a Convolutional Neural Network with three convolutional layers is trained to predict single\/multiple TF binding. The output of the last hidden layer before sigmoid transformation is used as the LSTM input. A weighted sum of similarity score (sigmoid of cosine similarity, similar to attention mechanism of LSTMs) along with prototype vectors are used to update the read vector. The final output is a sigmoid of the final hidden state concatenated with the read vector. The loss function used is difference of a cross-entropy loss function and a lambda weighted prototype loss function. The latter is the mean square error between the output label and the similarity score.  The authors compare the PMN with different lambda values with CNN with single\/multi-label and see marginal improvement in auROC, auPR and Recall at 50% FDR with the PWM. To test that PWN finds biologically relevant TF interactions, the authors perform hierarchical clustering on the prototypes of 86 TFs and compare the clusters found to the known co-regulators from the TRRUST database and find 6 significant clusters. \n\n\nPros:\n1. The authors utilize the idea of prototypes and few shot learning to the task of TF-binding and cooperation. \n\n2. Attention LSTMs are used to model label interactions. \n\nJust like CNN can be related to discriminative training of PSSM or PWM, the above points demonstrate nicely how ideas\/concepts from the recent developments in DL can be adopted\/relate (and possibly improve on) to  similar generative modeling approaches used in the past  for learning cooperative TF binding.\n\nCons:\n\n1. Authors do not compare their model’s performance to the previously published TF binding prediction algorithms (DeepBind, DeepSEA). \n2. The authors miss important context and make some inaccurate statements: TF do not just “control if a gene is expressed or not” (p.1). It’s not true that previous DL works did not consider co-binding. Works such as DeepSea combined many filters which can capture cooperative binding to define which sequence is “regulated”. It is true this or DeepBind did not construct a structure a structure over those as learned by an LSTM. The authors do point out a model that does add LSTM (Quang and Xie) but then do not compare to it and make a vague claim about it modeling interactions between features but not labels (p. 6 top). Comparing to it and directly to DeepSee\/Bind seems crucial to claim improvements on previous works. Furthermore, the authors acknowledge the existence of vast literature on this specific problem but completely discard it as “loose connection to our TFBS formulation”. In reality though, many works in that area are highly relevant and should be discussed in the context of what the authors are trying to achieve. For example, numerous works by Prof. Saurabh Sinha have focused specifically on joint TF modeling (e.g. Kazemian NAR 2011, He Plos One 2009, Ivan Gen Bio 2008, MORPH Plos Comp Bio 2007). In general, trying to lay claims about significant contributions to a problem, as stated here by the authors, while completely disregarding previous work simply because it’s not in a DL framework (which the authors are clearly more familiar with) can easily alienate reviewers and readers alike.  \n\n3. The learning setup seems problematic:\n3a. The model may overfit for the genomic sequences that contain TF binding sites as it has never seen genomic sequences without TF binding sites (the genomic sequences that don’t have CHIP peaks are discarded from the dataset). Performance for genome wide scans should definitely include those to assess accuracy.\n3b. The train\/validation\/test are defined by chromosome. There does not seem to be any screening for sequence similarity (e.g. repetitive sequences, paralogs). This may inflate performance, especially for more complicated models which may be able to “memorize” sequences better. \n4. The paper claims to have 4 major contributions. The details of second claim that the prototype matching loss learns motif like features is not explained anywhere in the paper. If we look at the actual loss function equation (12), it penalizes the difference between the label and the similarity score but the prototypes are not updated. The fourth claim about the biological relevance of the network is not sufficiently explored. The authors show that it learns co-bindings already known in the literature which is a good sanity check but does not offer any new biological insight.  The actual motifs or the structure of their relations is not shown or explored.\n5. PWN offers only marginal improvement over the CNN networks \n\n","sentences":[{"sentence_type":"2","sentence":"The authors miss important context and make some inaccurate statements: TF do not just \\","rephrased":"The authors could provide a more nuanced discussion of TF functions beyond the binary expression control, as TF roles are more complex and have been explored in various contexts."},{"sentence_type":"1","sentence":"In reality though, many works in that area are highly relevant and should be discussed in the context of what the authors are trying to achieve.","rephrased":"It would be beneficial for the authors to consider and discuss the existing literature in this field, as there are many relevant studies that could provide valuable context for their work."},{"sentence_type":"2","sentence":"Furthermore, the authors acknowledge the existence of vast literature on this specific problem but completely discard it as \\","rephrased":"The authors might strengthen their paper by acknowledging and integrating insights from the extensive literature on this topic, which could provide a more comprehensive background for their study."},{"sentence_type":"3","sentence":"while completely disregarding previous work simply because it's not in a DL framework (which the authors are clearly more familiar with) can easily alienate reviewers and readers alike.","rephrased":"It is important for the authors to consider previous work in a broader context, not limited to deep learning frameworks, to ensure a comprehensive review and to engage a wider audience effectively."},{"sentence_type":"1","sentence":"The paper claims to have 4 major contributions. The details of second claim that the prototype matching loss learns motif like features is not explained anywhere in the paper.","rephrased":"The paper could be improved by providing a clearer explanation of how the prototype matching loss contributes to learning motif-like features, as this is listed as one of the major contributions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2659,2853,"Missed by Model"],[3123,3267,"Not concerning"],[4393,4568,"Confirmed"]],"Comments":[]}
{"id":"eV87eE1nQV","text":"**Overview**\n\nThe paper presents a novel Bayesian framework, ABCI, to integrate causal discovery and reasoning, which in prior works are addressed separately. The authors introduce the notion of a causal query that subsumes causal discovery, causal model learning and causal reasoning. The query posterior can then be computed to achieve the learning objective. In addition, the framework proposes actively collecting interventional data at each time step by first inferring a maximally informative intervention and then performing this intervention on the *true* causal model. The proposed approach is evaluated using simple data-generating processes and compared against baselines of collecting 1. observational data and 2. performing random interventions.\n\n**Strengths**\n\nIntegrating causal discovery and reasoning is an important challenge and this paper presents a novel and principled approach to tackle it. Taking a Bayesian approach allows a natural and intuitive way to actively infer the best intervention to perform in each interation. The experimental results, although on a simple synthetic dataset, demonstrate the effectiveness of ABCI.\n\n**Weaknesses**\nA more thorough discussion on the restricted class of causal models for which the marginalization needed is computationally feasible would be useful. Also, the scalability of this approach needs to be addressed. Experiments on more complex data-generating processes might help in this regard.\n\nMinor comment: The labels for the graphs in figure 3 seem to be missing.\n\nOverall, this approach seems promising and potentially extensible to a wider class of causal models.","sentences":[{"sentence_type":"1","sentence":"A more thorough discussion on the restricted class of causal models for which the marginalization needed is computationally feasible would be useful.","rephrased":"It would be beneficial to include a more detailed discussion on the specific class of causal models where the required marginalization is computationally feasible."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1168,1317,"Not concerning"]],"Comments":[]}
{"id":"P0owHqDTE","text":"This short paper proposes a method for classification of glioma grade, IDH mutation, and 1p19q co-deletion, and trains\/evaluates it on a fairly large dataset. The method also performs a segmentation, using a standard 3D U-Net trained on BraTS 2019 training data, with dropout on MRI sequences, to make the network robust to missing sequences in the application phase. \nStrengths:\n- A reasonable sized test set (100 patients).\n- The pipeline seems engineered well.\n- The classification accuracies are quite high.\nWeaknesses:\n- It is not clear how the tumor segmentation is exactly used in the classification network. Do you only use it to define a bounding box for the region of interest? Or do you mask the original image and set all pixels outside the segmentation to zero, for example?\n- Section 3: \"For 1p19q status we only included LGG cases\" -> it's not clear whether you did this for the train or test set, or both. \n- Confidence intervals should be given for the classification results in Table 1.\n- Too many decimals are given in Table 1. \n- Section 1: the relation to this work also could be discussed: https:\/\/www.ncbi.nlm.nih.gov\/pubmed\/31548344\n","sentences":[{"sentence_type":"1","sentence":"The pipeline seems engineered well.","rephrased":"The design of the pipeline appears to be thoughtfully engineered."},{"sentence_type":"2","sentence":"Too many decimals are given in Table 1.","rephrased":"Consider reducing the number of decimal places in Table 1 for better readability."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[428,463,"Not concerning"],[1007,1046,"Not concerning"]],"Comments":[]}
{"id":"Sygj1wxNq4","text":"The paper presents a framework to unify different Maximum-entropy inverse RL methods and to compare them with Behaviour Cloning (BC). Specifically, the paper is motivated by the question of why BC performs significantly worse than Maximum-Entropy IRL in the small data regime. The authors hypothesise that the reasons are (i) that BC tries to model conditional policies while other approaches try to match also state marginals and (ii) due to the moment matching properties of BC as opposed to  mode seeking divergences that can better match expert policies to learning policies.  \n\nI believe that the paper presents an interesting unified framework based on f-divergences together with some novel modifications of previous methods. The experiments on continuous optimal control support to some extend the theoretical analysis of the paper. However, a more extensive experimental comparison is needed to draw more clear conclusions.   \n","sentences":[{"sentence_type":"1","sentence":"However, a more extensive experimental comparison is needed to draw more clear conclusions.","rephrased":"To strengthen the findings, a more extensive experimental comparison could help in drawing clearer conclusions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[841,932,"Not concerning"]],"Comments":[]}
{"id":"rJg8QSNJ9S","text":"The paper suggests that one common problem encountered by reinforcement learning algorithms in open environments is \"data confusion\", which essentially means showing the same input data with different --possibly contradictory-- labels\/targets.\n\nThe proposed solution to this conceptual problem is to split the original MDP \"M\" up into multiple simpler MDPs \"Mk\", where M does contain possibly contradictory (\"confusing\") data, while each individual Mk does not contain any such problem and, even better, is stationary.\n\nThe \"subjectivity\" function \"h\" then has as role to split any data tuple across Mk, possibly using extra information kappa.\n\nFurthermore, several theorems show that under several conditions, the return of the subjective policy (learned via Mk) is not worse than that of the \"traditional\" policy.\n\n\nI lean towards rejecting this paper. The whole gist of the framework can be crudely summarized as \"if data contradicts, split up into non-contradictory sets using extra info.\" The motivation keeps repeating that no task-specific prior knowledge being necessary, but I believe this hinges on \"h\" being sensible, which might not be feasible without task-specific prior knowledge.\n\nFurthermore, and this is my main concern, there is not a single experiment demonstrating how any of this would behave in practice. It would be good to have one (possibly constructed) experiment showing that data confusion indeed is a problem in practice (intuitively, it is), and then a specific instantiation of the framework that solves this example. Furthermore, I am not convinced that the proposed bounds can easily be concretized for an instantiation of the proposed framework, especially when considering deep networks; again, this concern could be alleviated by an example instantiation. Proposing something that is in principle more general and \"in principle cannot be worse\" but then not demonstrating that it actually is the case is, in my opinion, not enough.\n\n\n\nFinally, and this is not a deciding factor in my rating, the paper has quite some writing problems. On the first page alone, I found a lot of spelling and grammatical mistakes (see list at end) and the notation is sometimes confusing to me. For example, \"R\" is defined as a mapping of S x \/R -> [0,1], but what is \"\/R\" (curly R)? And then in (1) R is used with a single argument while in (2) not anymore. I can guess what is meant, but it feels inconsistent. In Theorem 1, I believe it should be \"the gap \\delta >= 0\" and not \"the gap g >= 0\", no?\n\nAbstract and 1st paragraph mistakes (unfortunately, no line numbers in this template!): \"researches\" -> \"research\", \"algorithm designing\" -> \"algorithm design\", \"task-specific prior knowledge about tasks.\" -> \"task-specific prior knowledge.\", \"not known in prior\" -> \"not known a priori\", \"Classical RL model environment...\" -> \"Classical RL models environment...\".\nAlso, quite some citations are missing the year, e.g. Schaul et al., Papavassiliou&Russell, ...","sentences":[{"sentence_type":"2","sentence":"I lean towards rejecting this paper.","rephrased":"I am currently inclined to not accept this paper."},{"sentence_type":"2","sentence":"The whole gist of the framework can be crudely summarized as \"if data contradicts, split up into non-contradictory sets using extra info.\"","rephrased":"The core concept of the framework appears to be the division of contradictory data into non-contradictory sets with the aid of additional information."},{"sentence_type":"2","sentence":"Proposing something that is in principle more general and \"in principle cannot be worse\" but then not demonstrating that it actually is the case is, in my opinion, not enough.","rephrased":"While the proposal is theoretically more general and should not perform worse, providing empirical evidence to support this claim would strengthen the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[818,854,"Not concerning"],[855,993,"Confirmed"],[994,1194,"Missed by Model"],[1197,1326,"Missed by Model"],[1793,1968,"Maybe"]],"Comments":[]}
{"id":"S1lsYBrI2m","text":"This paper considers the finite-sum optimization problem that is typically seen in machine learning, and proposes methods that adaptively adjust the learning rate by estimating the local Lipschitz constant of the gradient. \n\nThe contributions of the paper seem very limited.  The proposed method which estimates the local Lipschitz constant of the gradient, named local predictive local smoothness (PLS) method in the paper (equation (10)), has been proposed in [1] long ago (see equation (11) in [1]) and is very well-known to the community. It is quite surprising that the authors claim to be the first to propose this while completely ignoring previous works.\n\nI also believe that there are major issues with the analysis for the methods. For example, I do not understand how equation (9) could possibly hold for general functions, and how it could be possible to transform their method into the linear system in (11). Therefore I do not think this paper is technically correct. \n\nIn summary, I believe this paper is limited in its contribution and also has major issues in terms of technical correctness, and is well below the standard for ICLR. \n\nReference: \n\n[1] Magoulas, G. D., Vrahatis, M. N., & Androulakis, G. S. (1997). Effective backpropagation training with variable stepsize. Neural networks, 10(1), 69-82.\n\n","sentences":[{"sentence_type":"2","sentence":"The contributions of the paper seem very limited.","rephrased":"The paper could benefit from a clearer demonstration of its unique contributions to the field."},{"sentence_type":"2","sentence":"It is quite surprising that the authors claim to be the first to propose this while completely ignoring previous works.","rephrased":"The authors may want to acknowledge the similarities between their method and those found in previous works, such as [1]."},{"sentence_type":"2","sentence":"Therefore I do not think this paper is technically correct.","rephrased":"The technical correctness of the paper could be further substantiated by clarifying how equation (9) applies to general functions."},{"sentence_type":"3","sentence":"In summary, I believe this paper is limited in its contribution and also has major issues in terms of technical correctness, and is well below the standard for ICLR.","rephrased":"In summary, the paper would benefit from a more robust demonstration of its contributions and a thorough review to address the concerns regarding technical correctness to meet the conference standards."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[225,274,"Confirmed"],[543,662,"Confirmed"],[922,981,"Confirmed"],[984,1149,"Confirmed"]],"Comments":[]}
{"id":"JCeRarEgy9U","text":"Introduction mentions \"AutoML\" but I don't believe the main paper focuses on AutoML or even mentions it again. There seems to be a disconnect between this motivation and the content. \n\nSaying their proposed PMS approach is “tuning free” is kind of overselling: you still have to pick the  $O$ and $\\alpha$ hyperparameters, and additionally tuning the models architecture\/training details for the value estimation procedure (probably FQI) that is used in each iteration to get $\\hat{Q}$. Consider adjusting this claim; also compare to Zhang & Jiang 2021 [1] (this paper is very new so the authors are not expected to know\/cite it, it is however important to illustrate what tuning free might mean). \n\nMain results seem to have been aggregated over all 6 domains considered, however it is unclear whether the regret across domains are comparable i.e. on the same scale. It would be clearer to also provide per-domain results (the experiments section says these should be in Appendix B be but they are not). \n\nWhat are $O$ and $\\alpha$ set to for the experiments? \n\nSince the method splits the data into $O$ parts, this will lead to higher variance estimates for each iteration compared to using the full dataset. Is this accounted for in the theoretical analysis? \n\n[1] Siyuan Zhang, Nan Jiang. Towards Hyperparameter-free Policy Selection for Offline Reinforcement Learning. NeurIPS 2021. https:\/\/arxiv.org\/abs\/2110.14000","sentences":[{"sentence_type":"2","sentence":"Saying their proposed PMS approach is \r\n\rtuning free\r\n\r is kind of overselling: you still have to pick the  $O$ and $\r\n\ralpha\r\n\r hyperparameters, and additionally tuning the models architecture\/training details for the value estimation procedure (probably FQI) that is used in each iteration to get $\r\n\rhat{Q}\r\n\r.","rephrased":"The claim that the proposed PMS approach is 'tuning free' may be somewhat overstated, as it still requires the selection of $O$ and $\r\n\ralpha\r\n\r hyperparameters. Furthermore, there is a need to adjust the model's architecture and training details for the value estimation procedure used in each iteration to obtain $\r\n\rhat{Q}\r\n\r. It would be beneficial to clarify this aspect and perhaps compare it to the approach in Zhang & Jiang 2021 [1] to provide a clearer definition of what 'tuning free' entails."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[],"Comments":[]}
{"id":"sqBofKizg9e","text":"Major points:\n-I find it relevant and interesting to assess generalization capabilities of neural networks by means of TDA without requiring a validation set, and I am curious to see where this line of research is developing.\n- The paper is clearly written, and the non-familiar reader also receives a clear introduction to TDA.\n- My biggest concern is that the main finding, i.e., that PH of the network architecture allows to monitor performance without a validation set, is not novel. For instance, in Reference [26], Rieck et al employed PH of the network architecture (albeit using a weighted undirected graph) to distinguish good from poor performing networks and even proposed an early stopping scheme with a PH-based patience approach for guiding training and monitoring of neural nets without a validation set, amongst others also using MNIST and CIFAR-10. That being said, even though the empirical observation that PH of the network correlates with generalization has been known before, to my knowledge it is still an open question *why* this is the case, i.e., the theoretical workup of this phenomenon is still pending and would be quite relevant to have addressed - which I encourage the authors of this paper to investigate, as this would considerably strengthen the paper.\n\nOne way I could imagine that potential explanations of this phenomen could be identified could be via dedicated comparison studies:\ne.g. do simple statistical moments of the weight distribution also correlate with generalisation, or could there be a way to identify relevant cliques in the network which are topologically relevant and also coinciding with a \"lottery winning\" subnetwork, etc?\n\n- The experiments could be strenghened by the addition of certain monitoring baselines to showcase the gained value of employing PH here.\n    For instance, in [26] the PH-based measure was compared to patience with validation loss (what is the difference in performance and epochs after when early stopping was initiated). Also, it would be interesting to add simple baselines measures to check that they are not already helpful alone (like non-topological information about the weight distribution).\n\n\nMinor points:\n- Figure 6: it took me some time to understand the legend \/ caption. I would suggest to repeat \"# layers\" in the legend, such that is easier to understand the legend without reading the caption first.\n- Line 294, typo: \"We posed the of question whether\"","sentences":[{"sentence_type":"2","sentence":"My biggest concern is that the main finding, i.e., that PH of the network architecture allows to monitor performance without a validation set, is not novel.","rephrased":"While the application of PH to monitor network performance without a validation set is intriguing, it would be beneficial to discuss how this work builds upon and differs from existing studies, such as the approach taken by Rieck et al. in Reference [26]."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[331,487,"Maybe"]],"Comments":[]}
{"id":"bDLdQE6huIz","text":" I have read the other reviews and responses from the authors. Two highly-related papers should be added. So the claims and experiments need major revisions. I lower my score to 5. \n===========================================\n\nThe paper is well-written and organized. The experiments are convincing. I have the following two main concerns, which prevents me from improving the score.\n1. For a PDE solver, the data is specialized for the PDE. So the whole solving process should include the pre-training stage.\n2. For vision tasks, using the pre-trained models to improve the accuracy and efficiency of the downstream tasks is a promising way. These vision tasks share the features from images. However, for a given PDE solving problem, when one can use the pre-trained model? Do we need to train a lot of pre-trained models?","sentences":[{"sentence_type":"2","sentence":"I lower my score to 5.","rephrased":"After considering the additional literature and the need for major revisions, I have adjusted my score accordingly."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[158,180,"Not concerning"]],"Comments":[]}
{"id":"INPxK-KiBER","text":"The paper proposes the integration of causal discovery methods into the training of state transition models to build a causal world model. The method combines regular world models with DCDI and trains a latent variable model with interventional data (different environments)\nOverall the paper is interesting and a good enough submission for a workshop.\n\nStrengths:\n- The application of causal modelling to world models is useful and yields good performance.\n- The experiments seem to indicate that the method outperforms a relevant baseline.\n\nWeaknesses:\n- Given that the interventions and the state are unknown I am not sure whether this model can be correctly identified.\n- It'd be good to clarify earlier that the interventions are unknown and what this means.\n- It would be interesting whether one could also think of the interventions as an intervention on one or multiple separate global latent variable(s) that describes the behaviour of the system, e.g. the strength of the forces. Then the intervention becomes atomic and one could amortise the function over different environments. It'd be useful to discuss this.\n- There are a few typos etc:\n  - L97: \"minic\" instead of \"mimic\"\n  - Eq. 6 - please explicitly explain what each lambda is used for\n  - Fig 3: Please add a legend for the different colours. Also, I think it'd be useful to discuss the intervention matrix and how one could potentially evaluate that.","sentences":[{"sentence_type":"1","sentence":"Overall the paper is interesting and a good enough submission for a workshop.","rephrased":"Overall, the paper is interesting and presents a valuable contribution suitable for a workshop."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[275,352,"Not concerning"]],"Comments":[]}
{"id":"IC6D-Qll2","text":"This paper concerns the assessment of saliency map validity.  It was shown that GradCAM is superior to other methods in terms of model and parameter randomization. This is a useful results, as the interpretability that saliency mapping enables is becoming more and more important to help visualize why deep networks are making their decisions. However, there was a lack of discussion of these results in this paper - are there any possible explanations for why GradCAM is performing better? Furthermore, the images in the figures hard to see. They should be larger and as much whitespace should be removed between images.","sentences":[{"sentence_type":"1","sentence":"Furthermore, the images in the figures hard to see.","rephrased":"Additionally, enhancing the clarity and size of the images in the figures could further improve the paper's visual presentation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[491,542,"Not concerning"]],"Comments":[]}
{"id":"B1xwnpPRFE","text":"This paper proposes deep generative model consisting of VAE + autoregressive LSTM decoder for learning to generate fonts in SVG (scalable vector graphics format)\n\nThe paper is well written, well motivated. Perhaps it would be great to see some plot of different hyperparameters and different modeling choices and its effect on results. Additionally, it would be great if authors could elaborate on details of cost function that they used (I would imagine that it is a mix of classifier that predicts actions like moveTo\/lineTo etc and well as regression module that predicts coordinates). \n\nOverall it looks like a well executed paper.\nI recommend accept","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"yQPrHZiz0v","text":"The authors consider the problem of deriving a condition on probabilistic circuits under which causal queries remain tractable. Specifically, they first show that even under the assumptions of structured decomposability and determinism the backdoor query remains non-tractable. They then propose a new condition called strong determinism under and show that under this assumption the backdoor query is tractable for certain backdoor sets. \n\nThe problem of causal queries in probabilistic queries is very interesting and of some practical relevance. Therefore, the presented results would be relevant and interesting if correct. It is however, difficult to evaluate the results since the crucial property of strong determinism is introduced only in the Appendix where the definition contains a typo in a crucial sentence. As a result, it is difficult to understand the definition and therefore evaluate the correctness of the results. In addition I also have two more minor comments:\n- The L in the subset notation is nowhere defined I think (although I suppose it means the scope of the left child in most places).\n- Is there some simple intuition on why the backdoor query is in general non-tractable even if computing conditional probabilities is given that it seems to mostly require computing conditional probabilities?","sentences":[{"sentence_type":"2","sentence":"It is however, difficult to evaluate the results since the crucial property of strong determinism is introduced only in the Appendix where the definition contains a typo in a crucial sentence.","rephrased":"However, evaluating the results is challenging because the key concept of strong determinism is introduced in the Appendix, and there appears to be a typo in an important sentence of its definition."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[628,820,"Not concerning"]],"Comments":[]}
{"id":"Skg2zRlWnV","text":"The paper is written in the form of a position paper where authors raise the problems of deceptive or rebellious explanations. Authors give a brief overview of relevant studies and provide examples of potentially deceptive and rebellious explanations, and give some directions for ways of enabling rebellious explanations and providing evaluation.\n\nThe topic and the presented research problems are of high interest and significance for XAI community. However, my main concern is the maturity of the paper.  The examples of rebellious explanations described in the paper could be formalized, and there could be given more details to more precisely identify the problems. Additionally, authors identify the ways for generating deceptive explanations by exploiting existing work such as model reconciliation, discrepancy detection or Goal Networks. However, they do not give any clear ideas and suggestions on how any of these methods could be used. Adding at least one example with the formalization of the problem and explanation with the detailed insight on how to utilize the existing approach or proposing a new one would be desired. ","sentences":[{"sentence_type":"2","sentence":"However, my main concern is the maturity of the paper.","rephrased":"However, I believe the paper could benefit from further development to fully realize its potential."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[452,506,"Not concerning"]],"Comments":[]}
{"id":"VfcJ4UB9QSq","text":"In this work,  the authors addressed the problem of Matrix Completion on Non-Euclidean domains.  They mainly adopt the method Matrix Data Deep Decoder, inspired by the Deep Decoder method for Image Completion. Here are my main concerns:\n\n1. The technical contributions of this paper is limited since it mainly adopts existing methods, like Matrix Completion + Deep Decoder + multi-graph convolution. It seems for me this paper is more like an engineering paper consist of lots of stuff. It is better to release the source code to understand this kind of composition stuffs.\n\n2. The motivation of this work is also not very sound. The authors spend lots of content on the related work. However, the main idea is only presented in a presuppose-code style in Page 6, which is not very clear.\n\n3. In the experimental parts. Why use different methods for different dataset in Table 2(a), (b), (c)?  Is it possible to conduct all of the baselines for all datasets? Also,  the matrix completion has been studied for many years with many solid theory results,  the baselines in the experiments are not SOAT.\n\nTypos:\nIn page 4: stracture -------> structure\nIn page 7:  can be found in the work of [30] -----> the cite form is not correct.\n\nIn summary, the paper show that a GCN network is a good prior for the Matrix completion problem. However,  the technical contributions of this paper is limited and the overall presentation can be further improved.","sentences":[{"sentence_type":"2","sentence":"The technical contributions of this paper is limited since it mainly adopts existing methods, like Matrix Completion + Deep Decoder + multi-graph convolution.","rephrased":"While the paper builds upon existing methods such as Matrix Completion, Deep Decoder, and multi-graph convolution, it would be beneficial to highlight any unique contributions or novel integrations that enhance the field."},{"sentence_type":"2","sentence":"It seems for me this paper is more like an engineering paper consist of lots of stuff.","rephrased":"The paper appears to have a strong engineering focus; clarifying how these implementations advance the theoretical aspects could strengthen the paper's impact."},{"sentence_type":"2","sentence":"The motivation of this work is also not very sound.","rephrased":"The motivation for this work could be articulated more clearly to better understand its significance in the context of existing research."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[241,399,"Maybe"],[400,486,"Confirmed"],[578,629,"Confirmed"]],"Comments":[]}
{"id":"XV0UJQAVnL","text":"\nThis paper addresses the problem of slower training speed with low-precision training of neural nets. It presents a simple solution: first train with full precision on half of the budgeted trainining time, then train with low pecision in the remaining time. This achieves 1.2x - 1.6x speedup compared to low-precision training. \n\nPro:\n- The proposed idea is simple and it is nice to see that it works\n\nCons:\n- I feel there is not enough content (in terms of ideas and experiments) to warrant a full paper. Compared to other ICLR papers, the contributions seem on the low side. See suggestions below. \n- The paper mainly compares the proposed method with low-precision training, but the results would be stronger if also compared with full-precision training followed by quantization. This is especially because all the low-precision accuracies trail behind the full precision ones in the results. \n\nSuggestions:\n- Experiment with more quantization methods. Currently we do not know whether the proposed method is uniquely suited to the PACT method used, or is a general technique. \n- A 1.2x-1.6x speedup on a training process that takes 600 seconds (e.g. CIFG-10 result in Fig 2) seems not so impactful in the grander scheme of things. Even the 12500 second training time is just <4 hours. I understand the results should transfer, but the results would be more impressive if done on larger training runs.\n\nMinor questions\/comments:\n- Please comment on the terminology. Is what you call low precision training similar to the mixed-precision training now implemented in TensorCore NVIDIA GPUs?\n- Table 2: what is it\/s. Is it iterations per second? \n- Table 1 shows learning rate schedule for t up to 60k in CIFAR or 450k in ImageNet, but Figure 1 stops way before those points in the x-axis. This was somewhat confusing. \n- Another clarification point about Fig 1 and 2: for the proposed method, is the full precision training part of the time included in the calculation? I believe so but just want to double-check. \n","sentences":[{"sentence_type":"2","sentence":"I feel there is not enough content (in terms of ideas and experiments) to warrant a full paper.","rephrased":"The paper could be strengthened by expanding on the ideas and experiments to fully justify a standalone publication."},{"sentence_type":"2","sentence":"A 1.2x-1.6x speedup on a training process that takes 600 seconds (e.g. CIFG-10 result in Fig 2) seems not so impactful in the grander scheme of things.","rephrased":"While the 1.2x-1.6x speedup is a positive result, further research could explore its impact on longer training processes to better understand its significance in larger contexts."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[411,506,"Maybe"],[1085,1236,"Not concerning"]],"Comments":[]}
{"id":"uBqGHjM1FQb","text":"This manuscript describes a connection between Potts models and attention as implemented in modern transformers. The authors then present an attention model in which positional encodings are defined as one-hot vectors indicating fixed positions in the multiple sequence alignment and train single layer attention models. These models, unsurprisingly, perform similarly to Potts models without APC correction for contact prediction. The methods section is somewhat confusingly written. I think the factored attention model would benefit from being described on it’s own terms rather than in connection with typical multiheaded attention, especially because the isolation of position encodings and amino acids at those positions dramatically simplifies the understanding of W_Q, W_K,  and W_V. The authors also spend a long time describing well known methods, but without providing additional insight. The connection between the Potts model and attention described in this paper should be obvious to those who already understand attention models and Potts models and the empirical results of the factored attention model don’t make this approach seem compelling. In the discussion, the authors make several broad future speculations. Some of these would be interesting contributions and I encourage the authors to develop this work further. Maybe factored attention could be promising for better capturing dependencies between positions for deeper transformers on MSAs, but it isn’t likely that this work will be of broad interest to the machine learning community. This manuscript seems better suited to a workshop or other specialized venue. Some specific comments on this work follow below.\n1.\tIn the factored attention model, the authors use one-hot encoding of the position index as the position encoding. This is equivalent to learned position embeddings as in BERT which is worth mentioning. \n2.\tThe authors discuss single-site potentials as a difference between Potts models and single layer attention models and then show a comparison of attention models with and without single-site potentials showing little difference. However, attention models already implicitly have single-site potentials which arise from the positional encoding input features. Granted, this is not the case for the factored attention model where single-site potentials seem to have more effect, though in the negative direction.\n3.\tThe authors state that “The ability of factored attention to capture similar contacts to Potts without use of APC suggest that it may be more suitable for protein design.” I don’t follow this conclusion. If the factored attention model performs equivalently to the Potts model alone and worse than the Potts model with APC correction, why would it be more suitable for protein design?\n4.\t What makes the single-layer attention or factored attention models compelling for protein modeling? What problems do these models solve that are not better solved by the Potts model or traditional transformers?\n\nWhat would raise my score:\n1.\tPresent a compelling use case for the factored attention model. What questions can be answered (or better answered) with this model over the Potts model or other alternatives? One idea is to use the factored attention model as the layers in a full deep transformer model and see if this architecture can improve tasks where MSA training data is available.\n\nEdit: I have increased my score in light of the response and manuscript edits. The manuscript is improved, but I think the method still needs more development. There are a number of interesting pieces but the final picture of an improved protein model is not fully resolved.","sentences":[{"sentence_type":"2","sentence":"These models, unsurprisingly, perform similarly to Potts models without APC correction for contact prediction.","rephrased":"It would be beneficial to see how these models compare to Potts models with APC correction, as they currently show similar performance to Potts models without it."},{"sentence_type":"2","sentence":"The connection between the Potts model and attention described in this paper should be obvious to those who already understand attention models and Potts models and the empirical results of the factored attention model don't make this approach seem compelling.","rephrased":"The paper could further clarify the novel aspects of the connection between the Potts model and attention for those already familiar with these concepts, and provide more evidence to demonstrate the advantages of the factored attention model."},{"sentence_type":"2","sentence":"Maybe factored attention could be promising for better capturing dependencies between positions for deeper transformers on MSAs, but it isn't likely that this work will be of broad interest to the machine learning community.","rephrased":"Exploring how factored attention might capture dependencies between positions for deeper transformers on MSAs could be a promising direction, and further work could help to demonstrate its relevance to the broader machine learning community."},{"sentence_type":"1","sentence":"This manuscript seems better suited to a workshop or other specialized venue.","rephrased":"Given the specialized nature of this work, presenting it at a workshop or in a specialized venue might provide valuable feedback for further development."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[321,431,"Not concerning"],[1564,1641,"Not concerning"]],"Comments":[]}
{"id":"HZNx2BKtbWc","text":"This paper builds upon two recently popular fields of work, the object-centric representation learning and the self-supervised contrastive learning. Instead of using the pixel-wise reconstruction loss as the main supervision signal, this paper introduces both image-level and object-level contrastive loss to help object discovery. The segmentation masks can be extracted as the attention masks in Slot\/Cross Attention. The trained model achieves reasonable performance on segmentation IoU and VQA AP. More comments are as follows:\n\n- I completely agree with the author that, per-pixel reconstruction loss might hinder the model to scale up to real-world images. I am very happy to see the contrastive loss from SimSiam can work here. Simply maximizing the similarity of positive pair is indeed an easy-to-implement and promising technique\n- I am a bit surprised by the fact that the global loss matters that much, and I am interested in how the segmentation masks look like in this case. After all the object loss is still minimized, especially in the CTRALL case\n- The IoU result (40%) is not very good. The Slot Attention paper only has numbers for ARI. But on the other hand, object-centric representation learning doesn't necessarily require segmentation. The learned good object representation is verified by the VQA task\n- It would be very interesting to extend this work by incorporating with techniques in unsupervised video representation learning papers\n\nOverall, I believe this paper presents an interesting direction of object-centric representation learning. I vote for the acceptance of this paper.\n","sentences":[{"sentence_type":"2","sentence":"The IoU result (40%) is not very good.","rephrased":"While the IoU result (40%) suggests there is room for improvement, it's important to note that object-centric representation learning is not solely dependent on segmentation performance, as evidenced by the VQA task results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1067,1105,"Not concerning"]],"Comments":[]}
{"id":"Hyx-uH4W3V","text":"The paper proposes an interesting framework for explaining plans in terms of binary plan properties.\n\n> Description versus Explanation: My biggest criticism of the framework would be that it is an explanation framework without any consideration of the explainee in it! What is the model of the person who is receiving the explanation? How do they evaluate plans? Are they optimal planners? Can they arrive at the same plan space given a problem? Are they able to evaluate the entailment property completely and accurately? \n\n---> 1. What is the definition of an explanation in this framework? \n---> 2. Under what assumptions of the explainee model is this framework capable of producing a valid explanation?\n\nWithout these key definitions in the framework, I would say that the proposed work is one of plan description rather than explanation. The need for evaluations is noted only as an afterthought. This is worrying, especially since the framework does not account for the user model at all. As such, I am not sure who has been helped with explanations of this form. I would like to see more discussion on what the evaluation plans are, with respect to the design of experiments that evaluate not the descriptive power but the explanatory power of the framework.\n\n> This also raises the issue that the set of properties are inputs to the algorithm. I see this as an artifact of not having the explainee model in the framework. I think the set of plan properties would follow directly from a complete framework that accounts for the explainee, either from their mental model of the task or from the questions asked. Interestingly, recent work [Sreedharan et al. IJCAI 2018] has looked at estimating this model (in a different context) and answer such why questions.\n\nother: I am not sure that using coverage is an apples-to-apples comparison. Is there a reason to generate the explanation at planning-time? Usually, it is in response to the question (can potentially re-use search data).\n\nother: I would strongly suggest merging (and expanding) the example at the end with the section where plan properties and entailment are introduced. It would be useful to carry this example through in following sections as well. I had a hard time going back and forth making sense of the presentation. Having a running example would really help in readability.\n\nminor: section number depth is probably set to zero, all the section are missing.\n\n","sentences":[{"sentence_type":"2","sentence":"Without these key definitions in the framework, I would say that the proposed work is one of plan description rather than explanation.","rephrased":"Incorporating these key definitions into the framework could strengthen the distinction between plan description and explanation, and clarify the intended contribution of the work."},{"sentence_type":"2","sentence":"The need for evaluations is noted only as an afterthought. This is worrying, especially since the framework does not account for the user model at all.","rephrased":"It would be beneficial to integrate the evaluation process more prominently within the framework, particularly with regard to accounting for the user model."},{"sentence_type":"2","sentence":"As such, I am not sure who has been helped with explanations of this form.","rephrased":"Clarifying who the target audience is and how they benefit from this form of explanation would enhance the paper's impact."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[709,843,"Not concerning"],[844,995,"Confirmed"],[996,1070,"Maybe"]],"Comments":[]}
{"id":"NamFEfqLpa","text":"Summary: \n\nActive contour based object detection strategy is transformed into unsupervised\/self-supervised learning setting for segmentation tasks. This work proposes to parameterise contour evolution with a convolution neural network and self-supervise the learning with intensity based statistics without requiring any concrete labels. A strategy to incorporate few label to further refinement segmentation is also proposed.\n\nStrengths:\n+ Use of Active contour without edges (ACWE) strategy for unsupervised\/self-supervised learning is novel.\n+ Further, use of intensity level statistics for self-supervision is an interesting contribution.\n+ The possibility of refining segmentations with few labels is additional advantage\n+ Results are convincing\n\nWeakness: \n- Perhaps due to the limitation in space, the concept of ACWE is not clearly elucidated. As the work is heavily dependent on the ideas from Chan and Vese, 2001, strengthening this discussion with further motivation is recommended\n- The experiments are demonstrated on simulated data. How realistic are these images and how would the model fare on real data?\n- No baseline methods are reported to appreciate the reported performance","sentences":[{"sentence_type":"2","sentence":"- No baseline methods are reported to appreciate the reported performance","rephrased":"Including baseline methods for comparison could enhance the appreciation of the reported performance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1122,1195,"Not concerning"]],"Comments":[]}
{"id":"r1lQVT49FB","text":"First, I do not follow the authors’ argumentation in the motivating example where the discus calibration in a mis-specified model. They argue that it should not be possible to calibrate the output of a mis-specified model. It is of course a bad idea to model a Gaussian with a Cauchy distribution (the way it is always a bad idea to have a mis-specified model), but I would actually argue that the isotonic regression based approach by Kuleshov et al., 2018 is more robust against model mis-specification due to its higher flexibility and thus a more powerful approach for pos-hoc calibration. \n\nSecond, I find the approach lacks novelty and is a straightforward application of the well established temperature scaling method and the expected calibration error to regression tasks. In addition, there are only minor differences to Phan et al 2018, CoRR.\n\nMost importantly, I have major concerns regarding the lack of in-depth evaluation. The authors provide no systematic comparison to the state-of-the art (Kuleshov et al., 2018) and only show reliability diagrams (they introduced themselves) for one singe (real) dataset and only their own method.  ","sentences":[{"sentence_type":"2","sentence":"It is of course a bad idea to model a Gaussian with a Cauchy distribution (the way it is always a bad idea to have a mis-specified model),","rephrased":"While modeling a Gaussian with a Cauchy distribution may not be ideal due to the mis-specification of the model,"},{"sentence_type":"2","sentence":"Second, I find the approach lacks novelty and is a straightforward application of the well established temperature scaling method and the expected calibration error to regression tasks.","rephrased":"Second, the approach seems to build upon the established temperature scaling method and the expected calibration error for regression tasks, which may benefit from further differentiation to enhance its novelty."},{"sentence_type":"2","sentence":"Most importantly, I have major concerns regarding the lack of in-depth evaluation.","rephrased":"Most importantly, I believe the paper would be strengthened by a more in-depth evaluation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[223,361,"Not concerning"],[596,781,"Confirmed"],[855,937,"Confirmed"]],"Comments":[]}
{"id":"TD5pjPIKGv","text":"The authors designed a GAN based synthesised method for cardiac data segmentation. I have some concerns regarding the results of this work: for instance, the authors proposed a complicated model but the segmentation results are quite similar or even slightly worse than the data augmentation. Also GAN based synthesise was proposed and widely tested before. The novelty of the study is quite limited.","sentences":[{"sentence_type":"2","sentence":"The novelty of the study is quite limited.","rephrased":"While the study builds upon existing GAN-based methods, further clarification on its unique contributions could enhance the perceived novelty."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[358,400,"Maybe"]],"Comments":[]}
{"id":"r1esT_GTKr","text":"The goal of this work is to best understand the performance and benchmarking of continual learning algorithms when applied to sequential data processing problems like language or sequence data sets. The contributions of the paper are 3 fold - new benchmarks for CL with sequential data for RNN processing, new architecture introduced for more effective processing and a thorough empirical evaluation. \n\nIntroduction: \nI think a little more insight into why the sequential data processing CL scenario is any different than the vision scenario would be quite helpful. Specifically, it would be quite impactful to tell us more about what the additional challenges with RNNs for CL vs feedforward for CL are in the intro. \n\nThe paper is written as if the benchmark is the main contribution and the architecture improvement is just a delta on top of this, but it gets confusing when the methods section starts off with just directly stating the new architecture. \n\nThe algorithm seems like a straightforward combination of recurrent progressive nets and gated autoencoders for CL. Can the authors provide more justification if that is the contribution or there is more to the insight than has been previously suggested in prior work?\n\nFigure 1 has a very uninformative caption. It also doesn’t show how modules feed into one another properly. \n\nThe motivation for why one needs GIM after one already has A-LSTM or A-LMN is not very clear?\n\nOverall the contribution does seem a bit incremental based on prior work and the description lacks enough detail to properly indicate why this is a very important contribution?\n\nExperiments:\nWhat does it mean to be application agnostic but restricted to particular datasets and losses? This doesn’t quite parse to me. \n\nThe description of the tasks is very informal and hard to follow. It’s not clear what exactly the tasks and datasets look like \n\n“using morehidden units can bridge this gap” -> why not just do it? Its a benchmark after all. \n\nOverall the task descriptions should be in a separate section where the setup is described in a lot of detail and motivated properly. \n\nThe results in the experiments section are very hard to parse. The captions need much more detail for eg Table 2. \n\nCould we also possibly have more baselines from continual learning? For instance EWC (Kirkpatrick) or generative replay might be competitive baselines. \n\nOverall I think that the GIM and A-LMN and A-LSTM methods are reasonable although somewhat incremental. But the proposed benchmarks are pretty unclear and the results are a bit hard to really interpret well. It would also be important to run comparisons with more baselines and to provide more ablation\/analysis experiments to really see the benefit of GIM\/A-LMN or A-LSTM. I also think that the task descriptions should be much earlier in the paper and desribed in much more rigorous detail. \n","sentences":[{"sentence_type":"2","sentence":"The paper is written as if the benchmark is the main contribution and the architecture improvement is just a delta on top of this, but it gets confusing when the methods section starts off with just directly stating the new architecture.","rephrased":"It would be helpful if the paper could clarify the primary contribution, as the current structure suggests the benchmark is the main focus, with the architecture improvement appearing secondary. Ensuring consistency between the introduction and the methods section, where the new architecture is introduced, would enhance the paper's clarity."},{"sentence_type":"1","sentence":"Figure 1 has a very uninformative caption. It also doesn't show how modules feed into one another properly.","rephrased":"The caption for Figure 1 could be more informative, and it would be beneficial to illustrate how the modules interact with one another more clearly."},{"sentence_type":"1","sentence":"The motivation for why one needs GIM after one already has A-LSTM or A-LMN is not very clear?","rephrased":"Could the authors elaborate on the motivation for introducing GIM in addition to A-LSTM or A-LMN?"},{"sentence_type":"2","sentence":"Overall the contribution does seem a bit incremental based on prior work and the description lacks enough detail to properly indicate why this is a very important contribution?","rephrased":"The authors might consider providing more details to emphasize the significance of their contribution, which at present appears to be a modest extension of prior work."},{"sentence_type":"1","sentence":"The description of the tasks is very informal and hard to follow. It's not clear what exactly the tasks and datasets look like","rephrased":"A more formal and detailed description of the tasks and datasets would aid in understanding the experimental setup."},{"sentence_type":"2","sentence":"\"using morehidden units can bridge this gap\" -> why not just do it? Its a benchmark after all.","rephrased":"If using more hidden units could bridge the identified gap, it would be valuable to explore this in the benchmark for a more comprehensive evaluation."},{"sentence_type":"1","sentence":"The results in the experiments section are very hard to parse. The captions need much more detail for eg Table 2.","rephrased":"Enhancing the clarity of the results in the experiments section, particularly with more detailed captions for tables such as Table 2, would be beneficial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[720,957,"Maybe"],[1340,1433,"Not concerning"],[1435,1611,"Maybe"],[2117,2230,"Not concerning"]],"Comments":[]}
{"id":"Bs8rH5w0G7C","text":"In order to compare different MARL algorithms more fairly, the author compared the differences in the performance of different algorithms(MADDPG, MATD3, MASAC, Qmix, MAPPO) in different environments(Particle-World, StarCraft Micromanagement, Hanabi, The Hide-and-Seek Domain).  The author's writing and organization are very good, so that I can clearly understand the content of the paper, and also has certain highlights, but I think it has not reached the ICLR criteria.\n\nFirst of all, as an article about BENCHMARKING MULTI-AGENT DEEP REINFORCE- MENT LEARNING ALGORITHMS, I think the author should compare a series of algorithms to bring more insightful analysis and inspiration. Unfortunately, I found that the author simply I enumerate the performance differences of different algorithms in different environments, and there is also a lack of analysis of what methods are suitable for what tasks. I suggest that the author conduct further analysis and experiments, and also pay attention to the advantages and disadvantages of different algorithms. I hope that the author can adjust the content of the paper, and don't make people feel that the author has collected different official implementations, and then simply run them and compare directly.\n\nIn addition, I think the author may be missing some important MARL algorithms. For example, in terms of policy-base, it is recommended that the author consider adding algorithms such as COMA[1] and MAAC[2] (the authors of these algorithms have already announced their official implementations). At the same time, most of the author's algorithms have official implementations on the Internet. How to compare different algorithms fairly is of great concern, but the author's content is still relatively weak, and the author is recommended to improve this part of the discussion.\n\nOverall, I vote for a rejection\n\n[1] Counterfactual Multi-Agent Policy Gradients, Foerster et.al. AAAI 2018\n\n[2] Actor-Attention-Critic for Multi-Agent Reinforcement Learning, Iqbal and Sha, ICML 2019","sentences":[{"sentence_type":"2","sentence":"Unfortunately, I found that the author simply I enumerate the performance differences of different algorithms in different environments, and there is also a lack of analysis of what methods are suitable for what tasks.","rephrased":"While the author provides a comparison of algorithm performance across environments, a deeper analysis of which methods are best suited for specific tasks would enhance the paper's contribution."},{"sentence_type":"2","sentence":"I hope that the author can adjust the content of the paper, and don't make people feel that the author has collected different official implementations, and then simply run them and compare directly.","rephrased":"I encourage the author to enrich the content with more nuanced comparisons and analyses to avoid the impression of merely running and comparing official implementations."},{"sentence_type":"1","sentence":"Overall, I vote for a rejection","rephrased":"Based on the current version of the manuscript, I am inclined to recommend rejection; however, I would be open to reconsidering if the aforementioned issues are addressed."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[683,901,"Not concerning"],[1054,1253,"Maybe"],[1833,1864,"Not concerning"]],"Comments":[]}
{"id":"ckp0fjYhOIM","text":"Strengths:\n1) The paper is well organised and moreover, the research pursued is very important in the cyber security field.\n2) In section 4 (Experimental section), the varying trade-offs of gamma parameter and data on varying length of signal hiding could be valuable\/important for researchers in the field of steganography.\n\nWeaknesses:\nThe paper can be improved based on the following points:\n1) In section 1, the authors talk about the drawback of variable length hiding, however, the definition of variable length is not mentioned. Please mention this as it could be any length.\n2) In section 2, several of the recent works in steganography\/deep learning have been missed and would be great to mention them as well.\n3) In section 3 (method), it would be better to connect the algorithm (Algorithm 1) mentioned in the text body such that readers find it easier to follow.\n4) The encoding and decoding process lacks novelty. It would be better to justify why such a method has been chosen, apart from the reason of enabling variable length signal hiding. The point of the paper is to contribute to the scientific knowledge of the community, however, the proposed method felt more as applicative based method where a new design proposal is made rather than the advancement of the scientific field. The design justification is missing from the Method's section.\n5)  In section 3.3 and 3.4, the symbols used in the equations are also not described\/defined intuitively, which could be a hindrance for many readers. Please update that so that readers of broader interest find it interesting to understand and read the proposed work as well.\n6) In section 4, the experiments are lacking in comparative study. There has been some methods in the same domain to utilize steganography\/deep learning to hide signal, however, the proposed method has not been compared with them to show the efficacy of the proposed. The authors should consider this.\n","sentences":[{"sentence_type":"2","sentence":"The encoding and decoding process lacks novelty.","rephrased":"The encoding and decoding process could be further elaborated to highlight its novelty and contribution to the field."},{"sentence_type":"2","sentence":"The proposed method felt more as applicative based method where a new design proposal is made rather than the advancement of the scientific field.","rephrased":"It would be beneficial to clarify how the proposed method advances the scientific field in addition to its applicative aspects."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[878,926,"Confirmed"]],"Comments":[]}
{"id":"d_kdTlKCe1","text":"The paper introduces a new benchmark dataset containing synthetic videos of colliding objects, and generated questions about them. It is designed to explore the ability of VQA models to infer latent physical properties, such as object mass. This ability is challenged through counterfactual (\"what would happen if an object is added\/replaced\/removed?\") and planning (\"what action should be taken on an object to produce\/prevent a certain collision\") questions. A number of recent VQA models, and modifications thereof, are evaluated on the new benchmark.\n\nPros:\n - The paper investigates an interesting question relevant to the workshop, namely how VQA models may infer latent object properties for better counterfactual reasoning.\n - The dataset design is generally sensible.\n - The Aloe model is adapted to the new dataset to ensure a fair comparison.\n\nCons:\n - While the stated purpose of the new dataset is to investigate the relevance of latent object properties, it remains unclear to what degree the observed results are a consequence of the latent mass differences. Performance disparities could also result from the new visual setting (as was observed for MONet), or the fact that counterfactual questions are generally harder than descriptive ones. It would have been helpful to either directly measure the models' ability to predict mass through a descriptive question, or to compare results with a dataset variant in which masses are identical for all objects.\n - The paper somewhat overlaps with other recent work on VQA benchmarks, such as ComPhy. The authors argue that their dataset differentiates itself by featuring both hidden properties and counterfactual add\/replace\/remove questions, but, for the reasons above, I feel like this doesn't necessarily make analyzing the results any easier.\n - While the paper is generally clear, the text, especially section 3, contains a number of grammatical errors, e.g. \"[...] whether all options of correctly predicted or not\". I was also left with a number of questions that would be good to clarify (see below). \n\nDespite these weaknesses somewhat limiting the paper's significance, I still think it will make a reasonable contribution to a question that is very relevant for the nCSI workshop.\n\nQuestions:\n - Are the mass values of certain object types (e.g. teal aluminum cube) consistent throughout the dataset, or resampled for each scene? I assume the latter, as otherwise models would not need to infer it at test time.\n - What exactly is meant by the term \"option\"? \n - Are the human performance scores per option or per question?\n - When a counterfactual question introduces a new object, does the model always have a chance to infer the latent mass, or is it possible that previously unseen object identities are introduced?","sentences":[{"sentence_type":"1","sentence":"The paper somewhat overlaps with other recent work on VQA benchmarks, such as ComPhy.","rephrased":"The paper appears to have some overlap with other recent work on VQA benchmarks, such as ComPhy, which could be further differentiated by the authors."},{"sentence_type":"2","sentence":"Despite these weaknesses somewhat limiting the paper's significance, I still think it will make a reasonable contribution to a question that is very relevant for the nCSI workshop.","rephrased":"While there are areas for improvement that could enhance the paper's significance, it has the potential to contribute meaningfully to a topic of relevance for the nCSI workshop."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1476,1561,"Not concerning"],[2074,2254,"Not concerning"]],"Comments":[]}
{"id":"rJxtaOEv3E","text":"The paper extends the model reconciliation paradigm, specifically the previous work line by Kambhampati's group, to consider the case where the robot may have it wrong and thus a 2-way communication is required. The paper delineates relevant cases in this context, poutlines issues and possible solutions.\n\nOverall, I find this fine for the purpose of discussion at the workshop.\n\nMy main concern with the paper is the way in which it disscusses, or rather *not* discusses, any other work in the area. One gets the impression the authors think they are alone in XAIP. This is inconsiderate in the best case, arrogant in the worst. I urge the authors to improve this, in the papoer and its preesentation, if accepted.\n\nA technical note is that the recursive nature of \"x's model of y's model of x's model\" seems deeply related to epistemic logic\/epistemic planning. It would seem that the entire problem of model reconciliation could be formulated as an epistemic planning problem, with additional predicates representing which literals occur in preconditions\/effects\/etc. It would be nice if the authors could comment on that.","sentences":[{"sentence_type":"3","sentence":"This is inconsiderate in the best case, arrogant in the worst.","rephrased":"I encourage the authors to consider a more comprehensive review of related work in the field of XAIP to acknowledge the contributions of others and situate their work within the broader context."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[568,630,"Confirmed"]],"Comments":[]}
{"id":"49gTuszt22","text":"CNN interpretability methods are used more and more in medical image analysis. The authors present a thourough evaluation of several of these methods (localisation capabilities, robustness to model parameter and label randomisation, repeatability and reproducibility with model architectures) extending the work first proposed by Adebayo et al.. This work is very interesting and was most needed. ","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"3RddyLH2-P_","text":"1. No novelty, not limited.  This is a simple combination of multi-scale and DANet.\n2. Extremely poor paper organization, see Fig.1, Fig. 2, and Fig. 3.\n3. Bad presentation, e.g, \"Multi scale architectures have been used sucessfully for a lot of vision problems (?), (Hu et al., 2018b) and (Sagar and Soundrapandiyan, 2020).\"  Even in this one sentence, there are a lot of mistakes. What is \"(?)\"? \"sucessfully\" -> \"successfully\"\n4. Could authors explain why a simple \"multi-scale + dual attention\" idea could achieve such big improvements over all vision tasks? Based on my experience, that is impossible.\n\n","sentences":[{"sentence_type":"2","sentence":"1. No novelty, not limited.  This is a simple combination of multi-scale and DANet.","rephrased":"1. The paper could benefit from a clearer articulation of its novel contributions, as it currently appears to be a straightforward combination of multi-scale and DANet techniques."},{"sentence_type":"3","sentence":"2. Extremely poor paper organization, see Fig.1, Fig. 2, and Fig. 3.","rephrased":"2. The organization of the paper could be improved for better clarity, particularly in how figures 1, 2, and 3 are presented and discussed."},{"sentence_type":"2","sentence":"4. Could authors explain why a simple \"multi-scale + dual attention\" idea could achieve such big improvements over all vision tasks? Based on my experience, that is impossible.","rephrased":"4. It would be helpful if the authors could provide a more detailed explanation of how the combination of multi-scale and dual attention mechanisms leads to significant improvements across various vision tasks, as such results are quite remarkable and not typically observed."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[0,83,"Confirmed"],[84,152,"Confirmed"],[156,172,"Missed by Model"],[430,606,"Not concerning"]],"Comments":[]}
{"id":"EM6nENB9ut8","text":"Paper summary:\nThe authors argue that they have proposed a method to train robust models to biases without having prior knowledge of the biases. They argue also to provide analysis on how weak learner capacity impacts the in-domain\/out-of-domain performance.\n\nReasons to reject:\n1) The authors argue they have shown the model with limited capacity capture biases. However, this has been shown already in [1] in 2019 and therefore is not a contribution of the authors.\n2) The main method proposed in this paper, is exactly the same method proposed in [2]. Please note that [2] was already available in early July 2020, and on top of existing work, the paper does not provide other contributions. \n3) About the third argued contribution on showing how the performance of the debiasing method change based on the capacity of weak learners, in [1], the authors included the discussion between the choice of weak learners on their impact. Though the method in [1] is different, the discussion in that paper still would apply here as well.  Please refer to table 1-3 and Figure 1 in [1]. \n\nGiven the points above, and since the main method in the paper is proposed in [2], the paper does not provide enough contributions to be suitable for the ICLR venue. \n\n[1] Robust Natural Language Inference Models with Example Forgetting, Yaghoobzadeh et al, https:\/\/arxiv.org\/pdf\/1911.03861.pdf, 2019 \n[2] Towards Debiasing NLU Models from Unknown Biases, Utama et al, 13 July 2020, https:\/\/openreview.net\/forum?id=UHpxm2K-jHE, EMNLP 2020 ","sentences":[{"sentence_type":"2","sentence":"The authors argue they have shown the model with limited capacity capture biases. However, this has been shown already in [1] in 2019 and therefore is not a contribution of the authors.","rephrased":"While the authors discuss models with limited capacity capturing biases, it appears similar findings have been previously reported in [1] in 2019. It would be beneficial for the authors to clarify how their contributions differ from or build upon these earlier results."},{"sentence_type":"2","sentence":"The main method proposed in this paper, is exactly the same method proposed in [2].","rephrased":"The main method proposed in this paper seems to closely resemble the method outlined in [2]. It would be helpful if the authors could highlight any distinctions or improvements made over the referenced work."},{"sentence_type":"2","sentence":"Given the points above, and since the main method in the paper is proposed in [2], the paper does not provide enough contributions to be suitable for the ICLR venue.","rephrased":"Considering the similarities with the method in [2], it would be important for the paper to more clearly define its novel contributions to meet the expectations for the ICLR venue."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[282,467,"Not concerning"],[471,554,"Not concerning"],[1084,1249,"Not concerning"]],"Comments":[]}
{"id":"BkldR7lIcB","text":"The paper proposes a theoretical framework for studying the generalization of deep neural networks in a broader sense; i.e.,  generalizing with underrepresented or unrepresented training\/test samples. The main idea is to cast the problem of improving generalization as the problem of minimizing the normalized information distance between the learned source code and the true source code, defined using the Kolmogorov complexity. Built upon this framework, the method of using extended encodings of an input sample is presented, which empirically seems to lead to better generalization in the settings of adversarial attack and corruptions.\n\nWhile the idea and the results seem to be appealing, and the concept is novel to the mainstream deep learning community, I suspect that some of the proofs in the paper might not be well grounded. For example, in Equation (3), the authors claim that \"a necessary and sufficient condition ensuring that ... the learned source code C_0 is more general than the learned source code C1 is ...\". However, this is not proved and does not seem obvious to me. Also, in the proof of Theorem 1 in the Appendix, the authors state \"Because a sufficiently high-capacity neural network can memorize its input samples (Zhang et al 2017), the Kolmogorov complexity of the true source code is larger than that of the source code\". This, to me, is more like some intuition or conjecture, rather than rigorous mathematical proof. As a result, I am skeptical about the theoretical claims made in the paper.\n","sentences":[{"sentence_type":"2","sentence":"However, this is not proved and does not seem obvious to me.","rephrased":"However, it would be beneficial if the authors could provide a proof or further clarification to support this claim, as it is not immediately apparent."},{"sentence_type":"2","sentence":"This, to me, is more like some intuition or conjecture, rather than rigorous mathematical proof.","rephrased":"This statement appears to rely more on intuition than on a rigorous mathematical proof, which may require further elaboration or evidence to strengthen the argument."},{"sentence_type":"2","sentence":"As a result, I am skeptical about the theoretical claims made in the paper.","rephrased":"As a result, these points raise some questions about the theoretical claims made in the paper, and addressing them could enhance the paper's credibility."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1032,1092,"Maybe"],[1355,1451,"Not concerning"],[1452,1527,"Maybe"]],"Comments":[]}
{"id":"H1e59mLw27","text":"The paper pretenses reinforcement learning algorithms for dealing with the \"exposure bias\" problem of RNNs in sequence labeling problems.  While I admire the thoroughness of  both the algorithmic work and experimental setup, I am afraid the paper suffers from two major problems:\n\n1. The paper suffers from serious clarity issues. Particularly, the main problem the paper deals with - exposure bias- is not well explained. I admit that while I am working with RNNs on a regular basis, I was not familiar with this problem. Unfortunately, I was also not able to understand it from the paper.  This may be a very basic concept, but a paper must be self-contained. Unfortunately, after reading the paper, front to cover, I cannot tell what is the problem the authors are trying to solve (except, of course, from providing a better training algorithm for RNNs).\n\n2. As the authors say already in the abstract, one of the best performing models on structured NLP tasks is LSTM-CRF, which combines the power of both the neural and the structured prediction frameworks. However, the authors do not compare their solution to LSTM-CRF, but only to LSTM and to CRF. This is a very important baseline, and without a proper comparison it is hard to evaluation the contribution of this paper.\n\n\n","sentences":[{"sentence_type":"2","sentence":"The paper suffers from serious clarity issues.","rephrased":"The paper could benefit from improved clarity, particularly in explaining the core problem of exposure bias."},{"sentence_type":"2","sentence":"Unfortunately, after reading the paper, front to cover, I cannot tell what is the problem the authors are trying to solve (except, of course, from providing a better training algorithm for RNNs).","rephrased":"It would be helpful if the authors could more clearly define the specific problem they are addressing, in addition to offering a better training algorithm for RNNs."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[284,330,"Confirmed"],[662,857,"Not concerning"]],"Comments":[]}
{"id":"YeLgdYTLL0n","text":"This paper proposes compression methods for solving variational inequalities. It is good to cover various settings such as unbiased vs. contractive, deterministic vs. stochastic. Detailed convergence analysis is also provided. However, I also have the following concerns. \n\n1. For practical problems such as GAN or adversarial training, the objective of min-max optimization is nonconvex-nonconcave, which results in a non-monotonic operator in variational inequalities. This more practical assumption has been considered in existing work with sound theoretical analysis (see reference [1] as below). The authors are encouraged to extend the analysis to the more practical nonconvex-nonconcave regime. \n\n2. In the paragraph right above Figure 2, the authors mentioned that “the learning curves on Figure 1(upper) follow a predictable pattern, with more extreme compression techniques demonstrating slower per-iteration convergence”. First, is Figure 1(upper) a typo? Should it be Figure 2(upper). Second, the learning curves in Figure 2(upper) are overlapping with each other (except for pure 8-bit in the upper-left figure). I am not sure how the authors get the observation that  “more extreme compression techniques demonstrating slower per-iteration convergence”. Besides, some discussion is needed to compare the compression ratio between 8-bit quantization and power compression with rank r=8. This is because power compression with rank r would decompose the dense matrix of size m\\*n into two matrices of size \nm\\*r and n\\*r. The exact compression ratio would depend on the values of m and n. \n\n3. In Figure 2(lower), it’s customary to also list average scores across different tasks in GLUE benchmark. It’s easier to compare different methods by checking their corresponding average scores. \n\n4. In Figure 1, it looks like that extra-step method also diverges (i.e., accuracy decreases as training goes). Since the extra-step method is specific for solving saddle point problems, it’s counter-intuitive when it diverges. \n\n5. It looks like there is no conclusion section at the end of this paper.\n\nReference:   \n[1] Diakonikolas, Jelena, Constantinos Daskalakis, and Michael Jordan. \"Efficient methods for structured nonconvex-nonconcave min-max optimization.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2021.\n\n","sentences":[{"sentence_type":"2","sentence":"It looks like there is no conclusion section at the end of this paper.","rephrased":"The paper would benefit from a conclusion section to summarize the findings and implications of the work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2035,2105,"Not concerning"]],"Comments":[]}
{"id":"SlgddePTe9","text":"**1. Summary and Contributions**\n\nThe paper considers causal discovery (or induction), that is, learning the underlying causal relations of our data's variables using said data. Specifically, it builds upon previous works that have considered settings in which we might get access to interventional data (on top of our standard, observational data) which leverages the identifiability of the causal structure of interest. The paper proposes an active approach to selecting interventions to be simulated and iterated over for improving our graph estimate. The paper develops the intuitive idea and further provides justification for the practicality of the approach by providing an empirical investigation on synthetic data sets.\n\n**2. Strengths**\n\nThe paper has noteworthy strengths, considered one-by-one in the following list (the list is ordered in correspondence to the paper presentation):\n\n* The grand problem of causal discovery is essential to human cognition and thus to science and engineering, and all its instances, and tackling specific sub-problems - as done in this work - is determining for developing next generation learning systems.\n* The paper provides a comprehensive context of existing works in causal and more general structure discovery.\n* The paper proposes a new, general paradigm to causal discovery that involves access to a simulator (or oracle for that matter). Said paradigm might be re-fined in later iterations through specific inductive biases or prior knowledge potentially rendering it suitable for specific application domains of interest (as motivated in the initial example of reasoning about traffic). [Furthermore, the empirical investigation seems to suggest that settings in which unlikely bla bla]\n\n**3. Weaknesses**\n\nThe paper suffers from several disadvantages (ranging in importance from minor to more fundamental) that however IMHO can be improved upon mostly quickly. Thereby, the following list - again one-by-one - aims to provide specific pointers with improvement suggestions if applicable (please note, the list is unordered):\n\n* Consider making the oracle setting more clear. While a white-box simulator is a strong assumption and arguably renders the problem of causal discovery trivial, in this paper the authors seem to consider a black-box simulator (in other words an oracle) and therefore should consider making distinction more clear. To achieve this, the authors might want to also consider examples such as the illustrating example on p.1 concerning traffic.\n* The authors should consider removing either Alg.1 or Fig.1 to re-use the extra space for alternate elaborations and improved versions of compact representation of the paradigm (as intended by both Alg.1 and Fig.1), since Alg.1 is arguably simply a more detailed form of presentation of the content in Fig.1 minus the structural information and color coding. An option would be to remove Alg.1, keep Fig.1, incorporate key details that were otherwise only in Alg.1 and add an illustrative, motivating example to the figure (as on p.1 concerning traffic).\n* Consider removing or re-iterating the experiment in Sec.4.3. Said experiment does consider only partially the proposed paradigm (since the methods do not allow for a posterior over the edges) therefore it is not corroborating on the proposed paradigm. Furthermore, the key result stated in said experiment (interventional data is better than simply more observational data for recovering the true causal graph) is arguably not of value to the paper since it is (a) to be expected from existing literature and (b) it does not corroborate on the proposed paradigm.\n* Consider calling graphical neural networks simply graph neural nets (GNN) to keep consistency with existing literature on GNN.\n* Consider using the original invariant causal prediction paper by Peters et al. as reference.\n* Consider using an alternate notation for $==$ since it is an arguably atypical notation for graph learning reminiscent of programming language literature.\n\n**3. Correctness, Clarity, and Literature**\n\nNo contradictions or any sort of relevant mistake have been detected in the paper. Existing bodies of work are being referenced accordingly at the end of the paper.\n\n**4. Reproducibility, Code Release, and Assumptions**\n\nSufficient details for reproduction are being provided. Unfortunately, without actual code. All key assumptions for the method are being pointed out explicitly.","sentences":[{"sentence_type":"2","sentence":"The paper suffers from several disadvantages (ranging in importance from minor to more fundamental) that however IMHO can be improved upon mostly quickly.","rephrased":"The paper presents several areas for improvement, which range from minor to more substantial, but I believe these can be addressed effectively with some revisions."},{"sentence_type":"2","sentence":"Furthermore, the key result stated in said experiment (interventional data is better than simply more observational data for recovering the true causal graph) is arguably not of value to the paper since it is (a) to be expected from existing literature and (b) it does not corroborate on the proposed paradigm.","rephrased":"While the key result of the experiment in Section 4.3 aligns with expectations from existing literature, it would be beneficial to see how it specifically supports the proposed paradigm."},{"sentence_type":"1","sentence":"Consider using an alternate notation for $==$ since it is an arguably atypical notation for graph learning reminiscent of programming language literature.","rephrased":"It may be helpful to use a more conventional notation instead of $==$ to align with common practices in graph learning literature."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1763,1917,"Not concerning"],[3334,3644,"Confirmed"],[3871,4025,"Not concerning"]],"Comments":[]}
{"id":"SooiU6_zYjK","text":"### Summary\n\nThis work studies using physics-informed neural networks to estimate the unknown parameters of epidemic compartmental models. To achieve this, this work first proposes an extended counterpart model, named SEIRD, to model the dynamics of the COVID-19 pandemic, which takes the Death (D) counts into consideration. This paper then posits that the parameters for the pandemic in different phases are dynamic. Therefore, this paper proposes a graph neural network to fit the reported cases and epidemic model parameters simultaneously. In experiments, this work evaluates the proposed GNN on the reported cases from Italy. The results show that the model is able to fit the reported cases and generate corresponding epidemic model parameters. Lastly, the model is applied to forecast the infected cases. The results show that the model predicts the reported cases reasonably accurately, mostly achieving within 20% relative absolute error. \n\n### Strengths\n\n- This paper designs a physics-informed neural network to fit case counts and the parameters  in the epidemic model simultaneously and considers the dynamics of the epidemic model parameters. \n- The empirical study on the reported cases from Italy shows that model fits the reported cases accurately and generates meaningful model parameters. \n\n### Weaknesses\n\n- It would be interesting to connect the intepretation of estimated epidemic parameters to the intervention policicies. Figure 3 shows the intervention policies conducted by the government during the pandemic. I wondering whether the estimated parameters can be incorporated to explain the effect of each intervention policy. Can the local changes of estimated parameters be interpreted corresponding to the application of the intervention policy. \n- The proposed methods needs to be described in more details. For example, in Figure 2, there is a automatic differentiation step to convert the estimated cases to its differentiation. It would be helpful to describe how this step is conducted, since it connects the two conterparts of the neural networks. \n- Experimental setup is not well described. For example, in data fitting experiments in Section 3.3.1, it would be better for the reader to interprete the results, if the authors can explain the data splitting for fitting the model to the data. Would different data splitting leads to different results? \n- Comparison with related baselines needs to be incorporated. This paper shows the error of the model regarding forecasting the reported cases of the pandemic. However, the comparison with related baselines, such as other PINN or time series prediction methods, would be helpful to assess to the effect of the proposed model. \n- Discussion of related work is missing. It would be better to provide a more detailed discussion of previous epidemic models and phisics-informed neural networks. \n\n","sentences":[{"sentence_type":"2","sentence":"Experimental setup is not well described.","rephrased":"The description of the experimental setup could be enhanced to provide clearer insights into the methodology."},{"sentence_type":"2","sentence":"Discussion of related work is missing.","rephrased":"Including a discussion of related work would enrich the context and significance of the findings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2086,2127,"Not concerning"],[2718,2756,"Not concerning"]],"Comments":[]}
{"id":"k87ZumWBy7a","text":"\nThis paper proposes a CoIL framework - Co-Imitation Learning, that trains two agents at the same time and “cooperatively” leverages past good experiences of the agents to learn a policy. This approach avoids the need for potentially expensive expert demonstrations in imitation learning, and is better than related approaches like self-imitation learning because the experiences of the other agent provide external supervised information.\n\nThe Introduction section explains the intuition behind the proposed idea in a simple and understandable manner using results from various approaches on the MiniGrid-MultiRoom-N6 task. The methodology's theoretical and practical aspects are clearly explained and motivated in subsequent sections. It is tested on various environments, and the selection of baselines and experimental setup is carefully documented. The results demonstrate the approach's applicability and effectiveness. Overall, the paper is succinct and makes for an interesting read.\n\nThe proposal is interesting and evokes similarities to bio-inspired algorithms like Particle Swarm Optimization. Here are a few suggestions on improvements and further work that would strengthen the paper but also serve as interesting future directions to pursue:\n+ Extend the co-imitation learning approach to ensembles, i.e. more than 2 agents. It’d be interesting to contrast the improvements with the tradeoffs like greater resource requirements and training time per step.\n+ More agents may lead to better generalization by avoiding local minimas. The phenomenon may be more evident with a higher number of agents and would be worth studying.\n+ The paper mostly talks about cooperation between agents; it’d be interesting to explore the adversarial aspects of training multiple agents in tandem.\n","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"Byg5fBqTKr","text":"\n====== Updates ======\nI appreciate the authors' time and effort in the response. I have read the rebuttal, but I am not convinced by the authors' argument on using L2 (or L_\\infty) constraints. No matter whether L2 or L_\\infty constraint is used, the authors' method is not directly comparable to methods in Song et al. (2018), making the results in Table 2 and Table 3 meaningless and confusing. \n\n- Song et al. (2018) indeed constraints the search region of latent code to be within a small L2 ball of a randomly sampled anchor latent code. However, this anchor latent code is not directly related to any given image in the dataset, and therefore the generated adversarial examples are not close to any existing image. In contrast, the authors' attack is still basically a norm-bounded attack, which is not directly comparable to the unrestricted attack in Song et al. (2018).\n\n- Song et al. (2018) is a white box attack, while the attack in this paper is black box.\n\n====== Original review =======\n\nThis paper proposes to generate semantic preserving adversarial examples by first learning a manifold and then perturbing data along the manifold. In this way the generated adversarial examples can be semantically close to the original clean examples, and the perturbations can be hopefully more natural. For manifold learning, the authors propose to use a similar approach to that proposed in Pu et al. (2017), which uses SVGD to train a VAE. After the VAE is trained, the authors use GBSM to train a model to produce semantic adversarial examples efficiently.\n\nI have many concerns for this paper:\n\n- The approach is not well motivated. It is unclear why using a fully Bayesian framework and employing SVGD to learn the VAE model is preferred for conducting semantic adversarial attacks. Many choices in the algorithm seem to be arbitrary, and there are many approximations in the method whose accuracies have no guarantees. For example, the recognition networks  are used to approximate the updated parameters of the encoder from SVGD. Sampling from the posterior distribution of z is approximated by first doing Monte Carlo over \\Theta. For \"manifold alignment\" another recognition network is used to approximate the updates from SVGD. It is hard to predict how those approximation errors accumulate when all pieces are combined together to form a very complicated algorithm.\n\n- In Equation (6) the authors hard-constrain the generated adversarial example such that they cannot differ from the original data by some pre-specified l_2-norm. This leads to many unfair comparisons in the experiments:\n\n    1. The authors compare their approach to other attacking methods on the success rates of attacking Madry's model and Kolter & Wong's certified model. However, both Madry and Kolter & Wong's model are for attacks using the l_infinity norm. It is unfair that the authors' attack uses l_2 norm. In fact, it is known that models robust to l_infinity norm attacks are generally not robust to attacks using other norms. \n\n    2. The authors also compare their approach to methods in Song et al. (2018) and Zhao et al. (2018a). However, the two previous approaches did not directly constrain the distance between generated adversarial examples and the corresponding clean inputs. Therefore, when using human evaluation to assess the image quality of generated adversarial examples, the two previous methods are naturally at a huge disadvantage. In stark contrast, the authors' adversarial images are constrained to be close to the corresponding unperturbed images under a small l_2 norm, which naturally have higher image quality.","sentences":[{"sentence_type":"2","sentence":"making the results in Table 2 and Table 3 meaningless and confusing.","rephrased":"The results in Table 2 and Table 3 could be more clearly presented and directly comparable to the methods in Song et al. (2018) to enhance their significance."},{"sentence_type":"2","sentence":"Many choices in the algorithm seem to be arbitrary, and there are many approximations in the method whose accuracies have no guarantees.","rephrased":"The rationale for many choices in the algorithm could be better explained, and the method would benefit from a more thorough analysis of the approximations used and their potential impact on accuracy."},{"sentence_type":"2","sentence":"It is hard to predict how those approximation errors accumulate when all pieces are combined together to form a very complicated algorithm.","rephrased":"It would be helpful to provide an analysis or discussion on how the approximation errors might accumulate and affect the overall performance of the algorithm."},{"sentence_type":"2","sentence":"It is unfair that the authors' attack uses l_2 norm.","rephrased":"It would be more equitable to compare the authors' l_2 norm-based attack with other methods that use the same norm for a balanced evaluation."},{"sentence_type":"2","sentence":"Therefore, when using human evaluation to assess the image quality of generated adversarial examples, the two previous methods are naturally at a huge disadvantage.","rephrased":"For a fair assessment, human evaluation of image quality should consider the different constraints applied by the previous methods, which may affect their performance in comparison."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[329,397,"Confirmed"],[1793,1929,"Confirmed"],[2243,2382,"Not concerning"],[2849,2901,"Not concerning"],[3283,3447,"Maybe"]],"Comments":[]}
{"id":"r1xcT5bSYE","text":"This paper describes the collection and analysis of tweets expressing denial or acceptance of climate change. Training and development data for supervised training of a binary tweet classifier are collected from influential tweeters with known opinions towards climate change. The trained classifier is then used to classify a larger collection of tweets around natural disasters in the US and its predictions are analyzed, with respect to geolocation and change over time.\n\nPros:\n- Interesting insights into reaction on twitter towards climate change.\n- Comparison of a diverse set of classic binary classification algorithms.\n- Good visualizations and discussion of outcomes, including significance tests.\n\nCons:\n- Data: Is the data made publicly available? How were the influencers chosen? \n- Analysis: It's not clear whether the classifier is reliable enough to draw these conclusions. Examples from the classifications would allow a rough inspection of the quality. If a different classifier would have been chosen, would the conclusions from the analysis still hold? \n- The trick for dealing with unlimited data is not in the focus of this paper and also not evaluated against any other method.\n\nIn summary, I find the analysis of the classified tweets interesting and neat, but my background knowledge on twitter analysis for climate change is too limited to assess whether its novelty. However, possible inaccuracies or biases of the deployed classifier are not discussed and the aspect of learning with limited data is not in the focus of the paper, which makes me question the relevance for this workshop.","sentences":[{"sentence_type":"2","sentence":"The trick for dealing with unlimited data is not in the focus of this paper and also not evaluated against any other method.","rephrased":"While the paper does not focus on the challenge of dealing with unlimited data, it would be beneficial to see an evaluation of the proposed method against alternative approaches."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1076,1200,"Maybe"],[1394,1614,"Missed Maybe"]],"Comments":[]}
{"id":"S1ghLD70FH","text":"This paper proposes a new algorithm which brings closer SGD and Adam while also incorporating new corrections to improve behavior of the optimizer in contexts where there is very small or very large eigen values.\n\nDecision\n\nI vote for weak rejection because the core modification proposed to Adam is minor and is mostly supported by intuition and preliminary experiments.\n\nJustification\n\nThere is many modifications proposed, but most are secondary corrections for stability, such as the warm-up schedule with the redefinition of beta_2. These modifications could as well be incorporated in Adam without the core modification that is the smoothing presented in section 3. These additional modifications also make it difficult to measure the importance of the core contribution. Without getting rid of them, an ablation study on toy problems (even synthetic data) would be necessary for a better understanding.\n\nIn section 3.1, the temporal definition of beta_2t is integrating a warm-up. While the reason for doing so is supported in introduction of section 3, the effect of this modification should be weighted against no warm-up, and also compared with its effect on Adam.\n\nThere is an error in algorithm 1. The last element of the last line (Perform the update) should be \\alpha (1 - \\eta) m_t\/d_t. The code in Appendix corroborates this correction. Minor related note, the use of d_t to define the denominator of what d_i represents in section 3 is very confusing. I would suggest to use the ratio notation of d_i from the equations in the algorithm for coherence.\n\nIf we get pass the warm-up scheduling, by massaging the equation we get that the algorithm is different from Adam on 2 points, 1) the bias are not corrected and 2) the denominator sqrt(v) + epsilon is replaced by sqrt(v) + sqrt(mean(v) + epsilon^2). I have difficulty convincing myself that smoothing by the average is solving the issues raised in the paper and there is no experiments to study its effect directly.\n\nThe experiments are on 3 datasets, but only the computer vision ones are run on multiple architectures. Caption of figure 1 explains that each model is trained 3 times, but the source of variation between each run is not described. Are the models initialized differently? In any case, there is an overlap for 3 of the 5 models between SGD and SoftAdam which makes the comparison rather unconvincing. There is no standard deviation for Adam, and none on Penn Treebank dataset and IWSLT. For a better comparison, all hyper-parameters of the algorithms should be optimized for each run. I understand that SoftAdam is meant to be close to both SGD and Adam, but using the same hyper-parameters may induces misleading results by favoring some (model, optimizer) combination nevertheless.\n\nMinor comments\n\nIn section 2, second paragraph, the term 'mini-batch' should be used instead of 'batch'.\nIn section 2, last sentence, the betas should have no t.\nIn section 2.1, fourth equation (unnumbered), the eigen vector xi_i is presented as a vector and then used as a scalar. Notation should be uniformed.\nIn Section 2.1 around equation (2), the use of i and j is incoherent.\nIn Section 3:\n- Overall, this understanding *of* has\n- we consider the *an* update","sentences":[{"sentence_type":"2","sentence":"I vote for weak rejection because the core modification proposed to Adam is minor and is mostly supported by intuition and preliminary experiments.","rephrased":"I lean towards rejection because I believe the core modification to Adam could benefit from more substantial evidence and rigorous testing beyond the preliminary experiments presented."},{"sentence_type":"1","sentence":"There is an error in algorithm 1. The last element of the last line (Perform the update) should be \\alpha (1 - \\eta) m_t\/d_t.","rephrased":"I noticed a discrepancy in algorithm 1. It appears that the last element of the last line (Perform the update) might be more accurately represented as \\alpha (1 - \\eta) m_t\/d_t, as supported by the code in the Appendix."},{"sentence_type":"2","sentence":"I have difficulty convincing myself that smoothing by the average is solving the issues raised in the paper and there is no experiments to study its effect directly.","rephrased":"It would be beneficial to include experiments that directly study the effect of smoothing by the average to address the issues raised in the paper more convincingly."},{"sentence_type":"1","sentence":"There is no standard deviation for Adam, and none on Penn Treebank dataset and IWSLT. For a better comparison, all hyper-parameters of the algorithms should be optimized for each run.","rephrased":"Including standard deviation for Adam and on datasets such as Penn Treebank and IWSLT would enhance the comparison. Additionally, optimizing all hyper-parameters of the algorithms for each run could provide a more accurate assessment."},{"sentence_type":"2","sentence":"In any case, there is an overlap for 3 of the 5 models between SGD and SoftAdam which makes the comparison rather unconvincing.","rephrased":"The observed overlap for 3 of the 5 models between SGD and SoftAdam suggests that further analysis might be needed to strengthen the comparison."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[224,371,"Not concerning"],[1176,1301,"Not concerning"],[1820,1985,"Maybe"],[2259,2386,"Confirmed"],[2387,2570,"Confirmed"]],"Comments":[]}
{"id":"yT97j3ocJ6D","text":"#### **Strengths of paper**\n1. This blog adapts the ICLR 2019 paper by Tessler et al., 'Reward Constrained Policy Optimization,' to propose a method in safe reinforcement learning using safety constraints (i.e., constrained optimization problem). \n\n2. The proposed method leads to adaptive reward shaping that yields the desired reward function.\n\n3. The authors also verify the performance of their method using experiments on the HalfCheetah task in OpenAI MuJoCo Gym.\n\n#### **Weaknesses of paper**\n1. There is no discussion on how training the robust policy and adaptive reward shaping are related. \n\n2. There are notation issues, e.g., $J_R^\\pi$ is not defined in defined before using it in the objective of the constrained optimization problem. Even  $J^\\pi$ initially denotes the infinite horizon discounted total return, which is later used for denoted the objective value of the constrained optimization problem after using the Lagrange relaxation technique. It is not mentioned what RCPPO means.\n\n3. No details on how the RCPO algorithm works. A brief overview can help readers to understand the algorithm and its adaption to safe RL. \n\n4. Using 'observing the cost' (something similar) is a better choice than 'Get Constraint' because the constraint is part of the optimization problem, and you can't observe it as it is set beforehand. \n\n5. \"... parallel environments is a bit more complex.\" Authors need to give at least some high-level reason why it is complex. \n\n6. No details on how one can set constrained in a safe reinforcement problem. I think the problem of reward shaping in the proposed method is transferred to designing appropriate safety constraints.","sentences":[{"sentence_type":"2","sentence":"No details on how the RCPO algorithm works.","rephrased":"The paper would benefit from including details on how the RCPO algorithm functions, which would aid readers in understanding its application to safe RL."},{"sentence_type":"2","sentence":"Using 'observing the cost' (something similar) is a better choice than 'Get Constraint' because the constraint is part of the optimization problem, and you can't observe it as it is set beforehand.","rephrased":"It may be more accurate to use terminology such as 'observing the cost' rather than 'Get Constraint', as the latter implies observability of a pre-set element of the optimization problem."},{"sentence_type":"2","sentence":"\"... parallel environments is a bit more complex.\" Authors need to give at least some high-level reason why it is complex.","rephrased":"The authors could enhance the paper by providing a high-level explanation of the complexities involved with parallel environments."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1008,1051,"Not concerning"],[1148,1345,"Not concerning"],[1351,1473,"Not concerning"]],"Comments":[]}
{"id":"_Egkrswxzn","text":"**Summary.** The authors propose using a neural network to learn a canonical transformation of the data coordinates before learning a Hamiltonian. This is a novel contribution in that previous work has shown how to learn Hamiltonians with neural networks but it has not shown how to learn the proper canonical transformation. In the course of learning this canonical transformation, they show how to project out other symmetries (linear and angular momentum) and hence improve upon HNNs while also learning these other symmetries to a good approximation.\n\n**Strong points.** The authors have a strong grasp of Hamiltonian mechanics and they lay out the theory in an accurate and easy-to-follow manner. The core idea is a good one and it leads to promising (although entirely qualitative) results. The experimental setup is reasonable and the behavior of the trained models is visualized effectively. The symbolic regression applied to the learned models shows that they learned physically relevant quantities, and this is an excellent empirical validation of the authors’ approach, eg. Equation 16.\n\n**Weak points.** Some sections of the paper were very hard to follow. For example, the experimental setup which was introduced in the form of “Model 1, Model 2, Model 3…” was very confusing. First of all, the authors never gave intuition for what each of these models was specifically aiming to test. Here are my best guesses, although I would like to see the authors’ definitions as well:\n* Model 1: This appears to be the generic Symmetry Control NN. They enforce a Poisson loss in latent space and then train an HNN on it. Since they set \\beta to zero, H ends up being invariant to the transformed coordinates (P, Q) only implicitly, by way of the Poisson loss and the HNN loss. Since the fourth loss term is regularizing P_i to be constant, it appears that they are regularizing *all* P_i in the model to be constant. I don’t quite understand this. This presumes that all momenta are stationary, which is not the case for the 2-body system -- we only expect two of them to be constant. Is the idea that this regularization will hopefully force two to be constant while the other two are not?\n* Model 2: This enforces only half of the transformed coordinates to be cyclic. But the authors make another change: they force the learned canonical transformation to be linear by construction. So to summarize, they are changing two things: 1) now we're using a linear transformation for (p,q)->(P,Q) and 2) now we're using a different number of cyclical coordinates. A proper ablation of the experiment should just change one of these, and the authors should describe what they are trying to ablate.\n* Model 3: This resembles Model 1 more closely, but here we are explicitly defining the first two symmetries (x and y momentum conservation) but not the third (angular momentum)\n* Model 4: This is complementary to Model 3 in that they are fixing the angular momentum and learning the linear momenta\n* Model 5: They fix all the known symmetries (both angular and linear momenta). This corresponds to adding maximal domain knowledge to the model.\nThe remainder of the experimental results likewise need more explanations. There should be a table of quantitative results. There should be more discussion regarding the system of coupled oscillators. There should be quantitative measurements of error-of-fit for the symbolic regression models\n\tThe 3-body results are quite good and it was interesting to see that these models excelled in this context compared to baseline NNs and HNNs. The authors provide a nice, intuitive discussion of these results.\n\n**Recommendation.** 5 : Marginally below acceptance threshold\n\n**Reasoning.** This paper tackles a significant problem, presents a novel and useful method, and achieves promising empirical results. Its weaknesses were 1) that experimental methods and results were not sufficiently well explained and 2) there were not enough quantitative results. The paper cannot be accepted to ICLR as-is. I would consider changing my recommendation if these two core issues were addressed in a substantial way.\n\n**To improve the paper.** The authors should make their explanation of methods substantially clearer, with special attention paid to explaining why they design the experiments and models the way they did. The authors should provide qualitative results for all three tasks.","sentences":[{"sentence_type":"1","sentence":"Some sections of the paper were very hard to follow.","rephrased":"Some sections of the paper could benefit from additional clarity to enhance understanding."},{"sentence_type":"1","sentence":"The remainder of the experimental results likewise need more explanations.","rephrased":"Further explanations of the experimental results would be beneficial for a more comprehensive understanding."},{"sentence_type":"2","sentence":"The paper cannot be accepted to ICLR as-is.","rephrased":"The paper would benefit from revisions to meet the acceptance criteria for ICLR."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1117,1169,"Not concerning"],[3143,3217,"Not concerning"],[3995,4038,"Not concerning"]],"Comments":[]}
{"id":"0-kn8rZimK","text":"This paper empirically studies the effect of combining deeper networks, layer normalization, and large batch size in the context of offline RL. Specifically, the paper extends BRAC algorithm with a few modifications (some borrowed from TD3+BC) that stabilize its training, and then incorporate the 3 additional modifications. The resulting ReBRAC algorithm achieves state-of-art performance on D4RL.\n\nStrengths:\n1. The paper is well-written and clear\n2. The experiments are thorough; the ablations clear demonstrate the utilities of the proposed modifications\n\nWeaknesses:\n1. Hyperparameters are tuned per environment+dataset combination. In practice, you cannot do this as there is no \"free\" evaluation of the offline learned policies. Furthermore, this reduces the significance of the results as it is not clear whether the gains are just from better hyperparameters.\n\n2. Some missing related works:\nSinha et al., D2RL: Deep Dense Architectures in Reinforcement Learning\nBjorck et al., Towards deeper deep reinforcement learning\n\nFinally, I would note that this is a paper strictly in the domain of offline RL; while relevant, I do not think it is directly related to the notion of reincarnating RL.","sentences":[{"sentence_type":"2","sentence":"In practice, you cannot do this as there is no \"free\" evaluation of the offline learned policies.","rephrased":"In practice, it may be challenging to tune hyperparameters per environment+dataset combination without a cost-free evaluation of the offline learned policies."},{"sentence_type":"2","sentence":"Furthermore, this reduces the significance of the results as it is not clear whether the gains are just from better hyperparameters.","rephrased":"Additionally, it would be beneficial to clarify if the performance gains are due to the algorithmic contributions or primarily from hyperparameter optimization."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[639,736,"Not concerning"],[737,869,"Not concerning"]],"Comments":[]}
{"id":"Syep7Jnz5E","text":"This paper applies normalizing flows into denoising autoencoders, and derives a variational lower bound when the posterior has this form. Experiments on MNIST show improvements over VAE, but worse than other NF models.\n\npros: The paper is well written and easy to follow. It does a good job in reviewing related work.\n\ncons: While it combines VAE, NF and DAE, no particular novel technique is introduced, and it‘s no better than existing models, so the significance of the proposed framework is unclear. In addition, the expensive complexity of L-VDAE makes it  difficult to scale to high-dimensional data. Nevertheless, the topic is very relevant and I think it's worth discussing at this workshop.","sentences":[{"sentence_type":"2","sentence":"no particular novel technique is introduced, and it‘s no better than existing models, so the significance of the proposed framework is unclear.","rephrased":"The paper could benefit from highlighting the novelty of the proposed combination of VAE, NF, and DAE, as it is not immediately clear how it advances beyond existing models. Clarifying the unique contributions could help underscore the significance of the framework."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[360,503,"Confirmed"]],"Comments":[]}
{"id":"rkeupP1wFN","text":"Summary: The authors propose a VAE architecture that leverages multi-modal information, namely images and text in order to learn a matched latent space representation. The representation is created by minimizing two additional objectives in addition to the beta-VAE loss: the cross-reconstruction (CA) and the distribution-alignment (DA) regularizers. The learnt joint-posterior is then utilized to train a classifier in a GZSL setting. The method posed shows promising results as it beats SOTA in several benchmarks but should address the following points in the camera ready version.\n\nMajor:\n  - There is no motivation or reasoning specified for the L1 cross-reconstruction (CA) loss in Equation 2. If the decoder is a gaussian then the natural assumption is a likelihood proportional to the L2 loss. If there is indeed a Laplace-likelihood this should be clearly stated. If not, then a small ablation study \/ discussion demonstrating the difference between the L1 & L2  (and corresponding distributional assumptions) for the CA should be provided.\n\n  - For the classifier part of the model is the dimensionality of the softmax fixed? Or does it simply refer to which sample it is associated with as in few-shot learning? In addition, how is the classifier trained? I.e. does it use both \\mu's and \\Sigma's ? Are they concatenated? Passed through separate networks?\n\n  - The final loss does not show the dependence on the hyper-parameters that weight the different terms of the loss; specifically the L_{CA} term seems to be hyper-parameter free? Training of multi-objective VAEs critically relies on the scale of these hyper-parameters. Beta in the beta-VAE is also not specified. These are critical and should be described.\n\nMinor:\n  - are the image features extracted from a pre-trained Resnet-101 model or is the encoder a Resnet-101 model? This should be made clear.\n  - How many posterior samples are extracted for classification? How are they used? Is a classification made for each sample or is the latent representation averaged \/ concatenated and then classified? Why isn’t just the mean used as is standard in a test-setting for VAEs?\n - title is missing the word “Shot”","sentences":[{"sentence_type":"1","sentence":"The method posed shows promising results as it beats SOTA in several benchmarks but should address the following points in the camera ready version.","rephrased":"The method demonstrates promising results, outperforming state-of-the-art in several benchmarks. To further strengthen the paper, the authors should consider addressing the following points before the final submission."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[437,585,"Not concerning"]],"Comments":[]}
{"id":"SygFLpeAYB","text":"This paper attempts to learn a preconditioner for optimization, specifically for the Dual space preconditioned descent (DPGD). \n- The techniques used to learn the preconditioner are heuristic, not scalable and without justification or ablation studies. \n- It does not compare against \"standard\" optimization techniques that construct data-driven preconditioners such as Adam or Adagrad or even to more Newton, natural gradient methods that use the Hessian or the Fisher information matrix as preconditioners. It shows ad-hoc synthetic experiments in dimensions 1 and 50. This is clearly not enough. \nDetailed review below:\n- Section 2: Please explain why Legendre functions are useful in ML. For assumption 1, 2; it needs to be explained why these hold for a given f*. What constraints do you need on f? What functions satisfy these? Please explain this explicitly. \n- Section 3: What is the number of points x_i needed in high dimensions to learn? Is it even possible to scale up this method to high dimensions?\n- Constructing \\mu requires computing the determinant of the Jacobian. What is the computational complexity? Moreover, it seems that we need access to the \\nabla f(x) for all x in D(f)? \n- Please state all the assumptions in the beginning rather than introducing one at a time in the propositions. \n- Remark 1: It is unclear that the cost of an inverse Hessian matrix is more than the procedure proposed in this paper. \n- Section 3.5: Please explain what is the advantage of this learned optimizer compared to other methods? Note that there is literature on non-smooth optimization and methods like sub-gradient descent can be used in this case. \n- What is the justification for the selection of the loss function and log-rescaling?\n- The result of Lemma 1 is standard. Please acknowledge this. \n-  Section 4: \"The step-size is set to 1\". It seems that the optimizer has been overfit and engineered to work on this specific problem. Either these decisions need to be justified, there needs to be an ablation study or there needs to be a larger set of experiments. \n\n\n","sentences":[{"sentence_type":"2","sentence":"The techniques used to learn the preconditioner are heuristic, not scalable and without justification or ablation studies.","rephrased":"It would be beneficial to provide justification for the techniques used to learn the preconditioner, address their scalability, and include ablation studies to strengthen the paper."},{"sentence_type":"2","sentence":"It does not compare against \"standard\" optimization techniques that construct data-driven preconditioners such as Adam or Adagrad or even to more Newton, natural gradient methods that use the Hessian or the Fisher information matrix as preconditioners. It shows ad-hoc synthetic experiments in dimensions 1 and 50. This is clearly not enough.","rephrased":"The paper would be more comprehensive if it included comparisons with standard optimization techniques like Adam or Adagrad, and with methods that use the Hessian or the Fisher information matrix as preconditioners. Additionally, expanding the experiments beyond the ad-hoc synthetic ones in dimensions 1 and 50 could provide a more robust validation of the proposed method."},{"sentence_type":"2","sentence":"The step-size is set to 1. It seems that the optimizer has been overfit and engineered to work on this specific problem.","rephrased":"Clarification on the choice of a step-size set to 1 would be helpful, as well as evidence to show that the optimizer generalizes well beyond the specific problem it was tested on."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[130,252,"Not concerning"],[256,598,"Not concerning"]],"Comments":[]}
{"id":"UzIAlELm6","text":"This paper describes a method to leverage unlabelled images to improve image segmentation via convolutional neural network.\nThe idea is based on the well-known “active contour without edges” segmentation method introduced by Chan & Vese, which consists in minimizing an energy such that both the background and the segmented object have homogeneous intensities, and the boundary between them is smooth. \nThe authors train a network with such a loss for all unlabelled images, and a standard segmentation loss for the labelled ones.\n\n* The main limitation of this method is that it assumes that the object and respectively the background have consistent intensities, i.e. that they can be approximated by a single intensity value: $c_1$ (resp. $c_2$).\nThis is a very strong hypothesis that is not discussed at all by the authors.\nIn particular, it rarely holds in medical imaging where structures are more often distinguishable by their shape, their texture or their surrounding but not necessarily by a single and absolute intensity value.\nThis is actually why methods like Chan & Vese have fallen out of fashion in our field. Here this might even be more dramatic if $c_1$ and $c_2$ are supposed to represent the reference intensities for all unlabelled images.\n* The experiments are based only on simulated data, and in particular on one phantom. It is also not clear whether training and validation images are really different.\n\nOn the method itself:\n* I find it a bit surprising to define F with both the length and area, only to discard the length on the very next line. While I agree that the two quantities are related, they favor different kind of shapes.\nMoreover, length is not that difficult to encode as a loss, for instance consider a norm of the gradient of the network output.\nThis is all the more surprising that this has been done in $L_{label}$, see first term of equation 3.\n* Why not use the Dice coefficient or the cross entropy for the labelled images, which are widely considered to be the standard losses for medical image segmentation?\n\nMinor issues:\n* The images are not very readable, especially Figures 2 and 3.\n* The statement “generating annotated data [..] could take several months to a year to complete” seems a bit exaggerated.\n* The paper could benefit from a proof-reading since there are many typos, for instance\n- base on -> based on\n- prposed -> proposed\n- CovNet -> ConvNet\n- avaiable -> available \n$\\lambda1$ -> $\\lambda_1$","sentences":[{"sentence_type":"2","sentence":"This is actually why methods like Chan & Vese have fallen out of fashion in our field.","rephrased":"It would be beneficial for the authors to consider that methods like Chan & Vese are less commonly used in our field, possibly due to the complexity of medical imaging characteristics such as shape and texture."},{"sentence_type":"2","sentence":"The statement \\","rephrased":"The authors might want to address the perception that generating annotated data is a lengthy process, providing more context or evidence to support this statement."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1040,1126,"Not concerning"]],"Comments":[]}
{"id":"iLayvWD1I87","text":"The paper proposes a method that modifies double Q-learning by eliminating a linearly correlated part of one Q. I am not familiar with the proof of Double Q-learning and TD3, and thus find the proof of this paper hard to read as it omits the majority of proof by claiming it is similar to the proof of the aforementioned two algorithms. To name some of the part that confused me while reading: what is the definition of F^Q_t and c_t in (14)? Why does a small delta_2 exist in (16)? Why does Delta_t converge to zero as claimed in the line after (16)? Why is the randomness of s_{t+1} not mentioned in the subscripts of E's in (5) and (9)? etc. Therefore, I suggest the author(s) write a thorough proof and put it in the appendix to make the convergence analysis readable. I am also curious how the de-correlation term helps to improve the convergence in the analysis as it is the main contribution of this paper. Besides,  double Q-learning and TD are mostly used in function approximations. I wonder if the analysis can extend to some simple case of parameterized Q functions, e.g. linear approximations. The experiment part looks good to me as it compares D2Q with several sota algorithms and get satisfying results.","sentences":[{"sentence_type":"2","sentence":"I am not familiar with the proof of Double Q-learning and TD3, and thus find the proof of this paper hard to read as it omits the majority of proof by claiming it is similar to the proof of the aforementioned two algorithms.","rephrased":"The proof in this paper could be made more accessible by including more detailed explanations or comparisons with the proofs of Double Q-learning and TD3, rather than assuming similarity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[112,336,"Not concerning"]],"Comments":[]}
{"id":"fTf_BpgKJsE","text":"\nSummary:\n \nThis paper introduced a general framework that incorporates multi-object reinforcement learning(MORL) perspective for constrained reinforcement learning to a policy set, called Pareto front, that meets the constrained. The author has instantiated a method based on the previous method MO-MPO. Compared to previous Lagrangian-based approaches, the proposed method has advantages in solution quality, stability, and sample-efficiency in few empirical environments.\n\n##########################################################################\nReasons for score: \n \nOverall, I'd vote for rejection for this paper. My major concerns lie in two aspects: 1) the innovation is minor compared to the previous method(MO-MPO). 2) the empirical evidence for the proposed method is marginal to me. Hopefully, the authors can address my concern in the rebuttal period.  \n\nPros:\n\t1. The paper is straightforward and clear to read.\n\nCons:\n\t1. The motivation of the proposed framework is not strong. Besides that, the improvement of constrained MO-MPO is minor.\n\t2. The domains ( runs & walk) didn't illustrate the idea well. It is not clear to me what the constrained is. The advantage of constrained MO-MPO over lagrangian-based approaches is marginal. The advantages could vary from sed choice. \n##########################################################################","sentences":[{"sentence_type":"2","sentence":"Overall, I'd vote for rejection for this paper.","rephrased":"Overall, my assessment leads me to lean towards rejection for this paper."},{"sentence_type":"2","sentence":"the innovation is minor compared to the previous method(MO-MPO).","rephrased":"the innovation seems incremental when compared to the previous method (MO-MPO)."},{"sentence_type":"2","sentence":"the empirical evidence for the proposed method is marginal to me.","rephrased":"I find the empirical evidence supporting the proposed method to be insufficient."},{"sentence_type":"2","sentence":"The motivation of the proposed framework is not strong.","rephrased":"The motivation behind the proposed framework could be articulated more compellingly."},{"sentence_type":"2","sentence":"The advantage of constrained MO-MPO over lagrangian-based approaches is marginal.","rephrased":"The demonstrated advantage of constrained MO-MPO over Lagrangian-based approaches appears to be limited."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[573,620,"Maybe"],[662,726,"Maybe"],[730,795,"Maybe"],[938,993,"Confirmed"],[1167,1248,"Maybe"]],"Comments":[]}
{"id":"7rBSXHpWMfo","text":"\nStrengths  \n\nS1 The dynamic rule memory module is interesting.\n\nS2 Detailed ablation study and case study.\n\nS2 The paper is well written and well organized.\n\nWeaknesses\n\nW1 RL agent aims to seek long-term and maximum overall reward to achieve an optimal solution. However, this paper aims to divide the long-term decision into independent short-term decision. Therefore, I don’t see why RL should be used in this scenario.\n\nW2 Too much reliance on heuristics. For example, it utilizes statistical features, such as the number of occurrences to represent relation pairs. \n\nW3 How to recover the logical rule is unclear to me. Should we enumerate over the whole rule space to select the rules with the highest score?\n\nW4 How do the authors handle uncertainty during the deduction is unclear. It is possible for a two relation sequence to have multi heads. For example, given two relation sequences hasAunt and hasSister, both hasMother and HasAunt can be the head. How can the proposed solution solve the multi head scenario?\n\nW5 The author should discuss more about how to choose the value of n (number of unknown relations). Intuitively, a small n may reduce the expressiveness of the model while a big n may cause computational inefficiency. Choosing the value of n could be a tricky problem.\n\nW6 Lack of some representative baselines. For example, NeuralLP, RNNLogic are missing.\n\nW7 Datasets include too few relations.To show the scalability of the proposed model, it will be better to conduct experiments on datasets with more relations e.g., FB15k.","sentences":[{"sentence_type":"2","sentence":"Therefore, I don’t see why RL should be used in this scenario.","rephrased":"It would be helpful if the authors could clarify the rationale for using RL in this scenario, given that the paper divides the long-term decision into independent short-term decisions."},{"sentence_type":"1","sentence":"How to recover the logical rule is unclear to me.","rephrased":"The method for recovering logical rules could be further elaborated to enhance clarity."},{"sentence_type":"1","sentence":"How do the authors handle uncertainty during the deduction is unclear.","rephrased":"The authors may want to address how uncertainty is managed during the deduction process."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[361,423,"Maybe"],[576,625,"Not concerning"],[720,790,"Not concerning"]],"Comments":[]}
{"id":"cbzFAdpPVSw","text":"This paper improves sample efficiency from the pre-training perspective by incorporating prior computations as the baseline values in PPO. The topic is interesting and on the trend. Based on the experiment, it seems that the method did fasten the training processes.\n\nPros:\n1. The experiments settings are thorough. \n2. The paper is written to make readers easy to understand\n3. The idea of including pre-trained computations into baselines is interesting.\n\nCons:\n1. The idea of improving sample efficiency of gradient methods from the perspective of pre-training is interesting. However, in PPO with baseline, the idea of using estimated value function as the baselines has been proposed before. The paper simply proposes a weighted combination of current value function estimation and the one from prior computations.\n2. In the method, the paper presents REINFORCE, while in the experiment they adopt PPO. The inconsistency causes confusions. Furthermore, in line 188-189 the authors mentioned the *Q-function to Value Estimate* is demonstrated for discrete action spaces, while in the experiment the action space of all the environments are continuous. The authors left out the details for the adaptation.\n3. Though the experiment settings are thorough, this paper only compares their method with one baseline method.\n\nIn summary, in combination with the experiments I agree that the paper proposes a valid idea to improve sample efficiency, and the perspective is interesting. However, the paper has some spaces for improvement in clarifying confusions, and the idea is yet to be confirmed on more SOTA methods. Therefore I propose a marginally acceptance.","sentences":[{"sentence_type":"2","sentence":"The paper simply proposes a weighted combination of current value function estimation and the one from prior computations.","rephrased":"The paper proposes a method that builds upon existing work by introducing a weighted combination of current value function estimation with prior computations, which could be further elaborated to highlight its novelty."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[697,819,"Not concerning"]],"Comments":[]}
{"id":"BGzgfoRtn-5","text":"The paper presents an analysis of a generalized Fourier transform for signals on DAGs. This is a linear transformation that diagonalizes a generalized form of \"causal shift\" on DAGs. The Fourier features are used to classify infection status in a contact tracing application.\n\nI found the paper mathematically interesting, innovative and elegant. After reading I was left with a few questions which could be answered in the text (see below). I also wonder how well the mathematical setup fits the application (again see below). Nevertheless I think this is a strong workshop submission, with fundamental ideas about Fourier transforms on graphs, that have potential to impact future work in various areas.\n\nDetailed comments:\n\nSome technical questions that could be answered in the text:\n- When is the shift operator invertible?\n- Do shifts commute?\n- How do we see that a shift operator is diagonalizable? How do we see that all shifts are simultaneously diagonalizable? (This would follow if shifts always commute)\n\nIn the sentence: \".. filters are shift-invariant (resp. equivariant)\". I don't understand the word respectively here, as only one noun is mentioned before (filters). The equation that follows shows equivariance not invariance.\n\nIt would be good to explain the intuition of the contact tracing model and Fourier features a bit more. As I understand it, the probability that x is infected is modelled as a sparse linear combination of Fourier features. This means that only nodes upstream of x can contribute to its probability of being infected, which makes sense as x can only have been infected through a path of contacts to an infected individual. So a positive coefficient hat{r_y} means that this individual was probably infected, and thus contributes positively to all downstream nodes. However the distance to the downstream node is not taken into account, I think. I don't really understand the interpretation of negative coefficients either: if we are very sure someone is not infected, that could lower the probability that downstream nodes are infected, but not if those nodes have other ancestors that are infected. That is, a negative contribution should not cancel a positive one; addition of reals is probably not the right way to combine contributions. Perhaps you can model this situation nicely with enriched categories \/ preorders -- see the book on Applied Category Theory by Fong & Spivak.","sentences":[{"sentence_type":"1","sentence":"I don't really understand the interpretation of negative coefficients either: if we are very sure someone is not infected, that could lower the probability that downstream nodes are infected, but not if those nodes have other ancestors that are infected.","rephrased":"The interpretation of negative coefficients could be clarified further. For instance, if a node is very likely not infected, it might reduce the probability that downstream nodes are infected. However, this might not be the case if those nodes have other ancestors that are infected. Could you elaborate on how these situations are modeled?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1890,2144,"Not concerning"]],"Comments":[]}
{"id":"SyxlnxOXFE","text":"The paper presents an image generation model, focusing on learning a program that explores the regularities within the data, such as cycling patterns. The model aims at learning two hidden variables, one that defines the structure of the program and another that defines how the model fills the patches defined within the program. \n\nI believe this is a good direction for research in image generation, or any generation tasks of similar nature. Such models would allow for computationally efficient models, especially for generating higher resolution images, since there is a quadratic increase of the number of parameters needed. It would be great that in the future versions of the paper the authors could show that larger images can be learned with similar numbers of model parameters. \n\nFinally, I would like to see results on medium to larger scale datasets, such as CIFAR-10 or Imagenet. Not only samples are more diversified, it would also allow for an analysis of the sample efficiency of the proposed method compared to existing methods.","sentences":[{"sentence_type":"1","sentence":"Finally, I would like to see results on medium to larger scale datasets, such as CIFAR-10 or Imagenet.","rephrased":"It would be beneficial for future work to include results on medium to larger scale datasets, such as CIFAR-10 or Imagenet, to further demonstrate the model's capabilities and sample efficiency."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[791,893,"Not concerning"]],"Comments":[]}
{"id":"H1gIxC_m9H","text":"This paper proposed Graph Enhanced Transformer(GET) to combine the graphical and sequential representations of the molecule to improve the retrosynthesis prediction performance. Experiments indicated that the proposed model outperforms state-of-the-art Seq2Seq-based methods on USPTO-50K dataset, and showed ability in reducing invalid SMILES rate.\n\nTwo main comments: \n\n1. This paper provide no novelty with respect to deep learning method. It is just a combination of sequence transformer and graph neural network (using RDKit(Landrum, 2016) to transform a SMILES into the molecular graph). The decoder is the same as vanilla Transformer to generate SMILE string output. \n\n2. The writing can be improved. For instance, in the caption of Figure 1 - \"somehow to be transformed\" ...  plus a few other places have wording issues like this.  \n\n \n\n\n","sentences":[{"sentence_type":"2","sentence":"This paper provide no novelty with respect to deep learning method.","rephrased":"While the paper leverages existing deep learning methods, it would be beneficial to highlight any novel aspects or contributions that differentiate this work from previous studies."},{"sentence_type":"1","sentence":"The writing can be improved.","rephrased":"The manuscript would benefit from further revisions to enhance clarity, such as refining the caption of Figure 1 and addressing other wording issues throughout the text."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[374,441,"Confirmed"],[678,706,"Confirmed"]],"Comments":[]}
{"id":"6pasjKg1tV","text":"The paper presents a method to generate mamography images with styles from different acquisition devices (Hologic, Gioto, Anke). The main motivation is to adapt different images to the preference of the expert reader.\n\nThe idea is interesting but the paper lacks any information regarding the training process or the training dataset used to generate the transformation models. Also, the experiment with the two experts contains a small number of images and the distribution of the classes is not described. The results does not allow to claim that using the style generation model by generating images with the expert’s preference improves  the expert’s performance.","sentences":[{"sentence_type":"2","sentence":"The results does not allow to claim that using the style generation model by generating images with the expert’s preference improves  the expert’s performance.","rephrased":"The results do not conclusively support the claim that using the style generation model to generate images tailored to the expert's preference enhances the expert's performance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[508,667,"Not concerning"]],"Comments":[]}
{"id":"cVY7QPCT0ex","text":"This paper studies the correlation between the flatness of the converged local minimum and the margin. The authors report experimental results that verify the positive correlation. They suggest using margin-based measures to assess the generalizability. Also, the authors argue that large-batch optimization does not have enough time to maximize margins and hence generalize worse and suggest using it to replace the “misleading folklore” that small-batch methods generalize better because they are able to escape sharp minima. In addition, the authors significantly narrowed the margin which would have violated the policy: “Tweaking the style files may be grounds for rejection.”\n\nOverall, I vote for rejection. The experiments are described in detail and seem correct. However, I was worried that (1) the reported results are not new; and (2) the authors argue existing results are misleading but did not give enough establishment to support their argument. Extraordinary claims require extraordinary evidence. It would be good if the authors can address thesis concerns in the rebuttal session.\n\nPros:\n\n+ The authors conduct experiments which verify a positive correlation between the margin and the flatness.\n\nCons:\n\n- The results are not new. It is well-known that (1) margin is a good measure for assessing the generalizability [1-4]; and (2) flatness has a strong correlation with the generalizability as the authors have stated. Combining (1) and (2), it is not surprising margin and flatness has a strong correlation.\n\n- The authors argue that large-batch optimization does not have enough time to maximize margins and hence generalize worse. This argument lacks evidence from either theoretical or empirical aspect.\n\n- The authors argue that it is a misleading folklore that small-batch methods generalize better because they are able to escape sharp minima, still without evidence. In contrast, this has been established in many works; e.g., Sagun et al. (2017) as the authors mentioned.\n\n- The authors significantly narrowed the margin. As stated in the template: “Tweaking the style files may be grounds for rejection.”\n\nQuestions: It would be good if the authors can address the cons.\n\n[1] Vladimir Vapnik and Vlamimir Vapnik. Statistical learning theory. Wiley New York, 1:624, 1998.  \n[2] Peter Bartlett and John Shawe-Taylor. “Generalization performance of support vector machines and other pattern classifiers.” In Advances in Kernel Methods: Support Vector Learning, pages 43–54, 1999.  \n[3] Vladimir Koltchinskii, Dmitry Panchenko. “Empirical margin distributions and bounding the generalization error of combined classifiers.” The Annals of Statistics, 30(1):1–50, 2002.  \n[4] Ben Taskar, Carlos Guestrin, and Daphne Koller. “Max-margin Markov networks.” In Advances in Neural Information Processing Systems, pages 25–32, 2004.","sentences":[{"sentence_type":"2","sentence":"Extraordinary claims require extraordinary evidence.","rephrased":"For claims that significantly challenge existing understanding, it is important to provide robust and comprehensive evidence."},{"sentence_type":"2","sentence":"The authors argue that it is a misleading folklore that small-batch methods generalize better because they are able to escape sharp minima, still without evidence.","rephrased":"The authors' challenge to the common belief that small-batch methods generalize better due to escaping sharp minima would be strengthened by additional supporting evidence."},{"sentence_type":"1","sentence":"Tweaking the style files may be grounds for rejection.","rephrased":"Please adhere to the provided style files as deviations from them can be a concern during the review process."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[626,680,"Not concerning"],[961,1013,"Not concerning"],[1653,1726,"Missed Maybe"],[1730,1893,"Not concerning"]],"Comments":[]}
{"id":"lmDI7SZTJx0","text":"This paper studies representation learning in an e-commerce setting. In particular, the paper explores the use of the recently proposed Bootstrap Your Own Latent (BYOL) framework to learn product representations. Rather than using different views of the same entity (as is done in the image domain), different products within a single shopping session are used. Experiments show that the unsupervised BYOL alone does not perform well in this setting. To remedy this issue, the objective is modified by adding a supervised product category prediction loss. Experimental comparisons are made to several baselines on four downstream supervised learning tasks.\n\n### Strengths\n1. Much of the recent success in unsupervised representation learning has been in the CV and NLP domain. Studying the effectiveness of these techniques in other domains is an important practical research direction.\n2. Experiments empirically confirm the benefit of the proposed modification to the BYOL objective.\n\n### Weaknesses\n1. The study of the BYOL framework in a new domain is a welcome contribution (contribution 3). Unfortunately, the experiments do not effectively isolate and study this topic due to the number of factors which change between baselines (architecture, objective, training data, etc). Notably missing are benchmarks for an equivalent architecture (TextCNN) trained with a more standard representation learning setup using a contrastive loss. Without such comparisons it is not possible to determine whether the improved representation learning abilities of the BYOL framework in the CV domain transfer to the e-commerce domain, or if the improved performance is the result of architectural and other experimental differences between baselines.\n2. The paper does not justify the precise modification of the BYOL objective presented here. Would adding an explicit contrastive term, which would be advantageous in scenarios where supervised data is not available, have been less, equally, or more effective? Why predict $c_{p_j}$ from $p_i$ rather than $c_{p_i}$? What about predicting the categories of all products in the session in a multi-label manner, etc? The choices made in the paper should be explained and justified.\n3. Experimental details are not clearly described. For example, I could not find a description of the difference between Site A and Site B. The number of unique products and users is not specified. Are the products that appear in the supervised tasks a subset of the products that appear in the session level data, or are there \"cold-start\" items which the model did not see during pre-training? Is the BERT model fine-tuned for the specific down stream supervised task, or are only the classifier parameters updates? The Appendix leads me to believe the the latter, \"we only use the encoded version of the data\", in which case this baseline seems less representative of best practices.\n4. The Appendix mentions that the Meta-Prod2Vec baseline uses the full session dataset, that this caused \"some problems\" with direct comparison, and that it will be addressed in a \"future releases.\" The nature of \"some problems\" should be clarified and possibly mentioned in the main paper. If results are not comparable they should be removed or fixed before publication.\n5. The paper overstates contributions. The architecture used here (TextCNN) is quite standard, and does not represent a significant contribution alone (contributions 1 and 2). \n\n### Recommendation\nI vote for rejection. Although I believe understanding the effectiveness of BYOL in non-CV domains is an important research direction, I do not believe the current paper effectively addresses this topic due to issues with baselines and a lack of experimental details.\n\n### Additional Info\nThe paper contains grammar mistakes which I found made reading difficult at times. Most are relatively minor and did not obscure from the overall message and content of the paper, and therefore did not contribute substantially to my assessment. Below are several examples from Section 5.1.\n\n1. \"As we can **observer**, in almost all plots\" => \"As we can **observe**, in almost all plots\"\n2. \"the better performance is for the value of α of 0.9 **specially** at very low training samples\" => \"the better performance is for the value of α of 0.9 **especially** at very low training samples\"\n3. \"the curve is **more steep** for cases\" => \"the curve is **steeper** for cases\"","sentences":[{"sentence_type":"2","sentence":"I vote for rejection.","rephrased":"I recommend reconsideration after addressing the highlighted issues."},{"sentence_type":"2","sentence":"The paper overstates contributions.","rephrased":"The paper could more accurately represent its contributions."},{"sentence_type":"1","sentence":"The Appendix leads me to believe the the latter, \"we only use the encoded version of the data\", in which case this baseline seems less representative of best practices.","rephrased":"The Appendix suggests that only the encoded version of the data is used; it would be beneficial to clarify if this approach aligns with best practices."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2740,2908,"Not concerning"],[3285,3320,"Confirmed"],[3321,3455,"Missed by Model"],[3479,3500,"Not concerning"]],"Comments":[]}
{"id":"vlWDKaq0olE","text":"- No Baseline Comparisons: Paper proposed a way to generate object level representation that can be used across the tasks with same objects. Authors claim that this should reduce the number of environment interactions required to solve the new task. However, there is no baseline comparison being done to figure out how sample efficient it is.\n\n- Paper assumed that tasks are solvable from set of provided options, will the method work of the task is out of provided options space ?\n\n\n\n","sentences":[{"sentence_type":"1","sentence":"However, there is no baseline comparison being done to figure out how sample efficient it is.","rephrased":"It would be beneficial to include baseline comparisons to better understand the sample efficiency of the proposed method."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[250,343,"Confirmed"]],"Comments":[]}
{"id":"HWxslgGgMq","text":"This paper is in the scope of the workshop and proposes to use the dot product similarity between object embeddings at two separate timesteps to infer the underlying action in a video.\n\nThere are some typos in the paper, for example missing table references on table 4. While it does seem like using the difference in object states to infer an action is good -- it feels like some actions are best inferred not from a change in object state, but rather the actions needed to move the object from one state to another. So, it may be interesting to see how to extend the work to a video of different frames.\n\nIts interesting that the approach appears to outperform other baselines on this task -- why this happening? Is this generally applicable to other setting besides actions also?","sentences":[{"sentence_type":"1","sentence":"Its interesting that the approach appears to outperform other baselines on this task -- why this happening?","rephrased":"It's interesting to note that the approach seems to outperform other baselines on this task. Could you provide some insight into the reasons for this performance? Is there something inherent in the method that might explain its success?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[607,714,"Not concerning"]],"Comments":[]}
{"id":"_RSmtgNi8e","text":"In this paper, the authors combine the advantages of joint learning and transfer learning to improve the performance on\nliver lesion segmentation and classification. Although the techniques are not new, it is good to use them in new applications.\n\nI am just curious about the performance in the following settings:\n(1) The segmentation performance on the authors' private data using the pretrained model from LiTS dataset.\n(2) The segmentation performance on the authors' private data if only finetuning a segmentation model instead of the joint model.\n\nSetting (1) can show us how much performance the finetuning can improve based on the good pretrained model from LiTS dataset.\nSetting (2) can show us whether the joint learning has a bad effect on the segmentation task.","sentences":[{"sentence_type":"2","sentence":"Setting (2) can show us whether the joint learning has a bad effect on the segmentation task.","rephrased":"Setting (2) can help us understand the impact of joint learning on the segmentation task, and whether it enhances or hinders performance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[680,773,"Not concerning"]],"Comments":[]}
{"id":"BklBXunLqN","text":"General:\n\nThis paper revisits auxiliary latent variable formulation of variational inference. Inspired by that, the authors develop a generative model based on self-normalized importance sampling (SNIS), and connect it to recent approaches such as  NCE and CPC. The view is very interesting. In experiments on MNIST, SNIS combined with VAE framework outperforms recently proposed LARS, while being faster and computationally cheaper.\n\nPros:\n\n+ This paper provides a unified view of variational lower bound through auxiliary latent variables (this is not new though), relates that to the generative model side, and proposes a self-normalized importance sampling process as a generative model. This new method called SNIS can be connected with NCE and CPC. As mentioned in the paper, a unified view over different approaches might provide insights for future research\n\n+ While only evaluated in the VAE context, the method can be potentially general and effective for other settings (as mentioned in the LARS paper).\n\nCons:\n- I would like to see more experiments under different settings to show efficacy of the method\n","sentences":[{"sentence_type":"1","sentence":"This paper provides a unified view of variational lower bound through auxiliary latent variables (this is not new though)","rephrased":"This paper provides a unified view of variational lower bound through auxiliary latent variables, building upon existing concepts in the field."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[444,565,"Not concerning"]],"Comments":[]}
{"id":"Skgu_zsaKH","text":"This paper unfortunately violates the blind-review policy: its acknowledgement exposes the authors. I thus support desk rejection. \n                                                                                                                                                                                                                                                                                                                                                                                ","sentences":[{"sentence_type":"2","sentence":"This paper unfortunately violates the blind-review policy: its acknowledgement exposes the authors. I thus support desk rejection.","rephrased":"The paper appears to have breached the blind-review policy due to acknowledgments that may reveal author identity. A desk rejection may be considered, but I would recommend addressing this issue with the authors first."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,130,"Not concerning"]],"Comments":[]}
{"id":"l2MbNyEgSjP","text":"-In the methods section, the authors claim to describe their model. However, all we have is the description of a U-Net. Any modification was made to the U-Net?\n - In the results section, it is not clear why the authors chose only one fold? Furthermore, it is unclear by how much the results got improved by the proposed method\n - In the conclusion it is said '... augmented inference *may* dramatically improve...', does that mean that it sometimes work and sometimes not? Please be more clear.","sentences":[{"sentence_type":"2","sentence":"However, all we have is the description of a U-Net.","rephrased":"Could you please clarify if there were any modifications made to the standard U-Net architecture?"},{"sentence_type":"1","sentence":"Furthermore, it is unclear by how much the results got improved by the proposed method","rephrased":"Could you provide more details on the extent of the improvements achieved by the proposed method?"},{"sentence_type":"2","sentence":"does that mean that it sometimes work and sometimes not?","rephrased":"Could you elaborate on the conditions under which the augmented inference is expected to improve the results?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[68,119,"Not concerning"],[240,326,"Maybe"],[416,472,"Not concerning"]],"Comments":[]}
{"id":"KPNdS-gafvn","text":"Strengths:\n1. This paper is very clear and easy to follow and understand.\n2. It conducted solid experiments to show the performance differences for each method.\n\nWeakness:\nIt is very difficult to position and evaluates this paper. Though it concretely introduces lots of methods, the paper itself does not propose any new methods or insights, such that it does not qualify as a \"new-method\" paper. As for the \"review & benchmark\" paper, this paper lacks a more detailed exploration of this topic and the experimental validation is rather poor compared with review papers. Still, I will treat this paper as a review paper and below are some of my unuseful comments.\n\n1. The mathematical background could be more concrete. Instead of briefly introducing the cut and conductance, the author would also show the equation of graph Ncut, which reveals the power and need of conducting spectral clustering for node embedding.\n\n2. While introducing related methods, it would be better to use mathematical equations to showcase their insights and improvement compared with previous methods.\n\n3. The \"orthogonal projection\", \"radial projection\" and \"geometric partitioning\" can be unified in the classifier section. All these projections could be considered as the preprocessing for classifiers. The author could consider introducing them in the neural classifier part altogether. \n\n4. Though section 2.1.3 talks about clustering from the geometric perspective. But it does feel disconnected in this paper. I don't see the benefit here.\n\n5. About the efficient computing of the eigendecomposition, the author could consider eigengame (ICLR 2020). \n\n6. For a more comprehensive experiments. The author could consider compare spectral clustering embedding with other embedding. Like node2vec, and more graph neural network based methods like GAT, GraphSage et al.\n\n\n\n","sentences":[{"sentence_type":"2","sentence":"Still, I will treat this paper as a review paper and below are some of my unuseful comments.","rephrased":"Nonetheless, I will consider this paper as a review paper and below are some comments that could further enhance its value."},{"sentence_type":"2","sentence":"But it does feel disconnected in this paper. I don't see the benefit here.","rephrased":"However, the connection of this section to the rest of the paper could be made clearer, and its benefits more explicitly outlined."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[231,396,"Missed by Model"],[572,664,"Confirmed"],[1452,1526,"Confirmed"]],"Comments":[]}
{"id":"HJh2yfcgz","text":"Summary: This paper proposes to use the latent representations learned by a model-free RL agent to learn a transition model for use in model-based RL (specifically MCTS). The paper introduces a strong model-free baseline (win rate ~80% in the MiniRTS environment) and shows that the latent space learned by this baseline does include relevant game information. They use the latent state representation to learn a model for planning, which performs slightly better than a random baseline (win rate ~25%).\n\nPros:\n- Improvement of the model-free method from previous work by incorporating information about previously observed states, demonstrating the importance of memory.\n- Interesting evaluation of which input features are important for the model-free algorithm, such as base HP ratio and the amount of resources available.\n\nCons:\n- The model-based approach is disappointing compared to the model-free approach.\n\nQuality and Clarity:\n\nThe paper in general is well-written and easy to follow and seems technically correct, though I found some of the figures and definitions confusing, specifically:\n\n- The terms for different forward models are not defined (e.g. MatchPi, MatchA, etc.). I can infer what they mean based on Figure 1 but it would be helpful to readers to define them explicitly.\n- In Figure 3b, it is not clear to me what the difference between the red and blue curves is.\n- In Figure 4, it would be helpful to label which color corresponds to the agent and which to the rule-based AI.\n- The caption in Figure 8 is malformatted.\n- In Figure 7, the baseline of \\hat{h_t}=h_{t-2} seems strange---I would find it more useful for Figure 7 to compare to the performance if the model were not used (i.e. if \\hat{h_t}=h_t) to see how much performance suffers as a result of model error.\n\nOriginality:\n\nI am unfamiliar with the MiniRTS environment, but given that it is only published in this year's NIPS (and that I couldn't find any other papers about it on Google Scholar) it seems that this is the first paper to compare model-free and model-based approaches in this domain. However, the model-free approach does not seem particularly novel in that it is just an extension of that from Tian et al. (2017) plus some additional features. The idea of learning a model based on the features from a model-free agent seems novel but lacks significance in that the results are not very compelling (see below).\n\nSignificance:\n\nI feel the paper overstates the results in saying that the learned forward model is usable in MCTS. The implication in the abstract and introduction (at least as I interpreted it) is that the learned model would outperform a model-free method, but upon reading the rest of the paper I was disappointed to learn that in reality it drastically underperforms. The baseline used in the paper is a random baseline, which seems a bit unfair---a good baseline is usually an algorithm that is an obvious first choice, such as the model-free approach.","sentences":[{"sentence_type":"2","sentence":"The model-based approach is disappointing compared to the model-free approach.","rephrased":"While the model-based approach shows potential, it does not yet achieve the same level of performance as the model-free approach."},{"sentence_type":"2","sentence":"I feel the paper overstates the results in saying that the learned forward model is usable in MCTS.","rephrased":"The paper could present a more balanced view on the applicability of the learned forward model in MCTS, considering the current performance outcomes."},{"sentence_type":"2","sentence":"I was disappointed to learn that in reality it drastically underperforms.","rephrased":"The results indicate that there is a significant performance gap that needs to be addressed."},{"sentence_type":"2","sentence":"The baseline used in the paper is a random baseline, which seems a bit unfair---a good baseline is usually an algorithm that is an obvious first choice, such as the model-free approach.","rephrased":"For a more rigorous evaluation, it would be beneficial to compare the learned model against a stronger baseline, such as the model-free approach, which is commonly used in the field."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[835,913,"Confirmed"],[2431,2530,"Confirmed"],[2714,2787,"Confirmed"],[2788,2973,"Not concerning"]],"Comments":[]}
{"id":"wXxnSBiRYJ","text":"The paper studies fair classification by using the notion of Exponential Renyi Mutual Information. As certain notions of fairness can be encoded using (conditional) independence, this paper propose to use some information theory notions of mutual information to quantify this degree of (conditional) independence, which indirectly translates to the degree of fairness. A classification algorithm with low value of mutual information between the prediction and the sensitive attributes can be considered as fair.\n\nThe paper establishes that the Exponential Renyi Mutual Information is a strong notion to ensure fairness: the authors show that this notion is stronger than many existing notions such as Lq fairness, etc. The authors propose an algorithm to train a fair classifier, with the mutual information being penalized in the objective function.\n\nStrength:\n- The idea of combining information theory notions to measure independency and applying it to fair machine learning is natural.\n\nWeakness:\n- I have some concerns with the mathematical notations in this paper.\ni) The definition 2 is very misleading. Consider for equalized odds with \\mathcal Z = \\{0, 1\\}: it is not clear to me why this definition correctly capture the conditional independence. To my best understanding, the conditioning here should be taken as 2 separate conditional expectation: one conditional expectation with Z = 0, and another conditional expectation with Z = 1. The mathematical definition in equation (2) does not seem to segregate the values of Z. Moreover, why is the expectation taken over Z when we already condition on Z \\in \\mathcal Z?\nii) What is D_R(\\hat Y_\\theta, S) in equation (11)? I guess the authors mean the D_R function with condition as in equation (2)?\n\n- The authors show that ERMI is stronger than existing notions, which is nice. However, it is not clear why a stronger notion is preferable for the penalized optimization of the form (11). One can think of penalizing the Shannon mutual information with higher penalty parameter lambda, and one may expect to see similar end results as problem (11) -- especially if we plot the accuracy-fairness tradeoff similar to Figure 1.\n\nMinor comments:\n- Lemma 1 is quite trivial. I think this lemma should be put as discussion in the paper, and not a separate lemma.\n- Why are the expectation in equation (15) taken with X?\n- The proof of Theorem 5 does not seem to prove what is stated in Theorem 5.\n- The notations in equation (11) can be made more explicit. For example, I think there is a dependence of \\hat Y_\\theta on X which is not made explicit.","sentences":[{"sentence_type":"1","sentence":"I have some concerns with the mathematical notations in this paper.","rephrased":"I would like to discuss some aspects of the mathematical notations in this paper that could be improved."},{"sentence_type":"2","sentence":"Lemma 1 is quite trivial.","rephrased":"Lemma 1 seems to be straightforward and might be better discussed within the text rather than presented as a separate lemma."},{"sentence_type":"2","sentence":"The proof of Theorem 5 does not seem to prove what is stated in Theorem 5.","rephrased":"The proof of Theorem 5 could be clarified to better align with the claims made in the theorem."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1003,1070,"Not concerning"],[2203,2228,"Not concerning"],[2375,2449,"Not concerning"]],"Comments":[]}
{"id":"B4hxEu105Wc","text":"**Summary**\nIn this work, the authors propose a linear relation network (LRN) to tackle manipulation tasks in zero-shot settings where an unseen number of objects are present. Specifically, it is assumed that only the number of distractor objects varies. The proposed LRN is a simple linearized version of the existing work, pairwise relation network. While the original relation network encodes the relation between each pair, the proposed LRN only models the relation between goal and each object, hence reducing the computation complexity from O(K^2) to O(K), where K is the number of objects. The proposed method was evaluated on the proposed multi-object manipulation domain. It was compared with relation network and attention model, and LRN outperformed the attention model by a large margin, and performed similarly to the relation network.\n\n\n**Novelty**\nLow. The proposed LRN is a simple and domain specific variation of the existing work RN.\n\n**Relevance**\nHigh. This work concerns modeling the relation between known objects, hence has high relevance to the workshop.\n\n\n**Significance**\nLow. The proposed model can only handle generalization over a number of distractor objects of the same kind, which is limited to only a specific setting.\n\n\n**Soundness**\nThe paper is sound.\n\n\n**Quality of writing\/presentation**\nThe paper reads well.\n\n**Comment**\nThe paper presents a reasonable model and the experiment result is at least positive for a specific task. However, it has relatively limited novelty and significance. It can be improved by more clearly presenting how the proposed model can be extended to a more general setting. Also, it would be great if the authors can provide more analysis on why ATTN model underperform the relational models.","sentences":[{"sentence_type":"2","sentence":"Low. The proposed LRN is a simple and domain specific variation of the existing work RN.","rephrased":"The proposed LRN appears to be a targeted and domain-specific adaptation of the existing work RN, which could be further elaborated to highlight its unique contributions."},{"sentence_type":"2","sentence":"Low. The proposed model can only handle generalization over a number of distractor objects of the same kind, which is limited to only a specific setting.","rephrased":"The generalization capability of the proposed model is currently specialized for scenarios with distractor objects of the same kind; exploring its applicability to more varied settings could enhance its significance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[863,951,"Not concerning"],[1098,1251,"Not concerning"],[1467,1526,"Missed Maybe"]],"Comments":[]}
{"id":"S1geNV6BKN","text":"Paper summary:\nThis paper targets machine translation of low-resource languages, where the main problem of current approaches is dealing with Out-Of-Vocabulary words. Given a small parallel corpus of the source and target language, the authors propose a data augmentation technique using dictionaries of the source-target languages. Specifically, given a relatively small parallel corpus of source and target sentences, and given a new set of sentences in the target language (English, in this work) and a dictionary from the target to the source language, the set of sentences are translated word by word using the dictionary the source language (Germen, and Spanish in this work), then the original sentence and the resulting sentences are added to target and source datasets in the parallel corpus, respectively. \nThe authors compare their proposed methods to two existing techniques: Back translation, COPY which copies OOV words into the sentence without translation. In their various experiments, the results convey the effectiveness of the proposed approach where it achieves an increase in the BLEU score.\n\nPros.\n1-\tThe paper suits the workshop domain.\n2-\tThe proposed approach is simple, yet it performs on par with the other baseline methods. \n3-\tThe proposed model is evaluated in different scenarios, and the experimental details are provided in the paper. \n4-\tGenerally, the paper is well-written and easy to follow. \n5-\tThe authors discussed how their proposed method has higher coverage on both the target and source languages, in contrast to the COPY method which targets only the target language. I think this is an important contribution and could replace the third contribution.\n6-\tThe authors discussed one of the potential side effects that word-by-word translation can cause, which is the syntax\/grammar correctness of the resulting sentence. \nCons.\n1-\tI believe this paper should include a comparison with Sennrich et al 2015 below or at least a discussion on why it was excluded. This work was proposed to address the same problem that the authors target. In this work, sub-words are used as the tokens for translation in order to address the OOV problem. Specifically, an external dataset is used to get a list of most common subwords instead of full words. \nSennrich, R., Haddow, B., & Birch, A. (2015). Neural machine translation of rare words with subword units. arXiv preprint arXiv:1508.07909.\n\n2-\tUsing a dictionary for word by word translation is very similar to the idea of using synonyms to mask a writing style. Both these ideas result in not only syntactic issues but semantic ones as well. For example, ‘Kicked the bucket’ which means ‘passed away’ will lose its meaning if translated word by word. The syntactic part was covered properly in Section 4, while the semantic part was partially covered in Section 5.4 where the authors discuss domain adaptation. In my opinion, (and of course as the results show) using COPY with the authors’ method should be elaborated more, both in the discussion and the experiments.   \n\nAdditional minor (formatting) issues:\n-Table 1 is not clear. First, since the study is performed on two languages, the caption should specify this example is on which language. Second, since different approaches target a different part of the corpus (either the source or the target language) I suggest separating them either in two smaller tables or by having an empty row. What I see in this table is an alternation between languages and I find it a bit confusing. \n-Tables 2 and 3. Please add ‘using BLUE score’ to the captions. That would be faster to spot compared to looking for it in the text. \n","sentences":[{"sentence_type":"1","sentence":"I believe this paper should include a comparison with Sennrich et al 2015 below or at least a discussion on why it was excluded.","rephrased":"It would be beneficial for the paper to include a comparison with Sennrich et al. 2015 or provide a rationale for its exclusion, given its relevance to the topic."},{"sentence_type":"2","sentence":"Using a dictionary for word by word translation is very similar to the idea of using synonyms to mask a writing style.","rephrased":"The approach of using a dictionary for word-by-word translation may have parallels with the technique of using synonyms to mask writing style, which could raise concerns about syntactic and semantic integrity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1875,2003,"Not concerning"],[2428,2546,"Not concerning"]],"Comments":[]}
{"id":"r1l0VF88F4","text":"The authors present a data augmentation technique for rumor detection using recently introduced contextualized word representations, like ELMo. Last, they fine-tune them with diverse datasets (tweets at their majority) in order to build rumor-specific embeddings.\n\nThe paper is very clear and easy to comprehend. The authors present a very analytical data augmentation technique for the task of rumor detection by employing semantic relatedness fine-tuning on a large Twitter corpus that they collected. This way the effectively address the labeled data scarcity and class imbalance problems.\n\nPros:\n- using state-of-the-art neural language models\n- semantic relatedness fine-tuning\n\nCons: \n- not compared with other data augmentation techniques (other than using Kochkina's method)\n- considerable time for collecting the data, fine-tuning, and kxn pair comparison\n\nWhat was the time (as well as resources) requested to fine-tune on the CREDBANK corpus, as well as the time required for the whole process? Will the data and methods be available to the public? Could other methods be used than semantic relatedness? What about involving transfer learning for similar tasks?","sentences":[{"sentence_type":"2","sentence":"considerable time for collecting the data, fine-tuning, and kxn pair comparison","rephrased":"The time and effort required for data collection, fine-tuning, and kxn pair comparison seem significant. Could you provide more details on the resources and time involved in these processes?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[785,864,"Not concerning"]],"Comments":[]}
{"id":"H1lEfW8aFB","text":"\nReview Summary\n--------------\nWhile I think there are some interesting innovations here, I don't think this is ready for ICLR. I have concerns that the evaluation doesn't focus enough on application-relevant scenarios (why exclude cells that are not in the top 50? why not use 7-day windows to capture day-of-week effects?), and that the evaluations don't quantify uncertainty (and thus the claimed improvements due to attention may not be significant). The presentation quality of the method details in Sec. 3 needs a significant rewrite to improve clarity. I do think the non-standard convolution operator is a nice idea.\n\nPaper Summary\n-------------\nThis paper addresses the forecasting of origin-destination demand data, with a focus on ride-sharing transportation applications. We assume an urban area has been divided up into N cells (known in advance). The problem is to forecast demand for *directed* rides from cell i to cell j, using historical demand data.\n\nThe paper's first contribution is the design of a convolutional neural net architecture that uses non-rectangular receptive fields more suitable to origin-destination data. Instead of assuming that cells in a given 2D euclidean neighborhood are correlated, it assumes that all journeys that overlap with the one of the cells in the current origin-destination pair are similar. They call this the \"SACN\" architecture.\n\nThe second contribution is developing an \"ST-Conv\" block that combines the above SACN convolution with gated temporal convolutions, so that both space and time can be summarized via convolution operators. A periodically-shifting attention mechanism is further used to measure long-term data's similarities to short-term data and weight accordingly.\n\nOverall, these two ideas (SACN convolutions and ST-Conv blocks with attention) are combined into what they call their Latent Spatio-Temporal Origin-Destination or \"LSTOD\" architecture, which is claimed to be the first to use both short-term and long-term features in prediction.\n\nEvaluation examines demand for ride-sharing in two major cities, A and B (presumably masked because they are proprietary). RMSE error comparing to several classic (e.g. ARIMA) and deep feature learning (e.g. LSTMs and SRCN) baselines, with primary results in Table 1. A few side experiments examine superiority over standard convolutions (Fig 3) and experiments without the attention and long-term bits of the model (Table 2). \n\n\nNovelty & Significance\n-----------------------\nThe current paper is quite niche when it comes to significance; I think it may be a bit too specialized for most ICLR readers. Solving this kind of forecasting problem seems important to ride-sharing applications, but is highly specialized for origin-destination demand data. Would be nice to see the paper attempt to connect to other problems beyond ride-sharing (maybe animal migration? maybe package logistics?).\n\nThat said, I think there's sufficient novelty. The architectural design contributions here do appear new to me (though I don't follow this kind of data closely). \n\n\nMethod Concerns\n------------------\n\n## M1: Complexity analysis missing, scaling could be a problem\n\nWhen comparing the current square receptive field architecture for CNNs with the proposed SACN, I felt there was an opportunity to clarify how both scale with N and other key problem size parameters in terms of number of parameters or execution time. I'm concerned that it will be non-scalable given the O(N) cost in terms of number of parameters and the O(N^2) cost of runtime (you need to execute Eq. 2 for each of the N^2 entries at each layer). I'd like to see some careful breakdown of this compared to other approaches. \n\nExperimental Concerns\n---------------------\n\n## E1: Why not use a 7-day past history?\n\nShouldn't ride share demand have a day-of-week trend? Why wouldn't we use last Sunday's demand to predict this Sunday's demand? I find it quite odd that for the Historical Average baseline, only the last 5 days (rather than last 7) are used, and for the presented method, only the last 3 days are used. I'd be happy to be proven wrong, but I'd guess including a 7-day window would lead to noticeably better results.\n\n## E2: Lack of error bars \/ uncertainty quantification\n\nA natural question is, can we reliably tell that the difference between (for example) RMSE 2.49 and 2.54 is significant and not noise?  I'd like to see some attempt at quantifying the uncertainty for measurements in Table 1 (perhaps taking each full day in test set as its own \"mini\" test set that produces one RMSE score, then reporting average as well as 2.5th and 97.5th percentiles or something across each day). Without this, I think the claim that attention is useful here is unproven, since the change in performance is so small (less than 0.1 RMSE). \n\n## E3: Why focus only on the N=50 most common cells?\n\nI would think to really assess demand forecasting, you want to know when to task drivers to visit less-common cells. The focus on the cells with only the top 80% of journeys means that 1 of every 5 rides would not be covered by this prediction system. I wonder if part of the reason is that using N much larger than 50 is problematic due to the scaling mentioned earlier.\n\n\nPresentation Concerns\n---------------------\n\n## P1: Need to simplify notation\n\nI found the descriptions of the neural net architecture throughout Sec. 3 quite hard to parse. I think there's an overreliance on math notation and there could be more simple description of high level intent and motivation.\n\nFor example, Eq. 2 could be simplified to avoid the channel \"m\" and layer \"l\" notation and thus let the reader focus on what matters, which is how any part of input A that involves the origin node i or the destination node j is included in the weighted sum.  Words can be used around this to clarify this same operation can happen across channels and layers. \n\nSimilarly, Eq. 3 and Eq. 4 could perhaps be replaced by a good diagram. Currently, Eq. 3 both P and Q are undefined and quite confusing.\n\n## P2: Name of the convolution operation\n\nI'm not sure \"SACN\" is the best name. The receptive field of a standard CNN looks much more \"spatially adjacent\" to me (a compact rectangle surrounding the target cell). Instead, you might call it \"topologically adjacent\" or even something like \"vertex adjacent\". You want to emphasize that you are getting strength by finding all journeys whose start or end overlaps with one of the endpoints of the current journey.","sentences":[{"sentence_type":"2","sentence":"The current paper is quite niche when it comes to significance; I think it may be a bit too specialized for most ICLR readers.","rephrased":"While the paper addresses a specialized topic, broadening the applications discussed could enhance its appeal to a wider ICLR audience."},{"sentence_type":"2","sentence":"I'm concerned that it will be non-scalable given the O(N) cost in terms of number of parameters and the O(N^2) cost of runtime.","rephrased":"It would be beneficial to include a scalability analysis, particularly considering the O(N) cost in terms of number of parameters and the O(N^2) cost of runtime, to better understand the model's practicality."},{"sentence_type":"2","sentence":"Without this, I think the claim that attention is useful here is unproven, since the change in performance is so small (less than 0.1 RMSE).","rephrased":"To substantiate the claim that the attention mechanism improves performance, it would be helpful to include uncertainty quantification, given the relatively small change in RMSE."},{"sentence_type":"1","sentence":"I wonder if part of the reason is that using N much larger than 50 is problematic due to the scaling mentioned earlier.","rephrased":"Could you please clarify if the choice to focus on the top 50 cells is related to the scaling issues mentioned earlier? Expanding on this could provide valuable insights into the model's limitations."},{"sentence_type":"1","sentence":"I'm not sure \"SACN\" is the best name.","rephrased":"The name \"SACN\" might be reconsidered to more accurately reflect the convolution operation's characteristics, such as \"topologically adjacent\" or \"vertex adjacent\"."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2495,2621,"Not concerning"],[4682,4822,"Not concerning"],[5131,5250,"Not concerning"],[5990,6053,"Missed Maybe"],[6098,6135,"Maybe"]],"Comments":[]}
{"id":"LtzEQpWylBm","text":"# Quality\nThe paper is well written and provides a comprehensive retrospective of OSU's pandemic response\n\n# Clarity\nThe paper seems to offer examples rather than comprehensive descriptions of data. Understandably difficult to cover everything, but in a retrospective like this, comprehensive analysis is going to be more useful.\n\n\n# Originality\nSimilar pandemic response retrospectives exist for other institutions, while interesting seeing OSU's work, originality is low.\n\n\n# Significance\nWhile a good snapshot of the work that occurred at a large scale public university, I feel the lack of originality reduces the overall significance.\n\n\nThe paper offers unique and detailed insight into the Ohio State pandemic response process and data collection, detailing the successes and failures of different applications and the lessons that the university leadership learned in the application of these policies. The lessons detailed would be applicable to another pandemic situation should one arise, making iterations on this faster and producing more useful insights more quickly.\n\nThe paper itself, while interesting to read and learn from, lacks large unique insights, rather agreeing with many other retrospectives with minor shifts in lessons and policies.\n\nNOTE: it looks like sections 6\/7 are incorrectly labeled (section 7 uses a \\section{} tag rather than a \\subsection{} tag)\n","sentences":[{"sentence_type":"2","sentence":"Similar pandemic response retrospectives exist for other institutions, while interesting seeing OSU's work, originality is low.","rephrased":"While the paper adds to the existing body of work on pandemic response retrospectives, further emphasis on the unique aspects of OSU's approach could enhance its originality."},{"sentence_type":"2","sentence":"While a good snapshot of the work that occurred at a large scale public university, I feel the lack of originality reduces the overall significance.","rephrased":"The paper provides a valuable snapshot of the pandemic response at a large public university, and could further increase its significance by highlighting more original findings or unique insights."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[346,473,"Not concerning"],[491,639,"Not concerning"],[1082,1259,"Missed by Model"]],"Comments":[]}
{"id":"H1emeU9CtH","text":"This paper attempts to model the development of the human visual system in infants, by training deep neural network architectures inspired by the human visual system on images from ImageNet, and learning a linear decoder on the outputs of each layer (following Zhang et al 2017) to measure how much information useful for distinguishing between classes is contained within each layer in the architecture. The paper measures the amount of class information in each layer over the progress of training.\n\nI agree that deep networks could serve as good models for various parts of the brain, including the visual system especially given that convolutional networks have been inspired from studies of the visual system. However, the paper doesn't seem to provide any evidence for how the training process used for deep neural networks should correspond to the development of the visual system in infants. In particular, backpropagation is considered biologically implausible [1], whereas backpropagation serves as the main method for learning in the neural networks. Furthermore, neural networks have randomly initialized parameters, whereas it seems unlikely that human infants' brains would lack existing organization to such a drastic extent. In order for the results in this paper to hold greater weight, I would expect to see more evidence about how the neural network training process (also including aspects such as batch normalization, and the self-supervised clustering method in DeepCluster) are expected to correlate with learning in human brains.\n\nFor the above reasons, I vote to reject the paper. My conclusions above are based on my surface-level knowledge of neuroscience, so I welcome any clarifications or corrections from the authors about the above points.\n\n[1] https:\/\/arxiv.org\/abs\/1502.04156","sentences":[{"sentence_type":"2","sentence":"For the above reasons, I vote to reject the paper.","rephrased":"Based on the concerns mentioned, I would recommend further evidence to strengthen the paper's claims before considering it for acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1555,1605,"Not concerning"]],"Comments":[]}
{"id":"aZhxHe6EbGU","text":"Description: The authors propose momentum contrastive Wasserstein autoencoders (MoCA), which is an extension of the Wasserstein autoencoder (WAE) that aims to match the prior p(z) and aggregate variational posterior q(z) through the use of contrastive learning, as opposed to earlier proposed techniques (MMD, GAN). The use of contrastive learning here is theoretically motivated by the fact that -- as shown in Wang & Isola (2020) -- in the limit of infinitely many negative samples, the distribution induced by the contrastive encoder is uniform on the hypersphere. Therefore, if p(z) is the unit + uniform hypersphere, then we can leverage contrastive learning to drive the aggregate variational posterior q(z) to be as close to it as possible. This provides a principled way to train WAEs since its corresponding optimisation assumes that P_Z == Q_Z.\n\nAdvantages:\n- A theoretical connection is made between contrastive learning and the training of WAEs.\n- Ablations explore the intricacies of combining MoCA with WAE.\n- Paper is written clearly.\n\nDisadvantages:\n- The empirical results in Table 1 suggest that MoCA is at least competitive with CelebA, though (1)  these should have uncertainty estimates and (2) the WAE-GAN result for CIFAR10 is missing. You should include uncertainty estimates over multiple runs. This may also involve you having to run WAE-GAN \/ WAE-MMD yourself, since I assume that you were not able to quote uncertainty estimates from their paper. Even if uncertainty estimates were in the cited papers, I *strongly recommend* to run these experiments yourself to remove any confounding variables from the fact that these numbers were quoted from the literature (since the experimental setup could be vastly different compared to yours). I'm not suggesting you do this for all the methods in Table 1, but I highly suggest you do so for the WAE experiments. Otherwise I have little confidence in the results you have presented.\n\nComments \/ suggestions \/ typos:\n\n- Theorem 1, \"...when g ~ P_z\". Don't you mean \"...when z ~ P_z\"?\n- Use subfigures for Figure 2 to make the presentation more clear (distinguishing between reconstructions, interpolations, and samples from the prior)\n- For the FID calculation in Table 1, what is the reference dataset here? (I see in the supplementary material you say it's the test set, ok, maybe mention this in the caption for Table 1 since it's important)\n- Generally, VAE papers also report the ELBO on the test set to examine generalisation performance. Can a similar metric be derived for your case? For instance, ELBO surgery [1] rewrites the vanilla KL term (the KL between q(z_i|x) and p(z)) as the KL between the aggregate posterior and prior (KL[ q(z) || p(z) ]) + an extra mutual information term (also mentioned in the \"Related work\" section of the original WAE paper). In that case, if you use a WAE-GAN, the discriminator estimates KL[ q(z) || p(z) ], and you could use that to obtain a rough lower bound on log p(x) on the test set. In fact, that in some sense makes WAE-GAN slightly more appealing to use here than what you have presented. What are your thoughts on this?\n- It's not clear to me whether using MoCA would be preferable from a more computationally 'economic' perspective than WAE-GAN. In the cases of both, hyperparameters are necessary, and GAN training has been made easier in recent times with the right 'tricks' (say, careful normalisation of the discriminator and using WGAN\/JSGAN). Can something be said about the memory\/computation time tradeoffs between using WAE-GAN and MoCA? For instance, if you're using contrastive learning, you either need a large batch size (for SimCLR) or a large queue (MoCA), whereas with GAN training you don't need this.\nThe main contribution is the nice theoretical connection between WAE training and contrastive learning. However, I am concerned with the statistical significance of some of the results.\n\nJustification of rating: my main concern is in the statistical significance of the results in Table 1. I am open to raising my score if my concerns have been addressed.\n\nReferences:\n- [1]: Hoffman, M. D., & Johnson, M. J. (2016, December). Elbo surgery: yet another way to carve up the variational evidence lower bound. In Workshop in Advances in Approximate Bayesian Inference, NIPS (Vol. 1, p. 2).","sentences":[{"sentence_type":"2","sentence":"Even if uncertainty estimates were in the cited papers, I *strongly recommend* to run these experiments yourself to remove any confounding variables from the fact that these numbers were quoted from the literature (since the experimental setup could be vastly different compared to yours).","rephrased":"To ensure the robustness of your results and to account for potential differences in experimental setups, it would be beneficial to include uncertainty estimates over multiple runs, particularly for the WAE experiments. If possible, consider conducting these experiments yourself to provide a direct comparison under the same conditions."},{"sentence_type":"3","sentence":"Otherwise I have little confidence in the results you have presented.","rephrased":"Providing additional data, such as uncertainty estimates and results from replicated experiments, would greatly enhance the credibility of the findings presented."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1475,1764,"Not concerning"],[1884,1953,"Confirmed"]],"Comments":[]}
{"id":"rJC1hZqxf","text":"This paper proposes a self-normalizing bipolar extension for the ReLU activation family. For every neuron out of two, authors propose to preserve the negative inputs. Such activation function allows to shift the mean of i.i.d. variables to zeros in the case of ReLU or to a given saturation value in the case of ELU.\n\nCombined with variance preserving initialization scheme, authors empirically observe that the bipolar ReLU allows to better preserve the mean and variance of the activations through training compared to regular ReLU for a deep stacked RNN.\n\nAuthors evaluate their bipolar activation on PTB and Text8 using a deep stacked RNN.  They show that bipolar activations allow to train deeper RNN (up to some limit) and leads to better generalization performances compared to the ReLU \/ELU activation functions. They also show that they can train deep residual network architecture on CIFAR without the use of BN.\n\nQuestion:\n- Which layer mean and variance are reported in Figure 2? What is the difference between the left and right plots?\n- In Table 1, we observe that ReLU-RNN (and BELU-RNN for very deep stacked RNN) leads to worst validation performances. It would be nice to report the training loss to see if this is an optimization or a generalization problem.\n- How does bipolar activation compare to model train with BN on CIFAR10?\n- Did you try bipolar activation function for gated recurrent neural networks for LSTM or GRU?\n- As stated in the text, BELU-RNN outperforms BN-LSTM for PTB. However, BN-LSTM outperforms BELU-RNN on Text8. Do you know why the trend is not consistent across datasets?\n\n-Clarity\/Quality\nThe paper is well written and pleasant to read\n\n\n- Originality:\nSelf-normalizing function have been explored also in scaled ELU, however the application of self-normalizing function to RNN seems novel.\n\n- Significance:\nActivation function is still a very active research topic and self-normalizing function could potentially be impactful for RNN given that the normalization approaches (batch norm, layer norm) add a significant computational cost. In this paper, bipolar activations are used to train very deep stacked RNN. However, the stacked RNN with bipolar activation are not competitive regarding to other recurrent architectures. It is not clear what are the advantage of deep stacked RNN in that context.","sentences":[{"sentence_type":"1","sentence":"It would be nice to report the training loss to see if this is an optimization or a generalization problem.","rephrased":"Including the training loss data could help determine whether the observed performance issues are due to optimization or generalization."},{"sentence_type":"2","sentence":"However, the stacked RNN with bipolar activation are not competitive regarding to other recurrent architectures.","rephrased":"It would be beneficial to discuss how the stacked RNN with bipolar activation compares in terms of competitiveness with other recurrent architectures."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1169,1276,"Not concerning"],[2160,2272,"Not concerning"]],"Comments":[]}
{"id":"sliAevVggO_","text":"## Summary\n\nIn their paper the authors test the abilities of different language models with regard to their ability of integrating counterfactual information in their decision process. Section 2 contains experiments about integrating provided counterfactuals into the model decision and measuring for common or counterfactual text completion. Section 3 inspects whether the LM completions are based on 'real' text understanding or simple correlations to cue words of the same domain. Section 4 tests whether LMs can infer counterfactuals in scenarios without applicable world knowledge by providing the models with sentences stating 'surprising' observations - indicating that the opposite statement should be inferred as the expected answer. All experiments are conducted using a small hand-crafted dataset and a larger, synthetically extended, version.\n\n## Related work\n\nThe paper seems to cover relevant related work with regard to querying information from LMs and inspecting counterfactuals.\n\n## Strengths\n\n* The authors present a set of straight forward experiments for querying LMs for counterfactual information using three different experimental setups in the main paper. The experiments take into account possible influences of word domain correlations as well as the influence (or absence) of previous world knowledge. The experiments are well designed to answer the posed questions.\n* The results are well presented and reveal significant differences in text understanding, especially, between GPT-3 and the other models.\n\n## Weaknesses\n\nWhile synthetic dataset samples are constructed to match the style of the smaller dataset, we see strong deviations between the small- and large-scale datasets results. E.g. Table 6 BBC results change from the expected random guessing (50%) in the small-scale dataset to 70% in the large-scale one. In my opinion the paper could be improved by inspecting and explaining which parts of the synthetic samples are responsible for this shift in performance. Overall, the paper could be improved by further analyzing which factors of the presented datasets appear to be more challenging\/difficult to the LMs.\n\n### Additional Comments\n\nResults for table 2 large-scale RW reports an exceptionally good performance for GPT-3 in comparison to the other models. I would like the authors to confirm whether the reported value is correct and may suggest discussing it in the paper.\n\n## Conclusion\n\nThe paper provides an overview over the reasoning capabilities of different LM within the domain of inferring counterfactual knowledge from text. The authors provide three empirical evaluations in the main paper that inspect the incorporation of counterfactual information into the LM reasoning process while testing against erroneous influence of lexical cues. With the upcoming popularity of LLMs, this research contributes towards a better understanding of LM capabilities and adds to the pile of evidence that helps the field of identifying the strengths and weaknesses of LM text understanding and reasoning capabilities.","sentences":[{"sentence_type":"1","sentence":"In my opinion the paper could be improved by inspecting and explaining which parts of the synthetic samples are responsible for this shift in performance.","rephrased":"It would be beneficial for the paper to explore and elucidate the aspects of the synthetic samples that contribute to the observed shift in performance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1849,2003,"Not concerning"]],"Comments":[]}
{"id":"BUQlxEcM2bq","text":"The authors introduce a novel generative RL environment graphical model. They introduce the concept of *Action-Sufficient state Representations* (ASRs), state representations that are minimally suffiicient to choose optimal actions, characterized conditions on the proposed environment model. The authors propose a SS-VAE model for explicitly learning ASRs, and achieve better results on the CarRacing and VizDoom environments against prior world-model related works (VRL, SLAC, PlaNet, DBC, Dreamer).\n\nStrengths:\n* Strong technical depth and detail, discussing derivation and relation to prior work\n* Strong results on CarRacing and VizDoom\n\nWeaknesses:\n* Technical parts are difficult to follow\n* Learning objective seems overly complex (8 parameters in equation 4)\n\nMisc. Comments\n* Baselines SLAC, PlaNet, Dreamer etc. all evaluate on the DeepMind Control Suite, why was this not evaluated here?\n* Prior work (Predictive Information) [Lee, et al. 2020](https:\/\/proceedings.neurips.cc\/paper\/2020\/hash\/89b9e0a6f6d1505fe13dea0f18a2dcfa-Abstract.html) has also tackled learning minimally sufficient state representations, but with a contrastive learning objective similar to CURL. I am wondering how the state representation minimization in this work compares to Predictive Information?\n\n","sentences":[{"sentence_type":"1","sentence":"Technical parts are difficult to follow","rephrased":"The technical sections could be made more accessible to a broader audience."},{"sentence_type":"2","sentence":"Learning objective seems overly complex (8 parameters in equation 4)","rephrased":"The learning objective, particularly with the 8 parameters in equation 4, could be simplified for clarity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[657,696,"Not concerning"],[699,767,"Maybe"]],"Comments":[]}
{"id":"ByggwiEAYN","text":"This paper tackles the problem of meta-learning, more precisely the possibility of considering off-policies. For this, a first network estimates, from the history on the current task (the \"context\"), which kind of task it is (represented by a variable 'z'), and a second network (in a standard actor-critic approach) learns the policy for the current task, thanks to a conditioning on this 'z' (which allows to perform transfer learning between similar tasks within the same network).\n\nExperiments are performed on a standard problem (MuJoCo) and significant gains are observed (from 20 to 100 fewer examples needed for training).\nWhich justifies the submission to this workshop on Limited Labeled Data, even though the primary objective of the article is not really to deal with a given dataset of limited data, but rather to target sampling data efficiency, as the article is about RL tasks.\n\nOverall, the paper is very good, with very interesting ideas; however it is clearly a very hastily made short version of a longer paper: abstract and conclusion were removed (are fully missing), text density maybe too high for a non-specialist.\n\nTherefore I hesitate between \"very good\" and \"borderline\".\n","sentences":[{"sentence_type":"2","sentence":"Overall, the paper is very good, with very interesting ideas; however it is clearly a very hastily made short version of a longer paper: abstract and conclusion were removed (are fully missing), text density maybe too high for a non-specialist.","rephrased":"Overall, the paper is very good and presents very interesting ideas. It appears to be a concise version of a more extensive paper, and I would suggest including an abstract and conclusion for completeness. Additionally, the text could be made more accessible to non-specialists by reducing its density."},{"sentence_type":"2","sentence":"Therefore I hesitate between \"very good\" and \"borderline\".","rephrased":"Therefore, while the paper is generally very good, I believe there is room for improvement to firmly place it in the 'very good' category."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[895,1139,"Confirmed"],[1141,1199,"Not concerning"]],"Comments":[]}
{"id":"H1ek-2mRKr","text":"* overview \n- This paper describes a model for transition-based dependency parser, and tested on the Amharic treebank. It proposes a modification that is different from the common practice of combining the transition with dependency relation, namely to predict the transitions first, then the dependency relations.\n    \n* strengthens\n - Unfortunately, I can't find any strength in this paper. It is more like a course project than a research paper for ICLR.\n\n* weaknesses\n- The main idea of first unlabeled parsing then predicting labels is hardly novel, and it generally won't help, since the predicted labels could be useful features for determining the transitions. There is also no experiment to compare the proposed model to normal parsing model with 2n+2 predictions to support the author's claim.\n- Generally, the architecture of the model is poorly explained. For example, it seems that the \"embeddings\" for the words are just one-hot index vectors (since the number of dimensions are the same as the vocabulary size), which is not what we mean by embeddings. It is also unclear what the dot product of the embeddings means. The attention layer is again not explained at all, e.g. what are the input and output.\n- The splitting of train\/test set does not make sense, the selection should not be influenced by the results at all. There is no reason not to use the standard split in UD. \n- I don't see what is the challenge in the discussion section, since UAS is by definition lower than LAS.\n- There numerous typos and grammar mistakes, and the citation format is broken.\n- In many places, the quoted presumably Amharic words are not shown.","sentences":[{"sentence_type":"3","sentence":"Unfortunately, I can't find any strength in this paper. It is more like a course project than a research paper for ICLR.","rephrased":"While the paper could benefit from further development and clarity to meet the research standards of ICLR, it would be helpful to highlight any potential strengths or unique contributions that may have been overlooked."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[337,457,"Confirmed"]],"Comments":[]}
{"id":"j1qiOvZkjb","text":"This work proposed a novel learning strategy for unsupervisedly anomaly detection. Particularly, authors propose to use an iterative mask generation process based on image impainting and reduction of a structural similarity metric (SSMI) between the input image and its reconstructed version. For evaluation purposes, authors resort to the public MVTec benchmark, showing better results than the baselines. Please find me comments below:\n\nStrengths\n-The paper is generally well written and easy to follow.\n-Results show that the proposed method outperforms the baselines.\n\nWeaknesses.\n-The methodological contribution is marginal\/incremental. Similarly to several methods in weakly supervised segmentation (see [1] for example) authors use iterative steps to refine the initial segmentation mask. The only difference is that instead of mine regions based on classification activation maps and classification scores the authors use a structural similarity pixel-wise metric. Beyond that there is nothing novel in the proposed methodology.\n\n-Some ideas\/motivations are unclear. For example, I don’t really understand why the mask initialization is needed at test time. Further, authors also mention in the Appendix. D that to cover whole images, they are split into X by X patches and then aggregated into four masks. Please provide more details since this is unclear. \n\n-Literature is poorly conducted with many relevant recent papers missing (furthermore, the literature comes late in the paper). In addition to the previous paper in weakly supervised segmentation, the works in [2-6] are recent works in anomaly detection, just to name a few. Authors should include all this papers, discuss their limitations and show how the proposed work can overcome these drawbacks. Authors mention that auto-encoders produce blurry images, which is true. Nevertheless, works including an adversarial discriminator have somehow addressed the issue of blurred reconstructed images. Given all this, authors should better motivate their work. \n\n-Among previous missing papers, there is the work in [2], which also employs an impainting strategy coupled with an adversarial model. Which are the differences with respect to this work?\n\n-Experiments need to be significantly extended. First, authors merely include two methods in their evaluation, while there exist more than those used in the comparisons. This is particularly important since some recent methods which have been omitted in the literature review made by the authors (e.g., [4]) significantly outperform the proposed method (0.863 vs 0.90 in AUC). Second, authors report results in terms of AUC, while I strongly suggest that they use the accuracy for individual classes, and the AUC as average of the classes. The reason for this is to better compare to related work (See for example Table 6 in [4]).\n\n\nReferences:\n[1] Wang et al. Weakly-supervised semantic segmentation by iteratively mining common object features. CVPR 2018.\n[2] Sabokrou et al. Avid: Adversarial visual irregularity detection. ACCV 2018 \n[3] Perera et al. Ocgan: One-class novelty detection using gans with constrained latent representations. CVPR 2019.\n[4] Venkataramananet al. Attention Guided Anomaly Localization in Images. ECCV 2020.\n[5] Deecke et al. Image anomaly detection with generative adversarial networks. In Joint european conference on machine learning and knowledge discovery in databases 2018.\n[6] Li et al. Exploring deep anomaly detection methods based on capsule net. In Canadian Conference on Artificial Intelligence 2020\n\n\nMinor: The paper in David Dehaene, Oriel Frigo, S´ebastien Combrexelle, and Pierre Eline. Iterative energy-based projection on a normal data manifold for anomaly localization. arXiv preprint arXiv:2002.03734 is an ICML 2020 published paper,\n","sentences":[{"sentence_type":"2","sentence":"The methodological contribution is marginal\/incremental.","rephrased":"While the methodological contribution builds upon existing work, it would be beneficial to highlight more clearly the distinct elements and innovations that differentiate your approach."},{"sentence_type":"2","sentence":"Literature is poorly conducted with many relevant recent papers missing (furthermore, the literature comes late in the paper).","rephrased":"The literature review could be strengthened by including additional recent papers that are currently missing, and it may be helpful to introduce the literature earlier in the paper to better frame the research context."},{"sentence_type":"2","sentence":"Experiments need to be significantly extended.","rephrased":"To enhance the robustness of the evaluation, consider expanding the experiments to include a wider range of methods, which would provide a more comprehensive comparison with existing work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[586,642,"Not concerning"],[1370,1496,"Maybe"],[2220,2266,"Not concerning"]],"Comments":[]}
{"id":"BJgq2bPJ5S","text":"This paper studies the problem of semantic adversarial attacks with a differentiable de-rendering and rendering pipeline. More specifically, this paper proposed a variant of FGSM (Goodfellow et al. 2015) and PGD (Madry et al. 2017) by extending the traditional Lp-bounded adversarial attacks in the rich semantic space. It considered a list of semantic parameters including color, weather, foliage, rotation, transformation, and object shape. To facilitate back-propagation and improve the quality of rendering, this paper re-implemented the differentiable equivalents of several image manipulation operations based on the previous work (Yao et al. 2018). For experimental evaluations, this paper selected the object detector SqueezeDet (We et al. 2016) as the target model for attack on the virtual KITTI dataset. Experiments demonstrated that the generated semantic adversarial examples (SAEs) can attack the SqueezeDet (see Table 1 and Table 2). By re-training with augmented data by the proposed method, the robustness of SqueezeDet (see Table 3) can be further improved.\n\nOverall, this is an okay paper with incremental technical novelty and clear presentation. Reviewer has several concerns regarding the experiments.\n\n(1) This paper only conducts experiments on virtual KITTI dataset, a synthetic benchmark for object detection and semantic segmentation. In general, studying the adversarial examples in the synthetic domain seems not a significant contribution. Reviewer would like to know the performance on the real dataset such as Cityscape (used in Yao et al. 2018) and other challenging indoor datasets such as ADE20K. At least, reviewer would like to know whether re-training on adversarial examples help to improve the performance on real dataset?\n\n(2) The conclusion is largely based on the 1547 semantic adversarial examples generated, while there are more than 4K synthetic images in the dataset. This seems contradicts against the flexibility of generating semantic adversarial examples described in the paper (e.g., single parameter modifications). Reviewer suspects the proposed differentiable rendering pipeline is not very effective so that generating SAEs requires quite a bit exhaustive search over the parameter space. Please comment on the average running time for generating a semantic adversarial example. How does that compare to generating a pixel-based adversarial example?\n\n(3) While several different quantitative analyses have been conducted, this paper only provides two examples as the qualitative result (see Figure 2). It would be more convincing if this paper provides more such examples in the appendix. In addition, ablation studies on semantic parameters are currently missing. Furthermore, reviewer wonders if it is possible to report the FID score and make sure the generated adversarial examples have the same distribution as ground-truth images.\n\n(4) SqueezeDet is the only model used in the paper. Please also consider other models and report the attack performance and transferability. In a high-level, reviewer would like to know whether the proposed differentiable rendering method generalizes to other tasks including semantic segmentation and depth prediction.\n\n(5) The following paper is related (see Figure 5 of MeshAdv paper), but not even mentioned here. Reviewer would like to see the comparison between the proposed method and the MeshAdv baseline.\n\n-- MeshAdv: Adversarial Meshes for Visual Recognition. Xiao et al. In CVPR 2019.\n","sentences":[{"sentence_type":"2","sentence":"In general, studying the adversarial examples in the synthetic domain seems not a significant contribution.","rephrased":"The reviewer would appreciate further exploration into the impact of adversarial examples in real-world datasets, in addition to the synthetic domain, to enhance the significance of the contribution."},{"sentence_type":"2","sentence":"Reviewer suspects the proposed differentiable rendering pipeline is not very effective so that generating SAEs requires quite a bit exhaustive search over the parameter space.","rephrased":"The reviewer suggests providing more details on the efficiency of the differentiable rendering pipeline, as there may be concerns about the potential need for exhaustive search over the parameter space when generating SAEs."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1362,1469,"Confirmed"],[2069,2244,"Not concerning"],[3219,3310,"Missed Maybe"]],"Comments":[]}
{"id":"SkeePQCJTQ","text":"The main concerns come from the following parts:\n\n\n(1) Repeating the old story from other papers:\nA large part of math is from previous works, which seems not enough for the ICLR conference.\nIt is very surprising that the authors totally ignore the latest improvements in neural network compression. Their approach is extremely far away from the state of the art in terms of both methodological excellence and experimental results. The authors should read through at least some of the papers I list below, differentiate their approach from these pioneer works, and properly justify their position within the literature. They also need to show a clear improvement on all these existing pieces of work. \n\n(2) quite limited novelty:\nIn my opinion, the core contribution is replacing SGD with Adam.\nFor network compression, it is common to add L1 Penalty to loss function. The main difference of this paper is change SGD to Adam, which seems not enough. \n\n(3) lacking solid experiments:\nIn section Experiment, the authors claim \"Finally, we show the trade-off for pruning Resnet-50 on the ILSVRC dataset.\", but I cannot find the results. \n\nIs the ResNet-32 too complex for cifar-10? Of course, it can be easily pruned if the model is too much capacity for a simple dataset.  Why not try the Resnet-20 first?\n\n[1] C. Louizos et al., Bayesian Compression for Deep Learning, NIPS, 2017\n[2] J. Achterhold et al., Variational Network Quantization, ICLR, 2018","sentences":[{"sentence_type":"2","sentence":"It is very surprising that the authors totally ignore the latest improvements in neural network compression.","rephrased":"The authors may not have fully considered the latest advancements in neural network compression."},{"sentence_type":"3","sentence":"Their approach is extremely far away from the state of the art in terms of both methodological excellence and experimental results.","rephrased":"The authors' approach could benefit from closer alignment with the current state of the art, particularly in terms of methodology and experimental outcomes."},{"sentence_type":"2","sentence":"They also need to show a clear improvement on all these existing pieces of work.","rephrased":"It would be beneficial for the authors to demonstrate how their work builds upon and improves existing research in the field."},{"sentence_type":"2","sentence":"The main difference of this paper is change SGD to Adam, which seems not enough.","rephrased":"The primary distinction of this paper appears to be the substitution of SGD with Adam, and it would be advantageous to further elaborate on the novelty and impact of this change."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[191,299,"Confirmed"],[300,431,"Confirmed"],[620,700,"Not concerning"],[869,949,"Not concerning"]],"Comments":[]}
{"id":"yBuNanVagT","text":"\nThis is the second cycle of the review.   I mentioned about the poor presentation of the paper in the previous round.   The authors have added some comparison with another gaze model \" pyStar-FC\" in this version. \n\nI am rather confused about the comparison with pyStar-FC that the authors are adding:  I thought the point of the comparison is to show the proposed method produces better results in terms of human gaze or head motion - on the contrary, the authors simply mention that the proposed method can produce results similar to  pyStar-FC.  Then why not just use  pyStar-FC from the beginning?  \n\nThe authors should evaluate the motion of the head or animation that shows the improved realism of the animation due to the usage of their gaze model.  There is no evaluation or qualitative test like that in the paper.   The video shows some head motion of the characters watching different directions, but this is rather subtle, and it is difficult to judge if the resolution of the head area is low. \n\nThe authors mention about the potential interesting future work - these are interesting, but isn't there any evidence that this model is most suitable for such applications compared to other models? \n\n\n\"  page 6: First, it should be noted\nthat the PSM saliency maps our models are predicated on have been\npreviously evaluated against SALICON,\n\npage 6: so we construction scenarios in our virtual\nenvironment\n\npage 6: ior (inhibition of return)　-> IOR\n\npage 7:  Matching it to real human gaze data should therefore be possible and is important planned future work.\n-> this claim sounds very optimistic and without any justification\n\n\n","sentences":[{"sentence_type":"2","sentence":"Then why not just use pyStar-FC from the beginning?","rephrased":"Could the authors clarify what distinguishes their method from pyStar-FC, especially since the results are reported to be similar?"},{"sentence_type":"1","sentence":"The video shows some head motion of the characters watching different directions, but this is rather subtle, and it is difficult to judge if the resolution of the head area is low.","rephrased":"It would be helpful if the video could demonstrate the head motion more clearly or if the resolution of the head area could be increased to better evaluate the model's performance."},{"sentence_type":"2","sentence":"this claim sounds very optimistic and without any justification","rephrased":"The claim about matching real human gaze data seems promising; could the authors provide some preliminary evidence or a rationale for this future work?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[826,1006,"Not concerning"],[1576,1639,"Confirmed"]],"Comments":[]}
{"id":"xSYMvBSUPo_","text":"Summary:\nThis paper proposes a scheme to efficiently train a reinforcement learning agent by leveraging knowledge from a teacher policy in a growing-batch setting, where the agent updates its policy only after large batches of data collection. The approach involves the following steps:\n\n1. Pre-train the value function with BC on teacher demonstrations.\n2. During policy training, initialize the policy with the pre-trained policy and add a BC regularizer to the policy loss to prevent forgetting the pre-trained knowledge.\n3. Assume access to teacher annotations, either teacher-provided actions or gradients and incorporate a regularizer term that uses the teacher annotations to improve sample efficiency.\n\nIn the experiment, the authors compared their method with naively fine-tuning the BC initialization and also conducted several ablations to determine the best regularizer and decay rate. The authors showed that their method can achieve sample-efficient fine-tuning.\n\nStrengths:\n1. The paper is well-written, and the motivation for studying fine-tuning in the growing-batch setting is clear.\n2. The ablations shown in Figures 4 and 5 are interesting and demonstrate the effectiveness of the proposed method compared to the naive BC baseline.\n\nWeaknesses and Open Questions:\n\n1. Lack of baselines: The proposed method is only compared with naively fine-tuning the BC. It would be valuable to compare it with different methods such as using offline RL approaches (e.g., CQL, IQL) or off-policy approaches (e.g., DDPGfD) in each cycle. Additionally, it would be worthwhile to compare it with other prior works that study growing-batch settings (e.g., https:\/\/arxiv.org\/pdf\/2006.03647.pdf).\n2. The assumption of the availability of expert gradients is impractical. If the teacher is supposed to be a human annotator in real-world problems, it would be difficult to obtain the gradients.\n3. Instead, if the teacher is supposed to be a neural network policy (as in the experiment), other questions arise: if we already have a teacher policy that is near-optimal, why do we need to train another policy? If the teacher policy is sub-optimal, why don't we directly fine-tune the teacher policy?\n4. It would be valuable to show the results separately with different levels of teacher optimality and analyze if the learning performance is affected by the teacher's optimality.\n","sentences":[{"sentence_type":"2","sentence":"The assumption of the availability of expert gradients is impractical.","rephrased":"The practicality of the assumption regarding the availability of expert gradients could be further examined, especially in scenarios involving human annotators."},{"sentence_type":"2","sentence":"if we already have a teacher policy that is near-optimal, why do we need to train another policy?","rephrased":"It would be helpful to clarify the benefits of training a new policy when a near-optimal teacher policy is available."},{"sentence_type":"2","sentence":"If the teacher policy is sub-optimal, why don't we directly fine-tune the teacher policy?","rephrased":"Exploring the potential advantages of directly fine-tuning a sub-optimal teacher policy could provide additional insights."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1700,1770,"Confirmed"],[2009,2106,"Confirmed"],[2107,2196,"Not concerning"]],"Comments":[]}
{"id":"Byl9kPcRtE","text":"The main contribution of this paper is an improved GAN model for image captioning. First, a context-aware LSTM captioner is proposed, which provides some moderate modifications to the original adaptive attention paper. Second, a stronger co-attentive discriminator is introduced, which shows better performance than previous discriminator design. Third, SCST is used for this GAN training. \n\nPros: The experiments are relatively well designed to understand the effect of each individual model design. \n\nCons:\nThe novelty of this paper is limited. It improves the original conditional GAN for image captioning marginally by using different generator and discriminator design, and a new training method. However, each individual module only provides marginal contributions. There is no surprise in the generator and discriminator design, and the usage of SCST for GAN training is also a direct application of previous methods. ","sentences":[{"sentence_type":"2","sentence":"The novelty of this paper is limited.","rephrased":"While the paper introduces improvements to the existing model, the degree of novelty could be further enhanced."},{"sentence_type":"2","sentence":"However, each individual module only provides marginal contributions.","rephrased":"The contributions of each individual module, while incremental, could be articulated more clearly to demonstrate their impact."},{"sentence_type":"2","sentence":"There is no surprise in the generator and discriminator design, and the usage of SCST for GAN training is also a direct application of previous methods.","rephrased":"The generator and discriminator designs follow established methodologies, and the application of SCST for GAN training builds upon existing techniques."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[509,546,"Not concerning"],[702,771,"Not concerning"],[772,924,"Not concerning"]],"Comments":[]}
{"id":"IA74-4osF1H","text":"The paper proposes a multimodal agent for web navigation. The agent is based on a vision transformer and a language model. The vision transformer is used to extract image features from web page screenshots. The language model is used to encode HTML documents. The vision and language features are concatenated and used to predict web actions. The authors show that their method outperforms previous approaches on the MiniWoB and WebShop benchmarks. The paper presents extensive experiments and ablation studies. The paper is well written and easy to follow. Tables and figures are clear and easy to understand. The authors are also releasing a large dataset accompanying the paper.\n\nPros:\n- Very well written paper.\n- Extensive numerical experiments and ablation study.\n\nCons:\n- Some clarification about the novelty of the paper would be helpful.\n- The proposed method is still far away from the SOTA Humphreys et al. (2022) on the WebShop benchmark.\n\nI recommend acceptance.\n\n## Comments:\n\n### 1. Introduction\n\n- To help the reader locate the paper in the context of the field, it would be helpful to clarify the \"novel\" aspects of WebGUM in a distinct paragraph. Specifically, the unexpert reader will benefit from a brief description of which components of WebGUM (image+HTML multimodality, instruction-finetuning, etc.) are novel and which have already been proposed in previous work.\n\n### 5. Results\n\n#### 5.1. Does Image Modality Help for Task Success?\n\n- The impact of adding the image modality does not seem to be very significant in Table 2. What does \"single\" mean in the table? The reader will benefit if that information is provided in the caption. ","sentences":[{"sentence_type":"2","sentence":"The proposed method is still far away from the SOTA Humphreys et al. (2022) on the WebShop benchmark.","rephrased":"While the proposed method shows promise, there is an opportunity to further close the gap with the current state-of-the-art as demonstrated by Humphreys et al. (2022) on the WebShop benchmark."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[849,950,"Not concerning"],[1462,1549,"Missed Maybe"]],"Comments":[]}
{"id":"rkxC0wKhFH","text":"Theorem 2 and its proof are plagiarised: they are rephrased and reorganized formulation and proof of Theorem 1 of [1], while being presented as authors' own work. \n\nAlthough the assumptions are slightly different (random forest kernels vs general kernels), core of the proof is the same, including notation and its split into Lemmas and helper Theorems. In particular:\n- formulation is the same (even use of MMD_u is copied, while not being defined before),\n- main proof of Theorem 2 (p.25-26) is the proof of Corollary 3 of [1] followed by the proof of Theorem 5 of [1],\n- Lemma 13 is Lemma 3 of [1],\n- Definition 3 in Appendix B.2 is the same as Assumption D of [1] (Appendix C.2),\n- Proposition 4 and it's proof (p. 21) are the same as Lemma 2 of [1].\n\n[1] Mikołaj Bińkowski, Dougal J. Sutherland, Michael Arbel, and Arthur Gretton. Demystifying MMD GANs. International Conference on Learning Representations, 2018.","sentences":[{"sentence_type":"3","sentence":"Theorem 2 and its proof are plagiarised: they are rephrased and reorganized formulation and proof of Theorem 1 of [1], while being presented as authors' own work.","rephrased":"Theorem 2 and its proof appear to have significant similarities with Theorem 1 of [1], including the formulation and structure of the proof, which raises concerns about the originality of the authors' presentation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[0,162,"Confirmed"]],"Comments":[]}
{"id":"BkxE6t383X","text":"Strength: \n\nThe proposed approach is architecture-independent: the attack is constructed only from the dataset.\n\nWeaknesses: \n\nPaper is not sufficiently well written for a venue like ICLR. \nAttack has very low success rate.\nTo the exception of Figures 4 and 5, many experiments are conducted on MNIST.\n\nFeedback: \n\nExperimental results show that the attack is able to degrade a classifier’s performance by inserting perturbations that are computed on the data only. However, there are no baselines included to compare adversarial evasion rates achieved here to prior efforts. This makes it difficult to justify the fairly low success rate. In your rebuttal, could you clarify why baselines were not used to offer comparison points in the experiments?\n\nFurthermore, strong conclusions are made from the results despite the lack of supporting evidence. For instance, on P10, the attack is said to “also explains why adversarial examples can be universal.”. However, not only does the attack achieve less success than universal adversarial examples would (so it cannot explain all of them) but also does it not share any characteristics with the way universal adversarial examples are crafted. Drawing such a strong conclusion thus most likely needs a lot more supporting evidence. \n\nSeveral directions would improve the content of the paper: \n\n* Complete existing experimental results by being more systematic. For instance, in Section 3.1, measurements are only performed on one pair of MNIST images. Without studying a significant portion of the test set of two datasets, it is very difficult to draw any conclusions from the limited evidence.\n* Perform a human study to have all perturbed images labeled again. Indeed, because of the ways images are perturbed here, it is unclear how much perturbation can be added without changing the label of the resulting input. \n* Study how existing adversarial example techniques modify internal representations. This would help support conclusions made (e.g., about universal perturbations---see above). \n* Rewrite the related work section to scope it better: for instance, Sabour et al. in Adversarial Manipulation of Deep Representations and Wicker et al. in Feature-Guided Black-Box Safety Testing of Deep Neural Networks explore adversaries operating in the feature space. This will also help build better baselines for the evaluation.\n\nAdditional details: \n\nTLDR: typo in the first word\nP1: The following definition of adversarial examples is a bit restrictive, because they are not necessarily limited to vision applications (e.g., they could be found for text or speech as well). “Adversarial examples are modified samples that preserve original image structures” \nP1: The following statement is a bit vague (what is obvious impact referring to?): “Experiments show that simply by imitating distributions from a training set without any knowledge of the classifier can still lead to obvious impacts on classification results from deep networks.”\nP1: References do not typeset properly (the parentheses are missing: perhaps, the \\citep{} command was not used?)\nP2: What is the motivation for including references to prior work in the realm of image segmentation and more generally-speaking multi-camera settings in the related work section? \nP2: Typo in “ linear vibration”\nP2: It remains difficult to make a conclusion about humans being robust to the perturbations introduced by adversarial examples. For instance, Elsayed et al. at NIPS 2018 found that time-constrained humans were also misled by adversarial examples crafted to evade ML classifiers: see Adversarial Examples that Fool both Computer Vision and Time-Limited Humans.\nP2: Prior work suggests that the following conclusion is not entirely true: “Most of these kinds of examples are generated by carefully designed algorithms and procedures. This complexity to some extent shows that adversarial examples may only occupy a small percentage for total image space we can imagine with pixel representations.” For instance, Tramer et al. in ICLR 2018 found that adversarial subspaces were often large: “Ensemble Adversarial Training: Attacks and Defenses”.\nP2: Others have looked at internal representations of adversarial examples so the following statement would be best softened: “To the best of our knowledge, this paper should be the first one that discusses adversarial examples from the internal knowledge representation point of view.”. See for instance, Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning by Papernot and McDaniel.\nP3: Could you add pointers to support the description of human abstraction and sparsity? It reads a bit speculative as is, and adding some pointers would help relate the arguments made to relevant pointers for readers that are less familiar with this topic. \nP3: What is the motivation for including the discussion of computations performed by a neural network layer-by-layer in Section 2?\nP4: Given that saliency maps can be manipulated easily and are only applicable locally, it appears that Figure 1 is too limited to serve as sufficient evidence for the following conclusion: “This, in some way, proves the point that the knowledge storage and representation of current neural networks are not exactly sparse prototype based.”\nP5: The error rate reported on MNIST is quite low (45%). Even using the Fast Gradient Method, one should be able to have the error rate be as high as 90% on a standard CNN.\nP7: Would you be able to provide references to backup the following statement? “This is a network structure that is very common.”\nP10: How does the discussion in Section 4.2 relate to the attack described in the submission?\n","sentences":[{"sentence_type":"2","sentence":"Paper is not sufficiently well written for a venue like ICLR.","rephrased":"The paper could benefit from further revisions to meet the high writing standards expected at a venue like ICLR."},{"sentence_type":"1","sentence":"Attack has very low success rate.","rephrased":"The success rate of the attack appears to be lower than expected, which could be addressed by comparing it with baseline methods."},{"sentence_type":"2","sentence":"Furthermore, strong conclusions are made from the results despite the lack of supporting evidence.","rephrased":"It would be beneficial to provide additional supporting evidence for the strong conclusions drawn from the results."},{"sentence_type":"1","sentence":"TLDR: typo in the first word","rephrased":"Please note that there is a typo in the first word of the document, which should be corrected."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[127,188,"Maybe"],[190,223,"Not concerning"],[752,850,"Not concerning"],[2404,2432,"Not concerning"],[2717,2993,"Missed Maybe"],[3686,3756,"Missed by Model"]],"Comments":[]}
{"id":"r1elVZBh5H","text":"The authors proposed Amortized Nesterov’s Momentum, a variant of Nesterov’s momentum that utilizes several past iterates, instead of one iterate, to provide the momentum.  The goal is to have more robust iterates, faster convergence in the early stage and higher efficiency. The authors designed two different realizations, AM1-SGD and AM2-SGD.\n\nComments:\n\nMy major concern for this paper is its unconvincing motivation and experiment results, especially when the approach is designed for deep learning.\n\nThe motivation for the proposed approach is not quite convincing. The authors said that “due to the large stochasticity, SGD with Nesterov’s momentum is not robust...This increased uncertainty slows down its convergence especially in the early stage of training and makes its single run less trustworthy” For image classification, Nesterov momentum is very popular and the final convergence values of different trails seems to be similar. It would be more convincing if the authors can provide practical evidence for supporting this claim.\n\nIt was claimed that Amortized Nesterov’s Momentum has “higher efficiency and faster convergence in the early stage without losing the good generalization performance”. What is the benefit or advantage for having faster early convergence without improving the final generalization performance?\n\nThe authors claim that “M-SGD2 is more robust and achieves slightly better performance”, in Figure 1a, however, it is really hard to tell the difference between M-SGD2 and M-SGD from Figure 1a.\n\nThe efficiency improvement in page 4 is really hard to follow for comparison with Algorithm 1 in page 3. Though m > 2 could reduce the number of operations in step 5 and 6, I don’t think this is a computational bottleneck. I believe these updates should be very fast in comparison with forward and gradient calculation. Making the 1% computation 50% faster does not mean more efficient. I would like to know how much computation cost can be saved with this modification. On the other hand, adding one more auxiliary buffer (scaled momentum) could significantly impact the training as the memory is often the limit. \n\n\nIn section 3.1, what is “identical iteration”? It is hard to compare AM2-SGD with AM1-SGD. It would be easier to follow if the side-by-side algorithm comparison can be shown early.\n\nThe section 4’s theoretical analysis based on the convex composite problem is not quite convincing. I am not sure how these results are related with the deep learning applications.\n\nIn the experiment section, the comparison of AM1\/2-SGD with other baselines seems not quite consistent. The authors first state that they use all 0.1 learning rate and 0.9 momentum for all methods, however, the setting for M-SGD is using 0.99 momentum and different learning rate schedule. This makes the comparison not very meaningful, while AM1-SGD and AM2-SGD do not use learning rate restart. With so many differences, the advantage of AM1-SGD and AM2-SGD are not that different with M-SGD.  In the task of ImageNet-152, M-SGD even is better than AM1-SGD. This makes the conclusion that “AM1-SGD has a lightweight design, which can serve as an excellent replacement for M-SGD in large-scale deep learning tasks” not quite valid.\n\nMinor: The author may assume readers maybe familiar Katyusha momentum, I think there may need more background about it. \n","sentences":[{"sentence_type":"1","sentence":"The motivation for the proposed approach is not quite convincing.","rephrased":"The motivation for the proposed approach could be strengthened with additional evidence."},{"sentence_type":"1","sentence":"It was claimed that Amortized Nesterov’s Momentum has \\","rephrased":"Could the authors elaborate on the benefits or advantages of faster early convergence if it does not improve the final generalization performance?"},{"sentence_type":"1","sentence":"however, it is really hard to tell the difference between M-SGD2 and M-SGD from Figure 1a.","rephrased":"It would be helpful if the authors could clarify the differences between M-SGD2 and M-SGD as they are not readily apparent from Figure 1a."},{"sentence_type":"2","sentence":"Making the 1% computation 50% faster does not mean more efficient.","rephrased":"It would be beneficial to quantify the overall efficiency gains from making certain computations faster, to better understand the impact on the total computational cost."},{"sentence_type":"1","sentence":"The section 4’s theoretical analysis based on the convex composite problem is not quite convincing.","rephrased":"The relevance of the theoretical analysis in Section 4 to deep learning applications could be made clearer."},{"sentence_type":"2","sentence":"This makes the comparison not very meaningful,","rephrased":"The comparison could be more meaningful if the settings for M-SGD were consistent with those for AM1-SGD and AM2-SGD."},{"sentence_type":"2","sentence":"This makes the conclusion that \\","rephrased":"The conclusion that 'AM1-SGD has a lightweight design, which can serve as an excellent replacement for M-SGD in large-scale deep learning tasks' could be revisited in light of the performance comparison with M-SGD."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[357,502,"Missed by Model"],[505,570,"Confirmed"],[1443,1533,"Not concerning"],[1855,1921,"Confirmed"],[2335,2434,"Confirmed"],[2807,2853,"Confirmed"],[3077,3248,"Missed Maybe"]],"Comments":[]}
{"id":"Skx_9r3_2X","text":"The authors are tackling sample efficiency in the reinforcement learning setting by designing a reward function that encourages exploration. To achieve this they propose you use the successor function which basically counts how often a state has been visited. At first the show this for discrete settings and extend their approach to the continuous state spaces in the Atari 2600 environments. \n\nThe paper is well written and the motivation and methods are clear from the beginning. \n\nMy biggest concerning is regarding the experimental results of this work. In Table 1 the authors show the results for the tabular games River Swim and Six Arms and copare their approach which they dub ESSR to three methods (E3, R-MAX, MBIE). The numbers in the table indicate that their method ESSR is outperforming E3 and R-MAX on both environments but is itself outperformed by MBIE. The authors don't mention this at al in the respective paragraph nor do the provide a reason as to why this could be case. Also, they neither introduce any of these methods nor do the explain the meaning of the acronyms. Only in the section 6 (of 7) they talk about related works are R-MAX and E3 introduced briefly. But yet again, MBIE is not mentioned. \n\nI have similar concerns about the results presented for the Atari benchmarks. In table 2 the authors compare their method to the classic DQN approach and two more approaches. While their approach outperforms DQN in almost all tasks, this does not hold for the remaining algorithms. Their method is being outperformed in all but one (Venture) task, where they report a higher variance and a small performance boost compared to DQN_e^MMC. Also it is not clear to me where the numbers for the DNQ_e^MMC come from. The authors just say \"[...] denotes another baseline used in the comparison\". Is this the proposed method of this work but without the successor representation?\n\nIn my opinion this work is lacking some clear and convincing results.  Is the main benefit of this method that it does not rely on domain-specific knowledge? If so, then it is not communicated clearly. The authors mention this briefly in the conclusion but provide no further analysis","sentences":[{"sentence_type":"1","sentence":"My biggest concerning is regarding the experimental results of this work.","rephrased":"My primary concern pertains to the experimental results of this work."},{"sentence_type":"2","sentence":"In my opinion this work is lacking some clear and convincing results.","rephrased":"In my view, the work could benefit from more clear and convincing results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[485,558,"Maybe"],[1901,1970,"Confirmed"]],"Comments":[]}
{"id":"HJeDy85anQ","text":"It was believed that sparse architectures generated by pruning are difficult to train from scratch. The authors show that there exist sparse subnetworks that can be trained from scratch with good generalization performance. To explain the difficulty of training pruned networks from scratch or why training needs the overparameterized networks that make pruning necessary,  the authors propose a lottery ticket hypothesis: unpruned, randomly initialized NNs contain subnetworks that can be trained from scratch with similar generalization accuracy.  They also present an algorithm to identify the winning tickets.\n\nThe conjecture is interesting and it is still a open question for whether a pruned network can reach the same accuracy when trained from scratch. It may helps to explain why bigger networks are easier to train due to “having more possible subnetworks from which training can recover a winning ticket”. It also shows the importance of both the pruned architecture and the initialization value. Actually another submission (https:\/\/openreview.net\/forum?id=rJlnB3C5Ym) made the opposite conclusions.\n\nThe limitations of this paper are several folds:\n\n- The paper seems a bit preliminary and unfinished.  A lot of notations seems confusing, such as “when pruned to 21%”. The author defines a winning lottery ticket as a sparse subnetwork that can reaching the same performance of the original network when trained from scratch with the “original initialization”. It is quite confusing as there is no definition anywhere about the “original initialization”. It would be clearer if the author can use some math notations.\n\n- As identified by the authors themself, lacking of supporting experiments on large-scale dataset and real-world models. Only MNIST\/CIFAR-10 and toy networks like LeNet, Conv2\/Conv4\/Conv6 are used. The author has done experiments on resnet, I would be better to move it to the main paper.\n\n- There is no explanation about why the “lottery ticket” can perform well when trained with the “original initialization” but not with random initialization. Is it because the original initialization is not far from the pruned solution? Then this is a kind of overting to the obtained solution.\n\n- The other problem is that the implications are not clearly useful without showing any applications. The paper could be stronger if the authors can provide more results to support the applications of this conjecture.\n\n- The authors only explore the sparse networks. Model compression by sparsification has good compression rate, especially for networks with large FC layers. However, the acceleration relies on specific hardware\/libraries. It would be more complete if the author can provide experiments on structurally pruned networks, especially for CNNs.\n\n- The x-axis of pruning ratios in Figure 1\/4\/5 could be uniformly sampled and make the figure easier to read.\n\nQuestions:\n- Does the winning tickets always exist?\n- What is the size of winning tickets for a very thin network? Would it also be less than 10%?\n\n\n------update----------\n\nI appreciate the author’s efforts on providing detailed response and more experiments. After reading the rebuttal and the revised version, though the paper has been improved, my concerns are not fully addressed to safely accept it.\n\nIt can be summarized that there exists a sparse network that can be trained well only provided with certain weight initialization.The winning tickets can only be found via iterative pruning of the trained network. This is a chicken-egg problem and I failed to see how it can improve the network design. It still feels incomplete to me by just providing a hypothesis with limited sets of experiments. The implications are actually the most valuable\/attractive part, such as “Improve our theoretical understanding of neural networks”, however, they are very vague with no clear instructions even after accepting this hypothesis. I would expect analysis of the reason behind failure and success. I understand that it could be left for another paper, but the observations\/experiments only are not strong enough for confirming the the hypothesis.\n\nSpecifically, the experiments are conducted on relatively wide and shallow CNNs. Note that VGG-16\/19 and ResNet-18 are designed for ImageNet but not CIFAR-10, which are much wider than normal CIFAR-10 networks, such as ResNet-56. Even “resnet18 has 16x fewer parameters than conv2 and 75x fewer than VGG19”, it is mainly due to the removal of FC layers with average pooling and cannot be claimed as “much thinner” networks. As increasing the wideness usually ease the optimization, and the pruned sparse network still enjoy this property unless significantly pruned. Thus, I still doubt whether the conclusion can hold for much thinner network, i.e., “winning tickets near or below 10-20%, depending on the level of overparameterization of the original network.”\n\nThe observation of “winning ticket weights tend to change by a larger amount then weights in the rest of the network” in Figure 19 seems natural and the conjecture of the reason “magnitude-pruning biases the winning tickets we find toward those containing weights that change in the direction of higher magnitude” sounds reasonable. It would be great if the authors can dig into this and make more comparison with the distribution of random weights initialization.\n\nThe figures could also be improved and simplified as the lines are hard to read and compare.\n\n","sentences":[{"sentence_type":"2","sentence":"The paper seems a bit preliminary and unfinished.","rephrased":"The paper could benefit from further development and clarification in certain areas."},{"sentence_type":"1","sentence":"It is quite confusing as there is no definition anywhere about the \\","rephrased":"The concept of \\"},{"sentence_type":"2","sentence":"Then this is a kind of overting to the obtained solution.","rephrased":"This could suggest an overfitting to the obtained solution, which may need further investigation."},{"sentence_type":"2","sentence":"The other problem is that the implications are not clearly useful without showing any applications.","rephrased":"The paper would be strengthened by demonstrating clear applications of the implications."},{"sentence_type":"2","sentence":"It still feels incomplete to me by just providing a hypothesis with limited sets of experiments.","rephrased":"The paper would feel more complete with a broader set of experiments to support the hypothesis."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1165,1214,"Not concerning"],[2159,2216,"Confirmed"],[2220,2319,"Confirmed"],[3598,3694,"Confirmed"],[3828,3920,"Missed by Model"],[4705,4781,"Missed by Model"]],"Comments":[]}
{"id":"rHeeUqnA1fq","text":"This paper builds on the work of \"Fast Differentiable Sorting and Ranking\" for DAG learning.\n\nHere are my comments for the paper.\n\n1. The idea is interesting, however, the writing of the paper could be improved. \n2. There is a very related paper \"Differential DAG sampling\", which also learns a DAG by first learning the ordering of the nodes (permutation) and then learning an upper triangular matrix. It would be nice if the authors can discuss and compare to this paper.  \n3. The procedure used by the algorithm seems to reject\/ mask out edges that are not consistent with the permutation (ordering) of the nodes. I am curious to see what is the percentage of the edges that are rejected or masked out.\n4. The model is trained on observational data, hence, the underlying model can only discover up to a Markov equivalence class of graphs. I am curious to see if the model can indeed learn different modes, aka, can it sample different node pertmuations that are consistent with graphs within the same markov equivalence class.\n5. The authors also mentioned that they introduced the  Topological Ordering Pearson Correlation evaluation metric to evaluate the permutation (node ordering) the model has learned, but I did not see a description of this metric in the paper. Could the authors elaborate on that? \n\nOverall, I think this is an interesting idea, but the writing of the paper can benefit from some more work. Also, it would be interesting to see the ablations studies and also comparisons to related methods that was discussed earlier.","sentences":[{"sentence_type":"1","sentence":"Overall, I think this is an interesting idea, but the writing of the paper can benefit from some more work.","rephrased":"Overall, the concept of the paper is intriguing. To enhance clarity and impact, I suggest further refinement of the manuscript."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1313,1420,"Not concerning"]],"Comments":[]}
{"id":"HJg-dj07tE","text":"This paper evaluates two common RL algorithms in a simulated driving environment.\n\nPros:\n1- Nice choice of using a more realistic environment.\n2- The paper is easy to read and understand.\n\nCons:\n1- Some details are missing: how exactly the reward is computed? How long an episode lasts, on average? What is the average distance a vehicle runs before having a collision?\n2- Only two RL methods are evaluated (A2C and A3C). Given the abundance of methods in the literature, it would be nice to see comparisons with some other commonly used methods, such as Q-Learning and TRPO.\n\nQuestions:\n1- Does the agent use a third person (outside the vehicle) camera view? If yes, the results would be more convincing if the first-person view was used because that is closer to the viewpoint of real vehicle.\n2- In section 4 you mention that traffic rules are given as input to the agent. How do you extract these rules from the environment? For example, how a stop sign is given as an input to the agent? Also, a more realistic environment should not explicitly give these to the agent. Instead, inferring traffic rules should be a job of the agent as traffic signs often change due to constructions, accidents, etc.\n","sentences":[{"sentence_type":"1","sentence":"Given the abundance of methods in the literature, it would be nice to see comparisons with some other commonly used methods, such as Q-Learning and TRPO.","rephrased":"To strengthen the paper, it would be beneficial to include comparisons with additional commonly used methods such as Q-Learning and TRPO, considering the wide range of methods available in the literature."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[422,575,"Not concerning"]],"Comments":[]}
{"id":"rklH0mE8KN","text":"Pros:\n  * shows improvements in data augmentation, choosing samples from generative models, and model based policy elevation. \n  * well written.\n  * experiments in 3 domains, for evaluation, data augmentation and policy evaluation.\n\nCons:\n  * missing ablation experiments for what made the density ratio trick work: self normalization, architecture, etc.\n  * for policy evaluation, missing baseline with model free evaluation - by storing the log probs \/ policy that was used to obtain a particular trajectory, as standard in model free off policy learning.\n  * for the generative model evaluation experiments, the starting point is a pretrained classifier. Would be good to know what happens when a classifier is trained from scratch. \n  * lacking a bigger discussion for what happens when the two distributions lack common support. \n  \nMissing citations:\nAzadi S, Olsson C, Darrell T, Goodfellow I, Odena A. Discriminator rejection sampling. arXiv preprint arXiv:1810.06758. 2018 Oct 16.  - a discussion of using the discriminator in GANs \nRosca M, Lakshminarayanan B, Mohamed S. Distribution matching in variational inference. arXiv preprint arXiv:1802.06847. 2018 Feb 19. - experimental work showing the failure modes of the density ratio trick.","sentences":[{"sentence_type":"1","sentence":"lacking a bigger discussion for what happens when the two distributions lack common support.","rephrased":"It would be beneficial to include a more extensive discussion on the implications of the two distributions lacking common support."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[741,833,"Not concerning"]],"Comments":[]}
{"id":"B1lTqBu_KB","text":"The proposed method represents a single MDP using a learned, low-dimensional stochastic latent variable. On these grounds, given a set of tasks sampled from a distribution, the method jointly trains: (1) a variational auto-encoder that can infer the posterior distribution over the postulated latent variable when it encounters a new task while interacting with the environment, and (2) a policy that conditions on this posterior distribution over the MDP embeddings, and thus learns how to trade off exploration and exploitation when selecting actions.\n\nSuch variational inference arguments for transfer learning in the context of MDPs are not new. The authors have not made a good job reviewing the related literature. Most importantly, their experimental evaluations lack substantial comparison to such related methods. This is totally disappointing.","sentences":[{"sentence_type":"2","sentence":"The authors have not made a good job reviewing the related literature.","rephrased":"The authors could enhance the paper by providing a more comprehensive review of the related literature."},{"sentence_type":"3","sentence":"This is totally disappointing.","rephrased":"It would be beneficial for the authors to include a more extensive comparison with related methods to strengthen their experimental evaluations."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[650,720,"Confirmed"],[823,853,"Confirmed"]],"Comments":[]}
{"id":"HkemxceqhQ","text":"The authors attempt to propose an alternative explanation for the effect of dropout in a neural network and then present a technique to improve existing activation functions.\n\nSection 3.1 presents a experimental proof of higher co-adaptation in presence of dropout, in my opinion this is an incorrect experiment and request authors to double check. In my experience, using dropout results in sparse representations in the hidden layers which is the effect decreased co-adaptions. Also, a single experiment with MNIST data-set cannot be a proof to reject a theory.\n\nSection 3.2 Table 2 presents a comparison between average gradient flow through layers during training where flow with dropout is higher. This is not very surprising, in my opinion, given the variance of the activation of a neuron in presence of dropout the network tries to optimize the classification cost while trying to reduce the variance. The experimental details are almost nil.\n\nThe experiments section 5 presents very weak results. Very little or no improvement and authors randomly introduce BatchNorm into one of the experiment.","sentences":[{"sentence_type":"2","sentence":"in my opinion this is an incorrect experiment and request authors to double check.","rephrased":"I believe there may be a misunderstanding in the experimental design and would suggest the authors to review the methodology to ensure its validity."},{"sentence_type":"2","sentence":"The experiments section 5 presents very weak results.","rephrased":"The results presented in section 5 appear to be inconclusive and could benefit from further investigation to strengthen the findings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[266,348,"Confirmed"],[952,1005,"Not concerning"],[1006,1104,"Missed by Model"]],"Comments":[]}
{"id":"SB8HALcZva7","text":"The paper is reasonably well written, though section 3.1 would be easier to follow if the architecture of the generator model was described using a figure instead of just text. Moreover, since the authors evaluate their approach on optimizer models trained through reinforcement learning (according to section 2), I would have liked to see a discussion of other approaches that have been taken to improve the robustness of RL techniques in the related work section.\n\nThe evaluation section demonstrates empirically that data augmentation helps improve the performance of ML based combinatorial optimization techniques: it covers several enough combinatorial optimization problems (e.g TSP, CVRP, OP, PCTSP, KP) to give confidence to the reader that it is very likely to succeed on any combinatorial optimization problem. Furthermore, it evaluates the effectiveness of data augmentation in conjunction with 2 common optimizer models, AM and POMO, which indicates that data augmentation can be leveraged to improve the effectiveness of several prior work in this area.\n\nHowever, it is widely known that data augmentation helps the performance of neural networks, and the authors fail to demonstrate the effectiveness of their particular flavor of data augmentation. At the very least, they should have compared their approach against random data augmentation as well as against a simple policy that generates n examples, and keeps the k% of these n examples on which the optimizer model performs the worst. In other words, the paper needs to demonstrate that the generator model truly learns how to improve the quality of the dataset on which the optimizer model is trained. Put another way, the authors explain very well what they set out to accomplish in figure 2. They need to demonstrate in their evaluation that they accomplished this. \n","sentences":[{"sentence_type":"2","sentence":"However, it is widely known that data augmentation helps the performance of neural networks, and the authors fail to demonstrate the effectiveness of their particular flavor of data augmentation.","rephrased":"While data augmentation is a well-established technique for improving neural network performance, it would be beneficial for the authors to provide a more detailed comparison of their specific data augmentation method's effectiveness."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1068,1263,"Confirmed"]],"Comments":[]}
{"id":"rJg8d7lpiX","text":"The key idea of this paper is to expand the network for training on new tasks which is termed as C-Net, and train an additional generative model which is used for predicting task id (which is called H-Net), and use the task id for selecting weights from the C-Net.\n\nPros:\n1. It is relatively easy to understand the paper. \n2. The originality of this paper lies in the usage of generative model to predict task id (H-Net). To my knowledge has not been proposed before.\n3. In contrast to previous works in multi-task learning, which assumes task id is available both during training and inference, this work tries to remove the need of task id during inference, which makes it closer to the general definition of continual learning.\n\nCons:\n1. Expanding the network for new tasks is not a novel contribution of this paper, it has already been proposed in previous works on multi-task learning. Doing expansion on all of the layers does not qualify for a major contribution in my opinion.\n2. The experimental comparison is not very fair in my opinion, \n     a. Comparing accuracy of C-Net to other methods is not very useful. Because this methods expands the network for every new task, while other methods (EWC, LwF) has limited to no expansion in the network. Given that the single network result is far from state of the art (table 3), I suppose model size could contribute to the accuracy boost.\n     b. It is not explicitly stated in the paper whether the output neurons are shared between tasks or an individual set of output neurons are used for different tasks, but from the rest of the paper I suppose disjoint neurons are used. Then the comparison between EWC and this work is not fair because EWC shares the output neurons among tasks.\nThis is not to blame this paper for not making fair comparison, since given different assumptions between methods (availability of task id, shared output neurons etc.), it is usually difficult to fairly compare between continual learning methods.  This problem is raised in another submission https:\/\/openreview.net\/forum?id=ByGVui0ctm. The point here is that the accuracy of C-Net is not a good measure of how good this method is.\n3. I disagree with the point that MNIST and SVHN are similar, they have very different distributions and are very easy to tell apart with a model. One concern is that the generative H-Net may fail to work once the distributions of the tasks overlap to some extent. e.g. cifar10 vs cifar100.\n\nAs a conclusion, the key contribution of this work is using generative model to determine task id which removes the need for task id during inference. It is relatively insufficient for publication on ICLR.","sentences":[{"sentence_type":"2","sentence":"Doing expansion on all of the layers does not qualify for a major contribution in my opinion.","rephrased":"While the expansion of all layers is a known approach, further clarification on how this contributes uniquely to the field would strengthen the paper's claim of novelty."},{"sentence_type":"1","sentence":"The experimental comparison is not very fair in my opinion,","rephrased":"The experimental comparison could be improved for fairness and clarity,"},{"sentence_type":"1","sentence":"This is not to blame this paper for not making fair comparison, since given different assumptions between methods (availability of task id, shared output neurons etc.), it is usually difficult to fairly compare between continual learning methods.","rephrased":"The challenge in making fair comparisons due to differing assumptions between methods (availability of task id, shared output neurons, etc.) is acknowledged and is a common issue in the field of continual learning."},{"sentence_type":"3","sentence":"It is relatively insufficient for publication on ICLR.","rephrased":"The paper could benefit from further development to meet the publication criteria of ICLR."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[740,819,"Missed by Model"],[891,984,"Confirmed"],[988,1047,"Not concerning"],[1743,1989,"Not concerning"],[2618,2672,"Not concerning"]],"Comments":[]}
{"id":"8-FfxXbLVPh","text":"**Strengths:**\n\n- The introduction of soundness and consistency score for use in evaluating saliency maps is a good idea and is explored in several experiments.\n- The introduction did a good job of setting up the distinction between saliency methods and saliency evaluation metrics and laying the groundwork for the paper\n- The related work gives good background on related saliency methods and evaluation methods; however, the paper could include more context for the past work and its relationship to the current paper, especially in the \"arguments about saliency\" and \"controversies\" sections. It would be helpful to have a brief description of what the main points of controversy are and perhaps a note about how this work relates to those arguments. \n- The paper proposes soundness as a quantitative way of discovering artifacts in saliency-based approaches and back this up empirically r.e. TV regularization. \n\n**Weaknesses:**\n- The impact of the work is unclear. The new saliency method is similar to prior work and has mixed results when evaluated against other baselines (Table 1). The introduction of new saliency metrics has the potential to be useful, but I do not understand what new information soundness or consistency score provide that are missing from other measures; furthermore, they are expensive to compute (Section 6). \n- I found the descriptions and equations for completeness and soundness--Definition 3.2 on page 4--to be difficult to understand. I think it would be useful for the paper to include an intuitive description of the equations, how they interacted with each other, and whether alpha and beta should be minimized or maximized. For example, it would be nice to follow up the definition with an intuitive explanation of these metrics to help the reader understand what they are capturing. It may also be preferable to break up these two concepts into separate definitions. \n- This is my current understanding of completeness and soundness: alpha provides a lower bound and 1\/beta an upper bound on the ratio of the probability assigned to class a on the masked vs the unmasked input. It is desirable to have both alpha and beta close to 1 (however, additional constraints must be applied to avoid the trivial case where the whole image is considered salient). Alpha and beta close to 1 imply that for all classes, the model's scores on the masked input are similar to its scores on the unmasked input. Is my understanding correct? If not, could the authors please clarify? If so, it may help to include such a discussion in the paper. \n- The paper should justify why completeness is desirable. There is some discussion of this in the introduction, which ties increased soundness to reduction of artifacts in the mask itself. However, there are situations where it would make sense for different masks to significantly change a classifier output. Consider the case where a cat\/dog classifier is trying to classify an image with both a cat and a dog in it, then masking out the dog should increase the probability of cat. Similarly, a non-robust model might output very different results in response to different masks. As such, does completeness measure the goodness of the saliency method or the robustness of the model? \n- For the experiments described in Section 6.1, are the authors trying to validate the usefulness of their metric or prove the benefit of their saliency method? The proposed saliency method does not outperform other baselines for most metrics. \n\n**Additional small notes:**\n- The approach was inspired by logical proof systems, which is an interesting source of inspiration! But the connection is not clear--perhaps adding a brief description of how soundness is derived from logical proof systems or some references on this point would be helpful. \n- It would be helpful to readers if the contributions were stated more clearly. The introduction contains a bulleted list of \"Other contributions\"; I recommend changing this to a list of the top contributions.","sentences":[{"sentence_type":"2","sentence":"The impact of the work is unclear.","rephrased":"The paper could more clearly articulate the impact of the work, particularly how the new saliency metrics provide unique insights compared to existing measures."},{"sentence_type":"2","sentence":"The new saliency method is similar to prior work and has mixed results when evaluated against other baselines (Table 1).","rephrased":"It would be beneficial if the paper could further distinguish the new saliency method from prior work and provide a more detailed analysis of the results in Table 1, especially where the method differs from other baselines."},{"sentence_type":"2","sentence":"The introduction of new saliency metrics has the potential to be useful, but I do not understand what new information soundness or consistency score provide that are missing from other measures; furthermore, they are expensive to compute (Section 6).","rephrased":"The introduction of new saliency metrics is intriguing, and it would be helpful if the paper could clarify the unique contributions of soundness or consistency scores over existing measures, as well as address the concerns regarding computational expense."},{"sentence_type":"1","sentence":"I found the descriptions and equations for completeness and soundness--Definition 3.2 on page 4--to be difficult to understand.","rephrased":"The descriptions and equations for completeness and soundness in Definition 3.2 on page 4 could be made more accessible with additional intuitive explanations and examples."},{"sentence_type":"2","sentence":"The paper should justify why completeness is desirable.","rephrased":"It would strengthen the paper if the authors could provide a more comprehensive justification for the desirability of completeness in the context of saliency methods."},{"sentence_type":"2","sentence":"The proposed saliency method does not outperform other baselines for most metrics.","rephrased":"The paper could benefit from a discussion on the areas where the proposed saliency method does not outperform other baselines, including potential reasons and implications for future work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[936,970,"Confirmed"],[971,1091,"Not concerning"],[1092,1342,"Not concerning"],[1346,1473,"Not concerning"],[2576,2631,"Not concerning"],[3421,3503,"Not concerning"]],"Comments":[]}
{"id":"HebgTwXbYZq","text":"If I understand correctly this paper proposes a model which allows goal directed samples (goal defined by a specific behavioural graph) while constraining the model to respect a given causal graph. The method uses flows, together with masks over order or visibiliy to model the edges of the graphs and obtain a distribution which is both easy to sample from as well as respecting the causal constraints and goal.\nThe method is demonstrated to work well producing samples of driving scenes which are consistent with the specified behavioural graph.\n\nIt was a bit hard to follow the paper and though it's nicely presented it's not accessible to someone who doesn't know much about causality.\n\nI must say this is a bit out of my area of expertise but the paper seems interesting and I imagine people more well versed in causality would be interested in discussing this at the workshop.","sentences":[{"sentence_type":"2","sentence":"It was a bit hard to follow the paper and though it's nicely presented it's not accessible to someone who doesn't know much about causality.","rephrased":"While the paper is well-presented, it could benefit from additional background information or explanations to make it more accessible to readers who are not as familiar with causality."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[549,689,"Not concerning"]],"Comments":[]}
{"id":"B1l4dfipYE","text":"This paper investigates Attribute Perception Matching as an alternative to Adversarial Feature Learning. While Adversarial Feature Learning attempts to avoid a discriminator being able to discern a certain set of labels that should not be inferrable from a learned representation, the proposed approach attempts to actively generate similarity between the representations learned, across the different unwanted labels. It is also shown that AFL might be unstable.\n\nThe example gives some intuition but may not exhibit the same behavior with actual high-dimensional data.\n\nNo notation is introduced in the paper, making especially the beginning very hard to follow.\nOn the other hand the entropy of a uniform distribution is elevated to Theorem status, and proven in the appendix, which is not necessary.\n\nThere is a typo in the heading of section 3. Overall the paper is quite hard to understand.\n\nThe contribution of APL merits publication, but it seems to this reviewer that it actually misses the topic of this workshop. ","sentences":[{"sentence_type":"2","sentence":"No notation is introduced in the paper, making especially the beginning very hard to follow.","rephrased":"Introducing notation could enhance the clarity of the paper, particularly in the beginning sections."},{"sentence_type":"2","sentence":"Overall the paper is quite hard to understand.","rephrased":"Improving the overall clarity and structure of the paper could greatly facilitate comprehension."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[572,664,"Maybe"],[850,896,"Confirmed"]],"Comments":[]}
{"id":"rygEcQ61K4","text":"Summary: This paper is an interesting discussion of disentanglement with an experimental study on several VAE variants.  I strongly recommend acceptance, however the writing could be a bit more conservative in the claims given that only VAE-based latent variable models are studied experimentally.  \n\nNotes: \n  -This paper investigates many proposed methods for learning disentangled representations.  \n  -Introduction does a good job of laying out the intuition for what we want to get out of \"disentangled features\".  \n  -There is some intuition that changing some \"disentangled features\" should only change those factors of variation and not others.  \n  -Appendix A proves that unsupervised learning of disentangled representations is impossible without inductive biases (this doesn't seem obvious to me!)\n  -Paper measures disentanglement across 12k models.  \n  -Releases a \"disentanglement_lib\" for evaluating disentangled representations.  \n  -Study of different models shows that the \"aggregated posterior\" is not correlated, but the dimensions of the representation are correlated.  In this sentence I'm a bit confused about whether this is referring to q(z|x) or q(z).  On first reading, I find this claim a bit confusing, because if q(z) follows a gaussian distribution, then its dimensions should be disentangled?  \n  -All datasets considered work on the assumption that x is a deterministic function of an underlying disentangled z.  \n\nComments: \n  -Uses the wrong style sheet.  \n  -It's a bit weird to play up the \"10k models\" aspect, because presumably this comes from some kind of hyperparameter sweep or combinatorial explosion?  \n  -I think it seems like kind of a bad omission to not include ALI (Dumoulin 2016) or any other models in this family.  \n  -Beginning of 4.3 has a typo.  \n","sentences":[{"sentence_type":"2","sentence":"It's a bit weird to play up the \"10k models\" aspect, because presumably this comes from some kind of hyperparameter sweep or combinatorial explosion?","rephrased":"The emphasis on the \"10k models\" aspect could be better contextualized if it results from hyperparameter optimization or other systematic exploration methods."},{"sentence_type":"2","sentence":"I think it seems like kind of a bad omission to not include ALI (Dumoulin 2016) or any other models in this family.","rephrased":"The paper would be more comprehensive if it included a discussion of ALI (Dumoulin 2016) or other related models to provide a broader context."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1495,1644,"Confirmed"],[1650,1765,"Confirmed"]],"Comments":[]}
{"id":"rO6dl5aZwid","text":"This paper proposes a neural model called Span-Image Network that allows the model to output multiple spans as answers (existing BERT-based QA models usually only output two endpoints of the answer span). The model is evaluated on SQuAD (top-K answer prediction) and an internal Amazon dataset.\n\nUnfortunately, it is clear that this paper doesn’t meet the standard of the ICLR publications. I can’t recommend the acceptance of the paper.\n\nFirst of all, it is mentioned in the paper that “To the best of our knowledge, a multi-span QA architecture has not been proposed.” This is certainly incorrect. There have been many models proposed recently to tackle the multi-span QA problemm.  Some examples include:\n\n- (Hu et al., EMNLP 2019): A Multi-type Multi-span Network for Reading Comprehension that Requires Discrete Reasoning\n- (Segal et al, EMNLP 2020): A Simple and Effective Model for Answering Multi-span Questions\n- (Andor et al., EMNLP 2019): Giving BERT a Calculator: Finding Operations and Arguments with Reading Comprehension => This one is not straightforward but they support merging single spans at the end\n\nIt is very natural to cast a multi-span QA problem as a sequence tagging task and this paper doesn’t have such a baseline to compare with.\n\nSecond, I think the model is not motivated well and the writing of the paper needs to be improved. Why is it called a span-image network? Is it because there is a CNN layer applied? What is the rationale behind that? It is really not an image of pixels. It is just an N by N matrix, and each entry is an elementwise-multiplication of the BERT hidden vectors.\n\nThird, the evaluation of the paper also should be improved. SQuAD is a single-span QA dataset and using top-K prediction looks quite artificial and unnatural. Also, the performance on SQuAD 2 is also lower than expected. For a BERT-base-uncased model, it is expected to achieve at least ~75 F1 on SQuAD 2 so even the baselines don’t seem to be right. The internal Amazon dataset lacks details so I can’t comment much on that.  There are indeed several multi-span QA datasets (e.g., DROP, Quoref, Natural Questions) and I think the paper should experiment with those datasets and compare to previous approaches. \n","sentences":[{"sentence_type":"3","sentence":"Unfortunately, it is clear that this paper doesn't meet the standard of the ICLR publications. I can't recommend the acceptance of the paper.","rephrased":"The paper currently does not seem to meet the ICLR publication standards in its present form. I would recommend further development before considering it for acceptance."},{"sentence_type":"2","sentence":"Second, I think the model is not motivated well and the writing of the paper needs to be improved.","rephrased":"Second, the motivation behind the model could be articulated more clearly, and there is room for improvement in the writing of the paper."},{"sentence_type":"2","sentence":"SQuAD is a single-span QA dataset and using top-K prediction looks quite artificial and unnatural.","rephrased":"SQuAD is primarily a single-span QA dataset, and the use of top-K prediction may not be the most conventional approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[1261,1359,"Not concerning"],[1681,1779,"Confirmed"],[1972,2046,"Missed by Model"]],"Comments":[]}
{"id":"HkgXexY9nX","text":"This paper tries to draw connections between rate distortion theory and DNNs and use some intuitions from that domain to draw conclusions about robustness and generalization of the DNNs. \n\nThe paper is mostly written in a storytelling narrative with very little rigor. In my opinion, this lack of rigor is problematic for a conference paper that has to be concise and rigorous. Moreover, the story is not told in a cohesive way. In most parts of the paper, there is not much relationship between the consecutive paragraphs. And even within most of the paragraphs, I was lost in understanding what the authors meant. I wish the paper would have been self-contained and made concrete definitions and statements instead of very high-level ideas that are difficult to judge. In the current state, it is very difficult for me to say what exactly is the contribution of the paper in terms of the story other than some loosely related high-level ideas. I feel like most parts the story that the authors are telling is already told by many other papers in other forms(papers that authors have cited and many other ones).\n\n\n","sentences":[{"sentence_type":"2","sentence":"The paper is mostly written in a storytelling narrative with very little rigor.","rephrased":"The paper adopts a storytelling narrative which could benefit from increased academic rigor."},{"sentence_type":"2","sentence":"I feel like most parts the story that the authors are telling is already told by many other papers in other forms(papers that authors have cited and many other ones).","rephrased":"The narrative presented in the paper seems to overlap significantly with existing literature, including the cited works, which may limit its perceived originality."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[189,268,"Confirmed"],[616,769,"Missed by Model"],[946,1112,"Not concerning"]],"Comments":[]}
{"id":"SadbukLGEH5","text":"This paper discussed an approach to take priors into account in machine learning with a slightly different formula, which I have doubts on its correctness. In the experiments, they showed that performance in some tasks can be significantly improved by cleverly choosing class priors. The experiment results look good, but I do not think it fully justifies their algorithm because of the lack of baselines and inappropriate interpretations of an equation.\n\nThe authors mentioned a lot of different types of priors, however many of them (including most of those used in their experiments) could be characterized as cost-sensitive learning, a.k.a. taking priors into account in classification problems. In this regard, the citations to cost-sensitive learning literature and comparisons are vastly insufficient. e.g. papers that should be cited include:\n\nZadrozny et al. Cost-sensitive learning by cost-proportionate example weighting. ICDM 2003\n\nBranco et al. A survey of predictive modeling on imbalanced domains. ACM Computing Surveys 2016 is a recent survey paper on cost-sensitive learning.\n\nThey did not compare against any prior work on cost-sensitive classification, which is a major problem that lead me to the decision of rejection. A recent popular general approach to deal with class priors is focal loss, which should be cited and compared as well.\n \nLin et al. Focal Loss for Dense Object Detection. ICCV 2017\n\nDespite the authors claims, eq. (4) still seems fundamentally flawed in that in the case of 50%\/50% 2-class classification problems, the classifier could have entirely flipped one class with another and still optimize eq. (4). I believe what is working is NOT eq. (4), but the practice of applying eq. (4) on mini-batches. Because each mini-batch is much smaller, it becomes difficult to keep the balance in a mini-batch and the multiple resampling of each mini-batch from different epochs may lead to the effect of normalization, similar to the effects that we can see in minibatch regularization in the training of GANs. Hence, I have strong doubts that similar balance-breaking would not necessarily happen so reliably if mini-batches are not used.\n\nThe choice between QR and RQ is quite arbitrary in different experiments. Is there any principle about it? Or just trial-and-error?\n\nThere is an equation typo in eq. (4), the log-sum term should be log(\\sum_i q_i(l)), not log(\\sum_l q_i(l)). The interpretation in the subsequent paragraph is although correct in that it favors predicting a high-confidence label.\n\nMinor: The authors should mention that q_i(l) is an energy function (logits) instead of a probabilistic distribution, otherwise they should have \\sum_j q_j(l) = 1 and the derivation would be in a different place (e.g. the \\sum_j q_j term won't exist).\n","sentences":[{"sentence_type":"2","sentence":"I have doubts on its correctness.","rephrased":"I have some reservations about its correctness that I believe should be addressed."},{"sentence_type":"2","sentence":"I do not think it fully justifies their algorithm because of the lack of baselines and inappropriate interpretations of an equation.","rephrased":"The justification for the algorithm could be strengthened with additional baselines and a clearer interpretation of the equation."},{"sentence_type":"3","sentence":"which is a major problem that lead me to the decision of rejection.","rephrased":"This is a significant oversight that needs to be addressed before I can consider recommending acceptance."},{"sentence_type":"2","sentence":"I believe what is working is NOT eq. (4), but the practice of applying eq. (4) on mini-batches.","rephrased":"It seems that the effectiveness may stem from the application of eq. (4) on mini-batches rather than the equation itself."},{"sentence_type":"1","sentence":"The choice between QR and RQ is quite arbitrary in different experiments. Is there any principle about it? Or just trial-and-error?","rephrased":"Could you please clarify the principle guiding the choice between QR and RQ in different experiments, or is it based on trial-and-error?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[122,155,"Confirmed"],[322,454,"Confirmed"],[700,807,"Missed by Model"],[1172,1239,"Not concerning"],[1649,1744,"Not concerning"],[2175,2306,"Not concerning"]],"Comments":[]}
{"id":"7KOoqk8nycM","text":"Significance: The main contribution of this paper is to  investigate the impact of several code-level optimizations to the PPO model performance.\nNovelty: No.\nTechnical quality: Not very well.\nClarity: The paper investigate the impact of several optimizations. But lack of detailed experimental details and effect analysis and no experiment to support the conclusion.\nSpecific:\nPros: Seveal optimizations are tried such as normalization and clip.\nCons: a. Without any innovation. b. No practical meaning. c. The content is too simple. d. The experiment does not enough.","sentences":[{"sentence_type":"2","sentence":"Novelty: No.","rephrased":"Novelty: The paper could benefit from a clearer demonstration of novel contributions."},{"sentence_type":"2","sentence":"Technical quality: Not very well.","rephrased":"Technical quality: The technical aspects of the paper could be improved for better understanding."},{"sentence_type":"3","sentence":"Cons: a. Without any innovation. b. No practical meaning. c. The content is too simple. d. The experiment does not enough.","rephrased":"Cons: a. The paper would benefit from more innovative approaches. b. The practical implications of the findings could be made clearer. c. A more complex analysis could enhance the content. d. Additional experiments are needed to support the conclusions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[146,158,"Confirmed"],[159,192,"Confirmed"],[447,569,"Confirmed"]],"Comments":[]}
{"id":"i-8o1HHvd8","text":"Depending on up-to-date theoretical developments on FNN approximation such as Schmidt-Hieber (2020, Ann. Statist. 48:1875--1897), this submission makes a theoretical contribution to the FNN-assisted survival analysis. We guess this effort is of interest to the community of deep learning research. Also, this paper involves extensive numerical comparison among DeepEH and a dozen competitors.\n\nCorrectness: We believe the theories and proofs are generally correct. \n\nClarity: Most parts are easy to follow.\n","sentences":[{"sentence_type":"1","sentence":"We guess this effort is of interest to the community of deep learning research.","rephrased":"We believe this effort will be of interest to the community of deep learning research."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[218,297,"Not concerning"]],"Comments":[]}
{"id":"9Ots3Bx6Uk","text":"[Disclaimer: The reviewer has expertise in causality but little to no familiarity with probabilistic circuits.]\n\n**Summary.** The paper investigates the computational tractability of backdoor (BD) and frontdoor (FD) adjustment, that is, given a causal estimand such as the BD or FD formulae involving sums and products of marginal and conditional distributions, under which conditions can they be efficiently computed? To model the (observational) joint distribution of all variables, the paper focuses on the model class of probabilistic circuits (PC), for which tractability of *probabilistic* inference is well-studied. The paper then proceeds to provide some theoretical insights on tractability of PCs for *causal* inference. In particular, as an initial negative result it is shown that BD adjustment is #P hard, even for a fairly restricted class of PCs. The paper then defines additional conditions (for tractable conditioning) and proves that these are sufficient for tractably performing BD and FD adjustment. Very preliminary simulations are consistent with this theoretical insight. \n\n**Evaluation.** This is an interesting and very well-written paper. It studies a question (tractability of computing well-known identifying formulae) which is certainly important, but to which AFAIK not much attention was previously dedicated. The paper provides some theoretical insights into the fundamental limits of this task, and specifies clear conditions under which it becomes possible. Overall, I think the paper is a good fit for the workshop and will be a good addition. I therefore recommend acceptance. \n\n**Questions:**\n- It seems that Thm. 1 only applies to BD adjustment. Do you also have a similar negative result to Thm 1. for FD adjustment? If not, why?\n\n**Comments\/suggestions:**\n- The presentation of the scope of causal inference in the Abstract and Introduction (inferring causal effects from observational data) is slightly inaccurate as this is only a special case. It would be more general and accurate to speak of identifying and estimating causal queries of interest based on assumptions (e.g., causal diagram, but this could also involve, e.g., parametric assumptions) and the *available* data (this does not have to be purely observational, but can also contain mixtures of data from different interventional distributions). \n- The quantity $p_X(Y)$ is *not* a causal effect (l.24), it is an interventional distribution. Average causal effects typically take the form of an expectation w.r.t. an interventional distribution, e.g., $E[Y | do(X) ]$.\n- Depending on the target audience, especially if also geared towards causality researchers with interest in tractable inference, it would be helpful to provide a more detailed, less technical and more intuitive account of PCs, e.g., using additional figures. This would make the paper more accessible. \n- Note: when considering adjustment for sets of variables, in particular for multi-variate treatments $\\mathbf{x}$ as done in section 3, care needs to be taken, as some subleties arise w.r.t. proper causal paths. I believe the original backdoor adjustment criterion only applies to singleton treatments, though I'm not 100% sure about this. Worth double checking though. ","sentences":[{"sentence_type":"1","sentence":"Very preliminary simulations are consistent with this theoretical insight.","rephrased":"The simulations, although preliminary, support the theoretical insights presented in the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1020,1094,"Not concerning"]],"Comments":[]}
{"id":"SJlECS-_FE","text":"This work presents an empirical study of the first-order meta-learning Reptile algorithm, in particular investigating a proposed regularization technique and deeper networks. Their regularization method is to train as usual for the first \\psi steps and subsequently only apply the training update to the learned initialization if the difference between that initialization before and after the task-specific update on the current task is greater than another hyperparameter \\gamma.\n\nThey show experimentally that when training Reptile using the above procedure it overfits less: the gap between the training and testing accuracy is smaller (though not by a significant amount). What is perhaps more impressive is that they can obtain similar to state-of-the-art results on Omniglot and mini-ImageNet by applying 10x less updates than the corresponding state-of-the-art methods. Finally, they show that using deeper networks yields a benefit on Omniglot. This is an interesting observation, contradicting the intuition that when learning from little data larger networks would be more prone to overfitting.\n\nSome concerns \/ suggestions:\n-    I’m curious if a similar behaviour to the proposed regularization can be obtained simply by using a learning rate schedule, and \/ or using ADAM in the outer loop as well.\n-    The results in Table 2 are slightly lower than MAML and Reptile’s and it’s not clear how many additional iterations would be required to match those results. It may be that to squeeze out that last bit of performance a lot more updates are required even with the proposed method. It therefore seems more informative to keep running the proposed method until that performance is reached and then compare the number of iterations required. Alternatively, showing the curve of the performance on held-out data throughout training would address this point as well.\n-    Regarding the experiments with the deeper networks: the authors describe this as using deeper networks in the inner loop specifically. It found this confusing. Are the additional weights only “fast weights” (e.g. part of a task-specific classifier) that are not meta-learned (by the outer loop)? It would be useful to be more specific about this.\n-    It would be interesting to present deeper network experiments on mini-ImageNet instead of (or in addition to) Omniglot, since it’s a more realistic and challenging benchmark with larger resolution images.\n-    From what I understand, the proposed modifications are not applicable exclusively to first-order meta-learning. I would therefore be curious about whether applying these to second-order methods (e.g. full MAML) would yield similar conclusions.\n\nOverall, I feel that meta-training is still poorly understood so I think empirical investigations like the one in this work are useful for gaining stronger intuitions for best practices in this setup. I therefore recommend acceptance of this work.\n","sentences":[{"sentence_type":"1","sentence":"The results in Table 2 are slightly lower than MAML and Reptile's and it's not clear how many additional iterations would be required to match those results.","rephrased":"While the results in Table 2 are modestly lower than those of MAML and Reptile, it would be beneficial to clarify how many additional iterations might be needed to achieve comparable results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"S1eSanZ_YN","text":"The paper describes a method for embeddings entities, making use of the pre-trained BERT model.\nEntities are represented either as simple embeddings, by encoding the entity name with BERT, or by encoding the first paragraph of the wikipedia entry with BERT.\nThe contexts from entity mentions are also encoded with BERT and then optimized to be in the same space as the entity representations.\nThe model is evaluated on a task of producing more entities for a given category, given some examples. The proposed method performs best with more frequent entities and is outperformed on less frequent entities.\n\nThe method is fairly straightforward, with limited novelty, applying the existing BERT model to encode textual representations. \nHowever, the paper does present a comparison and analysis for different model variations on this task, which provides some useful insight. \nAlso, the frequency-based analysis of the entities is interesting, showing a clear boundary where the proposed model starts outperforming the baseline.\n\nIt is unclear what is the difference between the \"small number of exemplars (3-10)\" and \"one correct candidate entity\" and how these are used differently.\nAlso, for experiments where the candidates do not cover all possible entities, how were the candidates chosen?","sentences":[{"sentence_type":"2","sentence":"The method is fairly straightforward, with limited novelty, applying the existing BERT model to encode textual representations.","rephrased":"While the method builds on the established BERT model for encoding textual representations, further elaboration on its innovative aspects could strengthen the paper's contribution."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[606,733,"Not concerning"]],"Comments":[]}
{"id":"BkxzF3NCtr","text":"The paper studies adaptation of agent policies in a simplified baseball game, which is designed as a zero-sum two-agent game between a batter (B) and a pitcher (P), each of which has 5 discreet actions. The introduced game is fully observable but stochastic, which the authors argue is a challenging setup. The authors propose a Bayesian-style adaptation of the agent strategies (where each agent models the probability of the actions of the opponent by computing the posterior give a prior and evidence from the past observations), which seems to be computable analytically, from an initialization learned with counterfactual regret minimization (CFR) that approximates the Nash of the considered game.\n\nComments\/Questions:\n\n1. Why do we need adaptation if CFR already learns Nash? It looks like one of the key differences between the proposed game\/setup and many of the previous work is that it is a fully observable zero-sum game. The initialization learned by CFR already might come close to the Nash equilibrium. It's unclear why the agents need to play something different than Nash. Could the authors argue (preferably, formally theoretically or at least quantitatively) why adaptation is necessary?\n\n2. Related to point 1, in section 4.2, it looks like post-adaptation strategies turn out to be superior when playing against opponents that play Nash. I would like to understand why. Do opponents actually play Nash? Does the asymmetry of the game have to do something with this? There's virtually no analysis of the results in the paper, which significantly undermines any contribution.\n\n\nOther comments:\n\n1. I'm personally not familiar with baseball, and the paper doesn't really introduce the game. So, parts of the introduction and background that use baseball-specific terminology (paragraph 3) make no sense to readers unfamiliar with the game. It would be nice to have the game exemplified and explained along with the key simplifying assumptions.\n\n2. Writing can be significantly improved (and compressed!). There are typos throughout. Some phrases from the paper which meaning is really hard to parse (for example, \"To focus on the impact of strategy adaptation over the winning percentage <...>\").\n\nAlso, the last paragraph of the intro that describes the organization of the paper is unnecessary for conference submissions (it just takes spaces and no one reads it because it's easy to scroll through 10 pages to get a sense of the organization).","sentences":[{"sentence_type":"2","sentence":"There's virtually no analysis of the results in the paper, which significantly undermines any contribution.","rephrased":"The paper would benefit from a more thorough analysis of the results to strengthen the contribution."},{"sentence_type":"2","sentence":"Writing can be significantly improved (and compressed!). There are typos throughout.","rephrased":"The clarity of the writing could be enhanced by condensing the text and correcting the typos present."},{"sentence_type":"1","sentence":"Some phrases from the paper which meaning is really hard to parse","rephrased":"Some phrases in the paper could be clarified to improve comprehension."},{"sentence_type":"2","sentence":"the last paragraph of the intro that describes the organization of the paper is unnecessary for conference submissions (it just takes spaces and no one reads it because it's easy to scroll through 10 pages to get a sense of the organization).","rephrased":"Consider omitting the last paragraph of the introduction about the paper's organization, as it is generally not needed for conference submissions and can save space."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1487,1594,"Confirmed"],[1966,2050,"Not concerning"],[2051,2116,"Not concerning"],[2222,2464,"Confirmed"]],"Comments":[]}
{"id":"Skg-gEMl37","text":"General comment\n==============\nThe authors describe an attention mechanism for training with images of different sizes. The paper is hard to understand due to major grammatical errors and unclear descriptions. Methods for training with images of different sizes have been proposed before, e.g. spatial pyramid networks. I also have concerns about their evaluation. Overall, I believe that the paper is not ready to be submitted to a conference or journal.\n\nMajor comments\n=============\n1. Methods for training with images already exists, e.g. spatial pyramid pooling (http:\/\/arxiv.org\/abs\/1406.4729) or fully-convolutional networks (https:\/\/people.eecs.berkeley.edu\/~jonlong\/long_shelhamer_fcn.pdf). These are not cited in the paper and not included as baselines in their evaluation.\n\n2. The attention mechanisms looks similar to classificat soft-attention (https:\/\/arxiv.org\/abs\/1502.), which is not cited in the paper.\n\n3. The paper contains major spelling and grammatical errors, making it hard to understand important aspects.\n\n4. I can not see a clear improvement of their method over ResNet and DenseNet when the same number of model parameters is about the same. Without making sure that the number of model parameters is about the same, it is unclear if the performance gain is due the increased number of model parameters or the methodology.","sentences":[{"sentence_type":"2","sentence":"The paper is hard to understand due to major grammatical errors and unclear descriptions.","rephrased":"The paper could be improved by addressing grammatical errors and clarifying descriptions to enhance understanding."},{"sentence_type":"2","sentence":"Overall, I believe that the paper is not ready to be submitted to a conference or journal.","rephrased":"Overall, the paper would benefit from further refinement before it is ready for submission to a conference or journal."},{"sentence_type":"1","sentence":"The attention mechanisms looks similar to classificat soft-attention (https:\/\/arxiv.org\/abs\/1502.), which is not cited in the paper.","rephrased":"The attention mechanism appears to have similarities with classification soft-attention (https:\/\/arxiv.org\/abs\/1502.), which could be acknowledged and cited in the paper."},{"sentence_type":"1","sentence":"I can not see a clear improvement of their method over ResNet and DenseNet when the same number of model parameters is about the same.","rephrased":"It would be helpful to provide a clearer comparison of the proposed method with ResNet and DenseNet, particularly in terms of model parameters, to better understand any performance improvements."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[120,209,"Not concerning"],[365,455,"Not concerning"],[788,920,"Not concerning"],[1035,1169,"Not concerning"]],"Comments":[]}
{"id":"rkl93vlTKB","text":"This paper studies the inductive bias of neural nets by considering the toy example of learning an identity map through a single data point (and hence the NNs are always overparametrized). The authors compare CNNs versus FCNs, and find that CNNs tend to “generalize” in terms of actually learning the concept of an identity, whereas FCNs are prone to memorization. The authors also present results under various different settings such as changing the filter size or the number of hidden channels of CNNs. The conclusion is that the simpler the network architecture is, the better it generalizes. Another observation is that deep CNNs exhibit extreme memorization.\n\nOverall, this is a well-written paper with an interesting set of experiments. However, I do have several concerns regarding the generality of the observed phenomenon in this paper. The first one is that the authors have chosen the comparison between CNNs and FCNs. In this case, I think a more fair comparison is to restrict the number of links (number of nonzero entries in the weight matrices) for both to be the same. In the current setup, however, the authors seem to consider the same number of hidden neurons, which naturally grants advantages to CNNs as they are of lower complexity.\n\nSecond, the training data is always a simple image from MNIST, and I am unsure how much this setting can generalize to other tasks, such as different data (say, music or text) or more complicated images (how do these experiments compare when we use a single data from ImageNet or CIFAR to train?). For instance, since CNNs are designed to capture invariances in natural images, it is unsurprising that they can generalize better on image data, but it would be quite astonishing if the same still holds true for acoustic data. In that case, the conclusion of this paper can be strengthened from “CNNs generalize better on image data” to “CNN generalize better”. Given the scope of the current paper, however, the best we can conclude is that “CNNs generalize better on MNIST”.\n\nLast, again regarding the fair comparison, when comparing deep CNNs versus shallow ones, it is also of interest to see that, when restricted to the same number of parameters, if the deep CNNs still exhibit worse generalization. Otherwise, if some network complexities keep growing, we cannot really tell whether it is the network architecture that induces the inductive bias or it is simply the effect of complexities.\n\nI also would like to suggest a future direction based on the idea in this paper: Comparing the inductive bias of GD versus SGD, a subject of intense study in the current literature. Since the authors considered a single training data, the results in this paper are always for GD. Now, say let us use 5 data, and compare the training of CNNs with different batch-size. Do the results differ? I think such a thought experiment would shed some light on the mysterious behaviors of the first-order algorithms that are widely used in practice.\n\nFinally, a question: another submission to ICLR2020 [1] seems to suggest that optimization methods do not play a role in generalization, which is the opposite observation of this paper. Do the authors have any insight towards this contradiction?\n\n[1] Fantastic Generalization Measures and Where to Find Them https:\/\/openreview.net\/forum?id=SJgIPJBFvH","sentences":[{"sentence_type":"1","sentence":"The authors also present results under various different settings such as changing the filter size or the number of hidden channels of CNNs. The conclusion is that the simpler the network architecture is, the better it generalizes. Another observation is that deep CNNs exhibit extreme memorization.","rephrased":"The authors also explore the impact of different settings, like filter size and the number of hidden channels in CNNs, on generalization. They conclude that simpler network architectures tend to generalize better, and they note that deep CNNs may be more prone to memorization."},{"sentence_type":"2","sentence":"Last, again regarding the fair comparison, when comparing deep CNNs versus shallow ones, it is also of interest to see that, when restricted to the same number of parameters, if the deep CNNs still exhibit worse generalization. Otherwise, if some network complexities keep growing, we cannot really tell whether it is the network architecture that induces the inductive bias or it is simply the effect of complexities.","rephrased":"Lastly, to ensure a fair comparison between deep and shallow CNNs, it would be beneficial to control for the number of parameters. This would help determine whether the observed differences in generalization are due to the network architecture itself or merely a result of increasing complexity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[365,664,"Not concerning"],[2035,2453,"Not concerning"]],"Comments":[]}
{"id":"7vO3nScdg6F","text":"*Paper summary*: This paper proposes a method for measuring stereotypical associations about occupations that are associated with genders using the natural language inference task. The method involves setting up a NLI pair where the premise is a gender-neutral statement about an occupation, and the hypothesis is explicitly gender specific. The analysis shows that NLI models do incorporate stereotypes. The paper also investigates how to reduce this bias by data augmentation.\n\n*Review*: At a high level, the method proposed in this paper makes sense, but there is a critical problem in terms of novelty: the idea of using NLI to probe stereotypes is not new. In fact, nearly the same proposal outlined here is explored by Dev et al (2020), who additionally use the mechanism to probe for other kinds of stereotypes as well.\n\nThe hypothesis templates are interesting, but present a bit of a technical question. The hypothesis of the form \"This text talks about a female occupation\" refers to the *text* of the premise, rather than the *events* or *entities* in it. In other words, it talks about the form of the premise, rather than its meaning. Of course, there's nothing wrong with this, but it breaks a crucial assumptions about how the NLI data (in particular the SNLI data) was sourced: the events and entities in the hypothesis refer to the events and entities in the premise as much as possible. In contrast, the word \"text\" in the hypotheses constructed in this work refers to the entire text of the premise, and not its entities and events. It is not clear how this change affects model performance.\n\nOne way to fix the issue is to change the hypothesis templates to use the same (or similar) words as the premises, and replace the occupation word with a gendered word. (But doing so would make the work even closer to that of Dev et al 2020.)\n\nIt is not clear why the neutral label is removed and the problem is converted into a binary problem of deciding whether the hypothesis is entailed or contradicted. It seems that most of the hypotheses would actually be neutral, and a good model should allocate most of its probability mass to the neutral label. Why do we have to force a choice between entail and contradict, when a stereotype-free model would actually predict neutral?\n\nThe results in table 6 are interesting. It seems that the models \"memorize\" the distributional correlations between gender and jobs differently for men and women. Are there any conjectures about why this may be the case?\n\nIt is not clear whether the bias that is being measured is in the representation (i.e. the *BERT embeddings) or the task (i.e., the NLI data). The experiments suggest that the problem is perhaps in both. Previous work on stereotypes involving language has largely focused how they are encoded in the embeddings, and removing them. This paper seems to argue that the provenance of the stereotypes is the training data for the task. However, the final results suggest that this is not entirely the case, and the paper does say so in the section on debiasing. It may be worth posing the question about the source of the biases early on in the paper.\n\nSince the paper is talking about stereotypes in language technology, the authors should go over the work of Blodgett et al (2020) to better situate the motivations and outcomes of this work. Indeed, there should be a discussion in the paper about the cultural context and assumptions that are implicit in the measurements. (For example, is the definition of B based on an American context?  Would the measures transfer to a different country\/cultural perspective?)\n\n*Minor point*: The plot in figure 1 should not be a line plot because the horizontal axis is categorical. A bar chart would be a better fit (and would convey the point more clearly).\n\n*References*\n\n* Dev, Sunipa, Tao Li, Jeff M. Phillips, and Vivek Srikumar. \"On Measuring and Mitigating Biased Inferences of Word Embeddings.\" In AAAI, pp. 7659-7666. 2020.\n  \n* Blodgett, Su Lin, Solon Barocas, Hal III Daumé, and Hanna Wallach. \"Language (technology) is power: The need to be explicit about NLP harms.\" In Proceedings of the Annual Meeting of the Association for Computational Lingustics (ACL). 2020.\n","sentences":[{"sentence_type":"2","sentence":"At a high level, the method proposed in this paper makes sense, but there is a critical problem in terms of novelty: the idea of using NLI to probe stereotypes is not new.","rephrased":"While the method proposed in this paper is logical, it would benefit from a more distinct contribution to the field, as the application of NLI to probe stereotypes has been previously explored."},{"sentence_type":"1","sentence":"It is not clear why the neutral label is removed and the problem is converted into a binary problem of deciding whether the hypothesis is entailed or contradicted.","rephrased":"The rationale for removing the neutral label and framing the problem as a binary choice between entailment and contradiction could be further clarified, as it seems that a stereotype-free model might predict a neutral outcome more frequently."},{"sentence_type":"1","sentence":"It is not clear whether the bias that is being measured is in the representation (i.e. the *BERT embeddings) or the task (i.e., the NLI data).","rephrased":"The paper could provide a clearer distinction on whether the measured bias originates from the representation (i.e., the *BERT embeddings) or the task (i.e., the NLI data), as this could enhance the understanding of the results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[490,661,"Confirmed"],[1856,2019,"Not concerning"],[2516,2658,"Not concerning"]],"Comments":[]}
{"id":"rkef2JUcnQ","text":"This paper describes a multi-task video classification and captioning model applied to a fine-grained object relationship video dataset, for a range of different classification and captioning tasks at different levels of granularity. This paper also creates a new video action dataset around kitchen objects and actions.  Finally, the paper includes an empirical study on both the multi-task performance and transfer learning performance between the two datasets considered.\n\nPros:\n- This paper is clearly written and includes a thorough and well-laid out empirical component\n- The contribution to the video action classification and captioning space seems like a worthwhile one\n\nCons:\n- The novelty of this paper mainly seems to be with respect to video classification and captioning; other methodological aspects and empirical themes are interesting but fairly standard more generally.  The lack of experiments outside of one video action classification & captioning dataset (and one additional one for a transfer learning study) limit the empirical generality of the findings.\n\nOverall take: This paper's contributions seem of interest to the video classification and captioning community, but less so to a broader or more methodologically-focused one such as ICLR.\n\nNotes:\n- The comments on insufficiency of existing video classification tasks in Sec. 3 are interesting, but seem pretty restricted to that specific domain\n- The model used is a fairly standard CNN + LSTM video encoder, plus a basic MTL network approach with hard parameter sharing between tasks, as is commonly used today. Similarly, the transfer learning approach---pre-training on one task, then freezing layers and fine-tuning---is a standard approach.\n- The empirical findings are interesting---for example, that training on fine-grained tasks improves coarse-grained accuracy, that MTL training is helpful, etc---but (a) seem in general like known themes, and (b) have limited generality either way beyond the specific types of tasks considered in the dataset examined.\n- In general, much of the paper is focused on details specific to this application domain, rather than to general methods or themes potentially interesting to the broader ICLR community","sentences":[{"sentence_type":"2","sentence":"The novelty of this paper mainly seems to be with respect to video classification and captioning; other methodological aspects and empirical themes are interesting but fairly standard more generally.","rephrased":"While the paper's novelty is particularly evident in the area of video classification and captioning, it would be beneficial to see how the other methodological aspects and empirical themes, which are well-executed, could be further differentiated from existing standards."},{"sentence_type":"2","sentence":"The empirical findings are interesting---for example, that training on fine-grained tasks improves coarse-grained accuracy, that MTL training is helpful, etc---but (a) seem in general like known themes, and (b) have limited generality either way beyond the specific types of tasks considered in the dataset examined.","rephrased":"The empirical findings, such as the improvement of coarse-grained accuracy through training on fine-grained tasks and the benefits of MTL training, reinforce known themes and provide valuable insights within the context of the tasks and dataset examined. Expanding the scope of these findings to a broader range of tasks could further enhance the paper's contribution."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[688,887,"Not concerning"],[1729,2045,"Not concerning"]],"Comments":[]}
{"id":"SWe_s812bc","text":"**Summary of contribution**\nThis work presents a two-step policy that combines neural-network-based RL policy and a rule-based policy to deal with the knowledge graph input and state-dependent text action space. The proposed policy has the added benefits of interpretability, generalization, and robustness. Experiments on several text-based games demonstrated that the proposed approach achieves a new state-of-the-art performance for both generalization and robustness.\n\n**Pros**\n* The paper reads well\n* The proposed way of combining the RL policy with rule-based policy and rule mining process is interesting\n* It presents a strong empirical results\n\n\n**Cons**\n* The proposed method may not be readily scalable to other domain due to several assumptions (see “comment” section below for details)\n\n**Comments**\n* The proposed method seems to assume expert knowledge for constructing the “template” of action.\n* The proposed rule miner’s performance relies on the quality of demonstration, hence may not be readily scalable to other domains where the demonstration does not provide enough coverage of environment “knowledge” or is not given. It would be more interesting to discuss how the proposed method can be extended to more general tasks.\n* It would be interesting to discuss the relation between rule mining and precondition inference [1,2] and how they are used for policy.\n\n[1] Bradley Hayes and Brian Scassellati. Autonomously constructing hierarchical task networks for planning and human-robot collaboration. In 2016 IEEE International Conference on Robotics and Automation (ICRA), pp. 5469–5476. IEEE, 2016.\n\n[2] Sohn, Sungryull, et al. \"Meta Reinforcement Learning with Autonomous Inference of Subtask Dependencies.\" International Conference on Learning Representations. 2019.\n","sentences":[{"sentence_type":"2","sentence":"The proposed method may not be readily scalable to other domain due to several assumptions","rephrased":"It would be beneficial to explore the scalability of the proposed method to other domains, considering the assumptions made."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[667,757,"Confirmed"]],"Comments":[]}
{"id":"lBG_WMAb5z","text":"This short paper proposes a method for detection of segmentation errors. First, a network (cGAN) is trained to predict the original image based on its segmentation. Differences between the predicted image and the original image are an indication of segmentation errors. A second network takes this difference image as input, together with the original image, and predicts whether the segmentation was acceptable or not. Evaluation results are promising.\nStrengths:\n- Relevant topic\n- Method seems original\n- Promising results.\nWeaknesses:\n- Some motivation for the method is lacking. Why not directly train a classifier that takes the segmentation and the original image as input, and predicts whether the segmentation was acceptable or not? Why do we need to first predict the original image? Experimental comparison to such simpler approach would have made the paper stronger.\n- The experimental setup is a bit unclear. Specifically, it is not clear whether the final class-balanced dataset of 300+300 subjects had overlap with the previously mentioned datasets of 1600\/600\/190 subjects. This would be suspicious, since the cGAN was trained on part of that data.\n","sentences":[{"sentence_type":"1","sentence":"Why not directly train a classifier that takes the segmentation and the original image as input, and predicts whether the segmentation was acceptable or not?","rephrased":"It would be beneficial to include a comparison with a direct classifier that takes the segmentation and the original image as input to predict the acceptability of the segmentation. This could provide a clearer justification for the proposed method."},{"sentence_type":"2","sentence":"This would be suspicious, since the cGAN was trained on part of that data.","rephrased":"It would be helpful to clarify if there was any overlap between the final class-balanced dataset and the previously mentioned datasets, as the cGAN was trained on part of that data, and such overlap could affect the validity of the results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[584,741,"Not concerning"],[1090,1164,"Not concerning"]],"Comments":[]}
{"id":"SJlrvdkW5V","text":"The paper tackles the problem of teaching an RNNs to approximate list-processing algorithms. The authors argue that what distinguishes algorithms from arbitrary functions is that they commute with a family of element-wise changes to their inputs and propose a method that learns RNN functions to approximate such family from data.\n\nTo learn commuting functions, the authors propose to synthetically generate labeled data by testing whether a function commutes with a collection of swaps. The corresponding classifier that approximates commutative swap functions is used for data augmentation. I find the observation about the parametricity property from type theory is interesting and the proposed data augmentation approach seems novel and interesting. \n\nThe only concern I have (perhaps, stemming from a mild misunderstanding of the method), if the proposed approach would work beyond the simple inputs of integer sequences (i.e., with more complex input-output data types, such as images, text, sounds, etc. as most of the modern machine learning has to deal with), or there are potential limitations that need to be resolved.","sentences":[{"sentence_type":"1","sentence":"The only concern I have (perhaps, stemming from a mild misunderstanding of the method), if the proposed approach would work beyond the simple inputs of integer sequences","rephrased":"One question I have, which may be due to my current understanding of the method, is whether the proposed approach can be extended to work with more complex input-output data types beyond integer sequences"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[756,925,"Not concerning"]],"Comments":[]}
{"id":"H1g05tby5H","text":"This paper proposes an autocompletion model for UI layout based on adaptations of Transformers for tree structures and evaluates the models based on a few metrics on a public UI dataset.\n\nI like the area of research the authors are looking into and I think it's an important application. However, the paper doesn't answer key questions about both the application and the models:\n\n1) There is no clear rationale on why we need a new model based on Transformers for this task. What was wrong with LSTMs\/GRUs as they've been used extensively for recursive problems including operations on trees? Similarly, I'd have expected baselines that included those models in the evaluation section showing the differences in performance between the newly proposed Transformer model for trees and previously used methods.\n\n2) The evaluation metrics used while borrowed from the language or IR fields doesn't seem to translate to UI design. UI layout is about visual and functional representation of an application so if one is seeking to evaluate different models, they need to relate to those.","sentences":[{"sentence_type":"2","sentence":"However, the paper doesn't answer key questions about both the application and the models:","rephrased":"However, the paper could be strengthened by addressing key questions about both the application and the models:"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[288,378,"Confirmed"]],"Comments":[]}
{"id":"rJUMQfpeM","text":"I am not sure how to interpret this paper. The paper seems to be very thin technically, unless I missed some important details. Two proposals in the paper are:\n\n(1) Using a learning rate decay scheme that is fixed relative to the number of epochs used in training, and \n(2) Extract the penultimate layer output as features to train a conventional classifier such as SVM.\n\nI don't understand why (1) differs from other approaches, in the sense that one cannot simply reduce the number of epochs without hurting performance. And for (2), it is a relatively standard approach in utilizing CNN features. Essentially, if I understand correctly, this paper is proposing to prematurely stop training an use the intermediate feature to train a conventional classifier (which is not that away from the softmax classifier that CNNs usually use). I fail to see how this would lead to superior performance compared to conventional CNNs.","sentences":[{"sentence_type":"2","sentence":"The paper seems to be very thin technically, unless I missed some important details.","rephrased":"The technical depth of the paper could be further elaborated, or I may have overlooked some key details."},{"sentence_type":"2","sentence":"I fail to see how this would lead to superior performance compared to conventional CNNs.","rephrased":"It is not immediately clear how this approach would outperform conventional CNNs, and further clarification or evidence might be helpful."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[43,127,"Confirmed"],[836,924,"Confirmed"]],"Comments":[]}
{"id":"HkgRdsvQqr","text":"The paper presents a meta-learning algorithm to automatically detemine the depth of neural network through a policy to add depth if this bring improvement on accuracy.\n\nI have conserved opinion based on the technique being used here is extremely simple, basically is an implementation of naive greedy algorithm in such a scenario, which implies the problem may not be intrinsically hard, or even useful. The paper consists of detailed narrative about how these procedure are conducted, but still, it is really hard for me to find the true merit to appreciate, and why this brings a nontrivial and usefull contribution. The tables, visualization figures also didnot imply too much about whether this is more than overfitting on previous works with hand-chosen depth. ","sentences":[{"sentence_type":"2","sentence":"I have conserved opinion based on the technique being used here is extremely simple, basically is an implementation of naive greedy algorithm in such a scenario, which implies the problem may not be intrinsically hard, or even useful.","rephrased":"I believe the technique employed is quite straightforward, resembling an implementation of a naive greedy algorithm. This raises questions about the intrinsic difficulty and practical utility of the problem being addressed."},{"sentence_type":"2","sentence":"The paper consists of detailed narrative about how these procedure are conducted, but still, it is really hard for me to find the true merit to appreciate, and why this brings a nontrivial and usefull contribution.","rephrased":"While the paper provides a detailed narrative on the procedures conducted, I find it challenging to discern the significant merits and the substantial contributions it offers."},{"sentence_type":"2","sentence":"The tables, visualization figures also didnot imply too much about whether this is more than overfitting on previous works with hand-chosen depth.","rephrased":"The tables and visualization figures could be improved to better demonstrate how the approach differs from and improves upon previous works that used hand-chosen depth, particularly in avoiding overfitting."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[169,403,"Confirmed"],[404,618,"Confirmed"],[619,765,"Maybe"]],"Comments":[]}
{"id":"FHx8gFyYfdu","text":"This paper aims to tackle the matrix completion problem by drawing connection from prior work in image completion domain. It seems to be a combination of prior work: Multi-graph convolution combined with Dirichlet energy on row and column graph laplacian where the input rating matrix is corrupted with noise. The writing and presentation is significantly below par Iclr acceptance in the current form. Also, considering some of the work mentioned below, SOTA results is an overclaim.\n\na) Clarity Issues- \nPage 6 is incomprehensible in current form where the main algorithm is described. There are too many font changes in the results and main algorithm section. There is a grammatical \/ spelling error or typo almost every 5 lines throughout the paper. Few examples below:\n\n-results for Matrix Completion *where* obtained \n-Figure 3: Network Structure Illustration – MDDD algorithm flow *scatch*\n-then present in a *summerizing* tables the Results compared to other known methods.\n-the Non-Factorised and the *factosised* algorithms.\n-*translate\" its network \n-so it would *feet* for Matrix completion\n\nb) State of the art on Matrix completion:\nWhile this work claims state of the art results, it is missing some recent work (Iclr 20) that have achieved better state of the art results than reported in this paper.\n\n1) Inductive Matrix completion with gnn iclr 20 https:\/\/openreview.net\/forum?id=ByxxgCEYDS\n2) Deep Matrix Factorization with spectral regularizers (https:\/\/arxiv.org\/abs\/1911.07255)\n\nc) Related work :\nThis section is completely missing. While authors use 3 and half pages to describe the background needed,  it is not clear to me how this work uses multi graph convolution used in prior work or how does the authors make use of Dirichlet energy that is defined in preliminary section if it is differently used here than prior work.\n","sentences":[{"sentence_type":"2","sentence":"The writing and presentation is significantly below par Iclr acceptance in the current form.","rephrased":"The writing and presentation need improvement to meet the ICLR's standards for acceptance."},{"sentence_type":"2","sentence":"Page 6 is incomprehensible in current form where the main algorithm is described.","rephrased":"Page 6, which describes the main algorithm, could benefit from clearer explanations to enhance comprehension."},{"sentence_type":"2","sentence":"There is a grammatical \/ spelling error or typo almost every 5 lines throughout the paper.","rephrased":"The paper would benefit from a thorough proofreading to correct the frequent grammatical and spelling errors."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[310,402,"Confirmed"],[403,483,"Missed by Model"],[506,587,"Confirmed"],[663,753,"Confirmed"]],"Comments":[]}
{"id":"BJl60PYchX","text":"Summary of paper:\nThe authors partially integrate a neural network into classical approaches to classify the state of a quantum circuit. The model is not actually clear in what it is doing, but there are some trained weights somewhere. They allow for an \"uncertainty\" prediction by giving one more node than there are classification targets, corresponding to a less-penalized uncertain prediction. They evaluate their model on numerical simulations.\n\nStrengths:\n-\nWeaknesses:\n- The neural network architecture is entirely standard with nothing new.\n- The paper is poorly written and very hard to follow.\n- The focus is almost exclusively on the application, and yet the application is not explained effectively.\n- The implication of the results and usefulness is not elaborated.\n- The particular contributions are not clear.\n\nSuggested Revisions:\n- What is the 9b8d in the first sentence of the abstract?\n- \"...been developed to address the question [of] whether quantum mechanics...\"\n- \"...for all the dataset[s] in Table 1...\"","sentences":[{"sentence_type":"2","sentence":"The model is not actually clear in what it is doing, but there are some trained weights somewhere.","rephrased":"The description of the model and its operations could be made clearer, particularly regarding the role and configuration of the trained weights."},{"sentence_type":"2","sentence":"The neural network architecture is entirely standard with nothing new.","rephrased":"The neural network architecture appears to follow conventional designs, and it would be beneficial to highlight any novel aspects if present."},{"sentence_type":"3","sentence":"The paper is poorly written and very hard to follow.","rephrased":"The paper could benefit from improvements in clarity and structure to enhance its readability."},{"sentence_type":"2","sentence":"The focus is almost exclusively on the application, and yet the application is not explained effectively.","rephrased":"While the paper focuses on the application, providing a more detailed explanation of the application could improve understanding."},{"sentence_type":"1","sentence":"The implication of the results and usefulness is not elaborated.","rephrased":"Elaborating on the implications of the results and their potential usefulness would strengthen the paper."},{"sentence_type":"2","sentence":"The particular contributions are not clear.","rephrased":"Clarifying the specific contributions of this work would help to delineate its significance in the field."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[137,235,"Not concerning"],[478,548,"Maybe"],[551,603,"Confirmed"],[606,711,"Confirmed"],[714,778,"Confirmed"],[781,824,"Maybe"]],"Comments":[]}
{"id":"BlbecAMFCWc","text":"This paper presented a new natural language dataset for evaluating compositional generalization of machine learning models in the context of logic inference. The authors proposed a natural language interface for the underlying reasoning task. The dataset is generated by synthesizing possible reasoning chains in a subset of FOL with an upper length constraint.\n\nI believe the release of the dataset can be a good contribution to the community so I recommend accept this paper.\n\nFollowing are a few weaknesses I found while reading the paper.\n\n1. The presentation of \"OOD\" generalization split is unclear in the main text. I briefly skimed the appendix and couldn't find the exact setting either.\n2. The authors should discuss why they chose to include only a \"subset\" of FOL? What are the technical\/conceptual concerns?\n3. This is probably the most serious concern I have. The author have compared their new dataset with existing datasets in the introduction section. For example, the dataset is a more general dataset than CLUTRR. However, there is no empirical study of how these different design choices affect our findings. For example, do models show similar generalization results on these datasets?\n4. There are other mathematical reasoning datasets missing in the reference (as well as comparisons). For example, Saxton et al. \"Analysing Mathematical Reasoning Abilities of Neural Models\" Hong et al. \"Learning by Fixing: Solving Math Word Problems with Weak Supervision\"","sentences":[{"sentence_type":"1","sentence":"I briefly skimed the appendix and couldn't find the exact setting either.","rephrased":"I reviewed the appendix but was unable to locate the detailed explanation of the 'OOD' generalization split."},{"sentence_type":"2","sentence":"This is probably the most serious concern I have.","rephrased":"This concern stands out as particularly significant to me."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[623,696,"Not concerning"],[824,873,"Not concerning"]],"Comments":[]}
{"id":"Bkem3KVBYE","text":"Title:\nRating: 3\nConfidence: 1\n\nSummary:\nThe authors present a method of weakly supervising a topic model to guide it toward topic alignments that better align with user intuition for what topics should be. Their approach allows the user to label a subset of documents with a subset of their topics, making it flexible.\n\nI am not in a great position to confirm the soundness of the math, but the problem being solved and the suggested approach seem reasonable and relevant, with practical application.\n\nPoints:\n- I appreciate the flexibility of the design; allowing any number of documents to be labeled with any number of topics makes it much more likely to be used in practice, I believe.\n- The design decision to incorporate this information in the prior is nice and largely decoupled from the VAE in a good way.\n- I found the explanation of how ground truth was determined to be a little opaque. If this method in used in other works, please cite them. If it is not, more justification should be given here (possibly with a figure or equation for clarification).\n- Figure 1 is very helpful in justifying why you chose the model you did.\n- Table 2 does not seem to add much. It is not obvious from looking at the table that any of those methods is better than the others. \n- What are the confidence intervals on the results in Table 3? Some of this differences are quite small.\n\nNits:\n- Separate Table 1 from the text more\n- You mention in Section 5 that Delicious has 20 topics, but then say that \"half\" the number of labels is 11, and fully-labeled is up to 28? Please clarify what is being referred to or fix those numbers.","sentences":[{"sentence_type":"1","sentence":"I am not in a great position to confirm the soundness of the math, but the problem being solved and the suggested approach seem reasonable and relevant, with practical application.","rephrased":"While I am not fully equipped to evaluate the mathematical details, the problem addressed and the proposed solution appear to be reasonable, relevant, and practically applicable."},{"sentence_type":"2","sentence":"Table 2 does not seem to add much. It is not obvious from looking at the table that any of those methods is better than the others.","rephrased":"The contribution of Table 2 could be made clearer. It would be helpful if the table could more distinctly illustrate the advantages of the methods compared."},{"sentence_type":"1","sentence":"What are the confidence intervals on the results in Table 3? Some of this differences are quite small.","rephrased":"Could you provide the confidence intervals for the results in Table 3? This would help assess the significance of the differences, some of which appear to be marginal."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[321,501,"Not concerning"],[1143,1274,"Not concerning"],[1278,1380,"Not concerning"]],"Comments":[]}
{"id":"8laKax3TeC","text":"Authors present their work on identifying MS lesion change (appearance and enlarging lesions). This is a well-written abstract and an interesting method. The method uses GRU modules to include two or more images of the patient to identify lesion activity. \n\nI assume the method processes FLAIR images, but this is not 100% clear to me. Figure 1 seems to suggest that lesion maps are fed into the model in stead of FLAIR images. Can authors clarify this?\n\nAuthors identify three time points for each subject: HS (an early scan), BL (baseline, comes after HS), and FU (follow-up, the most recent scan). In the results, models are compared on T=2 (BL and FU) and T=3 (BL, FU, and HS). T=3 seems to work better and authors suggest that the added history might help. However, an alternative hypothesis for this improved performance could be that the difference between HS and FU is much larger than BL and FU; hence adding HS works. It would be interesting to also add T=2 with HS and FU; because I suspect that it is just the longer time period between HS and FU that leads to increased lesion activity that is easier to detect. \n\nIt is unclear to me whether authors used a separate validation dataset for optimizing the hyperparameters of their model. Or that the reported results are on the test set that was also used to select the best performing parameters and results?\n\nDid the human raters have access to HS when annotating lesion activity?\n\nAuthors look for 'new and enlarging' lesions (abstract): what about disappearing lesions?","sentences":[{"sentence_type":"1","sentence":"It is unclear to me whether authors used a separate validation dataset for optimizing the hyperparameters of their model. Or that the reported results are on the test set that was also used to select the best performing parameters and results?","rephrased":"Could the authors clarify if a separate validation dataset was used for optimizing the hyperparameters of their model, or if the reported results are from the test set that was also used for parameter selection?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1127,1370,"Not concerning"]],"Comments":[]}
{"id":"BJlokjiwYN","text":"\n* Paper summary:\n\nThis paper proposes to apply weak supervision to a wearable time-series classification problem.\n\nWeak supervision consists in using a collection of heuristic labeling functions to build a generative function of labels. A classifier is then trained using labels generated by this probabilistic model. This is definitely appealing when no human labeler is available.\n\nThis method is applied to a time-series classification problem relying on sensor data, with a bidirectional LSTM model. Depending on the considered setting, the weakly-supervised model achieves a performance which is significantly lower or slightly higher than a strongly-supervised model (trained with the true labels).\n\n* Decision\nThis paper suffers from experimental weaknesses and is not novel enough in terms of ideas to reach acceptance.\n\n* General remarks:\n- Major experimental weakness: the authors only compare the weakly supervised model to the strongly supervised one and to the *individual* labeling functions (which perform quite poorly individually). However, due to the very construction of weak supervision, a probabilistic *ensemble model* is constructed during weak supervision. The performance of this simple ensemble of heuristic functions is not reported by the authors. Thereby, it is impossible to distinguish the contribution of the weak supervision from the simple ensembling of heuristic functions, without any learning. The claim of the authors is therefore not supported by their experimental apparatus.\n- The paper is quite well written and easy to follow at high level, despite some imprecisions.\n- The methodology, task and dataset are not presented rigorously enough in section 3. (Cf detailed remarks)\n\n\n* Detailed questions\n1. What is exactly the classification task to be performed? For instance, in 3.2, x is first defined to have the length of a single gait cycle, but is then extended with windows before and after it.\n2. What is the total number of samples? The authors claim in the conclusion that it is « small ». A back of the envelope computation given numbers in Figure 1 leads me to think that each sample consists of a 2s window, plus ~3 s around it, so 5s in total. Sampling rate is 128Hz and there are two channels, so each channel has dimension ~1300. The recording shown in Figure1 goes until 350s, so 350\/5~70 samples \/ recording, with 9 patients and 36 trials per patient this leads to ~2300 recordings. This is not a « small data » problem.\n3. What value of the correlations C is used in the actual labeling functions?\n4. What kind of padding is used for the LSTM model?\n","sentences":[{"sentence_type":"2","sentence":"This paper suffers from experimental weaknesses and is not novel enough in terms of ideas to reach acceptance.","rephrased":"The paper could benefit from strengthening its experimental design and further developing its novel contributions to enhance its chances of acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[718,828,"Confirmed"]],"Comments":[]}
{"id":"9CmBPt0tOlP","text":"My recommendation would be to reject this paper for reasons which I will outline below.\n\nPros:\nThe problem of learning good features for RL is an important one to tackle and has application in many important tasks with complex input spaces like vision. The authors explain why this is important and I encourage them to continue to explore this line of research albeit more thoroughly as detailed below. \n\nCons:\nOne big issue with the paper is in its lack of experimental rigour. This can be improved by considering more than just the single Breakout task (the Atari suite itself contains many example tasks ripe for research) and also by comparing against more competitive baselines.\nFor instance the authors mention the AC-VAE (Yang et al. [1]) but do not compare against their method since ‘they do not report rewards achieved on Breakout’. To me this is not a good enough reason to not have a comparison. Instead I encourage the authors to reimplement the alternative approach and compare it on the tasks they consider.\nWhile the paper lists some early work on representation learning and learning features for RL they do not mention or compare against many other works (e.g. Jaderberg et. al. [2] and Achiam et al [3] to name a few). A thorough literature survey helps place the work in the broader context of the field and allows the work to be evaluated more comprehensively. \n\nFinally there are a number of minor points in the presentation which did not affect my final decision but would be good to fix.  There is a typo where 'Introduction' is spelled 'Introdction'. Reference capitalisation is inconsistent - in some places the paper refers to 'Figure 1' but elsewhere there is 'figure 3' and 'figure 4' (on page 7). If references are to be capitalised, 'table 1' would also have to be replaced with 'Table 1'.\n\nReferences: \n[1] John Yang, Gyuejeong Lee, Simyung Chang, and Nojun Kwak. Towards governing agent’s efficacy: Action-conditional β-vae for deep transparent reinforcement learning. volume 101 of Proceedings of Machine Learning Research, pp. 32–47, Nagoya, Japan, 17–19 Nov 2019. PMLR. URL http: \/\/proceedings.mlr.press\/v101\/yang19a.html.\n[2]. Max Jaderberg, Volodymyr Mnih, Wojciech Marian Czarnecki, Tom Schaul, Joel Z Leibo, David Silver, and Koray Kavukcuoglu. Reinforcement learning with unsupervised auxiliary tasks. arXiv preprint arXiv:1611.05397, 2016.\n[3] Joshua Achiam, Harrison Edwards, Dario Amodei, and Pieter Abbeel. Variational option discovery algorithms. arXiv preprint arXiv:1807.10299, 2018.\n\n","sentences":[{"sentence_type":"2","sentence":"To me this is not a good enough reason to not have a comparison.","rephrased":"I would suggest that the absence of reported rewards on Breakout by AC-VAE should not preclude a comparison. It would be beneficial for the authors to implement the AC-VAE method and provide a direct comparison in their study."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[843,907,"Confirmed"]],"Comments":[]}
{"id":"17fnXB-rVHO","text":"This paper studies the data leakage issue in the federated learning. More precisely, when the servers have access to model parameters and gradients. It can recover the input data via gradient matching, and the authors claim that their method performs well even with large training batch sizes, e.g. over 40. Finally, the author also studies the possibility of attacking during learning, where they suggest that multiple updates of fake data helps. However, their contribution seems incremental, gradient matching is used in previous literature [zhu et al 2019], and their main modification is extra two regularization terms: total variation and internal representation regularization, and a data index alignment technique (whose exact meaning is unclear in the paper).\n\nThe following are some questions:\n\nWhat does index alignment mean? Is that the server controls the indexes of samples chosen at each iteration? This seems to be very restrictive in practice, especially for horizontal federated learning.\n\nDoes the server have access to the aggregated grads from each worker separately or the workers aggregate all the gradients before sending them back to the server? The second scenario cab be achieved while secure aggregation technique.\n\nIn vertical federated learning, the gradients of part 1 of the network does not need to be exchanged with the server, as there is no average  operation needed, even the parameter itself does not need to be transferred to the server for the same reason, will your method work under this setting?\n\nSome terms are not properly defined, such as normalized gradient descent, batch ratio, et. al.\n\nOther questions:\n\nWhat does the iterations represent in table 1a? Is that the number of iterations need to reach a 35 PSNR?\n\nUsing cosine dissimilarity decreases the PSNR, I assume this is because PSNR penalize the scale, is there noticeable degradation visually when using cosine dissimilarity?\n\nIn the attack during learning scenario, is there any intuition why optimizing fake data multiple times works better?\n","sentences":[{"sentence_type":"2","sentence":"However, their contribution seems incremental, gradient matching is used in previous literature [zhu et al 2019], and their main modification is extra two regularization terms: total variation and internal representation regularization, and a data index alignment technique (whose exact meaning is unclear in the paper).","rephrased":"While the authors build upon existing gradient matching techniques, it would be beneficial to clarify how the introduction of two new regularization terms and the data index alignment technique contribute to the advancement of the field, especially since the latter's implementation is not entirely clear in the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[448,768,"Not concerning"]],"Comments":[]}
{"id":"rJluy5-qn7","text":"Differentiable Expected BLEU for Text Generation\n\nPaper Summary:\n\nNeural translation systems optimizes training data likelihood, not the end metric of interest BLEU. This work proposes to approximate BLEU with a continuous, differentiable function that can be optimized during training.\n\nReview:\n\nThe paper reads well. It has a few but crucial missing references. The motivation is easy to understand and a relevant problem to work on. The main weaknesses of the work lies in its very loose derivations, and its weak empirical results.\n\nFirst on context\/missing references: the author ignores approaches optimizing BLEU with log linear models (Franz Och 2003), and the structured prediction literature in general, both for exact (Tsochantaridis et al 2004) and approximate search (Daume and Marcu 2005). This type of approach has been applied to NMT recently (Edunov et al 2018). Your paper also misses important references addressing BLEU optimization with reinforcement strategies (Norouzi et al 2016) or (Bahdanau et al 2017). Although not targeting BLEU directly (Wiseman and Rush 16) is also a reference to cite wrt optimizing search quality directly. \n\nOn empirical results, you chose to work IWSLT in the de-en direction while most of the literature worked on en-de. It prevents comparing your results to other papers. I would suggest to switch directions and\/or to report results from other methods (Ranzato et al 2015; Wiseman and Rush 2016; Norouzi et al 2016; Edunov et al 2018). De-en is generally easier than en-de (generating German) and your BLEU scores are particularly low < 25 for de-en while other methods ranges in 26-33 BLEU for en-de (Edunov et al 2018).\n\nOn the method itself, approximating BLEU with a continuous function is not easy and the approach you take involves swapping function composition and expectation multiple times in a loose way. You acknowledge that (7) is unprincipled but (10) is also problematic since this equation does not acknowledge that successive ngrams overlap and cannot be considered independent. Also, the dependence of successive words is core to NMT\/conditional language models and the independence hypothesis from the footnote on page 4 can be true only for a bag of word model. Overall, I feel that given the shortcuts you take, you need to justify that your approximation of BLEU is still correlated with BLEU. I would suggest to sample from a well trained NMT system to collect several hypotheses and to measure how well your BLEU approximation correlate with BLEU. How many times BLEU decides that hypA > hypB but your approximation invert this relation? is it true for large difference, small difference of BLEU score? at low BLEU score, high BLEU score?\n\nFinally, you do not mention the distinction between expected BLEU  \\sum_y P(y|x) BLEU(y, ref) and the BLEU obtained by beam search which only look at (an estimate of) the most likely sequence y* = argmax P(y|x) . Your approach and most reinforcement strategy targets optimizing expected BLEU, but this has no guarantee to make BLEU(y*, ref) any better. Could you report both an estimate of expected BLEU and beam BLEU for different methods? In particular, MERT (), beam optimization (Wiseman and Rush 2016) and  structured prediction (Edunov et al 2018) explicitly make this distinction. This is not a side issue as this discussion is in tension with your motivations.\n\nReview Summary:\n\nThe paper misses important references. It chooses an empirical setup which prevents comparison with related work, and the report results on de-en seem weak. The proposed approach does not bound or estimate how far from BLEU is the proposed approximation. This means that the authors need to justify empirically that it preserves correlation with BLEU, which is not shown in the paper.\n\nMissing references\n\nAn Actor-Critic Algorithm for Sequence Prediction (ICLR 2017)  Dzmitry Bahdanau, Philemon Brakel, Kelvin Xu, Anirudh Goyal, Ryan Lowe, Joelle Pineau, Aaron Courville, Yoshua Bengio\n\nHal Daume III and Daniel Marcu. Learning as search optimization: Approximate large margin methods for structured prediction. ICML 2005.\n\nSergey Edunov, Myle Ott, Michael Auli, David Grangier, Marc'Aurelio Ranzato\nClassical Structured Prediction Losses for Sequence to Sequence Learning, NAACL 18\n\nMinimum Error Rate Training in Statistical Machine Translation Franz Josef Och. 2003 ACL\n\nI. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun, Support Vector Machine Learning for Interdependent and Structured Output Spaces, ICML 2004.\n\nMohammad Norouzi, Samy Bengio, Zhifeng Chen, Navdeep Jaitly, Mike Schuster, Yonghui Wu, Dale Schuurmans, Reward Augmented Maximum Likelihood for Neural Structured Prediction, 2016\n\nSequence-to-Sequence Learning as Beam-Search Optimization, Sam Wiseman and Alexander M. Rush., EMNLP 2016\n","sentences":[{"sentence_type":"2","sentence":"The main weaknesses of the work lies in its very loose derivations, and its weak empirical results.","rephrased":"The main areas for improvement in the work are the derivations, which could be more rigorous, and the empirical results, which could be strengthened."},{"sentence_type":"2","sentence":"You acknowledge that (7) is unprincipled but (10) is also problematic since this equation does not acknowledge that successive ngrams overlap and cannot be considered independent.","rephrased":"While you have acknowledged the limitations of equation (7), further attention may be needed for equation (10) to account for the overlap of successive ngrams and their dependency."},{"sentence_type":"2","sentence":"Overall, I feel that given the shortcuts you take, you need to justify that your approximation of BLEU is still correlated with BLEU.","rephrased":"It would be beneficial to provide a justification for how the approximations made in your method maintain a correlation with the BLEU metric."},{"sentence_type":"1","sentence":"Your paper also misses important references addressing BLEU optimization with reinforcement strategies (Norouzi et al 2016) or (Bahdanau et al 2017).","rephrased":"The paper would be more comprehensive if it included references to works that address BLEU optimization with reinforcement strategies, such as Norouzi et al 2016 and Bahdanau et al 2017."},{"sentence_type":"2","sentence":"De-en is generally easier than en-de (generating German) and your BLEU scores are particularly low < 25 for de-en while other methods ranges in 26-33 BLEU for en-de (Edunov et al 2018).","rephrased":"Considering that de-en is generally perceived as easier than en-de, it would be insightful to see how your BLEU scores compare to the 26-33 range achieved by other methods for en-de, as reported by Edunov et al 2018."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[436,535,"Not concerning"],[880,1029,"Not concerning"],[1491,1676,"Not concerning"],[1870,2049,"Not concerning"],[2236,2369,"Not concerning"]],"Comments":[]}
{"id":"nMNaKAcbo-P","text":"Strengths\n1. The approach presented in this paper is novel and differs significantly from past proposals.\n2. The approach is demonstrated on robotic applications.\n3. The concept of using a learned component within a control task is of interest to this community. \n\nWeaknesses\n1. The paper claims that the proposed method can be used to achieve behaviors of the controlled system which satisfy SITL specifications. This appears to be subtely incorrect. Theorem 1 describes asymptotic performance guarantees, not performance of the system during a finite horizon. Nothing can be said about the satisfaction of the \"prefix\" portion of the SITL specification. \n2. The paper correctly claims that the theorem makes no special requirements about the error of the learned component, and moreover that the selection of training data does not affect the claim. This is not the same thing as saying that these elements \"don't matter\", what is promised is that things won't go terribly wrong, not that the outcomes will be good. The experimental section could be improved by ablations of the off-policy data both in terms of variations of the system dynamics, the quantity of the data, and the diversity of tasks.\n3. The learning problem in which the learned component predicts the next control input seems like it could have issues (which do not affect the theoretical guarantees) in the case that there are two tasks with the same \"prefix\" trajectory but a different end trajectory. It seems that the network would then be forced to predict the average of the two outcomes. Does the methodology seek to avoid sampling such training data. What are the implications?\n4. In general the paper oversells some of the claims. See above. it could be improved by taking a less adversarial approach in the writing and acknowledging the trade off in relaxing the approach to ask that the learned component doesn't add arbitrarily large errors. In addition more discussion could be added about the controllability requirement and how limiting this is; I acknowledge that the paper has made some efforts to be precise here. \n5. A sketch of the proof in the main body could be useful. It is extremely technical. Moreover, it could be useful for the author's to discuss whether the learned component must be a neural network and specific properties of neural networks were necessary for the proof. It seems that the setup could be more general. \n6. The use of SITL seems needlessly complex and not the main point of the paper. Beyond its use as a specification language for generating training examples it seems ancillary. See point 1. The paper could be improved by incorporating specifications that use more properties of the SITL formalism for task specification (e.g. beyond reach like tasks). \n7. In the related work some discussion of work like: https:\/\/arxiv.org\/pdf\/1903.11239.pdf could be included. In this reference the authors also learn a component to augment control inputs. They do not have any similar guarantees but it is a better motivated setting. ","sentences":[{"sentence_type":"2","sentence":"This appears to be subtely incorrect.","rephrased":"There seems to be a subtle discrepancy here."},{"sentence_type":"2","sentence":"In general the paper oversells some of the claims. See above.","rephrased":"The paper could present some of the claims more cautiously to reflect the scope of the results more accurately."},{"sentence_type":"2","sentence":"it could be improved by taking a less adversarial approach in the writing","rephrased":"The paper could benefit from a more collaborative tone in the writing."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[414,451,"Confirmed"],[1659,1720,"Confirmed"],[1721,1794,"Not concerning"],[2162,2187,"Missed by Model"],[2425,2501,"Missed by Model"]],"Comments":[]}
{"id":"r2VeWpxd0Zc","text":"The paper proposes to learn state factorization with the assumption that the MDP reward is a sum of rewards for individual factors. The proposed model uses k encoders to learn k individual factors and an attention mechanism to condense the k factors into a single input to a policy. Predicting attention weights based on individual factor values is an interesting design decision.\n\nStrengths: The paper proposes novel approach that is evaluated on the challenging procgen benchmark, which tests generalization.\n\nWeaknesses: There is no analysis of what the individual factors learn. I'm especially curious if the model chooses to use all factors. Additionally, the number of trainable parameters in the proposed method and the baseline should be compared.\n\nThis is a relevant and interesting paper for the workshop.","sentences":[{"sentence_type":"1","sentence":"There is no analysis of what the individual factors learn.","rephrased":"The paper would be strengthened by including an analysis of what the individual factors learn."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[524,582,"Not concerning"]],"Comments":[]}
{"id":"HyeXCw_jF4","text":"The paper considers a multi-armed bandit problem in which on some iterations, the reward from the environment might be\ncompletely missing. To the rescue, a modified LinUCB-type algorithm is then proposed. Experimental results seam sound.\nThe authors show that their proposal outpowers a blind LinUCB algorithm. The t-SNE plots (Figs 1 and 2) also show that\nthe embeddings learned by the proposed model are more compactly clustered w.r.t the true labels.\n\nThe paper is well-written and the movitated problems are well described.\n\nThe paper considers a multi-armed bandit problem in which on some iterations, the reward from the environment might be\ncompletely missing. To the rescue, a modified LinUCB-type algorithm is then proposed. Experimental results seam sound.\nThe authors show that their proposal outpowers a blind LinUCB algorithm. The t-SNE plots (Figs 1 and 2) also show that\nthe embeddings learned by the proposed model are more compactly clustered w.r.t the true labels.\n\nThe paper is well-written and the movitated problems are well described.\n","sentences":[{"sentence_type":"1","sentence":"Experimental results seam sound.","rephrased":"The experimental results appear to be robust."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[205,237,"Not concerning"]],"Comments":[]}
{"id":"H1eL5x0l2N","text":"The paper describes a set of translations and transformations of temporal PDDL problems to support the generation of contrastive explanations.  It outlines how to accomplish this for seven question types related to actions within a temporal plan; for example \"why action a instead of action b?\" or \"why not action a in time interval [0, 2]\".  \n\nOverall, the paper was straightforward to read and well motivated.  Some minor structural changes could improve the paper (details below).  My main quibble was with the use of arity in the definition.  This was confusing when it was first presented since it was not clear to me why it needed to be included and deviates from the somewhat standard form of planning models.  It wasn't until Section 4.7 that I saw it was possibly necessary, but even then it seemed like this could be left off the descriptions to help improve the paper.   I don't recall any papers that discuss the arity of predicates  -- it seems like most planners will simply refuse to parse such invalid problems.  Also, the formal model starts what I assume was meant to be a lifted form (Ps, Vs..) that are eventually ground (P, V, ..) but I found this confusing.  For both of these, you might consider how to drop these for the sake of clarity, perhaps adding a paragraph to state what assumptions your sweeping with your notation.  Alternatively, more exposition is needed to help the reader get through the introduction of the model.\n\nThe approach is strongly reminiscent of plan trajectories from PDDL 3.0, which were used to represent preferences.  This approach fell out of favor after it was shown that soft goals could be compiled away.  However, it occurs to me that further work in this area could benefit from looking at the original PDDL 3.0 specifications as well as the compilations.  There may be some hidden gems in that old work that would apply here.\n\nOther comments:\n- What planner was used to generate plans?\n- Show Figure 5 first and then show the model.  I started to draw a picture of Figure 3 and then realized I just needed to turn the page.\n- Figure, Table, Section, etc., when referring to a single entity (e.g., the only Figure 3 in the paper), are proper nouns and should be capitalized throughout.  \n- Section 4.5 (forbid) should probably come before 4.4 (delay) since delay uses forbid.  This removes a forward reference.\n- the durative-action goto_waypoint_nota should probably be placed in its own figure for consistency.\n\n","sentences":[{"sentence_type":"1","sentence":"My main quibble was with the use of arity in the definition. This was confusing when it was first presented since it was not clear to me why it needed to be included and deviates from the somewhat standard form of planning models.","rephrased":"I found the inclusion of arity in the definition initially confusing, as its necessity was not immediately clear, and it appears to deviate from the more conventional forms of planning models. Clarifying its role early on could enhance understanding."},{"sentence_type":"2","sentence":"I don't recall any papers that discuss the arity of predicates  -- it seems like most planners will simply refuse to parse such invalid problems.","rephrased":"The discussion on the arity of predicates is unusual as it is not commonly addressed in the literature, and many planners may not accept problems with such specifications. It would be helpful to provide a rationale for its inclusion or consider aligning with more standard practices."},{"sentence_type":"1","sentence":"This approach fell out of favor after it was shown that soft goals could be compiled away.","rephrased":"It's worth noting that the approach is similar to plan trajectories from PDDL 3.0, which became less popular due to the ability to compile away soft goals. Exploring this further could provide valuable insights for your work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[485,716,"Not concerning"],[882,1027,"Not concerning"],[1570,1660,"Not concerning"]],"Comments":[]}
{"id":"rklB0nk6tB","text":"The paper studies methods for detecting adversarial examples using saliency maps. The authors propose using the method of Dabkowski and Gal (2017) to generate saliency maps and then train a classifier on these maps (or their dot product with the input image) to distinguish natural from adversarial examples. They perform experiments evaluating the white-box and black-box robustness of their detection scheme.\n\nFrom a technical perspective, the contribution of the paper is rather incremental. The detection of adversarial examples by training a classifier on saliency maps has already been studied in prior work. The only modification proposed in this work is using an (existing) alternative method for producing the saliency maps and utilizing the dot product of maps with images.\n\nFrom a conceptual perspective, the impact of detecting specific adversarial attacks is not clear. In a realistic setting, an adversary could use a very different attack or even utilize a different set of transformations (e.g. image rotations). Thus, in order to demonstrate the utility of their method in a black-box scenario, the authors would need to evaluate the defense in a variety of different scenarios. At the very least, they should consider generalization to difference attacks (e.g., train against FGSM and BIM, and test against DF).\n\nMoreover, the robustness against white-box adversaries is not sufficiently studied. Firstly, the robustness of the non-adversarially trained detector is suspiciously high. There is little reason to expect that a composition of two neural networks (the saliency map methods and the classifier) would be non-trivially robust. The authors should consider alternative attacks perhaps using more iterations with a smaller step size. Secondly, after adversarial training, only the robustness against the same attack is considered. In order to argue about white-box robustness, the authors would need to evaluate against a variety of diverse adversaries.\n\nOverall, the technical and conceptual contribution of this paper is insufficient for publication at ICLR, even ignoring the concerns about its experimental evaluation.","sentences":[{"sentence_type":"2","sentence":"From a technical perspective, the contribution of the paper is rather incremental.","rephrased":"While the paper builds upon existing methods, further elaboration on the distinct technical contributions could enhance the value of the work."},{"sentence_type":"2","sentence":"Moreover, the robustness against white-box adversaries is not sufficiently studied.","rephrased":"Additionally, a more comprehensive study on the robustness against white-box adversaries could strengthen the findings."},{"sentence_type":"3","sentence":"Overall, the technical and conceptual contribution of this paper is insufficient for publication at ICLR, even ignoring the concerns about its experimental evaluation.","rephrased":"In conclusion, while the paper presents interesting ideas, further development of the technical and conceptual aspects, as well as addressing the experimental evaluation concerns, may be necessary for publication at ICLR."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[412,494,"Maybe"],[1331,1414,"Maybe"],[1415,1502,"Missed Maybe"],[1980,2147,"Confirmed"]],"Comments":[]}
{"id":"Mf8dfe66T3s","text":"This paper proposes to learn patient-specific representation using patient physiological signals.  The authors design a PCP representation for each patient, which is learned to agree with signals from the same patients and disagrees with the remaining patients. In the supervised part, the classifier is generated from patient-specific parameters by meta-learning. The model was evaluated on three large ECG datasets: PhysioNet 2020 ECG, Chapman ECG, PTB-XL ECG.\n\nStrength: \nThis is an important problem\nThe paper is easy to follow, and the experiment settings are well elaborated \n\n___________________________________________________________________________\nWeakness:\n\nThe authors are ignorant to several lines of existing literature in deep learning for healthcare, particularly deep phenotyping and deep patient subtyping. They also seem not aware of the existing works on explaining Black-box models.   For deep phenotyping algorithms, the patient representations generated from existing deep phenotyping algorithms are ALL patient specific.  To list a few, the authors may take a look at [1-4]. For more related works on deep phenotyping, you may refer to [5]. For more related works on deep learning for ECG data, you may refer to [6]. To learn disease subtypes, patient prototypes, there are also a series of works. Below are several the authors could refer to [7-10]. In addition, there are several model agnostic algorithms designed for explaining deep learning models that could be used here to add more explanability. For example [11-13]. In addition, there are many existing works around contrastive learning on ECG signals, see [14-16]. The authors are either not aware of these lines of works or have wrong understanding on them, which cause several major issues as listed below.\n\n(a) Lack of Novelty. Given the existing works listed below. The novelty of the paper is not enough for the conference. The methodology of the paper consists of a standard contrastive learning method and a standard meta-learning setting. All have been done in one or more existing works.\n\n(b) Lack of Baselines. The paper does not include any baseline. It is unclear how it compares with existing works.  \n\n(c) The experiment results are mostly unconvincing. For example,\n- In Experiment 5.1, the paper states that “PCPs exhibit tighter clusters than those found with training representations” in Figure 2. However, it is hard to tell which result is more separable from my point of view. A possible suggestion is that the authors could use quantitative clustering metrics to demonstrate, such as Adjusted Rand index. Also, the resolution of figure 2 could be improved.\n- In Experiment 5.2,  the detail of meta-learning network, hypernetwork, is not mentioned in the paper. Is it just a matrix transform? Or a more complicated neural network? The detailed implementation of hypernetwork could be discussed.\n- In Experiment 5.3, The result is not surprising, since the model have used contrastive loss to maximize similarity of “PCP to Same Training Patient”. Therefore, it should have smaller distances, naturally. Also, we encourage the paper to discuss why using the Euclidean distance not the cosine similarity as mentioned in Sec. 3.1.\n- In Experiment 5.4, the paper shows two examples of similar patients, where the performance is hard to evaluate. The reviewer will suggest two ways: (i) using demographics, physiology, or treatment features to match two similar patients, and then quantitatively compare with the matching results given by the paper; (ii) setting distance threshold or cosine similarity threshold to decide whether two patients are similar, and then justify the threshold.\n- In Experiment 5.5. This experiment is very problematic. First, the paper claims and show that the PCP representation could provide the same classification performance as training on the whole training set. It is also not surprising, because when obtaining the PCP representations, the model already uses all the training data, then of course PCP would give the same performance; Second, we encourage the paper to compare with using different proportions of the training set. Often the time, the whole training set could be redundant in ECG setting.\n- The authors are encouraged to analyze the computational complexity of the proposed method.\n- In appendix, figure 9 (bottom) has exactly the same channel signals, which is a significant mistake. Figure 10 has a wrong title description.\n- For dataset PhysioNet 2020 ECG, the paper states that “Each recording can be associated with multiple labels”. It is unclear how to use the dataset for evaluation.\n- The motivation of the paper could be improved. Also, some related works on contrastive learning are missing, for example [17-18].\n\nReferences\n\n[1] RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism. NeurIPS 2016\n\n[2] MiME: Multilevel Medical Embedding of Electronic Health Records for Predictive Healthcare. NeurIPS 2017\n\n[3] MINA: Multilevel Knowledge-Guided Attention for Modeling Electrocardiography Signals. IJCAI 2019\n\n[4] RAIM: Recurrent Attentive and Intensive Model of Multimodal Patient Monitoring Data. KDD 2018\n\n[5] Opportunities and challenges in developing deep learning models using electronic health records data: a systematic review, Journal of the American Medical Informatics Association 2019\n\n[6] Opportunities and Challenges in Deep Learning Methods on Electrocardiogram Data: A Systematic Review, Computers in Biology and Medicine 2020\n\n[7] Patient subtyping via time-aware LSTM networks, KDD 2017\n\n[8] DDL: Deep Dictionary Learning for Predictive Phenotyping, IJCAI 2019\n\n[9] PEARL: Prototype Learning via Rule Learning, ACM BCB 2019\n\n[10] Identifying Sepsis Subphenotypes via Time-Aware Multi-Modal Auto-Encoder, KDD 2020\n\n[11] Why should I trust you?: Explaining the predictions of any classifier. KDD 2016\n\n[12] A Unified Approach to Interpreting Model Prediction. NeurIPS 2017\n\n[13] Anchors: High-Precision ModelAgnostic Explanation AAAI 2018\n\n[14] CLOCS: Contrastive learning of cardiac signals. arXiv preprint arXiv:2005.13249, 2020. \n\n[15] A simple framework for contrastive learning of visual representations. arXiv preprint arXiv:2002.05709, 2020. \n\n[16] Subject-aware contrastive learning for biosignals. arXiv preprint arXiv:2007.04871, 2020.\n\n[17] Momentum contrast for unsupervised visual representation learning. CVPR 2020\n\n[18] Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748.\n","sentences":[{"sentence_type":"3","sentence":"The authors are ignorant to several lines of existing literature in deep learning for healthcare, particularly deep phenotyping and deep patient subtyping.","rephrased":"The authors may have overlooked some relevant literature in deep learning for healthcare, such as deep phenotyping and deep patient subtyping."},{"sentence_type":"3","sentence":"The authors are either not aware of these lines of works or have wrong understanding on them, which cause several major issues as listed below.","rephrased":"It appears that the authors might not be fully aware of these lines of work, or there may be some misunderstandings, which have led to several issues that need to be addressed as listed below."},{"sentence_type":"2","sentence":"The novelty of the paper is not enough for the conference.","rephrased":"The paper could benefit from a clearer demonstration of its novelty to meet the conference's standards."},{"sentence_type":"2","sentence":"The experiment results are mostly unconvincing.","rephrased":"The experiment results could be strengthened with additional evidence and clearer demonstrations of the findings."},{"sentence_type":"2","sentence":"This experiment is very problematic.","rephrased":"There are some concerns with this experiment that could be addressed to improve the robustness of the results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[670,825,"Confirmed"],[1650,1793,"Confirmed"],[1855,1913,"Maybe"],[2205,2252,"Maybe"],[3711,3747,"Confirmed"]],"Comments":[]}
{"id":"HJgNRaZ0tr","text":"This paper proposes to use additional structures within and between sentences for pre-training BERT. The basic idea is to shuffle either some n-grams within sentences or the sentences in texts, then train the model to predict the correct orders. Experiments in this work show that, with this additional training objective, the proposed pre-trained model, StructBERT, obtains good performance on the tasks including natural language understanding and question answering.\n\nOverall, I think the experiments and results in this work are not sufficient enough to support the claim:\n\n- It is necessary to show the performance of BERT only trained with the proposed word and sentence objectives. Otherwise, it is not clear how much benefit the model can get from them and the work is basically incremental. \n- Some justification is needed about why choosing trigrams and why 5% is a good number of sampling trigrams from texts\n\nBesides, there are some recent work on analyzing why BERT encodes any linguistic properties of texts, for example \n\n- Goldberg. Assessing BERT's syntactic abilities. 2019\n- Tenny et al. BERT Rediscovers the Classical NLP Pipeline. ACL 2019\n- Tenny et al. What do you learn from context? ICLR 2019\n\nAll of them show positive results on BERT can capture some syntactic information from text automatically. Which makes me wonder why the simple additional training objective proposed in this work can still lead to performance improvement. Is there an explanation? \n","sentences":[{"sentence_type":"2","sentence":"Overall, I think the experiments and results in this work are not sufficient enough to support the claim:","rephrased":"To strengthen the paper's claims, it would be beneficial to include more comprehensive experiments and results."},{"sentence_type":"2","sentence":"Otherwise, it is not clear how much benefit the model can get from them and the work is basically incremental.","rephrased":"Clarifying the specific benefits derived from the model's word and sentence objectives would help differentiate this work from incremental advancements."},{"sentence_type":"1","sentence":"Which makes me wonder why the simple additional training objective proposed in this work can still lead to performance improvement. Is there an explanation?","rephrased":"Considering these findings, it would be interesting to see an explanation of how the additional training objective in this work contributes to performance improvement."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[471,576,"Not concerning"],[689,799,"Not concerning"],[1325,1481,"Not concerning"]],"Comments":[]}
{"id":"peTyZOxb7gq","text":"Summary\n\nThis paper attempts to address the fundamental barriers of learned optimization. The authors identify three barriers: computational requirements, number of training tasks and lack of inductive bias. A “large-scale” evaluation and comparison of learned optimizers is then carried out using many (1024) multi-core CPUs. A simple modification of an existing learned optimizer is also proposed that involves adding more input features. Unfortunately the results don’t seem to reveal any new insights.  \n\nStrengths\n- The paper proposes a new, simple hierarchical learned optimizer that outperforms existing learned optimizers. The proposed model is very simple in theory but the implementation seems to still require quite a bit of “hand-engineering” in terms of selecting features etc.\n\n\n- The experimental investigation reveals some interesting (albeit unsurprising) insights of large scale training of learned optimizers. These include things like training with more tasks improves performance, that learned optimization performs well in the hyper-parameter regime in which it was trained, that it learns some form of regularization and that it outperforms Adam when a non-optimal learning rate is used.\n\n\nConcerns:\n- My main concern with the paper is that some claims are over-blown. Although it is not clear at all that the current generation of learned optimizers can outperform hand-crafted optimizers, the paper makes misleading claims that can easily be taken out of context. Statements like, “We see this final accomplishment as being analogous to the first time a compiler is complete enough that it can be used to compile itself.” and “we believe learned algorithms will transform how we train models\" are too strong given the current evidence of the performance of the learned optimizers. I would suggest the authors tone down these claims.\n\n\n- The proposed hierarchical learned optimizer (as well as existing ones) seem to be more fragile than hand-crafted approaches such as Adam. For example, on CIFAR-10 in Figure 5 the learned optimizer fails even for batch sizes in the training regime. Is there any reason why this might be the case, especially considering that it has access to all the same information as Adam and Adam’s “hand-crafted” operations are quite simple? \n\n\n- The disadvantages of the proposed learned optimizer still seems to outweigh the benefits. For example, the “careful tuning of learning rate schedules and momentum timescales” is traded instead for the selection of design of a sufficient range of tasks on which to train the optimizer. This seems to be a far more difficult task than just tuning a few hyperparameters. In addition, although hand-crafted optimizers “do not leverage alternative sources of information beyond the gradient”, the learned optimizers do not do much better and just seem to learn very simple regularization strategies. Currently the discussion on the advantages and disadvantages is completely separate. I think these need to be contrasted and compared on the grounds of what properties a user would prefer in an optimizer.\n\n\n- The contribution of the paper in terms of new insight or knowledge is not clear. The “large-scale” training on a wide range of tasks and many unrolled steps is interesting but I’m not sure what new insights can be inferred from this? Furthermore, the hierarchical optimizer seems to be a small improvement of the mode proposed in (Wichrowska et al., 2017) with some additional input information (like validation loss).\n","sentences":[{"sentence_type":"2","sentence":"Unfortunately the results don't seem to reveal any new insights.","rephrased":"The results could be further elaborated to highlight any novel insights that may have been uncovered."},{"sentence_type":"2","sentence":"My main concern with the paper is that some claims are over-blown.","rephrased":"I would encourage the authors to ensure that the claims made in the paper are fully supported by the evidence presented."},{"sentence_type":"2","sentence":"The disadvantages of the proposed learned optimizer still seems to outweigh the benefits.","rephrased":"It would be beneficial to discuss how the proposed learned optimizer's advantages might be enhanced to outweigh its current disadvantages."},{"sentence_type":"2","sentence":"The contribution of the paper in terms of new insight or knowledge is not clear.","rephrased":"The authors could clarify the contributions of the paper in terms of new insights or knowledge gained from the research."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1225,1291,"Maybe"],[2296,2385,"Not concerning"],[3100,3180,"Not concerning"]],"Comments":[]}
{"id":"5OxrF4AwtON","text":"Strength:\nThe problem is important and interesting.\nThe paper was well written and easy to understand. \nThe experimental results also show the methods have better performance than the benchmarks.\n\nWeakness:\nThe key components of the methods, including using conditional normalizing flow to represent the behavioral prior, using chance constraints to represent unsafe constraints, using ELBO to optimize the chance constraints are all well-known standard treatments in the field of reinforcement learning. The authors provided heuristics on the choices of these tools but lack rigorous analysis on the proposed methods. Given the authors only one environment to evaluate the proposed method, it is unknown how well the methods could generalize to other problems. \n\nIt is suggested that authors add more theoretical analysis to unveil the novelty and insight of the method and more diverse experiments to show the strength and limits of the methods in a more comprehensive way.","sentences":[{"sentence_type":"2","sentence":"The authors provided heuristics on the choices of these tools but lack rigorous analysis on the proposed methods.","rephrased":"The authors offer heuristics for the selection of these tools; however, a more rigorous analysis of the proposed methods would strengthen the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[505,618,"Maybe"]],"Comments":[]}
{"id":"Srlx9M9R2Zc","text":"This paper is relevant to the topic of the workshop.\n\nThis work appears very similar to SPACE (https:\/\/arxiv.org\/abs\/2001.02407). It is not clear to me how this is a 3D representation? The methods section is very brief. \nAuthors show improvement over Nerf with a single object in an auto-encoder setup.\nResults in Figure 2 look good, however, some objects disappear under the transforms. It would also be help to highlight which object has been added.","sentences":[{"sentence_type":"1","sentence":"The methods section is very brief.","rephrased":"The methods section could be expanded to provide a clearer understanding of the approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[185,219,"Not concerning"]],"Comments":[]}
{"id":"8YC0Sr3sxi_","text":"The paper investigates methods for making slot attention exclusively multiset-equivariant, a property which allows them to map identical queries to different outputs. Starting with the observation that the normalization steps of standard slot attention resemble an iteration of the Sinkhorn algorithm for the entropy-regularized optimal transport problem, various methods are proposed to approximate solving the unregularized optimal transport problem within slot attention, yielding the desired properties. The methods are evaluated on CLEVR multiset property prediction.\n\nPros:\n - The paper makes a very intriguing and non-obvious connection between the attention matrix of slot attention and optimal transport problems, that I think will be of interest to the community even by itself.\n - The proposed slot attention variants represent a convincing exploration of this connection: First, the normalization steps are repeated, resembling the Sinkhorn algorithm. Then, solving the unregularized OT problem, and a fast approximation thereof is proposed.\n - The empirical results support the authors' claim that multiset prediction is a weak point of slot attention which can be improved via exclusively multiset-equivariant components.\n - The paper is well written and easy to follow.\n\nCons (which the authors do a good job of identifying themselves in the discussion section):\n - While the connection to OT has led to promising results, some of the choices made along the way appear somewhat ad hoc (e.g. in Eq. 8 and 9), and call for further investigation.\n - Additional experiments other than CLEVR would further support the hypothesis of the paper.\n\nOverall, I think this is a very enlightening paper that will be of great interest to the community.","sentences":[{"sentence_type":"1","sentence":"some of the choices made along the way appear somewhat ad hoc (e.g. in Eq. 8 and 9), and call for further investigation.","rephrased":"While the paper presents promising results, the rationale behind certain choices (e.g., in Eq. 8 and 9) could be elaborated on further to strengthen the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1438,1558,"Not concerning"]],"Comments":[]}
{"id":"rJgwCZ5x2V","text":"The paper is well written and addresses an interesting problem in robotics and knowledge engineering. The results look sound and show the improved accuracy and computational efficiency of the proposed architecture and the deep\nnetwork system. The only comment I would say is to define all the acronyms used in the paper (e.g. RNN) for completeness.","sentences":[{"sentence_type":"1","sentence":"The only comment I would say is to define all the acronyms used in the paper (e.g. RNN) for completeness.","rephrased":"I would suggest defining all the acronyms used in the paper (e.g., RNN) for completeness."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[243,348,"Not concerning"]],"Comments":[]}
{"id":"SyxiwuB_cH","text":"Recently, it has been shown that spiking neural networks (SNN) can be trained efficiently, in a supervised manner, using backpropagation through time. Indeed, the most commonly used spiking neuron model, the leaky integrate-and-fire neuron (LIF), obeys a differential equation which can be approximated using discrete time steps, leading to a recurrent relation for the potential. The firing threshold causes a non-differentiability issue, but it can be overcome using a surrogate gradient. In practice, it means that SNNs can be trained on GPUs using standard deep learning frameworks such as PyTorch or TensorFlow.\n\nHere the authors extend this approach by proposing two variations of the LIF model, called RLIF and LIF-LSTM. However, the presentation of these models is not clear at all.\nFor example:\n* what is U^t in Equation 4?\n* what is M^t in Equation 7?\n* what is the difference (if any) between u^t and u_d^t?\nEquation 8 is even more obscure. Why bothering defining a new variable Y if it is equal to F? What is index j, and why is it used only on the left hand side of the equation?\n\nThe description of the LIF-LSTM is even more obscure, nothing is defined.\n\nFigure 2 has an error. On the left, with the heavyside activation function, the gradient is actually defined everywhere (with a value of 0) but on the red segment!!!\n\nIn addition, the experiments are not convincing. I am not an expert in NLP, so I will focus on the vision experiments.\nTable 1 is incomplete. Wu et al 2019 (which they cite elsewhere!!!), reached 60.5% on DVS-CIFAR10, which is much better than this paper (56.93%)\n\nFor all these reasons, I recommend rejection.\n\n","sentences":[{"sentence_type":"2","sentence":"However, the presentation of these models is not clear at all.","rephrased":"However, the presentation of these models could be clarified further."},{"sentence_type":"2","sentence":"The description of the LIF-LSTM is even more obscure, nothing is defined.","rephrased":"The description of the LIF-LSTM model requires more detailed definitions to be understood."},{"sentence_type":"2","sentence":"In addition, the experiments are not convincing.","rephrased":"Additionally, the experiments could be strengthened to better support the findings."},{"sentence_type":"2","sentence":"For all these reasons, I recommend rejection.","rephrased":"Due to the issues mentioned, I would suggest a revision before considering acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[728,790,"Maybe"],[1094,1167,"Confirmed"],[1336,1384,"Maybe"],[1601,1646,"Not concerning"]],"Comments":[]}
{"id":"B3vgD1nt4x5","text":"\nThis paper studies the interestedness of fonts through a user-based experimental framework. \n \nUnfortunately, even if one agrees to the existence of the concept of interestingness of fonts, which I personally do not really submit to, there are major problems with the methodology.\n\nFirst, the user studies. The choice of having user queries with one and two fonts is not explained properly and to me does not make sense. \n\nSecond, if the problem is determining the most interesting font, this requires only analyzing the user study, I do not understand very well the learning part. If the idea is to extract some sort of predictor for font interestedness, this part of the paper is very unclear and improperly evaluated. From what I understand, the authors use all 100 fonts in the training data so it is not clear how the validation was performed, Section 5 is very unclear to me, Many details are very unclear, including basic things like the architecture in Figure 3.\n\nThe authors list 3 contributions:\n\n1) the first to study the problem of font interestingness --> ok, not sure I understand why this is a contribution\n\n2) We collect data of font interestingness in two different ways --> both ways are pretty trivial and not explained properly\n\n3) We compute font interestingness scores and show that the concept of font interestingness can be learned. This part is unclear and the methodology appears to have major flaws starting with the fact that there seems to be no testing data applied outside of the training data.\n\nFurthermore, I do not understand the application section - both applications presented are not clear at all.\n","sentences":[{"sentence_type":"2","sentence":"Unfortunately, even if one agrees to the existence of the concept of interestingness of fonts, which I personally do not really submit to, there are major problems with the methodology.","rephrased":"While the concept of font interestingness may be subject to debate, I believe there are significant issues with the methodology that need to be addressed."},{"sentence_type":"2","sentence":"The choice of having user queries with one and two fonts is not explained properly and to me does not make sense.","rephrased":"The rationale for using user queries with one and two fonts could be better explained to clarify its relevance to the study."},{"sentence_type":"2","sentence":"ok, not sure I understand why this is a contribution","rephrased":"It would be helpful if the authors could further clarify why they consider this a contribution to the field."},{"sentence_type":"2","sentence":"both ways are pretty trivial and not explained properly","rephrased":"The methods of data collection could be elaborated upon to demonstrate their significance and non-trivial nature."},{"sentence_type":"2","sentence":"This part is unclear and the methodology appears to have major flaws starting with the fact that there seems to be no testing data applied outside of the training data.","rephrased":"Clarification is needed on the methodology, particularly regarding the use of testing data separate from the training data to validate the findings."},{"sentence_type":"2","sentence":"Furthermore, I do not understand the application section - both applications presented are not clear at all.","rephrased":"The application section would benefit from additional clarity and detail to understand the practical implications of the research."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[96,281,"Confirmed"],[308,421,"Maybe"],[583,721,"Missed by Model"],[1070,1122,"Confirmed"],[1193,1248,"Confirmed"],[1358,1526,"Maybe"],[1528,1636,"Confirmed"]],"Comments":[]}
{"id":"_-cQFtPWVXG","text":"The authors address an important problem and come up with an interesting algorithm. They also provide a rigorous theoretical convergence analysis as well as many insights on their CUDA implementation. The performance of the proposed method is competitive with Sinkhorn.\n\nUnfortunately this paper also has some major limitations. The biggest one lies in its rather modest set of experiments. Some fundamentally important experiments are missing to support the claims of the paper.\n\n1. Implementation is presented as a core contribution of this paper: it is mentioned in the title, and in addition, it is devoted a substantial amount of space for presentation (almost 3 pages, a part of Section 3.1 and especially the whole Section 3.3). Therefore, it would be absolutely necessary to show that the presented materials are important by actually comparing the provided implementation (with highly-optimized CUDA kernels) with a naive implementation, e.g., using GPU linear algebra libraries such as PyTorch or TensorFlow. The proposed method (Algorithm 1) can be easily implemented using these libraries in just a few lines.\n\n2. The color transfer experiment is weird. Why aren't the results of Sinkhorn presented? Moreover, if sparsity is considered as an important objective, then the authors should also compare with Blondel et al. (2018). I would suggest to consider a more diverse set of examples to showcase the performance of DR in comparison with Sinkhorn (see also the next point).\n\n3. Sinkhorn has been highly successful not only because of its efficiency, but also because its updates are differentiable, which makes it suitable for learning with stochastic gradient descent. While the updates of Algorithm 1 are also differentiable almost everywhere, it is unclear how this algorithm performs in learning, compared to Sinkhorn. I would encourage the authors to add some learning experiments to make the paper even more solid.\n\n\nFinally, this paper also has some presentation issues.\n\n1. Major issues:\n\n- I wonder why the authors decided to denote 1_n as \"e\" and 1_m as \"f\". The notation \"f\" is used at multiple locations with different meanings (while the \"e\" can be confused with the Euler's number, though this is less critical than the \"f\"). It would be laborious to change because this is used everywhere, so I would suggest (as an acceptable fix) to replace the other instances of \"f\" with \"h\", e.g., \"h(x) + g(x)\" instead of \"f(x) + g(x)\".\n\n- In Figure 1 and 2, the descriptions of the axes should be clear from the captions (instead of being hidden in the text). Furthermore, the text in the plots (such as axis labels, markers, legends) are unreadable (too small).\n\n- Figure 3b shows that Sinkhorn is actually faster to reach a given accuracy (even though it is less numerically stable). This would deserve some comments (in a fair comparison of two methods, we should present both strengths and weaknesses of both methods).\n\n2. Minor issues:\n\n- Page 2, last paragraph of Section 1.1: \"Liang et al. (2017), derived\" --> \"Liang et al. (2017) derived\"\n\n- Page 2, line -5: \"methods(Rockafellar, 1976)\" --> \"methods (Rockafellar, 1976)\"\n\n- Section 2 2nd paragraph: \n\t- \"computed as Bauschke et al. (2021):\"  --> \"computed as (Bauschke et al., 2021):\"\n\t- \"linear program on the form\" --> \"linear program of the form\"\n\n- Page 3 last paragraph: \"problems on the form\" --> \"problems of the form\"\n\n- Section 3, 2nd paragraph: \"and fact that\" --> \"and the fact that\"\n\n- The notation for indicator function in Eq. (7) should be defined.\n\n- Page 5 first paragraph: \"matrix-vector multiples\" --> \"matrix-vector multiplications\"\n\n- Page 8 last paragraph: \"A algorithm\" --> \"An algorithm\"\n\n---\n**Update on November 10th:**\n\nI would like to have some additional comments\/questions. Hopefully the authors could address them as well in their rebuttal:\n\n1. There seems to be a minor (likely fixable) **flaw** in Theorem 1 and the discussion thereafter. The inequality \n\\begin{equation}\n\\langle C,\\bar{X}\\_k \\rangle - \\langle C,X^* \\rangle \\le \\mathcal{O}(\\|Y\\_0-Y^*\\|^2\/k)\\qquad (\\star)\n\\end{equation}\n\nis **not sufficient** to yield the convergence of the objective (let alone its rate). Note that **$\\bar{X}_k$ might not be feasible** and thus $\\langle C,\\bar{X}\\_k \\rangle - \\langle C,X^* \\rangle$ might be negative. In order to obtain the convergence of the objective, one would need a lower bound as well:\n\\begin{equation}\n\\alpha_k \\le \\langle C,\\bar{X}\\_k \\rangle - \\langle C,X^* \\rangle \\le \\mathcal{O}(\\|Y\\_0-Y^*\\|^2\/k),\\qquad (\\star\\star)\n\\end{equation}\nwhere $\\alpha_k\\to 0$. Furthermore, in order to obtain the claimed $\\mathcal{O}(1\/k)$ rate of convergence, one would also need to show that $(\\alpha_k)$ converges to $0$ at the same rate.\n\n2. The authors mentioned that they use the Sinkhorn implementation from POT. It is important to provide enough details so that the interested reader could reproduce the results. For example, which function of POT did the authors use and with which arguments? (ot.sinkhorn has quite several options for its arguments.)","sentences":[{"sentence_type":"2","sentence":"The color transfer experiment is weird.","rephrased":"The choice of color transfer experiment could be better justified, and it would be beneficial to include the results of Sinkhorn for a more comprehensive comparison."},{"sentence_type":"1","sentence":"Finally, this paper also has some presentation issues.","rephrased":"Additionally, there are some aspects of the paper's presentation that could be improved."},{"sentence_type":"2","sentence":"There seems to be a minor (likely fixable) **flaw** in Theorem 1 and the discussion thereafter.","rephrased":"There appears to be a minor issue in Theorem 1 that could likely be addressed, which would also enhance the subsequent discussion."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1126,1165,"Not concerning"],[1937,1991,"Not concerning"],[3855,3950,"Not concerning"]],"Comments":[]}
{"id":"9tx-1rgzM4","text":"This paper presents a large benchmark of machine learning tasks for molecules represented by the 3D coordinates of their atoms. The benchmark is a combination of existing data sets and newly created ones, and covers a variety of applications and tasks, from small molecules to RNA or protein structures, and including classification, regression and ranking tasks. In addition, three deep-learning algorithms are implemented and evaluated on these benchmarks, and compared to state-of-the-art methods that do not use 3D information, and empirically demonstrate the benefit of incorporating 3D information in the networks.\n\nThe vast majority of machine learning methods that have been developed for molecules use either 1D or 2D information. Therefore, this resource and the empirical demonstration that using 3D information can improve performance can be very valuable to the community. However, I have a number of concerns about this paper:\n\n1. I am assuming this has not been incorporated to the paper for anonymization reasons, but could the authors confirm that they are indeed planning to make both the data sets and the code used to produce the results (in particular, the three proposed neural networks architecture) available? This is obviously essential to the paper and I would feel more comfortable accepting a version of the paper that includes this information (possibly with URLs withdrawn if there is a concern about maintaining the review process blind).\n\n2. The paper does not discuss the nature of the 3D information further than \"By representing a molecule's atoms and their 3D positions\". However, molecules do not have a fixed 3D structure, but rather multiple conformations driven in particular by rotatable bonds. Determining the multiple possible conformations of drug-like molecules is still an ongoing research topic (see for example the review of Hawkins (2017)), not to mention the determination of the 3D structure of proteins, which is indeed the topic of one of the data sets provided. What information is provided in the different data sets (a single conformation? multiple conformations?) and how does this affect both algorithms (if several conformations are used) and prediction performance? \n\n3. I would really refrain from using \"atomistic learning\" to describe what the community has been referring to as \"learning from 3D molecular representations\" for decades. \n\nActually, the abstract (and, more generally, the paper) reads as if neural networks were the only kind of machine learning algorithms that could be applied to molecules and that very little work has been done in the past to incorporate 3D information in chemoinformatics. While it is true that most current techniques rely mostly on 2D (for small molecules) or 1D (for large molecules) representations, it is not for lack of trying to incorporate 3D information, but because 1) this information was either lacking or incomplete (in the sense that a single conformation gives somewhat limited information; for example, you may have the crystal structure of a protein, but that doesn't inform you directly on the pose of its pocket when binding a specific small molecule) and 2) earlier attempts at making use of 3D information have often found that it did not improve performance (see Swamidass et al. (2005) or Azencott et al. (2007)), either because of the aforementioned incompleteness or because the methods were not up to par. The framing of the paper ignores decades of work in chemoinformatics, in particular (but not limited to) around kernel methods. I am listing a few examples of such papers below, not because I think they should all be included in this paper, but because in my opinion the paper would benefit from considering this body of work.\n\nIn addition, although some authors have already used \"atomistic machine learning\" in the context of chemoinformatics (see Schütt et al. (2018)), the term \"atomistic learning\" is already often used in opposition to \"holistic learning\" in education.\n\n4. Finally, in Section 4, the paper could benefit from stating very explicitly what is novel and what is not novel in the three proposed 3D architectures.\n\nAxen, Seth D., et al. \"A simple representation of three-dimensional molecular structure.\" Journal of medicinal chemistry 60.17 (2017): 7393-7409.\n\nAzencott, C.-A., et al. \"One-to four-dimensional kernels for virtual screening and the prediction of physical, chemical, and biological properties.\" Journal of chemical information and modeling 47.3 (2007): 965-974.\n\nGaüzere, B., Brun, L., and Villemin D,. \"Two new graphs kernels in chemoinformatics.\" Pattern Recognition Letters 33.15 (2012): 2038-2047.\n\nHawkins, Paul C. D. \"Conformation generation: the state of the art.\" Journal of Chemical Information and Modeling 57.8 (2017): 1747-1756.\n\nMahé, P., et al. \"Graph kernels for molecular structure− activity relationship analysis with support vector machines.\" Journal of chemical information and modeling 45.4 (2005): 939-951.\n\nMohr, J. A., Jain, B. J., and Obermayer, K. \"Molecule kernels: a descriptor-and alignment-free quantitative structure–activity relationship approach.\" Journal of chemical information and modeling 48.9 (2008): 1868-1881.\n\nNettles, J. H. et al. Bridging chemical and biological space: “target fishing” using 2D and 3D molecular descriptors. J. Medicinal Chem. 49, 6802–6810 (2006).\n\nRhodes, N., Clark, D. E. & Willett, P. Similarity searching in databases of flexible 3d structures using autocorrelation vectors derived from smoothed bounded distance matrices. J. Chem. Info. Mod. 46, 615–619 (2006).\n\nSchütt, K. T. et al. SchNet - a deep learning architecture for molecules and materials. The Journal of Chemical Physics 148(24), 241722 (2018)\n\nSwamidass, S. J., et al. \"Kernels for small molecules and the prediction of mutagenicity, toxicity and anti-cancer activity.\" Bioinformatics 21.suppl_1 (2005): i359-i368.","sentences":[{"sentence_type":"2","sentence":"I would really refrain from using \"atomistic learning\" to describe what the community has been referring to as \"learning from 3D molecular representations\" for decades.","rephrased":"I suggest reconsidering the term \"atomistic learning\" as the community has traditionally used \"learning from 3D molecular representations\" for many years."},{"sentence_type":"2","sentence":"Actually, the abstract (and, more generally, the paper) reads as if neural networks were the only kind of machine learning algorithms that could be applied to molecules and that very little work has been done in the past to incorporate 3D information in chemoinformatics.","rephrased":"The abstract, and to some extent the paper, could give the impression that neural networks are the sole machine learning algorithms applicable to molecular data, which might overlook the extensive prior work on incorporating 3D information in chemoinformatics."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2231,2399,"Not concerning"],[2402,2673,"Not concerning"]],"Comments":[]}
{"id":"jrSACmLdWfF","text":"=== Strengnth ===\n1. The paper is mostly well-motivated, well-written, and very easy to read.\n\n2. The question raised by the authors in Section 1 is interesting. The experiments and metrics in Section 3 are inspiring and well-designed. They point out one direction for future research.\n\n3. Overall, I think the direction the authors proposed to approach imbalanced classification is quite interesting. Generative models have not been widely used in this task. The authors also make \"accurate\" claims: the proposed method is mainly to deal with task\/dataset-specific (but class-agnostic) variation.\n\n=== Weakness ===\n1. The technical part of the paper (GIT) is not well-written, described, and justified. The authors only simply mentioned that they apply MUNIT but didn't have more discussion or provide formulations. For example, why is MUNIT the appropriate method to be used? Why can we learn anything meaningful (i.e., the class-agnostic variance) by turning MUNIT to learn the mapping between the \"same\" domains? Are there related works that learn to change the input image (e.g., style transfer) and can be applied here? Finally, the authors should have mentioned in section 1 that the generative model is conditioned on the input image. \n\n2. The experimental results are not enough. The authors only use small-scale datasets, but not large-scale ones like iNaturalist or mini\/tiny-imagenet. The smaller improvement on CIFAR than on characters\/traffic signs also raises a question --- could the proposed method be applied to natural, more complicated images\/objects? Besides, the authors only compare to CB, LDAM, RS\/RW, which are a bit outdated (though they are proposed in 2019). Finally, the proposed method seems to be not stable (according to Table 5).\n\n3. As the authors argue that the proposed method is not merely data augmentation, I would like the authors to empirically compare it to existing sophisticated data augmentation methods, e.g., Zoph. et al. Rethinking Pre-training and Self-training, NeurIPS 2020.\n\n4. From the paper description and the qualitative results (Fig 2 and Fig 4), it seems that the proposed method can only make the class-agnostic background, color, lighting, and dilation\/erosion changes. However, in many large-scale datasets, there exists class-specific or semantically-related variation: for example, the appearance changes of cats might be similar to lions than to buses. Also, in many large-scale datasets, many tail classes seem to suffer from insufficient observations of their appearance changes (like from different viewpoints, insufficient instances (e.g., bag\/airplane styles)). These can be found in Fig 7. It seems that the proposed method cannot effectively resolve these variances (see Fig 4). \n\n5. Some highly relevant works are missing (not cited and discussed). \n\nTransferring data variance from many-shot to few-shot data (e.g., to generate more data)\n\n[a] B. Hariharan et al. Low-shot visual recognition by shrinking and hallucinating features. In ICCV, 2017\n\n[b] X. Yin et al. Feature transfer learning for face recognition with under-represented data. In CVPR, 2019\n\n[c] Y. Wang. Low-Shot Learning from Imaginary Data. In CVPR, 2018\n\nLearning class-agnostic information\n\n[d] Y. Yang. Rethinking the Value of Labels for Improving Class-Imbalanced Learning, NeurIPS, 2020\n\nStyle transfer or image-to-image translation should be discussed in related works.\n\nFinally, based on the proposed method, I was wondering if the method proposed by Mariani et al. (2018) is applicable. If so, it should be compared.\n\n=== Minor weakness\/questions ===\n1. The paper could cite and reference more existing works. For example, in Section 1, there are insufficient references (which dataset, which augmentation method?). \n\n2. When DR or DS is used, do the authors only apply the proposed augmentation to the final learning steps or the whole learning steps? As the proposed method does not simply over-or under-sample the examples in the original dataset, I think it could be applied to the entire learning process.","sentences":[{"sentence_type":"2","sentence":"The technical part of the paper (GIT) is not well-written, described, and justified.","rephrased":"The technical part of the paper (GIT) could benefit from a more detailed explanation, clearer descriptions, and stronger justification."},{"sentence_type":"2","sentence":"The experimental results are not enough.","rephrased":"The experimental results could be strengthened by including additional datasets, such as large-scale ones like iNaturalist or mini\/tiny-imagenet."},{"sentence_type":"2","sentence":"Finally, the proposed method seems to be not stable (according to Table 5).","rephrased":"The stability of the proposed method could be further investigated, as suggested by the results in Table 5."},{"sentence_type":"1","sentence":"Some highly relevant works are missing (not cited and discussed).","rephrased":"The paper would benefit from discussing and citing additional relevant works, such as..."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[619,703,"Confirmed"],[1248,1288,"Maybe"],[1687,1762,"Not concerning"],[2755,2820,"Not concerning"]],"Comments":[]}
{"id":"BkgNNh1dFE","text":"The authors provides a training paradigm to leverage \"weak supervision\" signal via a reference set, which they demonstrate empirically to be effective in regularizing the target factors to encode certain features of interests. This line of work seems quite similar in nature to [1,2,3], who propose to regularize the shared features instead of enforcing them to be a constant. \n\n\nPros: \n`1. to address the over-regularization problem in traditional VI, the author proposed to use the symmetrized KL loss to encourage the model to make use of the target factor, which is shown to be effective by their experiment. \n2. the authors have demonstrated the effectiveness of using a reference set to disentangle target factors from common factors. (see point 2 of Cons)\n\nCons: \n1. the author proposed to use adversarial training to minimize the two KL divergences, but a justification of the necessity of this method is not provided. \n2. it is not clear how forcing the target factor of a reference set to be a constant among all data points within the set can help with disentanglement in general. It seems to me to be a heuristic that providing some sort of \"weak supervision\" will impose some structure in the space of target factor, but I'm not sure to what extent this is effective; e.g. whether certain features will be discarded by \"e\" and be encoded by \"z\", or the other way around. Also, have you tried to (1) vary the size of the reference set, e.g. making it smaller, or (2) using multiple reference targets, e.g. with more shared features. \n\nIn general, this is an interesting direction. But I'd like to see some intuitive explanation of how this specific regularization help with \"disentanglement\", which is claimed by the authors. \n\n\n[1] Unsupervised Learning of Disentangled and Interpretable Representations from Sequential Data\n[2] Inferring Identity Factors for Grouped Examples\n[3] Disentangled Sequential Autoencoder","sentences":[{"sentence_type":"2","sentence":"It seems to me to be a heuristic that providing some sort of \"weak supervision\" will impose some structure in the space of target factor, but I'm not sure to what extent this is effective;","rephrased":"The use of \"weak supervision\" as a heuristic to impose structure in the space of target factor is an interesting approach, though it would be beneficial to have a clearer understanding of its effectiveness."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1092,1280,"Not concerning"]],"Comments":[]}
{"id":"HygkmNAPKV","text":"Paper Summary:\nThe authors present a method by which a denoising network can be trained using only examples of single noisy images.  The technique relies on idea of blind-spot networks, where the center pixel is eliminated from the receptive field, and reasonably strong statistical assumptions about the noise profile.  The authors define a network architecture based on a directional CNN applied to four rotations of the same image, with the receptive field of each restricted to a half-plane (just excluding the center row\/column), which is then combined via a set of 1-D convolutions.  The network is then optimized to learn the parameters of a multivariate Gaussian distribution describing the mean and covariance matrix characterizing each pixel value.  Using the assumption of additive Gaussian noise that is IID between the pixels, these parameters are used in a MAP estimation procedure at test time to arrive at the denoised value.  Empirical performance on several datasets appears promising.\n\nQuality (Pros):\nThe technical content of the paper represents an interesting approach to the denoising problem, which draws heavy inspiration from the recent Noise2Void technique.  Proposed improvements over this previous technique include (1) a more efficiently trainable network architecture (2) utilization of a Bayesian modeling approach and (3) integration of information from the center pixel at test time.  The network architecture itself is adequately described in Section 2, and the design choices seem reasonable.  Given the length requirements of the paper, it is reasonable that ablations were not performed on network design, but the lack of quantitative training efficiency comparisons to the Noise2Void technique limits this aspect of the contribution.  The Bayesian training approach seems a natural fit for this type of denoising problem, where the noise in an image is characterized by a probability distribution that is local to the pixel in question; of course, the assumption the the noise is additive, Gaussian, and IID amongst pixels is strong, but the relatively straightforward MAP estimation procedure these assumptions enable is a strength of the proposed approach.  Finally, integration of integration from the center pixel at test time, but not train time, is an important result of this modeling approach.\n\nOverall, the paper presents an interesting technique that contains several distinct improvements over previous approaches, and acknowledges that these are applicable only under strong statistical assumptions.  The performance experiments appear well-posed to assess how the proposed technique compares to appropriate baselines (Noise2Void, Noise2Noise, Noise2Clean), but comparison to the most similar baseline (Noise2Void) is only presented for one dataset.  Though these results appear compelling, the paper could be improved by adding the Noise2Void numbers for other tested datasets.\n\nClarity\nThe paper is clearly written, and at an appropriate level of detail.\n\nSignificance\nIn addition to suggesting the potential for improved image denoising results using only single noisy images for training, this paper presents an interesting application of Bayesian modeling approaches for denoising that may inspire future work that yields similar results without the strong statistical assumptions currently imposed on the noise distribution.\n\nLimitations (Cons)\nCurrent limitations of this work are as follows:\n(1) Lack of experiments quantitatively demonstrating training efficiency relative to Noise2Void\n(2) Lack of experiments demonstrating comparison to Noise2Void on any dataset but BSD68\n(3) No description of the various datasets in Table 1 is given; this would be helpful\n(4) Strong statistical assumptions required on the noise distributions -- to be clear, this is less a limitation of the authors’ analysis, but rather of the setting they chose to analyze; in particular, the assumption that all images are characterized by additive Gaussian noise with the same standard deviation, and that this standard deviation is known, may be limiting in practice\n(5) It would be instructive to demonstrate how performance of this method compares to others if statistical assumptions on the noise distribution are violated.\n","sentences":[{"sentence_type":"2","sentence":"Given the length requirements of the paper, it is reasonable that ablations were not performed on network design, but the lack of quantitative training efficiency comparisons to the Noise2Void technique limits this aspect of the contribution.","rephrased":"While the paper's length constraints understandably preclude extensive ablations on network design, including some quantitative comparisons on training efficiency relative to the Noise2Void technique could enhance the contribution."},{"sentence_type":"1","sentence":"The Bayesian training approach seems a natural fit for this type of denoising problem, where the noise in an image is characterized by a probability distribution that is local to the pixel in question; of course, the assumption the the noise is additive, Gaussian, and IID amongst pixels is strong, but the relatively straightforward MAP estimation procedure these assumptions enable is a strength of the proposed approach.","rephrased":"The Bayesian training approach is well-suited for this denoising problem, as it leverages the local probability distribution of noise per pixel. While the assumption of additive, Gaussian, IID noise is significant, it facilitates a straightforward MAP estimation procedure, which is a notable strength of the proposed method."},{"sentence_type":"2","sentence":"Strong statistical assumptions required on the noise distributions -- to be clear, this is less a limitation of the authors’ analysis, but rather of the setting they chose to analyze; in particular, the assumption that all images are characterized by additive Gaussian noise with the same standard deviation, and that this standard deviation is known, may be limiting in practice","rephrased":"The requirement for strong statistical assumptions on the noise distributions is a consideration for practical applications. While this reflects the chosen analytical setting more than the authors' analysis, future work could explore the implications of varying noise characteristics, such as different standard deviations, to broaden the method's applicability."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1530,1772,"Not concerning"],[1774,2197,"Not concerning"],[3725,4104,"Not concerning"]],"Comments":[]}
{"id":"rkgHD5LntS","text":"This paper proposes to use an extra feature (grammatical number) for context-aware coreference resolution and an attention-based weighting mechanism. The approach proposed is built on top of a recent well performing model by Lee et al. The improvement is rather minor in my view: 72.64 to 72.84 in the test set. \n\nThere is not much in the paper to review. I don't think the one extra feature warrants a paper at a top conference. The weighting mechanism over the features is also unclear to me why it benefits from attention. Couldn't we just learn the weights using another layer? It could be context dependent if desired.\n\nIt is also incorrect to criticise Lee et al. (2018) that they would give the same representation to the same mention every time. Their model is context dependent as they use a BiLSTM over the sentence. Of course the same mentions are likely to get similar representations, but this is desirable.","sentences":[{"sentence_type":"2","sentence":"There is not much in the paper to review.","rephrased":"The paper could benefit from a more extensive discussion of its contributions and methodology."},{"sentence_type":"3","sentence":"I don't think the one extra feature warrants a paper at a top conference.","rephrased":"The significance of the additional feature might need to be further justified to meet the high standards of a top conference."},{"sentence_type":"1","sentence":"It is also incorrect to criticise Lee et al. (2018) that they would give the same representation to the same mention every time.","rephrased":"It may be a misunderstanding to suggest that Lee et al. (2018) give the same representation to the same mention every time, considering their use of a BiLSTM over the sentence."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[314,355,"Confirmed"],[356,429,"Confirmed"],[625,753,"Not concerning"]],"Comments":[]}
{"id":"T8BWROQ0q-","text":"In this paper, it is proposed to have a new problem setting of \"unsupervised feature learning\", which as claimed, is supposed to be different from standard continual learning settings. In this proposed setting, a data point can be seen only once by a model for training. I think, this is too strict a condition, as it is reasonable for a model to keep a data point in memory for a short while so as to use it for training across multiple epochs. In the experimental setup, neural baselines are trained only for a \"single\" epoch, in consideration of the proposed problem setting, which doesn't make sense for all practical purposes as neural models need a decent number of epochs for training. Furthermore, the final classifier used after learning the unsupervised representations is k-NN which is again unrealistic in the context of continual learning literature, especially in the context of neural baselines. All of this is justified for accommodating the  proposed problem setting which is itself not well motivated. \n\nThe proposed model for the introduced problem setting is more of an engineering approach, relying upon some basic techniques such as clustering, novelty detection. There is no clear motivation for the learning algorithm, it is not clear how the model is optimized wholistically. It is more of a heuristic driven approach. The model is claimed to be brain-inspired; for instance there is a component in the proposed model which has a \"hierarchy of increasing receptive fields\", which is nothing but CNN-like neural net.  \n\nFor experiments, I have the following suggestions.\n(1) In Fig. 3, x-label should be changed to something more appropriate, number of new classes introduced.\n(2) Results are good for MNIST dataset primarily.\n(3) Any other evaluation metrics besides accuracy? Accuracy can be misleading for multi-class scenario. \n(4) Report accuracies separately for new classes introduced and the old classes.\n(5) It needs to be clarified exactly what \"class boundary information\" the baseline methods have access to.\n(6) Only 10 new classes introduced from the 5 phases, what about the datasets with a large number of classes?","sentences":[{"sentence_type":"1","sentence":"I think, this is too strict a condition, as it is reasonable for a model to keep a data point in memory for a short while so as to use it for training across multiple epochs.","rephrased":"While the condition that a data point can only be seen once by a model for training is quite stringent, it might be worth considering scenarios where retaining a data point for a brief period could be beneficial for training across multiple epochs."},{"sentence_type":"2","sentence":"which doesn't make sense for all practical purposes as neural models need a decent number of epochs for training.","rephrased":"It may be helpful to reconsider the training duration, as neural models typically require multiple epochs to achieve optimal performance."},{"sentence_type":"3","sentence":"All of this is justified for accommodating the proposed problem setting which is itself not well motivated.","rephrased":"The justification for the proposed problem setting could be strengthened with a clearer motivation and rationale."},{"sentence_type":"2","sentence":"There is no clear motivation for the learning algorithm, it is not clear how the model is optimized wholistically.","rephrased":"Providing a clear motivation for the learning algorithm and explaining how the model is optimized holistically would be beneficial."},{"sentence_type":"1","sentence":"It is more of a heuristic driven approach.","rephrased":"The approach seems to be driven by heuristics, which could be further elaborated upon to understand the underlying principles."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[271,445,"Not concerning"],[579,692,"Not concerning"],[1186,1300,"Maybe"],[1301,1343,"Not concerning"]],"Comments":[]}
{"id":"SJg2znvb5H","text":"This paper proposed an auxiliary loss based on mutual information for graph neural network. Such loss is to maximize the mutual information between edge representation and corresponding edge feature in GNN ‘message passing’ function. By assuming a gaussian distribution of edge feature given edge representation, the training can be done efficiently with tractable density. Experiments on molecule regression and knowledge graph completion show better performance than MPNN. \n\nOverall the paper is written in a clear way which is easy to follow. The idea of using mutual information as some kind of regularization is also interesting. However, there are some concerns I have with the paper:\n\nRegarding formulation\n\n1. The derivation up to Eq(8) looks fine to me, where the assumptions are reasonable. However from Eq(8) one can see this is reduced to an ‘auto-encoder’ type of regularization, where one can have a trivial solution for reconstruction -- the identity network, when the hidden dimension is larger than input dimension. And in this paper, dimension of W should always be larger than the dimension of e (for example, in molecules e should be low dimension vector with the bond type, distance, etc., while W should have dimension that matches the node embeddings).\n\nI think the original loss (i.e., the supervised MSE, cross entropy etc) would help a bit with such degenerated case, but it is possible that the learned f(e) contains both identity mapping (or equivalent) and the representation that contributes to original loss.  \n\n2. Actually I’m also not sure if I get the motivation here. If one needs to do this regularization for edges, why don’t we consider this auxiliary loss for node embeddings as well? As in molecules, atoms have more interesting features than bonds, which should account more if the mutual information loss is needed. \n\nRegarding experiment\n\n1. In Figure 1, the training loss of EIGNN is better than MPNN. This is a bit counterintuitive to me, as I think the auxiliary is a kind of regularization -- which might help with generalization but not necessarily the training loss. \n\n2. The original paper of MPNN reports the relative MAE. Is it possible to report the results using the same metric as previous paper? It would make the comparison more consistent -- though showing the improvement in current way is not too bad. \n\n3. I think one simple ablation study would to concat the edge feature directly inside the ‘message passing’ procedure, or have some ‘residual’ type of connection for edge features. \n","sentences":[{"sentence_type":"1","sentence":"This is a bit counterintuitive to me, as I think the auxiliary is a kind of regularization -- which might help with generalization but not necessarily the training loss.","rephrased":"While the auxiliary loss is typically seen as a form of regularization that may improve generalization, it's interesting to note that it also appears to have a positive impact on the training loss in Figure 1, which could be worth exploring further."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1946,2115,"Not concerning"]],"Comments":[]}
{"id":"O-wM94CC6s0","text":"\nThis paper aims to learn lightweight models from the bigGAN teacher using knowledge distillation (KL loss at both pixel\/feature levels). The Introduction, Related work, and Approach are easy to follow and well explained. \n\nUnfortunately, I find the exp part poorly written, making it extremely hard to understand: does the result support the claim? I lost track completely there. The same also happens in the appendix. Please add concrete conclusions or take-aways for each figure and re-write the exp part.\n\nDespite the fact the task\/problem addressed in the paper is both theoretically and practically meaningful, I would still recommend 'reject' given the flaws in the writing, especially the exp part. \n\n\n\nFig 1: left: are the modules in blue non-trainable? right: are the tinyGANs trainable during inference? Or there is a mistake in legend?\nline 223: Abuse of notation: \"S\" refers to the student model in eq2, while in eq4 it is defined as the generator\n\nline 344: what is the take-away from fig 2. I do not see a conclusion? It seems the SKDCGN generates less impressive results than the CGN.\n\n\nline 351: \"We realize that the student is as good as the teacher.\" where does this conclusion come from?\n\nline 356\/358: Grammarly incorrect. I do not follow these claims. It seems this part (exp 4.4) is not in a good shape as a submission.\n\nAppendix B2\/B3: It is unclear what the takeaways are in the figures? I find it hard to interpret\n\nappendix: line 226\/227 typos. ","sentences":[{"sentence_type":"2","sentence":"Unfortunately, I find the exp part poorly written, making it extremely hard to understand: does the result support the claim? I lost track completely there.","rephrased":"The explanation in the experimental section could be clearer to better understand how the results support the claims. It would be helpful to maintain a clearer narrative throughout this section."},{"sentence_type":"2","sentence":"Despite the fact the task\/problem addressed in the paper is both theoretically and practically meaningful, I would still recommend 'reject' given the flaws in the writing, especially the exp part.","rephrased":"Although the paper addresses a theoretically and practically significant problem, I would suggest a revision to address the writing issues, particularly in the experimental section, before considering acceptance."},{"sentence_type":"2","sentence":"line 356\/358: Grammarly incorrect. I do not follow these claims. It seems this part (exp 4.4) is not in a good shape as a submission.","rephrased":"The grammar and clarity in lines 356\/358 could be improved to better convey the claims. The experimental section 4.4 would benefit from further refinement for submission."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[224,380,"Confirmed"],[510,706,"Maybe"],[1209,1342,"Maybe"]],"Comments":[]}
{"id":"CVI9_GSNEc7","text":"This paper presents the casual discovery that integrates the continual learning paradigm in robotics.\nThe paper clearly states why the notion of continual learning in casual discovery could be practically helpful in robotics.\n\nThe research background and paradigm are interesting. However, it is hard to capture how the continual learning method contributes to casual discovery. The paper states the general flow of the casual discovery method with a brief mention that continual learning can overcome the streaming situation and hardware limits. However, this needs to clearly state how the continual learning methods overcome the issue of the aforementioned problem, and how catastrophic forgetting might impact casual discovery. \n\nOverall, the research question and practical settings are adequate and exciting. However, with the current form, it's hard to see the clear impact.","sentences":[{"sentence_type":"1","sentence":"However, it is hard to capture how the continual learning method contributes to casual discovery.","rephrased":"However, it would be beneficial for the paper to more explicitly detail how the continual learning method contributes to causal discovery."},{"sentence_type":"1","sentence":"However, this needs to clearly state how the continual learning methods overcome the issue of the aforementioned problem, and how catastrophic forgetting might impact casual discovery.","rephrased":"The paper could be strengthened by clearly stating how the continual learning methods address the issues mentioned, particularly how they mitigate the effects of catastrophic forgetting on causal discovery."},{"sentence_type":"1","sentence":"However, with the current form, it's hard to see the clear impact.","rephrased":"To enhance the paper's impact, it would be helpful to more clearly articulate the implications and contributions of the research findings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[281,378,"Not concerning"],[547,731,"Not concerning"],[815,881,"Not concerning"]],"Comments":[]}
{"id":"udMWMVHSmtv","text":"**Review summary**\n\nThis paper presents a novel method for test-time adaptation of an RL agent based on training a transformer to model a current belief over abstract, partial world models. The method makes sense, is demonstrated clearly on toy data, and the paper is of a high quality. \n\nDespite the strong assumptions, which limit the method to toy settings for now, I believe that this paper is certainly good enough to be accepted, with one catch: the conference organizers need to decide if this paper is in scope for the workshop, as it is not really about the reincarnation of prior knowledge or computation.\n\n**Paper summary**\n- The authors study the problem of in-context adaptation: solving new tasks with an agent solely based on real-time information, without updating its weights (as in many meta-RL methods, for instance).  \n- They propose a solution based on approximate posterior inference over partial models. Partial models are abstract, simplified MDPs represented as vectors that specify transition and reward models. A transformer is trained to learn a belief over these partial models conditional on past experience on the current task.  \n- To make this problem tractable, the authors make two key assumptions. They focus on problems where 1) training tasks are labeled with the relevant partial model and 2) the states in the partial model directly correspond to actions in the original environment. With these assumptions, training the transformer is a supervised learning problem, and the optimal policy in the reduced MDP can be transferred to the original MDP easily. The challenging problem of how to learn the state and action representations from interactions with the raw environment are not addressed.  \n- At test time, the authors iterate between sampling a partial model from the transformer and finding the optimal policy under this partial model through value iteration.  \n- The method is demonstrated on a toy environment, where it approaches oracle performance.  \n\n**Quality**\n- Within the assumptions, the method is sound.  \n- The demonstration in a toy experiment is convincing.  \n\n**Significance**\n- The paper works on the interesting and relevant problem of test-time adaptation to new tasks.  \n- However, the two key assumptions of 1) partial model labels and 2) a direct correspondence between partial model states and actions in the full MDP limit the impact of this method as is. In its current form, I cannot think of realistic problems that the algorithm could solve (I'd love to hear some examples from the authors if they have any). The authors are transparent about this limitation and I believe that there is still enough interesting content in this paper to make it a good research contribution.  \n- As far as I can tell (I am not an expert), the method is novel.  \n- The fit for the workshop is a little bit less clear. In which sense is the method reusing prior data or computations? I would like to leave it up to the organizers to decide whether this paper is in scope.  \n\n**Clarity**\n- Overall, the paper is very well written.  \n- There are two topics which (in my opinion) deserve some further discussion, see sections below.\n- Visualizaations and plots are of a high quality.  \n- Related work is discussed in depth.  \n\n**Discussion of the in-context adaptation setting**\n- I am curious whether there is a way of defining \"in-context adaptation\" purely through the *behaviour* of the agent, without replying on its inner workings (like whether it performs gradient updates). Can there be a decision rule that just looks at the sequence of states, actions, and rewards that result from the agent-environment interaction, and then outputs whether the agent performs in-context adaptation?  \n- If I understand the intention of the authors correctly, there are two criteria that make for \"in-context adaptation\": the first is the fact that the agent is stateless after the end of training. It cannot share experiences collected at test time except through the explicit conditioning. The second is the fact that the agent is computationally efficient. This forbids gradient updates as part of the decision process and forces the agent to stick to a single forward pass.  \n- If my interpretation is correct, I would politely suggest to the authors to update the description in Section 2 a bit. Currently, they write \"At testing time, models and policies should improve as a function of conditioning on longer contexts\". It is pretty clear what they have in mind. However, being a bit nitpicky, this phrasing does not really rule out agents that perform gradient steps \"internally\" on the context.  \n\n**Discussion of the partial MDPs**\n- The partial MDPs here have a restricted transition model. If I understand correctly, each action corresponds to a single edge (so a single target state in the reduced MDP). There is thus no way for stochastic transitions in which a single action could let the agent end up in multiple different states. Is this correct? If yes, maybe add a discussion about the usefulness of this setting?  \n- Another assumption of the partial MDP is that of binary rewards. This also deserves a bit more discussion.  \n\n**Minor comments and questions**\n- Line 36, right column: In which sense is approximate inference really an antonym to Bayesian inference? To me, this sentence would make more sense if it said \"We use approximate rather than exact Bayesian inference\" and so on  \n- Line 98-99: maybe explicitly add the dependence on the task k to the reward function and transition dynamics?  \n- Line 110: why does the context not include the rewards achieved by the agent?  \n- Line 127: what is this categorical distribution over vertices used for? This is mentioned in Section 4, but would be good to already explain here.","sentences":[{"sentence_type":"2","sentence":"In its current form, I cannot think of realistic problems that the algorithm could solve (I'd love to hear some examples from the authors if they have any).","rephrased":"I would be interested to see examples of realistic problems that the algorithm could address, which would help in understanding its potential applications beyond the toy settings presented."},{"sentence_type":"2","sentence":"The fit for the workshop is a little bit less clear. In which sense is the method reusing prior data or computations? I would like to leave it up to the organizers to decide whether this paper is in scope.","rephrased":"It would be beneficial for the authors to clarify how the method reuses prior data or computations to ensure that it aligns with the workshop's theme. This aspect could be further discussed to strengthen the paper's relevance to the workshop."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[2426,2582,"Not concerning"],[2821,3026,"Not concerning"]],"Comments":[]}
{"id":"hxgft8MTPn","text":"This paper is about improving the boundary of a predicted object in the task of image segmentation. Comparing to other losses, they show that they get on par or slightly better performances. \n\nThe authors propose a novel loss, that uses the Laplacian filter (which can be implemented efficiencly as successive convolution layers), and then minimize the L2-norm of the filtered output and filtered ground truth. Notice that this doesn't require to define the contour on the continuous softmax predictions, which is often difficult or intractable. \n\nThey get very good results on two different datasets. \n\nMany more work and evaluation can be done for that loss, and I am really looking forward to see an more detailed version of this work. But the current form definitely deserve a spot at MIDL2020.\n\nMisc:\n- [Kervadec et al. 2018], is actually a MIDL2019 paper\n","sentences":[{"sentence_type":"1","sentence":"Many more work and evaluation can be done for that loss, and I am really looking forward to see an more detailed version of this work.","rephrased":"Further work and evaluation would enhance the understanding of this loss, and I am eager to see a more detailed version of this work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[604,738,"Not concerning"]],"Comments":[]}
{"id":"t1I5OUDdZqZ","text":"In the first section, the paper motivates the moments penalization by showing that variance penalization leads to tighter confidence intervals (Maurer and Pontil, 2009). In the context of learning, the goal then becomes to find a \n$\\theta \\in \\Theta$ that minimizes the following (focusing on second moments for simplicity):\n$$ E_n [\\ell(X; \\theta)] + \\lambda V_n(\\ell(X; \\theta)), \\qquad \\qquad (1) $$\nwhere $E_n$ and $V_n$ denote empirical mean and covariance respectively of $X \\sim P_n$, the empirical distribution.\nHence the objective is to find a choice of weights $W(X;\\theta)$, that may depend on $\\theta$, so that the following holds:\n$$ E_n[W(X;\\theta) \\ell(X; \\theta)] =  E_n [\\ell(X; \\theta)] + \\lambda V_n(\\ell(X; \\theta)) \\qquad \\qquad (2).$$\n\nTheorem 1 shows that if one chooses $W(X;\\theta) = 1 + \\lambda (\\ell(X;\\theta) - E_n[\\ell(X;\\theta)] )$, then (2) above holds.\n\nAt this point, this result is not useful unless it is easy to minimize $E_n[W(X;\\theta) \\ell(X; \\theta)]$:  as Theorem 1 shows equality with (1), one could have directly tried optimizing (1) above. This is where Lemma 2 comes in (preserving convexity). \n\nHowever, the paper just drops the dependence on $\\theta$ everywhere in the paper: If $W$ were to depend on $\\theta$, which it does, then I do not think Lemma 2 is true, i.e., $E_n[W(X;\\theta) \\ell(X; \\theta)]$ might not be convex in $\\theta$. As $W$ clearly depends on $\\theta$, I do not even understand what Lemma $2$ means when $W$ does not depend on $\\theta$ --- convex in which parameter? I would appreciate if authors can clarify if my arguments are incorrect.\n\nAfter hiding this dependence on $\\theta$, the theoretical results in the paper ---Theorem 1, Lemma 2, Theorem 3 --- become straight-forward.\nEven in the experiments section, as noted on Page 4, Section 2, the operations for computing weights are not part of the computation graph, and it is not clear what Algorithm 1 is minimizing.\n\nIt is possible that Algorithm 1, by detaching weights from the computation graph, is approximately optimizing the desired objective of (1), but I don't see any immediate connection at this moment. Investigating this connection might be a possible research direction for future but it is beyond the scope of the submitted paper. \n\nThough paper claims that it builds and extends the works of Duchi and Namkoong (2019) and Li et al. (2021), this limitation of the present paper is not present there.\n\nI would be happy to increase my scores if my understanding of the results in the paper is flawed, and authors can clarify their contributions.  \n\n\n## Minor Comments\n\n1. Since the goal is to penalize by empirical variance, first section should cite the results from (Maurer and Pontil, 2009) who showed that penalizing from empirical variance also works (instead of true variance as is cited in Equation (1) from Hoeffding's inequality). \n3. Proposition 7 is a basic fact in probability and certainly not attributed to Duchi and Namkoong (2019).\n\n","sentences":[{"sentence_type":"2","sentence":"However, the paper just drops the dependence on \theta everywhere in the paper: If W were to depend on \theta, which it does, then I do not think Lemma 2 is true, i.e., En[W(X;\theta) \theta)] might not be convex in \theta.","rephrased":"The paper seems to overlook the dependence on \theta in various sections. If W is indeed a function of \theta, it would be beneficial to discuss the implications for the convexity of En[W(X;\theta) \theta)], as stated in Lemma 2."},{"sentence_type":"2","sentence":"As W clearly depends on \theta, I do not even understand what Lemma 2 means when W does not depend on \theta --- convex in which parameter?","rephrased":"It would be helpful if the paper could provide further clarification on Lemma 2, particularly on how it applies when W is independent of \theta, and which parameter the convexity refers to."},{"sentence_type":"2","sentence":"After hiding this dependence on \theta, the theoretical results in the paper ---Theorem 1, Lemma 2, Theorem 3 --- become straight-forward.","rephrased":"Clarifying the role of \theta's dependence in the theoretical framework could enhance the depth of Theorems 1, 2, and 3, as their current presentation appears to be straightforward."},{"sentence_type":"2","sentence":"Even in the experiments section, as noted on Page 4, Section 2, the operations for computing weights are not part of the computation graph, and it is not clear what Algorithm 1 is minimizing.","rephrased":"In the experiments section, particularly on Page 4, Section 2, it would be beneficial to explain how the operations for computing weights integrate with the computation graph and to clarify the objective that Algorithm 1 is minimizing."},{"sentence_type":"2","sentence":"Though paper claims that it builds and extends the works of Duchi and Namkoong (2019) and Li et al. (2021), this limitation of the present paper is not present there.","rephrased":"While the paper aims to build upon the works of Duchi and Namkoong (2019) and Li et al. (2021), it would be constructive to address how the current limitations are reconciled with these prior studies."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1141,1383,"Not concerning"],[1608,1748,"Not concerning"],[1749,1940,"Maybe"],[2272,2438,"Maybe"]],"Comments":[]}
{"id":"BkgInDxwtV","text":"This paper introduces the \"Online Partially Rewarded\" setting, which appears to be interesting both from a practical and a theoretical point of view. They then propose two approaches based on GCN, which maintain a similarity graph between observations to help predictions. As Rewarded Online GCN only cannot deal with missclassified observations, the authors propose to combine a multi-armed bandit approach with multiple GCN embedding.\n\nThe resulting algorithm maintains k different embeddings for the whole dataset, which are recomputed at each iteration (new observation t). This seems to be costly: would it be possible to update only a few last observations? As noted by the authors, this prevents them to apply their algorithm to bigger datasets. A discussion on the performance would still be a plus. \n\nThe detail of the algorithm shows that the proposed algorithm does not account for delayed environment response. This seems to be an important limitation, not implied by the OPR setting: at iteration t, the algorithm has to predict y_t and then observes response h_t. If h_t is missing, the corresponding context is set forever, and a late h_t will just be ignored. Recent works in the bandit community propose frameworks which seem to be more general (see e.g. Bandits with Delayed Anonymous Feedback by Pike-Burke et al. or Online Learning under Delayed Feedback by Joulani et al.).\n\nExperiments are conducted on real datasets but with a simulated OPR setting, which is a slight limitation. However, only the two proposed methods and a standard algorithm (LINUCB) of the literature are compared. The results are very encouraging, especially, as noted by the authors, when a natural graph structure is present in the data; but the LINUCB baseline is not adapted to the OPR setting and thus the experiments do not provide enough evidence to back the proposed approach. Here again, I would suggest comparisons with more recent works, such as Variational Thompson Sampling for Relational Recurrent Bandits by Lamprier et al.","sentences":[{"sentence_type":"1","sentence":"This seems to be costly: would it be possible to update only a few last observations?","rephrased":"Considering the computational cost, could the algorithm be modified to update only a subset of the most recent observations?"},{"sentence_type":"2","sentence":"The detail of the algorithm shows that the proposed algorithm does not account for delayed environment response. This seems to be an important limitation, not implied by the OPR setting: at iteration t, the algorithm has to predict y_t and then observes response h_t. If h_t is missing, the corresponding context is set forever, and a late h_t will just be ignored.","rephrased":"The algorithm's current design does not seem to accommodate delayed environment responses, which could be a significant limitation. It would be beneficial to explore how the algorithm could handle situations where the response h_t is delayed or missing at iteration t."},{"sentence_type":"2","sentence":"The results are very encouraging, especially, as noted by the authors, when a natural graph structure is present in the data; but the LINUCB baseline is not adapted to the OPR setting and thus the experiments do not provide enough evidence to back the proposed approach.","rephrased":"While the results are promising, particularly in cases with a natural graph structure, it would be advantageous to compare the proposed approach with additional baselines that are well-suited to the OPR setting to strengthen the evidence supporting the approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[578,663,"Not concerning"],[810,1175,"Not concerning"],[1608,1878,"Not concerning"]],"Comments":[]}
{"id":"rylEwLw6Yr","text":"This paper proposes a complicated NAS approach, with a lot more ops, a larger search space and an extra teacher network. However, the results on CIFAR10 and ImageNet are both not competitive to other SOTA results.\n\nMy major concern is whether the extra complexity introduced by this paper is necessary:\n\n1. The new search space includes a lot more ops and optimizations, which by themselves should improve other models. For example, according to Table1, dynamic conv and attention improve ResNet-18 without any architecture search. What if you simply apply the same optimizations to other SOTA models in Table 2 and 3?\n2. The extra ops already make the comparison in Table 2\/3 unfair. Despite that, NOS is still not competitive to other SOTA results (prroxylessNAS on CIFAR-10 and MnasNet-A3 on ImageNet).\n3. The authors argue that “NOS shows significant compactness advantages than proxylessNAS”, but it is somewhat misleading. By reading this paper, it seems the search algorithm used in this paper aims to find the highest accuracy model WITHOUT resource constraints, so smaller model size should not be related to the search algorithm.\n\nHere are a few other comments and suggestions:\n\n4. Section 3.2 is difficult to follow. I recommend the authors providing some visualization for the search space (see NASNet paper for example).\n5. Ablation study is relatively weak: for example, Figure 5 compares w\/ and w\/o attention-guided search, but it is unclear whether the gain is by the search or by the teacher distillation. A more fair comparison is to w\/o attention-guided search but also perform the distillation. It would be also helpful to verify whether the propose attention-guided search can work for existing  search space (such as the NASNet\/DARTS search space).","sentences":[{"sentence_type":"2","sentence":"However, the results on CIFAR10 and ImageNet are both not competitive to other SOTA results.","rephrased":"However, the results on CIFAR10 and ImageNet could benefit from further improvement to be on par with other SOTA results."},{"sentence_type":"2","sentence":"The extra ops already make the comparison in Table 2\/3 unfair.","rephrased":"The additional operations included may need to be considered more carefully to ensure a fair comparison in Table 2\/3."},{"sentence_type":"2","sentence":"but it is somewhat misleading.","rephrased":"but this point could be clarified to avoid potential misunderstandings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[121,213,"Not concerning"],[622,684,"Not concerning"],[898,928,"Not concerning"]],"Comments":[]}
{"id":"5Y8sB-Z26HA","text":"**Summary**.\nThis paper proposes a new type of models that are equivariant to entity permutations, which is an important criterion to build language models that can easily generalize to new entities. The authors modified a Memory-Network and a Third-order tensor product RNN to make them symbolic-shit invariant. The new models were evaluated and compared on the 20 bAbi tasks. Results show that the symbolic versions of the models yield better performance than the original ones.\n\n**Positives**.\nThe topic is of great interest and it is indeed crutial that neural language models become symbol-shift invariant to allow them to better generalize. This work is clearly motivated.\n\n**Confusions**.\nThe beginning of Section4 mentions that the main idea of this work is to concatenate a regular \"semantic\" word vector with a \"symbolic\" representation essentially corresponding to a one-hot vector of the token order of appearance.\nIn the following paragraphs, the work presented lacks clarity and seems to over-complicate concepts with hard-to-follow math notations. For instance, the “*Mapping words into and from symbolic representations*” paragraph introduces tedious math notations to describes something simple that was clear before, namely, the mapping from tokens to their respective symbolic vector, which is simply defined as the one-hot vector position appearance of this token in the context.\nSimilarly, the \"*Hybrid semantic-symbolic embeddings*\" paragraph uses again tedious math notations to describe how semantic and symbolic embedding are concatenated.\n\nGiven the confusion presented in Section4, it is currently not clear how adding a one-hot vector to the input embedding can make a neural model symbol-shift equivariant.\nIn particular, below are the two things I could not understand:\n1) The paper mentions that \"*all parameters are differentiable*\". It is not clear if that also includes the symbolic representation or not? If so, then the initial one-hot vector may not be a one-hot vector after the gradient updates performed during training, which would result in a non-symbolic representation? if it is kept fix during training, then it is not clear how it is used by the network.\n2) In addition, assuming that the symbolic representation of all tokens stays the same during training, I don't see how \"_permuted symbols share the same latent representations_\" if the latent representations are made of both on-hot vectors **and** regular word vectors. I understand that the symbolic representation does not change for a permuted word since it will appear at the same place as the original word. But the semantic representation will be different. For instance, the semantic word vector of “banana” is similar but still different than the word vector of “apple”.\n\n**Conclusion**.\nI would suggest the authors to simplify their mathematical notation and make their paper easier to read. As of now, I could not fully understand the paper and unfortunately for that reason could only put a score of 4 with a low confidence of 2.","sentences":[{"sentence_type":"2","sentence":"The work presented lacks clarity and seems to over-complicate concepts with hard-to-follow math notations.","rephrased":"The presentation of the work could be clearer, and the math notations might be simplified for better understanding."},{"sentence_type":"2","sentence":"I could not fully understand the paper and unfortunately for that reason could only put a score of 4 with a low confidence of 2.","rephrased":"I found some sections of the paper challenging to understand, which affected my confidence in the review score I could assign."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[927,1062,"Maybe"],[2914,3042,"Not concerning"]],"Comments":[]}
{"id":"RWgiUhPcUSR","text":"**Strengths:**\nThe line of work concerning adversarial weight perturbations is interesting and significant, as it is one of a few locations where the nascent theory of deep networks can provide easy tweaks to training that improve generalization. Identifying a problem with the current approach (even on MLPs) is valuable and significant, and ample evidence is presented to suggest the vanishing gradient problem is actually what is occurring. The proposed solutions are simple and easy to implement. The experimentation is thorough: while the improvements provided by AWP are very minor (less than a percent in some instances), it is yet another easy and cheap trick to ever-so-slightly boost the performance of a network. \n\n**Weaknesses:**\nFirst, while it is an important insight to notice the vanishing gradient, the proposed remedies (weight truncation and weighted AWP) are natural and not particularly novel. These are likely the first things that one would try to mitigate the observed problems with AWP and don't represent a great stride forward in the field. Similarly, it is not particularly surprising that the benefits of AWP as evidenced in MLPs carry over to GNNs: not enough motivation or evidence is presented to make this seem surprising or unexpected. Third, Theorem 1 is trivial. If the definition of Ltrain is to be the one that only performs a single first-order step, then of course the gradient evaluated at a minimum is going to be zero: the interesting question here is how the true AWP loss (eq2) relates to the standard training loss. This theorem doesn't add add anything to the story. \n\n**Questions:**\n- One of my complaints is about the novelty of contribution re: GNNs vs MLPs. Did I miss this, or is there simply a much more pronounced effect of the gradient-vanishing phenomenon in GNNS than MLPs? \n- How much do the gradient norms (with respect to the weights) actually change when training under AWP vs WT-AWP vs standard training?","sentences":[{"sentence_type":"2","sentence":"Third, Theorem 1 is trivial.","rephrased":"Third, Theorem 1 seems to be a straightforward result."},{"sentence_type":"2","sentence":"This theorem doesn't add anything to the story.","rephrased":"It would be beneficial to clarify how this theorem contributes to the overall narrative of the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1270,1298,"Not concerning"]],"Comments":[]}
{"id":"HJlR4udf9E","text":"The paper presents a new metric (FVD) for generative models of video. It basically builds on Frechet Inception Distance (FID) which has been proposed for Images and extends it to sequential data such as videos. It captures both the temporal coherence of the content of the video and the quality of each frame. Authors present a thorough evaluation of this proposed metric and show that it correlates with the qualitative human judgements of generated video.\n\nI am not an expert in this area. Still, I felt that the paper could have been presented in a better way. The new metric FVD is not well motivated. The paper is difficult to read, it is written as a summary, and most of experimental setup and evaluated systems are moved to appendices.  Given that the main paper is presented in only 3 pages (with appendices, it is only 8 pages), I  didn't understand the need of appendix sections. First three pages were not inclusive. If accepted, I would recommend to make the paper inclusive of all the details. \n\n","sentences":[{"sentence_type":"2","sentence":"The new metric FVD is not well motivated.","rephrased":"The motivation behind the new metric FVD could be further strengthened and more clearly articulated."},{"sentence_type":"2","sentence":"The paper is difficult to read, it is written as a summary, and most of experimental setup and evaluated systems are moved to appendices.","rephrased":"Improving the readability of the paper and including more details about the experimental setup and evaluated systems in the main text rather than in appendices could enhance the paper's clarity."},{"sentence_type":"1","sentence":"I didn't understand the need of appendix sections.","rephrased":"The rationale for including certain content in the appendix sections was not immediately clear to me."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[564,605,"Not concerning"],[606,743,"Maybe"]],"Comments":[]}
{"id":"Hyg7XVNUYN","text":"This paper proposes a two-tier machine learning system, combining a generative model and a discriminative model. The discriminative model is an LSTM, and the generative model is a \"label model\", which learns a labeling function based on domain-specific knowledge and empirical observations. The authors report successful experiments on wearable sensor data, which is an interesting and under-studied application domain of representation learning.\n\nThe introduction and discussion of prior literature is well written. However, the paper lacks a precise description of its main contribution, and how this contribution sets it apart from prior literature.\n\nMy other piece of criticism is that the description of the entire system is not summarized by a single diagram or algorithm listing. I had to jump back and forth between pages 2 and 3 to understand what the paper was about. Furthermore, calling the label model a generative model may be confusing to the reader. This choice of terminology may perhaps be appropriate, but in any case, the authors should strive for the maximum level of clarity. In the case of wearable sensor data, it is not clear what the end goal of the LSTM is: is it to predict freezing? Likewise, it is not clear how the label model manages to approximate domain-specific labeling functions.","sentences":[{"sentence_type":"2","sentence":"I had to jump back and forth between pages 2 and 3 to understand what the paper was about.","rephrased":"A single diagram or algorithm listing summarizing the entire system could enhance the paper's clarity and prevent the need to navigate between pages to understand the system."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[787,877,"Not concerning"]],"Comments":[]}
{"id":"Skgso79atr","text":"This paper provides a solution for batch active learning with noisy oracles in deep neural networks. Their algorithm suffers less from the well-known cold-start issue in active learning. They also improve the robustness by adding an extra denoising layer to the network. \n\nThe main concern is that the two contributions are rather orthogonal to each other and each of them is not that significant. \nThe first contribution, which alleviates the cold-start problem, is not very surprising, since it is a soft version of previous method BALD. \nThe second contribution, a de-noising layer, is relatively orthogonal to batch active learning. \n\nIn the experiments, the authors compared Proposed +noise with Proposed, Random, BALD, Coreset, and Entropy, but I think the only fair comparison here is between Proposed+noise and Proposed. \n\n","sentences":[{"sentence_type":"2","sentence":"The main concern is that the two contributions are rather orthogonal to each other and each of them is not that significant.","rephrased":"The main concern is that the two contributions seem to be quite distinct from each other, and it would be beneficial to demonstrate more clearly how each one significantly advances the field."},{"sentence_type":"2","sentence":"The first contribution, which alleviates the cold-start problem, is not very surprising, since it is a soft version of previous method BALD.","rephrased":"The first contribution, addressing the cold-start problem, appears to be an incremental improvement on the existing BALD method, and it would be helpful to highlight the novel aspects more distinctly."},{"sentence_type":"1","sentence":"The second contribution, a de-noising layer, is relatively orthogonal to batch active learning.","rephrased":"The second contribution, introducing a de-noising layer, seems to be somewhat independent of the batch active learning context, and further clarification on how it integrates with the overall framework would be valuable."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[273,397,"Not concerning"],[399,539,"Maybe"],[541,636,"Not concerning"]],"Comments":[]}
{"id":"QnApj9APll","text":"the paper is well-structured ane easy-to-follow, still I think important details are missing:\n- the motivation of using a CPH model instead of other modelling of non-linear variable interactions,\n- evaluation of more realistic cases, as the synthetic task is perhaps too simple\n- statistical significance tests via cross validation\n- some attention-based module to show that lesion localisation really helps the regression","sentences":[{"sentence_type":"1","sentence":"the synthetic task is perhaps too simple","rephrased":"considering more complex or realistic scenarios could enhance the applicability of the results"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[237,277,"Not concerning"]],"Comments":[]}
{"id":"SkeIzMP427","text":"Proposal to use polar regression for prediction problems. To do so, one maps the target variable into \"maximally separating prototypes\" laid in the D-hypersphere. For classification, the learning problem reduces to minimizing the angle between D-dimensional feature vectors and the associated D-dimensional polar prototype. A similar strategy applies to regression, where the continuous target variable is squeezed to the range of the hypersphere.\n\nThe authors claim that their method unifies, as opposed to much prior art, classification and regression approaches. I disagree with this claim, since we usually approach classification as a (normalized!) regression problem. In some cases the normalization is on the entire output space (single-label classification as in ImageNET), and in some other cases this normalization happens separately in each component of the output space (multi-label classification as in COCO). It is even possible to train an ImageNET classifier using mean squared error given unit-norm feature vectors (Tygert et al, 2017). As such, the \"unification\" proposed by the paper seems a bit blurry to me.\n\nI am unconvinced about the impact shown by the experiments. Table 1 shows accuracies far from the state-of-the-art (91% for all methods in CIFAR-10 versus 97% SOTA, 65% for the proposed method versus 75% SOTA) and throw some separation statistics without a clear correlation to accuracy. The experiment on semantic priors is inconclusive, as all non-baseline results are within error bars. The impact of Section 3.3. is also unclear, since obtaining semantic (digit rotation) interpolations in MNIST is a common feat achieved by unsupervised learning algorithms with decent feature learning.\n\nThe results from section 3.2 are interesting, although I would be interested in seeing a reduction-to-classification baseline, where the years are clustered to set up a classification problem, and the prediction is fine-tuned by a local regression.\n\nNote: Regressing to (random) polar prototypes was proposed in https:\/\/arxiv.org\/abs\/1704.05310","sentences":[{"sentence_type":"1","sentence":"The authors claim that their method unifies, as opposed to much prior art, classification and regression approaches. I disagree with this claim, since we usually approach classification as a (normalized!) regression problem.","rephrased":"While the authors present their method as a unification of classification and regression approaches, it's worth noting that classification is often treated as a normalized regression problem, which might suggest that the distinction between the two is not as pronounced as the paper implies."},{"sentence_type":"2","sentence":"I am unconvinced about the impact shown by the experiments.","rephrased":"The experiments could be strengthened to better demonstrate the impact of the proposed method."},{"sentence_type":"2","sentence":"The impact of Section 3.3. is also unclear, since obtaining semantic (digit rotation) interpolations in MNIST is a common feat achieved by unsupervised learning algorithms with decent feature learning.","rephrased":"It would be helpful if Section 3.3 could clarify its impact, especially considering that semantic interpolations in MNIST are commonly achieved by unsupervised learning algorithms."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[449,673,"Not concerning"],[1130,1189,"Not concerning"],[1520,1721,"Not concerning"]],"Comments":[]}
{"id":"txJeSrhiMo3","text":"**Paper Summary:** This paper proposes a decentralized federated learning algorithm called Online Push-Sum (OPS) for peer-to-peer learning in the context of social networks with the property of single-sided trust . \n\n**Questions for the authors**\n1. Sec 1, it is mentioned that “Only models rather than local gradients are exchanged among clients in our algorithm.” My understanding is in most of the federated learning algorithms, either model parameters or difference of model parameters are exchanged (also noise can be added on top of them to guarantee differential privacy). So, it would be great if the authors further explain why this is a feature of their algorithm worth highlighting.  \n2. Maybe I have missed it, but in Sec 4.1, why do we need an extra parameter (i.e., $w_{t+1}^{i}$) for normalization? Why can't we just use the summation of the weights (i.e. $W_{ki}$) to do the normalization ? Can you explain further?\n3. Sec 4.3, one assumption of the proposed algorithm is that the graph is strongly connected. I am afraid this may not be the case in practical applications. Fully decentralized algorithms for learning should be robust to the limited availability of the clients\/nodes (with clients temporarily unavailable, dropping out or joining during the execution) and limited reliability of the network (with possible message drops). Interested to see the authors’ thoughts on this. \n\n**Novelty**\nThe paper to me seems an incremental extension of the previous work (Zhao et al., 2019), and I think the novelty is a little thin.\n\n**Areas to Improve**\nI think it would be good to compare the proposed method with other existing Federated Learning methods such as (Dinh et al. NeurIPS, 2020) as well. \n\n**Minor Concerns**\nPage 2. Notation section. “denoting the sets of in neighbors of and out neighbors” -> \"denoting the sets of out neighbors of and in neighbors\" ?\n\n**References**\n1. Personalized Federated Learning with Moreau Envelopes (Dinh et al. NeurIPS, 2020)\n2. Peer-to-peer federated learning on graphs (Lalitha et al. 2019). This is a relevant paper which is missing.","sentences":[{"sentence_type":"2","sentence":"The paper to me seems an incremental extension of the previous work (Zhao et al., 2019), and I think the novelty is a little thin.","rephrased":"While the paper builds upon previous work (Zhao et al., 2019), it would be beneficial for the authors to more clearly articulate the distinct novel contributions that differentiate their work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1418,1548,"Not concerning"]],"Comments":[]}
{"id":"kGPznmEn0T","text":"The paper is tackle a very interesting biochemistry problem --  tandem mass spectrometry (MS\/MS).  The paper provides clear description for the audience to understand the data and the problem (e.g. Fig 4 and Fig5). The three modules are interesting (e.g. encode the peak embedding and incorporate fragmentation tree structure). \n\nSome questions: \n(1) Although the three modules framework is interestingly designed, it seems to me that the contribution of machine learning novelty seems not very clear. \n(2) Table 1 shows the MS\/MS number of pairs seem limited, especially CASMI. Are transformer-based or deep learning models that require a lot of training data the most appropriate methods, compared with non-deep learning based methods?  \n(3) MS\/MS is a well established technique for many years with mature data analysis pipeline (from spectrum to molecule identification), can the author provide evaluation against currently working data analysis pipeline to Table 2 and Table 3 so that the readers can understand the performance of deep learning model against conventional working model?\n(4) Fig 5 a,  why the true predictions in the circles have different scores? \n(5) Fig 3 SMILES-reconstruction module, why the input is smiles (shifted right). Is the smiles string the target, not the input? \n","sentences":[{"sentence_type":"1","sentence":"it seems to me that the contribution of machine learning novelty seems not very clear.","rephrased":"Could you please clarify the novel contributions of the machine learning aspects within the three modules framework?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[415,501,"Not concerning"]],"Comments":[]}
{"id":"rkliadzUjE","text":"This short submission (2 pages) seeks to motivate the use of AI planning technology to support the migration of computing resources to a Cloud environment. It outlines the problem at a high level, briefly describes an initial prototype built on Metric-FF for a simple version of the problem, and summarizes open challenges determined from the development of that first prototype. \n\nCloud Migration could potentially be a good application for AI planning but the case isn't made in a completely convincing manner in this paper. One issue is that the reader isn't presented with a clear description of what a planning model would need to encompass.  The problem is characterized as \"allocate ... resources ... and the migration expert's work efforts so all the assets can be migrated ... and running seamlessly as they were before the migration\".  Only sequencing constraints are mentioned as being essential to the model but presumably there are also capacity\/throughput constraints?  And isn't optimization important as well (cost, speed)?  Recognizing that this is a short paper, it still should be possible to provide more clarity on the nature of the planning constraints that are inherent to the problem.\n\nPROs:\n•\tPotentially interesting application domain to present to the community\n•\tThe authors have explored the space sufficiently that they should be able to share some insights into the challenges and opportunities\n\nCONs:\n•\tSubmission is light on content, in particular it lacks sufficient detail about what defines the core planning\/scheduling problem \n\nSome minor points:\n\n- It is mentioned that current practice is to plan manually or using tools called \"runbooks\" - it would be helpful to know more about what those tools do. \n\n - The criteria used for ordering the References is unclear - it is neither alphabetical, chronological, nor reference order.\n","sentences":[{"sentence_type":"2","sentence":"Cloud Migration could potentially be a good application for AI planning but the case isn't made in a completely convincing manner in this paper.","rephrased":"While Cloud Migration could be a promising application for AI planning, the paper would benefit from a more robust argument to fully convince the reader of its potential."},{"sentence_type":"2","sentence":"Submission is light on content, in particular it lacks sufficient detail about what defines the core planning\/scheduling problem","rephrased":"The submission could be strengthened by providing more detail on the core planning\/scheduling problem to enhance the reader's understanding."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[382,526,"Not concerning"],[1435,1563,"Maybe"]],"Comments":[]}
{"id":"S1eE7Wzw3V","text":"This paper extends previous works from the same authors on model reconciliation.\nThe novelty here is that they drop the assumption about having the explicit user model. In this work, the model is instead learned.\nThis is clearly an interesting work, and it's worth presenting and discussing it at the workshop.\n\nSome comments:\n1) I noticed that the authors make a number of assumptions, but they are scattered throughout the paper. For example, some of things that the authors assume:\n-the order in which the explanations are presented does not matter\n-human and robot MDP models only differ on the transition probabilities\n-the robot has access to a set of explanatory messages\n\nand others. Perhaps it would be clearer to state from the beginning what the assumptions are, so that the reader do not discover them here and then?\n\n2) I wonder how this approach can actually scale or be generalised to other (more complex) scenarios.\nAgain, I'm recommending acceptance of this paper, but I have to admit the use case considered is quite basic. \nCan the authors comment on potential\/limitation to scale to larger (and more complex\/interesting) scenarios? Also, I think that the sentence \"finding a complete policy explanation is relatively straightforward\" should be put in context! As in many cases is not so straightforward!\n\n3) What's the class of questions this approach aims to answer\/address?\nI didn't manage to understand which questions the authors are actually interested in.\n\n4) User study  \nThe user study looks nice (I did it myself through the website). But honestly I don't understand how you get from that an assessment of the effectiveness of the proposed explanations.\n\nMinor\/typos:\n\"another point point\"\n\"standins\"\n\n\nIn conclusion, I recommend accepting the paper. I have some major concerns, as I wrote, but I believe that XAIP being a new area we should be as inclusive as possible, and we should acknowledge that big contributions are made step by step.\n","sentences":[{"sentence_type":"2","sentence":"Again, I'm recommending acceptance of this paper, but I have to admit the use case considered is quite basic.","rephrased":"While I recommend accepting this paper, I suggest the authors consider elaborating on how the use case can be extended to more complex scenarios."},{"sentence_type":"2","sentence":"But honestly I don't understand how you get from that an assessment of the effectiveness of the proposed explanations.","rephrased":"Could you please clarify how the user study translates into an assessment of the effectiveness of the proposed explanations?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[932,1041,"Not concerning"],[1564,1682,"Not concerning"]],"Comments":[]}
{"id":"rygH6_Mh5r","text":"*What is this paper about?*\n\nThe authors propose a method to incorporate POS tags into a language model to improve its performance in Amharic language.\n\nShort review:\n\nThe authors tackle an interesting task which deserves more attention. Nonetheless, they do not fully describe their models or results with enough detail, so it is hard to evaluate this work.\n\n\nContributions:\n\nThis work tackles a relevant problem that seriously impacts speakers of low resource languages.\n\n*What strengths does this paper have?*\n\nIt tackles and interesting problem.\n\n*What weaknesses does this paper have?*\n\nThe authors do not present their models in enough details so that the reader fully understands it.\nThey also only gloss over the results, not presenting them in any concrete form, stating: “We believe the results obtained were effective in reflecting bet-ter speed, correctness of suggestions (grammatical), and search space since these are the basic issues in word sequence prediction and in assistive technology”. This referred results are not shown in the manuscript though.\n\n\n*Detailed comments:*\n\nThe paper does not use the official conference template. It is also very short, not going in details about the used techniques. Finally, references are not correctly formatted.\n\nSection 1.\n","sentences":[{"sentence_type":"1","sentence":"The paper does not use the official conference template.","rephrased":"The paper should adhere to the official conference template to meet the submission guidelines."},{"sentence_type":"2","sentence":"It is also very short, not going in details about the used techniques.","rephrased":"The paper could benefit from a more detailed explanation of the techniques used."},{"sentence_type":"1","sentence":"Finally, references are not correctly formatted.","rephrased":"Improving the formatting of the references would enhance the paper's professionalism and adherence to academic standards."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1094,1150,"Not concerning"],[1151,1221,"Not concerning"],[1222,1270,"Not concerning"]],"Comments":[]}
{"id":"r1gu1BMv2V","text":"The paper discusses branching-bounded contingent planning, a generalization of what is usually called contingent planning, where instead if binary observation actions we have a POMDP-style observatin function and can construct policies of varying forms depending on what they receive as input. The paper does a great job of formalizing and discussing the problem, and offering an algorithmic solution. There is no empirical evaluation yet but for a workshop paper I don't see this as a problem.\n\nThe main problem I do see is the relevance to this workshop. The authors say their work is motivated by explainability, based on the plausible hypothesis that understandability of a plan depends on the amount of branching. While this is fine and may be relevant to XAIP in the long term, the technical content of the paper is 100% contingent planning and belief space search. It seems doubtful that this will be interesting to the XAUP auience specifically (HSDIP may have been a better guess). Given the large number of submissions to XAIP, it is not clear whether it makes sense to include the paper.","sentences":[{"sentence_type":"2","sentence":"It seems doubtful that this will be interesting to the XAUP auience specifically (HSDIP may have been a better guess).","rephrased":"It may be worth considering how the paper's focus on contingent planning and belief space search aligns with the specific interests of the XAUP audience, as it could potentially be more suited to venues like HSDIP."},{"sentence_type":"2","sentence":"Given the large number of submissions to XAIP, it is not clear whether it makes sense to include the paper.","rephrased":"Considering the high volume of submissions to XAIP, it would be beneficial to further clarify the paper's unique contributions to ensure its inclusion is justified."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[719,871,"Missed Maybe"],[872,990,"Maybe"],[991,1098,"Not concerning"]],"Comments":[]}
{"id":"BklbJDXJqB","text":"The paper presents an interesting signal processing-based extension of CNNs, where the first layer convolution is replaced by some pre-defined filter banks. Since those filter banks are parameterized with a smaller number of parameters, while they have been proven to be effective in audio processing, I was convinced that this approach could produce better performance than a generic CNN with no such consideration. \n\nI am still wondering though, what is the main difference between this approach and Wavelet transform-based scatter transform networks that Stephane Mallat has proposed for years, for example in (Andén and Mallat 2014). I figure the proposed method in this paper is more flexible as it does not use the pre-defined filterbanks; instead it tries to learn the parameters to specify the only necessary filters for the particular problem. But I think the authors may need to address the difference from this previous work done by Mallat's group, because they at least share a similar philosophy. \n\nAnother thing that's not entirely clear for me was the effect of the filter length. Obviously, it should depend on the particular classification problem. For example, for speech, there needs to be consideration about the shortest stationary period of speech, while in some other cases like music and urban sound, it should be in different lengths to capture the specifics. It's a bit hard for me to believe that the different choices of filter banks from 1 to 100 ms all gave the same results (in Figure 1b). I think, if there is an optimal filter length depending on the problem, which has to be found to guarantee the performance, it has to be better investigated in the paper. \n\nIt is a confusing message to me, because the paper claims that the first layer of their network can cover a large area, which responds to a large receptive field, with a single filter by using a different parameter. It is a clearly a different kind of observation than the computer vision networks where the large receptive fields are defined with a deeper architecthre and strides. However, the shortest filter (1ms) and the longest one (100ms) doesn't make any difference, empirically? More discussion is needed to resolve this confusion.\n\n\nJ Andén and S Mallat, \"Deep scattering spectrum\", IEEE Transactions on Signal Processing, 2014","sentences":[{"sentence_type":"2","sentence":"It's a bit hard for me to believe that the different choices of filter banks from 1 to 100 ms all gave the same results (in Figure 1b).","rephrased":"I would appreciate further clarification on how the different choices of filter banks from 1 to 100 ms all resulted in the same outcomes as shown in Figure 1b, as it seems counterintuitive."},{"sentence_type":"1","sentence":"It is a confusing message to me, because the paper claims that the first layer of their network can cover a large area, which responds to a large receptive field, with a single filter by using a different parameter.","rephrased":"The paper's claim that the first layer of the network can cover a large area with a single filter by using a different parameter is intriguing, and I would welcome more explanation to fully understand this concept."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1385,1520,"Not concerning"],[1694,1909,"Not concerning"]],"Comments":[]}
{"id":"W31NCGvMldd","text":"EDIT: **post rebuttal. I'd like to thank the authors for their response. As scalability to high-dimensional hyperparameter spaces is presented as a key advantage of the method, direct comparisons to high-dimensional BO techniques would be needed. The fact that using trust regions could benefit HOZOG, or that HOZOG is a better strategy compared to TurBO and REMBO, should be demonstrated empirically. I am keeping my score to 4 as the current positioning of the paper would require direct comparisons with these baselines. **\n\n\nThe paper introduces HOZOG, a new HPO method combining the benefits of black-box and gradient-based optimization. This is achieved by means of a finite difference approximation that computes the gradients in a black-box fashion. By doing so, the method achieves both scalability to a large number of model parameters and hyperparameters, the latter being a bottleneck in standard BO methods. A feasibility analysis and experiments against baselines show the benefits of the proposed approach.\n\nPositive\n\n1. **Significance.** This is the first approach trying to take a black-box approach to tackle gradient-based optimization, inheriting the benefits of the two worlds.  I expect this can lead to follow-up work in this direction.\n2. **Clarity.** The paper is generally well articulated and easy to follow. I particularly appreciated the authors clearly comparing black-box and gradient based methods in Table 1 by listing desiderata. \n3. **Feasibility analysis.** The work contributes a rigorous feasibility analysis studying the use of the proposed approach in HPO.\n\nNegative\n\n1. **Missing baselines.** If scalability to high-dimensional hyperparameter spaces is a key selling point of the method, experiments should have focused on comparing against BO methods that are designd to scale to large dimensions. For instance, the authors claim \"a lot of references have pointed out that [BO] can only handle hyperparameters from a few to several dozens\". It would be helpful if the authors elaborated on this point. Is it due to the poor scalability of the Gaussian process model in high dimensions? In that case, non-GP, scalable models have been proposed (e.g., SMAC) or adaptations directly targeting high-dimensional BO problems (e.g., TurBO). Code for these methods is also publicly available but these baselines are missing from the experiments. These are specific references:\n\n(TurBO) Eriksson et al., Scalable Global Optimization via Local Bayesian Optimization. In NeurIPS 2019; \n\n (REMBO) Wang et al., Bayesian Optimization in High Dimensions via Random Embeddings, In IJCAI '13 + follow-ups, including Letham et al. 2020, \"Re-Examining Linear Embeddings for High-Dimensional Bayesian Optimization\" ;\n\n(SMAC) Hutter et al., 2011. Sequential Model-Based Optimization for General Algorithm Configuration.  In Proceedings of the conference on Learning and Intelligent Optimization, 2011.\n\n2. **Reproducibility.** No curves in the results include error bars. Are experiments only based on a single run? If not, clearly defined error bars should be reported. If yes, this is not enough to draw meaningful conclusions considering that the BO algortihms are highly stochastic with many sources of variability (e.g., how they are warm-started, often done through a random initial design).\n\n3. **Structure.** The paper is visually rather crammed and the plots are too small to be readable. The authors seem to be aware of this as they provide larger versions of the figures in the appendix. The main paper should be self-contained though and this is not an acceptable way to get around the 8-page limit.\n\nWhile the paper has its merits, I believe the current version falls below the acceptance bar due to the lack of competing high-dimensional BO baselines paired with reproducibility concerns (i.e., experiments have no error bars). I believe this is promising work with valuable theoretical contributions, but the experimental evaluation is currently not sufficient to justify the proposed approach. In particular, relevant baselines for high-dimensional BO should be both discussed and compared against, and all results should be based on multiple repetitions and report confidence intervals.\n\nMinor:\n\n1. Typos at Page 2: \"salable\"  ---> scalable; \"hyperparmaters\" --> hyperparameters\n2. Related to the \"structure\" point above, there is no space between \"results and discussion\" and the rest of the text in page 8. This is also done in several places, including captions. I'd suggest making the content more crisp instead.","sentences":[{"sentence_type":"2","sentence":"While the paper has its merits, I believe the current version falls below the acceptance bar due to the lack of competing high-dimensional BO baselines paired with reproducibility concerns (i.e., experiments have no error bars).","rephrased":"Although the paper presents notable strengths, I recommend that for the current version to meet the acceptance criteria, it should include comparisons with competing high-dimensional BO baselines and address reproducibility by providing error bars in the experiments."},{"sentence_type":"2","sentence":"The main paper should be self-contained though and this is not an acceptable way to get around the 8-page limit.","rephrased":"It is important for the main paper to be self-contained, and I suggest finding alternative ways to adhere to the 8-page limit while including all necessary figures and information."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[3520,3632,"Not concerning"],[3634,3862,"Not concerning"]],"Comments":[]}
{"id":"Bk3gLTuef","text":"This paper proposes a method to adapt a region proposal network (RPN) to the visual object tracking task. The authors also describe a method to compress the network to improve run-time performance. They also claim that an ensemble of the proposed trackers provides state-of-the-art performance on VOT 2016.\n\nThe main claimed contribution is \"a novel tracking loss which successfully converts a pre-trained object detector RPN to a state-of-the-art visual tracker...\" The idea to adapt an RPN to visual object tracking by generating samples for online learning was previously published in the CVPR 2016 workshops [1]. Some novelty is also claimed in the network compression, but it seems to be a straightforward implementation of knowledge distillation. In this reviewer's estimation, the novelty in this paper is limited to the specific design of the loss function described in Section 3.5.\n\nThe tracking loss is essentially a procedure to limit or gate back-propagation updates to proposal regions that have a high confidence to match the object being tracking. The intuition is that this strategy will enable better online learning and thus tracking performance. A small empirical study was conducted to determine which feature regions from the top layer of the RPN are most effective for this purpose. The authors argue that allowing only high matches could lead to centered but loose bounding boxes, while allowing further matches can improve the bounding box fit but might encourage drift. The loss function is combination of the two, with \\alpha and \\beta weighting the importance (it seems you only need one weight parameter here). No theoretical justification for the approach is given, it seems to be an ad hoc solution to adapt a region proposal architecture to perform online tracking.\n\nThe network compression in Section 4 seems to yield a nice increase in efficiency without any loss in performance. The network ensemble described in Section 5 improves tracking performance over a single network. These are nice technical improvements that push performance, but do not offer much in terms of novelty.\n\nThe proposed tracking network is tested on the VOT 2016 challenge data. The authors claim state-of-the-art performance on this dataset. The source code and raw results of participants of VOT 2016 are all publicly available - but unfortunately the no raw results or source code are provided for this paper either in supplementary material or in anonymous repository (it is not difficult to do this while keeping anonymity). Tracking papers usually provide some video results or, at minimum, still frames, to assist in the evaluation of performance, but none are provided here The Accuracy Rank and Robustness Rank numbers provided in Table 2 seem to be incorrectly computed - these numbers should be integers, see the VOT challenge report [2].\n\nPros:\n+ Strong practical and technical improvements to push performance\n+ State-of-the-art performance on VOT 2016\n\nCons:\n- Difficult to verify results\n- Limited novelty\n- Numerous language problems, making the paper difficult to read and understand in many places.\n\n\n[1] Zhu, G., Porikli, F., & Li, H. (2016). Robust visual tracking with deep convolutional neural network based object proposals on pets. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops (pp. 26-33).\n[2] VOT challenge report http:\/\/data.votchallenge.net\/vot2016\/presentations\/vot_2016_paper.pdf\n\nMinor notes:\n* Clearly explain what an anchor point is\n* Figures are introduced out of order\n* What is the purpose of Figure 1? There seems to be no clear message\n* \"Although ground truths are not provided in tracking...\" - what do you mean by this?\n* Do you fix the aspect ratio of the anchors to 1:1 for tracking, or only to define the confidences in Fig 2?\n* \"RPN is a relative large network to tracking\" - I understand what you mean but it is not written clearly\n* Unclear how \\alpha:\\beta is computed\n* Figure 6 is too small to read.\n* Table 2 size should be increased.\n\n","sentences":[{"sentence_type":"1","sentence":"In this reviewer's estimation, the novelty in this paper is limited to the specific design of the loss function described in Section 3.5.","rephrased":"The primary novel contribution of this paper appears to be the specific design of the loss function described in Section 3.5, as per the reviewer's assessment."},{"sentence_type":"2","sentence":"No theoretical justification for the approach is given, it seems to be an ad hoc solution to adapt a region proposal architecture to perform online tracking.","rephrased":"The paper would benefit from a theoretical justification for the approach, which would strengthen the case for the proposed solution to adapt a region proposal architecture for online tracking."},{"sentence_type":"2","sentence":"but unfortunately the no raw results or source code are provided for this paper either in supplementary material or in anonymous repository (it is not difficult to do this while keeping anonymity).","rephrased":"It would be helpful if the authors could provide the raw results or source code in supplementary material or an anonymous repository, which is often feasible while maintaining anonymity."},{"sentence_type":"2","sentence":"Numerous language problems, making the paper difficult to read and understand in many places.","rephrased":"The paper could be improved by addressing the language issues to enhance readability and comprehension throughout the document."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[753,890,"Not concerning"],[1639,1796,"Not concerning"],[2340,2537,"Not concerning"],[3031,3124,"Not concerning"]],"Comments":[]}
{"id":"rkeqEYSLFV","text":"The authors present a framework of fast and easy methods for boosting text classification. The methods include synonym replacement, random insertion of a word, random swap of two words and last random deletion. They empirically prove that their approach can increase accuracy, especially in small training set sizes.\n\nThe writing of the paper was very clear and easy to understand. The authors had a very extensive section with experiments, analysis, ablation studies as well as comparison to related previous work. The actual contributions of the paper are random insertions, swaps, and deletions as synonym replacement was previously \n\nPros:\n- fast and easy methods \n- compared with training techniques\n\nCons: \n- no learning or training\n- theoretical explanation \n\nI really liked the frequently asked questions section in the appendix, where the authors respond to questions that easily arise. \n\nBecause the gains are indeed marginal, statistical significance is something that should be added. As the authors state in the conclusion, a small theoretical explanation of the EDA operations could be done here, as the methods themselves did not include something extremely complex. The methods should be first compared with a non-training or learning approach, for example adding knn words as augmentation.\n\nSome questions that could be answered as well are: did you explore which replacements affected the model more? for example verbs, nouns or what was their POS-tag? Did you observe any pattern concerning that? As the random deletion seems to be the most effective for small training set sizes, what were the words that were deleted and what can you comment about this phenomenon?","sentences":[{"sentence_type":"2","sentence":"Because the gains are indeed marginal, statistical significance is something that should be added.","rephrased":"To strengthen the findings, it would be beneficial to include an analysis of statistical significance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[898,996,"Not concerning"]],"Comments":[]}
{"id":"odRZvloPM9","text":"The authors propose a data-driven method to predict the anatomical changes in the brain over time, encoded as a deformation field. The main contribution is to employ a neural network to predict the parameters f a diffeomorphic deformation field that morphs the images between exams, instead of directly predicting the anatomy at a later exam.\nThe paper addresses an important challenge in neuroimaging and is well written and validated\n\nIt is unclear if the method is predicting a deformation over time, this is , its evolution so that the intermediate deformed shapes between the initial scan and the follow on are meaningful or realistic, or if the method predicts the anatomy at follow up exam and uses  a diffeomorphic field  to regularise the problem or to try to give some intuition to what the neural network is doing.  Is the time between both imaging procedures always the same?\n\nAuthors indicate that there are some optional attributes (encoded in vector $a$) that can be used, but it is not clear if this is actually used in the experiments, and what is the impact. How is this reflected in Fig 2 or Fig 3?\n\nAuthors are say that they use the segmentations to train the model but Fig. 1 shows images ath both ends -Ithink this could be further clarified.","sentences":[{"sentence_type":"1","sentence":"Authors are say that they use the segmentations to train the model but Fig. 1 shows images ath both ends -Ithink this could be further clarified.","rephrased":"The authors mention that they use segmentations to train the model, however, Figure 1 displays images at both ends. Could you please clarify this aspect?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1119,1264,"Not concerning"]],"Comments":[]}
{"id":"HyeYxYAs_H","text":"Summary:\nThe paper introduces a hierarchical RNN architecture that could be trained more (memory) efficiently. The difference in the architecture seems to be an auxiliary loss that decodes k step inputs and some perturbation of TBPTT.\n\nComments on the paper\n\n1. The paper seems to be have been written in a rush. The language could be improved, the format is not always consistent and in general the paper could be much better written. There are quite some typos as well in the paper, for example , Trinh et al.  is not a proper citation.\n\n2. The authors mentioned that TBPTT is not memory efficient, this is not very clear to me, as it only needs to keep the number of truncation steps that it backprops through and hence much more memory efficient compared to full BPTT.\n\n3. It is not clear to me what is the benefit of gr-HMRNN. It is not clear why cutting of the gradients from the higher level to the lower level would help.\n\n4. It is surprising to me that HMRNN could only solve the copy task upto a length of 108. \n\n5. I would also suggest another copy task from Hochreiter, Sepp and Schmidhuber, Jürgen. Long short-term memory. Neural computation, 9(8): 1735–1780, 1997.\n\nIn general, the paper seems to have been written in a rush. I would recommend the papers to be revised.","sentences":[{"sentence_type":"2","sentence":"The paper seems to be have been written in a rush.","rephrased":"The paper could benefit from additional proofreading to address language and formatting inconsistencies, as well as to correct typographical errors."},{"sentence_type":"2","sentence":"In general, the paper seems to have been written in a rush.","rephrased":"Overall, the paper would greatly improve with a thorough revision for clarity and consistency."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[262,312,"Maybe"],[1180,1239,"Maybe"]],"Comments":[]}
{"id":"H1CZob5Jz","text":"This paper examines the nature of convolutional filters in the encoder and a decoder of a VAE, and a generator and a discriminator of a GAN. The authors treat the inputs (X) and outputs (Y) of each filter throughout each step of the convolving process as a time series, which allows them to do a Discrete Time Fourier Transform analysis of the resulting sequences. By comparing the power spectral density of the input and the output, they get a Spectral Dependency Ratio (SDR) ratio that characterises a filter as spectrally independent (neutral), correlating (amplifies certain frequencies), or anti-correlating (dampens frequencies). This analysis is performed in the context of the Independence of Cause and Mechanism (ICM) framework. The authors claim that their analysis demonstrates a different characterisation of the inference\/discriminator and generative networks in VAE and GAN, whereby the former are anti-causal and the latter are causal in line with the ICM framework. They also claim that this analysis can be used to improve the performance of the models.\n\nPros:\n-- SDR characterisation of the convolutional filters is interesting\n-- The authors show that filters with different characteristics are responsible for different aspects of image modelling\n\nCons:\n-- The authors do not actually demonstrate how their analysis can be used to improve VAEs or GANs\n-- Their proposed SDR analysis does not actually find much difference between the generator and the discriminator of the GAN \n-- The clarity of the writing could be improved (e.g. the discussion in section 3.1 seems inaccurate in the current form). Grammatical and spelling mistake are frequent. More background information could be helpful in section 2.2. All figures (but in particular Figure 3) need more informative captions\n-- The authors talk a lot about disentangling in the introduction, but this does not seem to be followed up in the rest of the text. Furthermore, they are missing a reference to beta-VAE (Higgins et al, 2017) when discussing VAE-based approaches to disentangled factor learning\n\n\nIn summary, the paper is not ready for publication in its current form. The authors are advised to use the insights from their proposed SDR analysis to demonstrate quantifiable improvements the VAEs\/GANs.","sentences":[{"sentence_type":"2","sentence":"-- The authors do not actually demonstrate how their analysis can be used to improve VAEs or GANs","rephrased":"The authors could strengthen their contribution by providing clear examples or demonstrations of how their analysis can be applied to enhance VAEs or GANs."},{"sentence_type":"2","sentence":"-- Their proposed SDR analysis does not actually find much difference between the generator and the discriminator of the GAN","rephrased":"It would be beneficial if the authors could further explore or clarify the differences between the generator and the discriminator of the GAN as revealed by their SDR analysis."},{"sentence_type":"2","sentence":"-- The clarity of the writing could be improved (e.g. the discussion in section 3.1 seems inaccurate in the current form). Grammatical and spelling mistake are frequent.","rephrased":"Enhancing the clarity of the writing, particularly in section 3.1, and addressing the grammatical and spelling errors would significantly improve the manuscript."},{"sentence_type":"2","sentence":"In summary, the paper is not ready for publication in its current form.","rephrased":"In summary, while the paper presents interesting ideas, further refinement and development are needed before it is ready for publication."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1274,1371,"Maybe"],[1372,1496,"Maybe"],[1498,1667,"Not concerning"],[2081,2152,"Not concerning"]],"Comments":[]}
{"id":"SJebxqCTtB","text":"The paper experimentally studies the reasons for the slow convergence of the Federated Averaging algorithm when the data are non-iid distributed between workers in the multiclass-classification case. Paper performs extensive experimental study and observes that the main reasons for failure are connected to (i) the parameter divergence during the local steps, (ii) steep-fall phenomena when parameters on different nodes are getting close fast, and to the (iii) high training loss. \n\nMy score is weak reject. The paper provides extensive but unclear experimental results. Improving presentation would significantly improve the paper. For example, why in experimental and theoretical study different parameter divergence metrics were used, etc (see below), why different networks use different optimizers. \nMoreover, provided experimental comparison might be unfair. The learning rate is constant throughout all of the experiments, depending only on the optimizer, but not on the neural network architecture. This can affect the final results. \n\nConcerns and questions that should be addressed:\n1. The initial learning rates were not tuned properly. It is set to be the same for different neural network topologies, which might significantly affect the results. What did the choice of initial learning rates is based on? \n\n2. Why the parameter divergence metric in Definition 1 is not the same as in the theoretical study (Appendix B)? What is the intuition behind Definition 1?\n\n3. Why the divergence of parameters is considered only at the last layer? It seems to hide many important interactions in the other layers. \n\n4. Some important experimental details --- should be added:\n   - At which moment the parameter divergence is computed in the plots? Is it computed at the end of the local iterations right before synchronization? \n   - How the training loss was computed in the plots? before or after synchronization? on the local only or the global data?\n   - Which batch size was used? \n   - Improve the figure caption to detail the experimental setup. (e.g. in fig 3. the network architecture was mentioned only for one of the figures, include which optimized was used, etc)\n\n5. In experiments on Fig. 2. and Fig.3 (middle) what is the accuracy for IID baseline? Is the observed phenomena connected to the poor network architecture or to the non-iid data? \n\n6. In table 5 of the appendix, why experiments use Adam optimizer, but not Momentum SGD as in the main paper to compare the performance of ResNet14 and ResNet20?\n\n7. Better re-prase the definition of the steep fall phenomena, now it is not very clear: in the IID setting parameter divergence values are also sometimes reducing sharply; in the network width study parameters divergence doesn’t experience sudden drop. Also, how does this phenomena (and parameter divergence too) connects to the training loss? \n\n8. Why for different experiments different baseline models are used? (NetA, NetB, NetC)\n\n\nOther minor comments: \n- Appendix B, first equation on page 13. (d_q)^t -> (d_q)^t_k; The size of gradient \\nabla_w [E ...] is different from the size of (d_q)_k. They cannot be added together.\n- page 7, last sentence of the first paragraph: what is the accuracy achieved with Batch Renormalization? Why the reason for accuracy gap is “significant parameter divergence”? on fig. 3 “parameter divergence” is smaller than for the baseline.\n- Why the name of the section on page 7 is “excessively high training loss of local updates” if later it is stated that it is actually smaller than for the IID case? \n- Defenition 1, line 4: “the then” -> “the”\n- section 3: “A pleasant level of parameter divergence can help to improve generalization” -> where was it shown?\n- section 4.2, paragraph 2: what is meant by “hyperparametric methods”?\n- section 4.2, paragraph 3: “quantitative increase in a layer level” -> not clear what does it mean.\n- page 4, effect of optimizers: what do you refer to as “all model parameters”? \n- page 5, last paragraph: Hinton et al... -> (Hinton et al…). Use \\citet(\\citep) instead of \\cite. \n- why Dropout yields bigger parameter divergence if on Fig 2, right it actually helps? \n- Last line of the page 5. Where was this observed? \n","sentences":[{"sentence_type":"2","sentence":"The paper provides extensive but unclear experimental results.","rephrased":"The paper provides extensive experimental results, which could be clarified further for better understanding."},{"sentence_type":"2","sentence":"Moreover, provided experimental comparison might be unfair.","rephrased":"Additionally, the experimental comparison could benefit from a review to ensure fairness and consistency."},{"sentence_type":"2","sentence":"The initial learning rates were not tuned properly.","rephrased":"It would be beneficial to provide a rationale for the choice of initial learning rates, especially considering the different neural network topologies."},{"sentence_type":"2","sentence":"Better re-prase the definition of the steep fall phenomena, now it is not very clear.","rephrased":"Clarifying the definition of the steep fall phenomena would enhance the reader's comprehension."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[510,572,"Not concerning"],[807,866,"Not concerning"],[1098,1149,"Not concerning"]],"Comments":[]}
{"id":"pv__8wyl3yf","text":"**Review Criteria**\n\nOriginality: McIlroy-Young et al. (2020b) have previously studied behavioral stylometry in chess. This paper provides a more accurate and scalable solution to an existing task domain using transformer-based game embeddings. The architecture is adapted from work on speaker adaptation but is novel in its application to this domain. \n\nQuality: The results appear technically sound and the proposed method achieves high accuracy. The authors run appropriate ablations, such as not including opening moves, evaluating out-of-domain generalization, etc. [These ablations are especially important because the accuracy values are *shockingly* good; as an expert chess player (~ELO 2100), I am quite surprised that it is theoretically possible to identify chess players with such high accuracy, and I was quite skeptical of the results at first.]\n\nClarity: The task and model architecture are clearly described. Some details of the few-shot classification setup are difficult to understand. \n\nSignificance: Behavioral stylometry in chess is not a particularly significant task, but the methods described could easily apply to other domains involving decision-making style, and chess serves as an appropriate and convincing testbed. In particular, the comparison between the embedding method and personalized \"move-matching\" models is interesting and likely to generalize to other domains. However, as noted below, stylometry is wrought with potential ethical issues that should be discussed further.\n\n**Notes on Specific Sections**\n\nAbstract: First paragraph of the abstract can be removed, since it reads more like an introduction and is in fact repeated in the introduction. I would recommend starting the abstract by describing what you did, rather than motivating the problem domain.\n\nIntroduction: It might be worth defining \"style\" and what it means in the context of chess. For example, one common distinction is between aggressive\/tactical vs. positional play, with certain players (Shirov, Tal) being known for aggressive play, and certain openings (e.g., gambits) being more or less tactical in nature. Presumably, this method also picks up on elements of \"style\" which do not readily correspond to human-interpretable concepts.\n\nRelated Work\/Methodology: Overall, this is all very clear and well-written. Possibly out-of-scope, but I wonder if you could achieve better results by initializing with board embeddings from the policy network of AlphaZero or some other neural chess engine. [But the results are already quite good, so this isn't top priority.]\n\nData: I'm not sure why the paper groups by the number of games played when the evaluation uses only 200 games for each player. However, sampling from ELO 1000-2000 is quite a large range, and I'm curious if these results would still hold for a narrower range. It seems possible to me that a model could be evaluating player strength rather than \"style.\" Similarly, the top 1500 players from Chess.com\/Lichess will also exhibit a lot variance in strength.\n\nEvaluation: \n - Task formulation: I found this section difficult to read, possibly because I had previously assumed D = R.\n - Can you confirm that k=15 means 15 moves for both players? Normally in chess a \"move\" consists of plays from both white and black, but I just wanted to confirm that's the case in your paper. There is technically opening theory that extends beyond the 15th move, but especially in Lichess 1000-2000 games, I wouldn't expect it to be very common. However, if k=15 actually meant 15 turns for both players combined (i.e., 7.5 moves), then this would definitely still be within the realm of opening theory, even for many amateur players.\n - Results for k=0\/k=15 and varying sizes of support\/query sets are useful, thanks!\n - Attention results seem straightforward and confirm my intuitions that openings are the most useful part of the game for stylometry, except for maybe the first move (where there are just less choices to be made). I'm less clear what takeaways I should have from the t-SNE plots, especially 3b and 3c. Does this just mean that choice of first move is an important factor in style but responses or not? Or how should I interpret 3b-3c?\n\nConclusion: Additional discussion of privacy concerns would be appreciated. See below.","sentences":[{"sentence_type":"2","sentence":"Behavioral stylometry in chess is not a particularly significant task,","rephrased":"While the direct application of behavioral stylometry in chess may have a niche scope, the methods described have broader potential in other significant domains."},{"sentence_type":"1","sentence":"First paragraph of the abstract can be removed, since it reads more like an introduction and is in fact repeated in the introduction.","rephrased":"Consider condensing the first paragraph of the abstract or integrating it into the introduction to avoid repetition and streamline the presentation of your work."},{"sentence_type":"2","sentence":"These ablations are especially important because the accuracy values are *shockingly* good; as an expert chess player (~ELO 2100), I am quite surprised that it is theoretically possible to identify chess players with such high accuracy, and I was quite skeptical of the results at first.","rephrased":"The ablations are particularly noteworthy given the impressive accuracy values achieved. As someone with considerable chess experience, I found the level of accuracy for player identification quite remarkable, which initially led me to approach the results with a degree of skepticism."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[572,859,"Not concerning"],[1021,1091,"Not concerning"],[1557,1690,"Not concerning"]],"Comments":[]}
{"id":"cG3bTwvlS5n","text":"Strengths\n+ I enjoyed the discussion on design decisions around normalization layers and agree that set norm is better than what was used in the Set Transformer paper because it discards less information. Furthermore, this intuition is confirmed by experiments in tables 2~4, which show that set norm improves performance.\n+ The discussion about having a clean residual path is interesting, and the paper draws a compelling parallel to design choices in ResNet models.\n\nWeaknesses\n- None of the results have error bounds, so it's hard to tell whether the differences are statistically significant. This problem is exacerbated because loss scales vary widely between tasks (10^1 Hematocrit, 10^-2~-4 Normal Var). Looking at the learning curves in Figure 1, the vanilla and ++ versions of some networks seem to have similar performance on a few tasks.\n- The paper increases the number of layers for both architectures, and this is never addressed in the experiments. For example, what is the performance of Set Transformer++ with 2 layers, compared to the vanilla version?\n\nMinor comments\n- Figure 1: the caption says that the figures have (grey, orange, blue) lines, but the colors seem closer to (pink, orange, green). This was slightly confusing.\n- The rightmost two columns of Table 4 were hard to understand at first. Maybe it's better to have two rows with the performance numbers for \"Original\" and \"No Norm\"?\n- I think Table 5 should be moved to the main paper, to show that permutation-invariant networks compare favorably to traditional approaches in this real-world setting.","sentences":[{"sentence_type":"2","sentence":"None of the results have error bounds, so it's hard to tell whether the differences are statistically significant.","rephrased":"Including error bounds in the results would help in assessing the statistical significance of the differences observed."},{"sentence_type":"2","sentence":"The paper increases the number of layers for both architectures, and this is never addressed in the experiments.","rephrased":"It would be beneficial for the study if the impact of increasing the number of layers for both architectures was explored in the experiments."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[483,597,"Not concerning"],[852,964,"Not concerning"]],"Comments":[]}
{"id":"HkePDwl_KN","text":"The paper proposed to augment training data by spacial transformer network, which impose a set of simple transformations to the image and is fully differentiable. The method can learn data-specific transformations and outperforms other GAN-based methods in limited-data setting. Compared to Ratner, the method can be trained in an end-to-end manner, but the evaluation result is lower.\n\nAs the experiment result is not so good, I'd recommend a weak accept.\n\n","sentences":[{"sentence_type":"2","sentence":"As the experiment result is not so good, I'd recommend a weak accept.","rephrased":"While the experimental results could be improved, the paper presents a novel approach and I would recommend it for acceptance with minor revisions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[387,456,"Not concerning"]],"Comments":[]}
{"id":"SkxuSXRx2N","text":"The paper describes an general approach for generating differences between positive and negative plan sets using LTL.  These resulting differences can then be used to generate contrastive explanations.  After detailing the approach, which can be intractible, the paper describes a mechanism to use Beyesian inferrence with search to identify plan differences.  In a set of experiments on 6 benchmark problems, they paper evaluates the approach and demonstrates that it is able to find more differences than an existing approach.  Finally, the paper summarizes the use of this approach for a real-world problem.\n\nGenerally, the paper is clear and well motivated.  I think it would make a fine contribution to the workshop.  It is especially noteworthy that this work presents a general method for producing contrastive explanations, which would benefit the XAIP community considerably.  The authors may want to add the work of Miller 2018 (previous XAI workshop) and 2019 (AIJ 267:1-38) regarding contrastive explanations.  Also, the paper should probably cite the recently accepted ICAPS 2019 paper by Chakraborti et al. called \"Explicability? Legibility? Predictability? Transparency? Privacy? Security? The emerging landscape of interpretable behavior\"\n\nMinor comments:\n - Consider a different variable from X for LTL or Bayesian Inference.  At first I was confused by how the same X could be used for both.   \n - Section 5 should have a segue rather than go straight into a subsection.","sentences":[{"sentence_type":"1","sentence":"After detailing the approach, which can be intractible, the paper describes a mechanism to use Beyesian inferrence with search to identify plan differences.","rephrased":"After detailing the approach, which can be complex in some cases, the paper describes a mechanism to use Bayesian inference with search to identify plan differences."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[203,359,"Not concerning"]],"Comments":[]}
{"id":"SkeQKHjaYH","text":"The paper proposes an imitation learning algorithm that learns from state-only demonstrations and assumes partial knowledge of the transition dynamics. The demonstrated states are decomposed into \"responsive\" and \"unresponsive\" features. The imitation policy is trained in an environment where the responsive state features are simulated and controllable by the agent, and the unresponsive state features are replayed from the demonstrations. The agent is rewarded for tracking the responsive state features in the demonstrations.\n\nOverall, I was confused by this paper. Isn't it problematic that the imitation agent is trained in an environment where unresponsive state features from the demonstrations are replayed and not affected by the agent's actions? It would be nice to expand Section 4 to explain why it makes sense to reflect the unresponsive component in the transition kernel. It would also be helpful to include some of this information in Section 1.\n\nI am also confused by the method. What is the purpose of observing unresponsive features, if the reward function for the imitation agent is only defined in terms of the responsive features? Is it that the imitation policy is conditioned on the unresponsive features?\n\nThere are several important experimental details missing from Sections 4 and 6. What distance metric was used to define the reward function? For example, was it Euclidean distance in pixel space for the Atari games? The main experimental results in Figure 2 are difficult to interpret without knowing the how the reward function is defined in the eMDP. Could the authors either provide definitions of the reward functions of the eMDPs in the experiments, or measure performance of the imitation agents using more interpretable or standardized metrics (e.g., game score) for the chosen environments?\n\nIt is also concerning that the Google Drive links to code and supplementary materials aren't anonymized.","sentences":[{"sentence_type":"1","sentence":"Overall, I was confused by this paper.","rephrased":"The paper presents some concepts that were not immediately clear to me."},{"sentence_type":"2","sentence":"It is also concerning that the Google Drive links to code and supplementary materials aren't anonymized.","rephrased":"Please ensure that the Google Drive links to code and supplementary materials are anonymized to maintain the integrity of the review process."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[532,570,"Not concerning"],[1833,1937,"Not concerning"]],"Comments":[]}
{"id":"YG5K1Ao7O","text":"This paper reviewed a series of two studies by Moyer et al. 2018 and 2019, and provide an overview of the proposed method to create a latent representation of fMRI data and remove the effect of scanner variant.\n\nPros:\n- Removing site effect from the data is an important topic. The original been reviewed here proposed an seemly effective way to achieve this task.\n- In the discussion, the limitation of the methods is stated. Although it would be better to propose or discuss potential improvement to resolve the reduce the effect of \"low information site\".\n\nCons:\n- I found the \"overview\" of the method to be too brief. For example, in figures:\n \n    - In the main method Figure (1) describing the diagram of the network, details need to be added in the legend, e.g. the meaning of each term in the loss function (now only abbreviation is given, and the reader shouldn't need to refer to the original papers to find their meanings there)\n    - In the main result paper, there is no description of what \"Oracle\" means. A brief description of the datasets used (Connectome 30\/60, and Prisma 30\/60) along with the meaning of the numbers comes along with It (30\/60) should also be needed.\n\n- The title is a bit misleading. The paper is mainly focusing on the overview of two previous papers, rather than an overview of the \"scanner invariant representations\" in more general sense, which is further limited by the lack of method comparison with other state-of-the-art methods used in papers mentioned in the introduction. Currently, only a comparison with a single baseline method which uses \"template-based methods\" which I found to be lacking. \n- I find the originality and novelty is a bit missing in this study.","sentences":[{"sentence_type":"2","sentence":"I find the originality and novelty is a bit missing in this study.","rephrased":"The study could benefit from a clearer emphasis on its original contributions and how it differentiates from existing work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1647,1713,"Maybe"]],"Comments":[]}
{"id":"5KVGQ8ycUmh","text":"Strengths\n\n- The motivation of this work is clear and the authors have covered the relevant literature adequately.\n\nWeaknesses \n\n-  Authors claim that the proposed MetaLoss is a loss-function agnostic framework (Page 3), however in the experiments, they have only used MAE as the loss function in the loss-learning block to evaluate the model. To claim MetaLoss is loss-function agnostic, authors must evaluate this framework using multiple loss functions such as MSE, Huber loss, Tweedie loss (can evaluated using intermittent time series data). \n\n- Moreover, authors have used only one prediction architecture (DNN) to train with the MetaLoss. This raises doubts over the extensibility of the proposed framework, whether MetaLoss can be used to train with other prediction architectures such as RNN, CNN, and tree based regressors such as LightGBM. This because these architectures are currently being heavily used in the time series forecasting literature; therefore, to assess the aptness of this method in the time series forecasting context, it is important to evaluate the proposed Metaloss method with these architectures. If these evaluations can’t be done, authors should clearly explain the limitations of this study (why these experiments can’t be done). Moreover, authors have not mentioned about the hyper-parameter ranges used to train the DNN and nor the procedure used to fine tune the hyper-parameters (at least using an appendix)\n\n- In the experiments, authors mention that they generate one-step forecasts for each time series. Does that mean you generate one step ahead forecasts, i.e., forecast horizon is equivalent to 1, What is the reason for that? Generally, in time series forecasting, we generate multi-step ahead forecasts, i.e., for multiple horizons. Also, the benchmark datasets used in the experiments are also not commonly used datasets in the forecasting literature (check [1] for more commonly used datasets) \n\n-  Another concern is that the study uses MAE as the primary loss function in the experiments and then evaluate the accuracy of the generated forecasts using MAE error measure again. What is the reason for this? This is not the general approach used in time series forecasting, because once the machine learning models are trained using the loss functions such as MAE, MSE, we use proper forecasting error measures such as sMAPE, MASE to evaluate the forecasts. Moreover, authors also do not show whether the result differences are statistically significant (showing the percentage of improvement is not adequate)\n\n-  My biggest concern is about the computational cost of the proposed framework. This study does not report the overall running time of the MetaLoss and compare it against the classical fixed learning-based models. Without the running times, it is quite difficult to conclude the usability of this framework for more data extensive applications. \n\n[1] https:\/\/forecastingdata.org\/ \n","sentences":[{"sentence_type":"1","sentence":"This raises doubts over the extensibility of the proposed framework, whether MetaLoss can be used to train with other prediction architectures such as RNN, CNN, and tree based regressors such as LightGBM.","rephrased":"It would be beneficial for the authors to explore the extensibility of the proposed framework by evaluating whether MetaLoss can be integrated with other prediction architectures such as RNN, CNN, and tree-based regressors like LightGBM."},{"sentence_type":"2","sentence":"Moreover, authors have not mentioned about the hyper-parameter ranges used to train the DNN and nor the procedure used to fine tune the hyper-parameters (at least using an appendix)","rephrased":"The authors should consider providing details on the hyper-parameter ranges used to train the DNN and the procedure for fine-tuning these hyper-parameters, potentially in an appendix for clarity."},{"sentence_type":"1","sentence":"My biggest concern is about the computational cost of the proposed framework. This study does not report the overall running time of the MetaLoss and compare it against the classical fixed learning-based models. Without the running times, it is quite difficult to conclude the usability of this framework for more data extensive applications.","rephrased":"An important aspect to consider is the computational cost of the proposed framework. It would be helpful if the study included the overall running time of MetaLoss and a comparison with classical fixed learning-based models to better assess its usability for data-intensive applications."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[646,850,"Not concerning"],[1267,1448,"Not concerning"],[2565,2907,"Not concerning"]],"Comments":[]}
{"id":"H1SAHAdlf","text":"This paper introduces a parameter server architecture to improve distributed training of CNNs in the presence of stragglers. Specifically, the paper proposes partial pulling where a worker only waits for first b blocks rather than all the blocks of the parameters. This technique is combined with existing methods such as partial pushing (Pan et. al. 2017) for a partial synchronous SGD method. The method is evaluated with Resnet -50 using synthetic delays.\n\nComments for the author:\n\nThe paper is well-written and easy to follow. The problem of synchronization costs being addressed is important but it is unclear how much of this is arising due to large blocks.\n\n1) The partial pushing method (Pan et. al. 2017, section 3.1) shows a clear evidence for the problem using a real workload with a large number of workers. Unfortunately, in your Figure 2, this is not as obvious and not real since it is using simulated delays. More specifically, it is not clear how the workers behave in a real environment and whether you get a clear benefit from using a partial number of blocks as opposed to sending all of them. \n\n2) Did you modify your code to support block-wise sending of gradients (some description of how the framework was modified will be helpful)? The idea is to send partial parameter blocks and when 'b' blocks are received, compute the gradients. I feel that, with such a design, you may actually end up hurting the performance by sending a large number of small packets in the no failure case. For real, large data centers, this may cause a packet storm and subsequent throughput collapse (e.g. the incast problem). You need to show the evidence that you do not hurt the failure-free case for a large number of workers.\n\n3) The evaluation is on fairly small workloads (CIFAR-10). Again, evaluating over Imagenet and demonstrating a clear speedup over existing sync methods will be helpful. Furthermore, a clear description of your “pull” configuration (such as in Figure 1) i.e. how many actual bytes or blocks are sent and what is the threshold will be helpful (beyond a vague 90%).\n\n4) Another concern with partial synchronization methods that I have is that how do you pick these configurations (pull 0.75 etc). These appear to be dataset specific and finding the optimal configuration here requires significant experimentation that takes significantly more time than just running the baseline.\n\nOverall, I feel there is not enough evidence for the problem specifically generating large blocks of gradients and this needs to be clearly shown. To propose a solution for stragglers, evaluation should be done in a datacenter environment with the presence of stragglers (and not small workloads with synthetic delays). Furthermore, the proposed technique despite the simplicity appears as a rather incremental contribution.","sentences":[{"sentence_type":"2","sentence":"Unfortunately, in your Figure 2, this is not as obvious and not real since it is using simulated delays.","rephrased":"In Figure 2, the impact of simulated delays is less clear. It would be beneficial to include results from real-world scenarios to strengthen the evidence."},{"sentence_type":"2","sentence":"I feel that, with such a design, you may actually end up hurting the performance by sending a large number of small packets in the no failure case.","rephrased":"There is a concern that the design might lead to performance degradation due to the transmission of numerous small packets in scenarios without failures."},{"sentence_type":"2","sentence":"Overall, I feel there is not enough evidence for the problem specifically generating large blocks of gradients and this needs to be clearly shown.","rephrased":"It would be helpful to provide more evidence to demonstrate the specific issue of generating large blocks of gradients."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[821,925,"Not concerning"],[1360,1507,"Not concerning"],[2413,2559,"Not concerning"]],"Comments":[]}
{"id":"HflJ5HCmeq","text":"Scope of reproducibility\n\nThe report presents clearly the scope of reproducibility and adheres to it.\n\nCode\n\nThe code of the original author is re-used. The code is submitted with an extension of how\ndo the authors perform the pre-processing the datasets.\n\nCommunication with original authors\n\nThere is no direct contact between the authors and the original authors.\n\nHyperparameter Search\nThe authors use the hyperparameters as described in the original paper.\n\nDiscussion on results\n\nThe reproduction results are discussed clearly. The easy and difficult parts in the\nreproducing are clearly presented.\n\nRecommendations for reproducibility\n\nThe authors mention that recreating the datasets (to obtain similar results) requires several\nassumptions.\n\nResults beyond the paper \n\nThere is no extra results beyond the original paper.\n\nOverall organization and clarity\n\nThe writing is good.\n\n","sentences":[{"sentence_type":"1","sentence":"There is no direct contact between the authors and the original authors.","rephrased":"Direct contact with the original authors was not reported, which could be an opportunity for further clarification if needed."},{"sentence_type":"1","sentence":"There is no extra results beyond the original paper.","rephrased":"The study focuses on reproducing the results of the original paper and does not include additional results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[294,366,"Not concerning"],[778,830,"Not concerning"]],"Comments":[]}
{"id":"RGHl3VkbIR9","text":"## Summary\nThe paper is concerned with the fundamental problem of whether concepts of the real world can be understood (exclusively) from text descriptions.\nIn particular the authors argue against the position presented in \"Climbing towards NLU: On meaning, form, and understanding in the age of data\" (Bender and Koller [2020]), in which it is argued that learning systems a priory cannot learn meaning of real-world concepts from text corpora.\nBender and Koller argue, e.g., with the example of the \"octopus test\", that learning the use of the word \"coconut\" and its relations from text correlation does not help an intelligent agent in identifying a coconut in the real world as there is no mapping from the textual concept to the real world entity or its related real world concepts. The authors argue that by such logic we would not be able to understand abstract or impossible concepts (e.g., \"contract\" \/ \"perpetual motion machines\") as there is no real world reference, while humans clearly do think of, and understand the meaning of such concepts.\nThe authors discuss the conceptual role theory in the context of LLMs (and other learning systems) and argue that the meaning of concepts is not only defined by observing correlation of the same concept across different modes (text+visual), but rather by the embedding of a concept (e.g., via church-encodings) into a network of related concepts within their domain.\n\n\n## Relevance\nThe paper is relevant to the workshop as it discusses the fundamental question of whether machines can learn meaning about real world concepts from textual descriptions without collecting additional experience e.g., in the form of images. The discussion relates closely to the task of (causal) structure discovery and discusses the conditions under which machine learning systems may be able to learn meaningful concepts by relating those concepts to each other and across domains.\n\n\n## Related work\nWhile I'm not familiar with the field of conceptual role theory the paper seems to thoroughly consider and discuss relevant literature throughout the paper.\n\n\n## Strengths\n* The authors extended the definition by which meaning has to be observed from correlations over different modes of presentation. Their novel extended definition allows the identification of meaning from the embedding structure of their related concepts, which overcomes the criticism of non-identifiability from the initial, purely correlational, definition.\n* The authors convincingly argue that projections into lower dimensional representations, e.g. onto time series, allow an agent to identify concepts by the structure of their embeddings across modes of presentation.\n\n\n## Weaknesses\n* While the authors provide a thorough discussion the paper might benefit from formalizing the discussed topics. This would help to analyze the specific preconditions needed to allow or prevent concept identification across different modes. In this context the authors might also consider connections to ideas in [1] and [2].\n* While the authors provide a novel way of defining and identifying meaning in the context of LLMs it would be helpfull if the authors could provide an exemplary proof of identifying in the octopus example.\n* The conclusion contains an unjustified generalization: \"people are happy to think [...] often don't know many details\" - which I consider to be vague and unsubstantiated. \"happy to think\" implies naivety, while \"often don't know many details\" is a vague and unproven statement. I would recommend to tone down this particular statement. For example, the authors might consider to restrict their criticism to the specific set of reviewed papers; and might want to list the specific missing \"details\", which in the first place seem to be a too narrow definition of reference in comparison to their papers' definition.\n\n\n## Conclusion\nThe authors convincingly argue that concept identification across different modes of observation is possible by taking advantage of shared representations in meta-level domains, such time-series or logic, to recover conceptual role. They further argue that using structure recovery methods allows the reconstruction of concepts from their lower-dimensional projections and match them across different modes of observation. While these results may hold in general between arbitrary domains, the authors specifically discuss the implications for LLMs of learning the meaning of real-world concepts from text representation. While the paper could benefit from a more formal definition of the proposed concepts I consider the presented work a valuable addition to the workshop as well as to the general debate about whether MLs\/LLMs are capable of developing understanding of the real-world from text.\n\n\n[1] Gresele, Luigi, et al. \"Causal inference through the structural causal marginal problem.\" *International Conference on Machine Learning*. PMLR, 2022.\n\n[2] Pfister, Niklas, and Jonas Peters. \"Identifiability of Sparse Causal Effects using Instrumental Variables.\" *arXiv preprint arXiv:2203.09380* (2022).","sentences":[{"sentence_type":"2","sentence":"The conclusion contains an unjustified generalization: \"people are happy to think [...] often don't know many details\" - which I consider to be vague and unsubstantiated. \"happy to think\" implies naivety, while \"often don't know many details\" is a vague and unproven statement.","rephrased":"The conclusion may benefit from a more precise articulation to avoid potential generalizations. For instance, the phrase \"people are happy to think [...] often don't know many details\" could be perceived as overly broad. A more focused critique, perhaps limited to the scope of the reviewed papers and supplemented with specific examples of the details in question, would strengthen this part of the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[3238,3515,"Maybe"]],"Comments":[]}
{"id":"HkekzXkbqV","text":"The paper proposes to use semantic hierarchies to estimate distance metrics between sample labels instead of the standard 0\/1 similarity values. The semantic distance is used as an additional supervision signal to regularize deep nets.\n\nThe topic is relevant and the paper could of interest to the workshop attendees. The approach is intuitive, described well, and the experimental results seem to be comprehensive (for the CIFAR-100 and ImageNet datasets they were carried on). It's also nice to see authors including an ablation study for their method.","sentences":[{"sentence_type":"1","sentence":"The paper could of interest to the workshop attendees.","rephrased":"The paper could be of interest to the workshop attendees."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"HyeKi-nlcH","text":"\n=== Summary ===\n\nThe authors motivate the development of new (automatic) metrics to evaluate language generation by using similarity with a given reference: standard metrics like BLEU, ROUGE or METEOR have been shown to have poor correlation with human judgment on a number of tasks and are vulnerable to changes in word re-ordering, semantics-changing word replacement, and syntactic transformations.\n  \nThey then propose a multi-dimensional evaluation criteria to evaluate sentence similarity based on semantic similarity (something that correlates with human judgments of the same), logical equivalence and fluency.\n  \nThe paper then goes on to describe possible directions to tackle several key problems in evaluation: evaluating semantic similarity by using models trained on the GLUE benchmark, evaluating logical equivalence using models trained on the MNLI corpus and fluency based on the CoLA corpus.\n\n=== Decision ===\n\nThe problem this paper seeks to tackle is clearly one of great\nimportance in the field, but I find it hard to argue that this paper\nsignificantly contributes to the existing body of work (more on this\nbelow) and as a result I vote to reject this paper.\n\nThere are two possible contributions for this paper: a set of criteria for what makes a good evaluation metric and the concrete proposals to implement these criteria.\n  \nFor the first, I find the proposed criteria to be overly generic and not helpful at providing additional clarity on what makes for a good evaluation: for example, how is semantic similarity different from logical consistency? Does it make sense to compare the semantic similarity of two sentences if one of them isn't even near grammatical? A lot of prior work already argue the shortcomings of the existing metrics this paper is making, e.g. Conroy and Dang (2008), Liu et al. (2016), Novikova et al. (2017). I think it would be valuable to present new axes to decompose the evaluation problem, but more work is needed to clarify and develop the axes presented in this paper.\n  \nFor the second possible contribution, the idea of evaluating language generation along dimensions is not novel and in fact quite standard in the NLP community. The challenge has been showing that there are subset of tasks that can be used a reliable metrics across different domains and systems. Unfortunately, this paper does not actually evaluate its own proposals, making it hard to evaluate how effective its proposals are.  \n","sentences":[{"sentence_type":"2","sentence":"but I find it hard to argue that this paper significantly contributes to the existing body of work (more on this below) and as a result I vote to reject this paper.","rephrased":"While the paper addresses an important issue, it would benefit from a more distinct contribution to the existing body of work to support a stronger case for acceptance."},{"sentence_type":"2","sentence":"For the first, I find the proposed criteria to be overly generic and not helpful at providing additional clarity on what makes for a good evaluation","rephrased":"The proposed criteria could be further refined to provide more clarity and specificity on what constitutes a good evaluation metric."},{"sentence_type":"2","sentence":"Unfortunately, this paper does not actually evaluate its own proposals, making it hard to evaluate how effective its proposals are.","rephrased":"To strengthen the paper, it would be beneficial if the authors could include an evaluation of their proposals to demonstrate their effectiveness."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1354,1502,"Not concerning"],[2330,2461,"Confirmed"]],"Comments":[]}
{"id":"vUA1ZVK46Nb","text":"the paper is presents a study in which 3 different 3D object manipulation techniques are presented. While the task of 3D object manipulation is obviously important, the paper contains numerous flaws. Plain manipulation could be a 5 DoF task (when the plane is finite). However, the metrics for accuracy used in the paper do not consider the fact that the task involves essentially a disk (at least, it's not clear of the centre of the disk needs to be close to the centre of the cube); this effectively makes the task 4DoF. The metrics chosen - \"accuracy\" - are rather non-standard. Euclidean distance normalized to object width\/screen width, or similar, could be used as a distance error (rather than the \"accuracy\") metric. The angle between two vectors could then be used as the other error metric.\n\nNow, if the task is a 4DoF, does the benefit of using a 3D manipulation device still apply? Why was mouse not considered as an alternative (using the best mouse-based technique found for a similar task)? Also, if input noise is a factor, was filtering ever considered (e.g., even as simple as just averaging 10 samples)?\n\nThe stats tests are presented in a fashion different from the accepted practice (Figure 4): e.g., for p values below some chosen threshold (0.05, 0.001, etc.) one reports them as \"p < .05\" (the leading zero is optional here)\n\nSome of the data in the graphs is probably unnecessary (e.g, the interaction count).\n\nGreek letters gamma and epsilon (and others) should be typeset accordingly. >= and x instead of a proper multiplication symbol look unprofessional.\n\nUnfortunately, the paper contains too many flaws for me to be able to recommend for its acceptance.","sentences":[{"sentence_type":"2","sentence":"Unfortunately, the paper contains too many flaws for me to be able to recommend for its acceptance.","rephrased":"While the paper has several areas that need improvement, I believe that addressing these issues could enhance the paper's potential for acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1586,1685,"Not concerning"]],"Comments":[]}
{"id":"r1ewN1AsYH","text":"UPDATE: I appreciate the authors' discussions and qualitative results. My main original concern was that the empirical evaluation only studies a single type of situation of inferring physical parameters. Given that the authors claim that the proposed method infers \"on the fly\" physical properties, I would expect that the authors demonstrate the the method works on other physical properties as well beyond just one setting. Because this concern was not sufficiently addressed, I maintain my original rating.\n\n----\nSummary: This paper tackle the question of learning to infer physical parameters of a novel physical scenario with which to predict future motion of objects. In particular, the authors propose a meta-learning framework for inferring parameters of physical objects from a few video observations of physical scenario, with the constraint that physical parameters are not apparent from appearance alone. The authors evaluate the approach on a domain where the learner needs to infer whether balls should pass above, pass below, or bounce off obstacles.\n\nRecommendation: Borderline. The main limitation of the paper is that the empirical evaluation only studies a single type of situation of inferring physical parameters (whether balls should pass above, pass below, or bounce off obstacles) but does not consider other situations for inferring physical parameters for prediction in a new domain. This paper has great potential, but the lack of evaluation on a wider variety of physical phenomena makes it difficult to evaluate the generality of the claims made by this paper. I would highly consider increasing my score if the authors would be able to provide a thorough evaluation of two more types of physical phenomena.\n\nResearch Problem: The research problem this paper tackles is to learn a model of intuitive physics that can learn \"on the fly\" physical properties specific to new environments.\n\nApproach: A meta-network compresses a set of video observations of a scenario using the dynamic image encoding. The meta-network produces context parameters m and a that parameterize the scenario-specific predictor \\hat{Phi} and conditional generator g respectively. The state x is represented with a two-dimensional array. The authors use a perceptual loss as an image reconstruction metric. The author also enforce that the predictions of the state-space predictor and the encoder eta should provide close predictions.\n\nStrengths\n- The meta-learning formalization is an interesting and intuitive contribution.\n- The experiments provide a proof-of-concept of the efficacy of the framework with thorough analysis.\n\nWeaknesses\n- While the work is well-motivated and the experiments provided show a proof-of-concept of the approach with thorough analysis, the paper could be significantly strengthened by considering more domains for inferring physical parameters - simply inferring whether balls will pass above, pass below, or bounce off obstacles is a good first step, but does not provide enough evidence to evaluate the generality of the proposed method to intuitive physics tasks. This I believe is the main limitation of the paper. \n\nQuestions\n- Would the authors be able to provide an empirical study (with qualitative analysis) or theoretical justification to explain the reason why the method can generalize to scenarios with more objects than observed during training? Prior work that does show generalization to more objects explicitly build in the locality constraint (e.g. van Steenkiste 2018) through the network architecture, so it is interesting to see that the proposed method also can generalize similarly.\n\nVan Steenkiste, S., Chang, M., Greff, K., & Schmidhuber, J. (2018). Relational neural expectation maximization: Unsupervised discovery of objects and their interactions. arXiv preprint arXiv:1802.10353.","sentences":[{"sentence_type":"2","sentence":"Because this concern was not sufficiently addressed, I maintain my original rating.","rephrased":"While I acknowledge the authors' efforts to address my concerns, I believe further work is needed to fully demonstrate the method's capabilities, which leads me to maintain my original rating."},{"sentence_type":"1","sentence":"This I believe is the main limitation of the paper.","rephrased":"I consider this to be a significant area for improvement in the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[426,509,"Not concerning"],[3101,3152,"Not concerning"]],"Comments":[]}
{"id":"HJlU9T4ph7","text":"- Summary:\nThis paper considers the problem of learning a GAN to capture a target distribution p_t with only very few training samples from p_t available.\n\n- Good\nAn interesting problem formulation. \nThe proposed approach is not new, but seems to be a sensible and simple solution to the problem formulated in this paper. I would see the contributions of the paper: (1) an interesting problem formulation on how to learn p_t (with a few assumptions) (2) a sensible adaptation of GANs on this problem (with minor modifications to GANs which have been observed\/adopted in many GAN literatures in the last two years)\nThe training appaoches\/tricks are rather straightforward and not new as well.\n\n- Suggestions\nThe main problem of this paper is that it does not provide sufficient results on any real applications that can support its problem&model formulations. \nFor example, in which scenarios would the users of the model need to train a GAN to mimic a target distribution p_t which is a difference of another two distributions (with examples available there but unavailable in p_t)? It would be good to show significant results on real applications to show the problem and the method useful.\n\nTwo applications on semi-supervised classification and adversarial training are discussed. While both seem to be very artificial IMO if considering the used dataset and designed experiments. The results are also not convincing even for the shown two experiments compared to baselines.\n\nNo related works on addressing the similar problems have been discussed nor compared in experiments.\n\n- Theoretical results:\nWhile the authors claim new theoretical results, in fact, I didn't see any contributions here as the theories developed in section 3 are mostly rather straightforward. There have been some similar theories being developed in previous papers where a component in GAN exhibits mixture-modeled forms, such as in TripleGan (Li et al. NIPS'17). So I would not recommend the authors to claim contributions here.\n\n- Writing:\nThe paper does not seem to be polished. It may not be necessary to exceed 8 pages as many spaces in this paper could be easily squeezed (apparently). The organization could be better; Some parts are vague and difficult to understand;  the writing could be improved to be more clearly demonstrate the contributions of this paper. ","sentences":[{"sentence_type":"1","sentence":"The proposed approach is not new, but seems to be a sensible and simple solution to the problem formulated in this paper.","rephrased":"While the proposed approach builds on existing methods, it is a sensible and straightforward solution to the problem formulated in this paper."},{"sentence_type":"1","sentence":"The training appaoches\/tricks are rather straightforward and not new as well.","rephrased":"The training approaches and techniques employed are well-established in the field, which may benefit the reproducibility of the results."},{"sentence_type":"2","sentence":"While both seem to be very artificial IMO if considering the used dataset and designed experiments.","rephrased":"The choice of dataset and design of the experiments could be refined to better represent real-world scenarios."},{"sentence_type":"2","sentence":"The results are also not convincing even for the shown two experiments compared to baselines.","rephrased":"It would be beneficial if the results could be further strengthened, particularly in comparison to existing baselines."},{"sentence_type":"2","sentence":"No related works on addressing the similar problems have been discussed nor compared in experiments.","rephrased":"Including a discussion and comparison with related work on similar problems could enhance the paper's context and relevance."},{"sentence_type":"3","sentence":"So I would not recommend the authors to claim contributions here.","rephrased":"I would suggest the authors to carefully consider the novelty of their theoretical contributions in light of existing literature."},{"sentence_type":"2","sentence":"The paper does not seem to be polished.","rephrased":"Further polishing and editing of the paper could improve its clarity and presentation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[200,321,"Not concerning"],[614,691,"Not concerning"],[1284,1383,"Maybe"],[1384,1477,"Maybe"],[1479,1579,"Not concerning"],[1944,2009,"Not concerning"],[2022,2061,"Not concerning"]],"Comments":[]}
{"id":"t4Gd-Z3BGzq","text":"This paper provides an empirical study of binary weight networks (BWNs), where they find that 1 the commonly adopted scaling factor is not critical 2 there exists a subnetwork that stabiles early in training 3 the 3x3 filters in VGG and ResNets demonstrate a sparse distribution. They combine all the observations and propose a novel quantization algorithm that achieves more aggressive compression than standard BWNs.\n\npros:\n+ I appreciate the careful examination of design and training details of standard BWNs. The identification of a persistent subnetwork and the analysis on the sparse distribution of kernels are particularly interesting.\n\n+ The proposed quantization algorithm is interesting, which has a potential of squeezing more redundancy out of standard BWNs\n\ncons:\n- If I understand correctly, in the proposed algorithm the kernel distribution is only drawn from the last conv layer of the full precision network, which is then shared across all layers when retraining the BWN. This seems a strong assumption and needs to be justified. What's the reason to believe that the selected frequent kernels are shared across different layers?\n\n-In Algorithm 1, W = where(abs(W ) > ∆E, sign(W ), W ) is not motivated and explained well. What's the reasoning of using the threshold when computing the distance to the frequency binary kernels? \n\n-The experimental results seem to be really hard to interpret for me, and this is perhaps the weakest point of the this paper. In particular, Table 1 needs to have proper baselines. This includes the full precision, standard BWN accuracies, as well as controls which allow one to draw comparisons between the proposed algorithm and basic binarization by equating certain quantities. \n\nI suggest the authors work on the suggested improvements which will make this a much stronger contribution.\n\n*****post rebuttal updates*****\nI want to thank the authors for responding to my questions. The additional explanations are indeed helpful for clarifying my first two questions (selection of the binary kernel and the use of ∆E). However, I still have concerns about Table 1 (and Table 2). For example, I have a really hard time interpreting the significance of achieving a 3.2x CR with a loss of 3% (92.3 - 89.2 from VGG-7) in acc with the proposed method (although the paper argues that it's a \"bearable\" loss). Considering that this is the main experiment supporting the efficacy of the proposed quantization algorithm, I think the paper needs more controlled experiments to demonstrate the practical usefulness of the proposed algorithm. As a result I'm keeping my original score and hope the authors can work on the improvements for the next version. ","sentences":[{"sentence_type":"2","sentence":"-The experimental results seem to be really hard to interpret for me, and this is perhaps the weakest point of the this paper.","rephrased":"The experimental results could be presented more clearly, which would strengthen this section of the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1350,1476,"Not concerning"]],"Comments":[]}
{"id":"SJlBb6tZnN","text":"If you state\n\n\"Providing explanations of machine learning is a very ac- tive research field. Several approaches have been proposed for standard supervised learning algorithms.\"  You should cite relevant articles supporting it.\n\nPg 2, 2nd paragraph:  You introduce the concept of \"local\" vs \"global\" explanations without fully defining or discussing them.\n\nI'm a bit confused at the end of the introduction, is the intent of the paper to compare and contrast the variance of explanation generation within the 6 techniques discussed? Or to showcase that explanations are important? Also, in what ways are these algorithms\/techniques going to be tested?\n\nThere was mention of \"intuitive\" explanations, is this tested against a group of Users?\n\nWhy do you display and show Equation (1) but then define a second one in the same paragraph but *don't* define it as Equation (2) ?\n\nDon't use a Figure Caption to explain stuff, define that in the text. Then use the Caption for a Label. \"The 8 sensors of the Rover\" or some such.\n\nAlso, try to keep figures to the top or bottom of a column, not in the middle (see Figure 3)\n\nFigure 3, the description of Figure 3 and the labels used for the two charts leave me very confused. Additionally, the caption is entirely too long again. SubFigures would have greatly helped readability.\n\nThe ending of the paragraph after Figure 3 is confusing to read and would benefit from a re-write. It's very jumbled and feels like its trying to say too many things. Is knowing about a unit test important to the overall reason you want to argue for explanations?\n\nWait.  Why is the problem statement \"In this paper we attempt to...\"  Hidden on page 3 in the middle of a paragraph. This should be known to me in the introduction! I care way more about that sentence than having a walk through of the paper structure -- especially when I'm not even sure of the paper's point yet!\n\nThis leads me to another thing I've been having issue with on these first 3 pages.  The section headings are too generic, I don't understand the flow.  Everything inside the \"test problem\" section is like setup and background to eventually test those 6 methods right?  That isn't actually stated anywhere. Additionally, the motivation behind utilizing the \"Test Problem\" is left for the reader to decipher a bit. Furthermore, if all of this is setup to begin testing things later on -- are these equations really necessary to know about? \n\nFirst Paragraph, 4th Page, Last Sentence. While I understand the intent of this sentence, it alludes to a longer\/deeper conversation that isn't given justice. Avoid the \"We didn't do it that way, cause that's hard.\" Line, allude to future endeavors or discuss the tradeoffs. This sentence seemingly does neither.\n\nFigure 4 needs way more context for me. This isn't intuitive to read at all. Let alone obstacle vs not. Also, *how* does AA Figure 4 confirm Bayesian Rule List explanations?  You just say it does, what's the connection.  Spell it out for me. Please.\n\nGradient Analysis: You discuss this without discussing it. This is starting to feel hand-wavy in its lack of detail. Figure 5 needs a lot of explanation and set-up. I have no idea what the numbers are for or why blue dots have anything to do with the action \"up\".\n\nExplanation Template: Equations, \"...shows that....\" How? Explain this to me.  Why \/ How?\n\nFig 6,7,8 I'm not sure these are all needed as figures. You... barely touch on them or discuss them in text? Are you arguing that these figures are sufficiently descriptive enough on their own? For instance, Fig. 8 you specify your own full grammar, but then move to figure 9 2 sentences later.\n\nConclusion Section: No conversation on follow-up? Ideas to facilitate improvement to one of the plethora of techniques introduced in the paper? An alternative *not* pursued by the paper?  What's the next beat of this research?\n\n\n\nMinor Things: \n  Please number your sections. Easier to reference.\n\n  Using lists and numbering things without breaking it out into new lines isn't the easiest to read at a glance. Either just list the things without numbers, or separate it out.\n\n  The \"overview paragraph\" at the end of the introduction starts as a list of things, then moves to a conversation\/defense of what's in the paper. It is a bit odd, pick one or the other.\n\n  Why is there a reference for saying your robot senses using 8 sensors. This seems odd.\n\n  Figure 2, if you try to reference parts of a Figure make it sub-figures \"Refer to Figure 2a\" as compared to \"Refer to the Left side of Figure 2\". Or just state it as a sentence and not a parenthesized referral.   \n\n  I'm not sure the workshop's view on footnotes, the footnote 1 can just as easily be stated within the paragraph it is relevant to.  This would make it easier to read overall as it is already a busy sentence with the citation in the middle of it. Also, the footnote is on the next line on its own which isn't ideal.\n\n  \"200 Monte Carlo runs... \" Don't start a sentence with a number.\n\n  Why is there no numberings to the equations on the 3rd page if you started numbering the equations on the previous page?\n\n  \"Note that the goal sensor.... \" is a good sentence to showcase how to redo that footnote from above. (Likewise, that could become Footnote 2)\n\n\n  \"... possible weight values to be on too narrow of interval for the the neural network... \"  ??? what?\n\nReferences: Make Sure All Titles Have Proper Capitalization.","sentences":[{"sentence_type":"2","sentence":"Don't use a Figure Caption to explain stuff, define that in the text. Then use the Caption for a Label.","rephrased":"Please provide the explanations in the main text rather than in the figure captions, which should be reserved for labels."},{"sentence_type":"2","sentence":"The ending of the paragraph after Figure 3 is confusing to read and would benefit from a re-write. It's very jumbled and feels like its trying to say too many things.","rephrased":"The paragraph following Figure 3 could be clarified. Consider focusing on the key points to enhance readability."},{"sentence_type":"3","sentence":"Wait.  Why is the problem statement \"In this paper we attempt to...\"  Hidden on page 3 in the middle of a paragraph. This should be known to me in the introduction!","rephrased":"The problem statement, \"In this paper we attempt to...\", would be more effective if presented in the introduction to guide the reader from the outset."},{"sentence_type":"2","sentence":"This leads me to another thing I've been having issue with on these first 3 pages.  The section headings are too generic, I don't understand the flow.","rephrased":"The section headings on the first three pages could be more descriptive to better guide the reader through the flow of the paper."},{"sentence_type":"2","sentence":"First Paragraph, 4th Page, Last Sentence. While I understand the intent of this sentence, it alludes to a longer\/deeper conversation that isn't given justice. Avoid the \"We didn't do it that way, cause that's hard.\" Line, allude to future endeavors or discuss the tradeoffs.","rephrased":"The last sentence of the first paragraph on the fourth page could be improved by either discussing the trade-offs or suggesting future research directions, rather than dismissing an approach as too difficult."},{"sentence_type":"3","sentence":"Gradient Analysis: You discuss this without discussing it. This is starting to feel hand-wavy in its lack of detail.","rephrased":"The section on Gradient Analysis would benefit from more detailed discussion to fully convey the methodology and findings."},{"sentence_type":"2","sentence":"Conclusion Section: No conversation on follow-up? Ideas to facilitate improvement to one of the plethora of techniques introduced in the paper? An alternative *not* pursued by the paper?  What's the next beat of this research?","rephrased":"In the conclusion section, it would be valuable to include discussions on potential follow-up work, ideas for improving the techniques introduced, or alternatives that were not explored in the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[874,977,"Maybe"],[1322,1488,"Maybe"],[1587,1751,"Confirmed"],[1902,2052,"Confirmed"],[2442,2716,"Maybe"],[3007,3123,"Confirmed"],[3659,3885,"Confirmed"]],"Comments":[]}
{"id":"tWg5U7RfeC","text":"I actually reviewed the journal version of this. It's an excellent paper which highlights the very important role that traditional feature based computer vision still has in medical imaging. Especially for tracking and comparing cortical features which deep learning is yet to prove it can do.\n\nMinor comments:\n\nI don't think the abstract does a good job of highlighting the key impact of the method. There is a lot of technical jargon. I would recommend re-summarising in plain english. In general the abstract is lacking a high level description of the motivations and the approach.","sentences":[{"sentence_type":"1","sentence":"I don't think the abstract does a good job of highlighting the key impact of the method.","rephrased":"The abstract could be improved to more effectively highlight the key impact of the method."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[312,400,"Not concerning"]],"Comments":[]}
{"id":"rJxr_fmNFS","text":"This paper builds a new graph convolutional network (GCN) based on hyperbolic representations of the graph nodes: all latent representations of the nodes are points on Poincare disks. The authors adapted the Hyperbolic Neural Networks by Ganea et al. (2018) into the Kipf & Welling's (2016) version of GCN. Specifically, the authors variated the right matrix multiplication in GCN with Ganea et al.'s Mobius matrix-vector multiplication (that can be regarded as a transformation between two Poincare disks). Moreover, as a non-trivial adaptation, the author defined the left matrix multiplication in GCN (that can be regarded as a weighted linear combination of several points on the same Poincare disk) with Ungar's (2010) weighted barycenter, which is from computational geometry but not the machine learning community. The resulting method is tested on a toy problem and semi-supervised node classification of commonly used datasets, showing the possibility of improvement.\n\nThis is a practical contribution but not a theoretical contribution, as there is no main theorem (or equivalent statements), and the main novelty is on using Ungar's (2010) weighted barycenter to perform neighborhood features aggregations. There are some general discussions on how to adapt gyrovector space theory into spherical spaces. This is interesting but no formal results are presented.\n\nI vote for rejection for four major weaknesses explained as follows.\n\n(1) The experimental results cannot show the usefulness of the proposed GCN. The results on real datasets are similar to the regular GCN. As the authors themselves remarked, \"it can be seen that our models sometimes outperform the two Euclidean GCN\". The experimental settings, e.g. how the train:test datasets are split, and hyperparameter settings, are not clearly given.\n\n(2) The method is not well motivated. The motivation, based on the writing, is that constant curvature spaces are more general where the computation is easy to handle. This is too general and not enough as a motivation. After reading, the reviewer cannot understand why the user should bother to use hyperbolic representations that are more complex to compute in GCNs, given that the experimental results are roughly the same.\n\n(3) A large body of graph neural network literature is omitted. The authors start from a very high-level description of machine learning in constant curvature spaces. Such high-level introductions require more comprehensive literatures to support. In the first mentioning of Graph Neural Networks, the authors only cited Kipf & Welling's GCN. This is misleading. For example, the original GNN, ChebNet, etc. that leads to GCN can be mentioned. The reviewer recommends the authors to read some literature review of the topic of GCN and re-organize the references, and use search engines to have a better view on the state of the art of (hyperbolic) geometric theories and graph convolutional networks. This is a thriving area that requires a careful literature review.\n\n(4) The writing quality is not satisfactory. Here are a few examples: The ICLR citation style needs to use sometimes \\citep. The authors instead used \\cite everywhere, making the paper hard to read. The authors are suggested to use unified notations to denote vectors\/matrices (e.g. all bold). The introduction can start at a lower level (such as flat\/hyperbolic neural networks). Section 3.4, as the main technical innovation, can be extended and includes some demonstrations.","sentences":[{"sentence_type":"2","sentence":"I vote for rejection for four major weaknesses explained as follows.","rephrased":"I recommend reconsideration of the paper based on four areas of concern that I will explain below."},{"sentence_type":"2","sentence":"The experimental results cannot show the usefulness of the proposed GCN.","rephrased":"The experimental results could be strengthened to better demonstrate the effectiveness of the proposed GCN."},{"sentence_type":"2","sentence":"The method is not well motivated.","rephrased":"The motivation for the method could be more clearly articulated."},{"sentence_type":"2","sentence":"The writing quality is not satisfactory.","rephrased":"The writing quality could be improved for better clarity and adherence to citation style guidelines."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1374,1442,"Not concerning"],[1448,1520,"Not concerning"],[1823,1856,"Not concerning"],[3020,3060,"Maybe"]],"Comments":[]}
{"id":"PqDj8vxIQCj","text":"\nThe findings of this work are that for contrastive learning, most of the negatives deemed easily separable are unnecessary, the most important negatives are somewhere in the top 5% closest to the positive sample, and that some of the exceedingly hard examples are detrimental.\n\n-In general, I felt the main findings of this work to be roughly in line with what we already know about contrastive learning. We can easily look at this work's findings with respect to the soft SVM margin, in that only the examples close to the decision boundary should matter (max margin), but some difficult examples  (the aforementioned exceedingly difficult ones) make the data inseparable, so we allow some violation (slack terms).  While I'm not suggesting that slapping a soft SVM here would solve the problem, there is a large body of SVM-based detection\/classification literature that precedes the findings of this work.\n\n-Validity of WordNet as a measure of semantic similarity: Section 4 uses WordNet distances to estimate the semantic similarities between classes by finding their shared subtree root. The deeper the subtree, the more semantically similar. While I do not dispute the claim of the hardest negatives being from semantically similar classes. Different parts of the WordNet synset tree have semantic hierarchies of varying levels of coarseness. A 2 hop distance in one subtree could easily be more of a semantic jump than a 3 hop distance in another. \n\n-The exist prior works dealing with the neglected semantic hierarchies in ImageNet by setting up hierarchical classifiers. An example is [1].\n\n-I would further argue that there's some nuance in the correlation between semantic similarity and example hardness, in that it really depends on your choice of feature representation. Visual features will naturally correlate with closer semantic levels in visually-defined categories. However, this will not necessarily hold for semantic categories defined by function, in that two visually distinct items may fall under close semantic labels. \n\n-The related works section claims object detection works have not \"explicitly involved negative examples as in CID.\" I have to imagine this statement is poorly phrased, as [2] (also cited in this paragraph) very explicitly mines for  face-like non-face patterns. There is a very long list of hard-negative mining works in object detection.\n\nOverall, I value the empirical impact of this work, in that the rather detailed analysis may lead to improvements to future versions of the contrastive feature learning task. However, I do not find the findings of this work to be sufficiently novel for this conference, and therefore cannot recommend this work for acceptance in its current state.\n\n\n\n[1] Yan et al. HD-CNN: Hierarchical Deep Convolutional Neural Networksfor Large Scale Visual Recognition. ICCV 2015\n\n[2] Sung and Poggio. Example-Based Learning for View-Based Human Face Detection. TPAMI 1998","sentences":[{"sentence_type":"2","sentence":"While I'm not suggesting that slapping a soft SVM here would solve the problem, there is a large body of SVM-based detection\/classification literature that precedes the findings of this work.","rephrased":"While the application of a soft SVM may not directly address the issue, it's important to consider the extensive literature on SVM-based detection\/classification that predates this work."},{"sentence_type":"2","sentence":"I have to imagine this statement is poorly phrased, as [2] (also cited in this paragraph) very explicitly mines for face-like non-face patterns.","rephrased":"The statement regarding object detection works might benefit from clarification, as reference [2], which is cited here, does explicitly involve mining for face-like non-face patterns."},{"sentence_type":"2","sentence":"However, I do not find the findings of this work to be sufficiently novel for this conference, and therefore cannot recommend this work for acceptance in its current state.","rephrased":"While the findings provide valuable insights, I believe that further innovation may be necessary to meet the novelty criteria of this conference for acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[718,909,"Not concerning"],[2564,2736,"Maybe"]],"Comments":[]}
{"id":"3H_24Hc0HmT","text":"1. What is the goal of the paper? If the goal is to present a dataset that is about misinformation -- it is not simply enough to create a contradictory passages. This is just another way of distracting a QA model but without having any reason for it to believe the information is \"fake\". In order for something to be \"fake\", there has to be some ground-truth known. The experiment called Contra-QA appears to be flawed given what it was supposed to check. How is a model expected to learn which passage is real? It has to be grounded in something that it can rely on for evidence isn't it? Would human beings know if something is fake unless there are also aware of what a \"trustworthy\" source says? Perhaps the authors can elaborate further (in case I have badly misunderstood the work). \n\n2. Similarly, if you add contradictory information to passages for a span-based QA model its no surprise it gets confused. Neither are those models trained to not respond in the presence of contradictory information nor are they being told which passage is real (the trust-score is truly not a trust-score -- it is just the output of a model that  frankly appears to be guessing because it has no way of knowing what is trustworthy!). \n\n3. What could perhaps have been interesting is to also see if a model could \"detect\" contradictions and says, that it should not answer. This is a model that you can easily train with this data and perhaps the only thing meaningful I can think of doing with this dataset without having any access to methods that tell the system what is \"real\". \n\nI found the methods for generating contradictory passages novel and interesting and could find more general use in other tasks related to dataset augmentation. That limited contribution, however is not enough to accept this paper in its current form.  ","sentences":[{"sentence_type":"2","sentence":"This is just another way of distracting a QA model but without having any reason for it to believe the information is \"fake\".","rephrased":"The paper could benefit from a clearer explanation of how the dataset challenges QA models with misinformation, ensuring there's a rationale for the model to identify information as \"fake\"."},{"sentence_type":"2","sentence":"The experiment called Contra-QA appears to be flawed given what it was supposed to check.","rephrased":"The design of the Contra-QA experiment may need to be revisited to align more closely with its intended objectives."},{"sentence_type":"2","sentence":"it is just the output of a model that frankly appears to be guessing because it has no way of knowing what is trustworthy!","rephrased":"The model's output could be perceived as uncertain, which suggests a need for a more robust method of establishing trustworthiness in the data."},{"sentence_type":"2","sentence":"That limited contribution, however is not enough to accept this paper in its current form.","rephrased":"While the contribution is noteworthy, further development may be necessary to meet the criteria for acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[162,287,"Not concerning"],[366,455,"Not concerning"],[1735,1825,"Not concerning"]],"Comments":[]}
{"id":"DmxXopoAnQu","text":"The paper provides a data-driven approach to the selection of sampling points for compressive sensing. This is not a new problem, and has been studied for a while now. There is a large literature on it. For example, see below, references within and papers citing those:\n- L. Baldassarre, Y. Li, J. Scarlett, B. Gözcü, I. Bogunovic and V. Cevher, \"Learning-Based Compressive Subsampling,\" in IEEE Journal of Selected Topics in Signal Processing, vol. 10, no. 4, pp. 809-822, June 2016, doi: 10.1109\/JSTSP.2016.2548442.\n- Gözcü, Baran, et al. \"Learning-based compressive MRI.\" IEEE transactions on medical imaging 37.6 (2018): 1394-1406.\n- Bahadir, Cagla Deniz, Adrian V. Dalca, and Mert R. Sabuncu. \"Learning-based optimization of the under-sampling pattern in MRI.\" International Conference on Information Processing in Medical Imaging. Springer, Cham, 2019.\n\nThe authors propose a relatively ad hoc relaxation of the problem to a continuous set instead of an index and then perform the selection there. However, there is no discussion on how this relaxed problem is in fact quite non-convex and how this choice of relaxation introduces a significant number of local minima. The comparison the authors offer is with very simplistic algorithms, rather than the more sophisticated ones in the literature.\n\nOverall, this is an interesting approach that I think deserves to be eventually published. However, the paper needs significant work and comparison with the state of the art in the literature.","sentences":[{"sentence_type":"2","sentence":"The authors propose a relatively ad hoc relaxation of the problem to a continuous set instead of an index and then perform the selection there.","rephrased":"The authors propose an innovative relaxation of the problem to a continuous set rather than a discrete index, which is an interesting approach, but it would be beneficial to discuss the potential challenges such as the introduction of non-convexity and local minima."},{"sentence_type":"2","sentence":"However, there is no discussion on how this relaxed problem is in fact quite non-convex and how this choice of relaxation introduces a significant number of local minima.","rephrased":"It would be constructive to include a discussion on the non-convex nature of the relaxed problem and how the chosen relaxation could lead to a significant number of local minima, which is important for understanding the full scope of the approach."},{"sentence_type":"2","sentence":"The comparison the authors offer is with very simplistic algorithms, rather than the more sophisticated ones in the literature.","rephrased":"For a more comprehensive evaluation, it would be advantageous if the authors could compare their method with the more sophisticated algorithms that are present in the current literature."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[860,1003,"Not concerning"],[1004,1174,"Not concerning"],[1175,1302,"Not concerning"]],"Comments":[]}
{"id":"S1crSKYgM","text":"The paper introduces a generative model for graphs. The three main decision functions in the sequential process are computed with neural nets. The neural nets also compute node embeddings and graph embeddings and the embeddings of the current graph are used to compute the decisions at time step T. The paper is well written but, in my opinion, a description of the learning framework should be given in the paper. Also, a summary of the hyperparameters used in the proposed system should be given. It is claimed that all possible types of graphs can be learned which seems rather optimistic. For instance, when learning trees, the system is tweaked for generating trees. Also, it is not clear whether models for large graphs can be learned. The paper contain many interesting contributions but, in my opinion, the model is too general and the focus should be given on some retricted classes of graphs. Therefore, I am not convinced that the paper is ready for publication at ICLR'18.\n\n* Introduction. I am not convinced by the discussion on graph grammars in the second paragraph. It is known that there does not exist a definition of regular grammars in graph (see Courcelle and Engelfriet, graph structure and monadic second-order logic ...). Moreover, many problems are known to be undecidable. For weighted automata, the reference Droste and Gastin considers weighted word automata and weighted logic for words. Therefore I does not seem pertinent here. A more complete reference is \"handbook of weighted automata\" by Droste. Also, many decision problems for wighted automata are known to be undecidable. I am not sure that the paragraph is useful for the paper. A discussion on learning as in footnote 1 shoud me more interesting.\n* Related work. I am not expert in the field but I think that there are recent references which could be cited for probablistic models of graphs.\n* Section 3.1. Constraints can be introduced to impose structural properties of the generated graphs. This leads to the question of cheating in the learning process.\n* Section 3.2. The functions f_m and g_m for defining graph embedding are left undefined. As the graph embedding is used in the generating process and for learning, the functions must be defined and their choice explained and justified.\n* Section 3. As said before, a general description of the learning framework should be given. Also, it is not clear to me how the node and graph embeddings are initialized and how they evolve along the learning process. Therefore, it is not clear to me why the proposed updating framework for the embeddings allow to generate decision functions adapted to the graphs to be learned.  Consequently, it is difficult to see the influence of T. Also, it should be said whether the node embeddings and graph embeddings for the output graph can be useful.\n* Section 3. A summary of all the hyperparameters should be given.\n* Section 4.1. The number of steps is not given. Do you present the same graph multiple times. Why T=2 and not 1 or 10 ?\n* Section 4.2. From table 2, it seems that all permutations are used for training which is rather large for molecules of size 20. Do you use tweaks in the generation process.\n* Section 4.3. The generation process is adapted for generating trees which seems to be cheating. Again the choice of T seems ad hoc and based on computational burden.\n* Section 5 should contain a discussion on complexity issues because it is not clear how the model can learn large graphs.\n* Section 5. The discussion on the difficulty of training shoud be emphasized and connected to the --missing-- description of the model architecture and its hyperparameters.\n* acronyms should be expansed at their first use","sentences":[{"sentence_type":"2","sentence":"It is claimed that all possible types of graphs can be learned which seems rather optimistic.","rephrased":"The claim that the model can learn all possible types of graphs is ambitious and may benefit from further clarification or evidence."},{"sentence_type":"2","sentence":"Therefore, I am not convinced that the paper is ready for publication at ICLR'18.","rephrased":"Therefore, I believe the paper could be strengthened before it is ready for publication at ICLR'18."},{"sentence_type":"2","sentence":"The paper contain many interesting contributions but, in my opinion, the model is too general and the focus should be given on some retricted classes of graphs.","rephrased":"While the paper contains many interesting contributions, I suggest that the model could be more impactful by focusing on specific classes of graphs."},{"sentence_type":"2","sentence":"I am not sure that the paragraph is useful for the paper.","rephrased":"It may be beneficial to reconsider the relevance of this paragraph to the paper's overall objectives."},{"sentence_type":"2","sentence":"This leads to the question of cheating in the learning process.","rephrased":"This raises questions about the integrity of the learning process that may need to be addressed."},{"sentence_type":"2","sentence":"The generation process is adapted for generating trees which seems to be cheating.","rephrased":"The generation process appears to be specifically tailored for generating trees, which could be perceived as lacking generality."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[499,592,"Not concerning"],[742,902,"Not concerning"],[903,984,"Not concerning"],[1610,1667,"Not concerning"],[1985,2048,"Maybe"],[3213,3295,"Not concerning"]],"Comments":[]}
{"id":"BJljG_pfqV","text":"This paper proposes a version of normalizing flows applicable to discrete data. The authors motivate this idea in two ways: (1) autoregressive models that are bidirectional, and (2) non-autoregressive likelihood-based models of discrete data. They show that flows on discrete data do not need an expensive log-det-Jacobian step. However, they require a function mapping from discrete variables to discrete variables. As such a function is not directly differentiable, this paper uses a straight-through gradient estimator.\n\nThis is an interesting idea but is not that well fleshed out. A more thorough discussion of calculating gradients through the discrete outputs of their neural networks seems in order. Additionally, the experiments shown are on very small toy data.\n\nPros:\n- Interesting idea\n- Clear, no-nonsense writing\n\nCons:\n- No experiments on real data \n- Straight-through estimator seems limiting (e.g. not sure how it applies to non-ordinal data)\n","sentences":[{"sentence_type":"2","sentence":"This is an interesting idea but is not that well fleshed out.","rephrased":"This is an interesting idea, but it would benefit from further development and a more detailed exploration."},{"sentence_type":"2","sentence":"Additionally, the experiments shown are on very small toy data.","rephrased":"Additionally, it would be valuable to see the experiments conducted on larger, more complex datasets to better understand the scalability and applicability of the approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[524,585,"Not concerning"],[708,771,"Not concerning"]],"Comments":[]}
{"id":"gMS2M8y83g","text":"Summary: the paper presents an interesting framework for single-subject analysis. Patients should be seen as 'anomalies' with respect to a normative model. The method is tested on white matter tract profiles with interesting and convincing results (even if the number of observations, especially for patients, is rather small).\n\nRemarks: \n1- Authors should better explain what the 20 features per tract represent. Is it as in Cousineau et al. (2017) or as in Chamberland et al. (2019) ? Do they represent average FA in the tract profile ? As authors have mentioned in the conclusions, it would also be interesting to inspect the robustness of the results with respect to this hyper-parameter (number of features per tract). This should be considered indeed as future work.\n2- How are the anomaly thresholds chosen in Fig. 1 ? Please clarify.\n3- In Fig. 3, authors show the R0 profile of a CNV patient which highlights discrepancies in the association tracts. What about the other patients and controls ? Is this R0 profile an actual outlier with respect to the profiles of the controls ? Please clarify.","sentences":[{"sentence_type":"1","sentence":"Patients should be seen as 'anomalies' with respect to a normative model.","rephrased":"The paper proposes viewing individual patient data as deviations from a normative model, which could be a valuable perspective for single-subject analysis."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[82,155,"Not concerning"]],"Comments":[]}
{"id":"SJlOnavpqB","text":"This paper proposed an unsupervised method to make better usage of the inconsistent longitudinal data by minimizing the ratio of Principal Components Analysis and Locality Preserving Projections.\n\nComments:\n1. It is out of the area of my expertise, but the innovation of combining the PCA and LPP to produce the dimensionally reduced representation of the longitudinal data seems not significant enough, especially when the author did not mention why they chose these two methods out of all the available projection\/hashing approaches.\n\n2. The paper is poorly written. Theorem 1 and Theorem 4 state the opposite conditions for v. Theorem  2 and Theorem 5 are exactly the same. If the same theorem has already been proved by previous work [Wang et al., 2014], it is not necessary to prove it again in this paper. The most important theorem which is claimed as the theoretical contribution of this paper (i.e. Theorem 6) did not even appear in the main contents but only in the appendix. The proof of theorems in appendix, Proof A.1, A.2, A.3 did not state which theorem they are corresponding to and are organized in different order as Theorem 3-5, make it hard to read.\n\n3. There are many grammar errors and sentences which are not consistent with English writing conventions. E.g. “This problem is heavily studied with (Wang et al., 2012; Brand et al., 2018; Lu et al., 2018) as example approaches which, despite their effectiveness, present an added complexity to the problem.” is better written as “This problem is excessively studied by (Wang et al., 2012; Brand et al., 2018; Lu et al., 2018) as example approaches which, despite their effectiveness, present an additional complexity to the problem”; “... to provide value in predicting patients’ diagnosis.” is better written as “... to provide valuable information in ...”; “... , we focus AD diagnosis from MRI scans ...” should be “... , we focus on AD diagnosis from MRI scans ...”; “consider outliers” is better as “handle outliers”; etc. \n\n4. In the sentence below equation (5), “J_LPP\/J_LPP” should be “J_LPP\/J_PCA”. \n","sentences":[{"sentence_type":"2","sentence":"The paper is poorly written.","rephrased":"The paper could benefit from improvements in clarity and structure."},{"sentence_type":"2","sentence":"There are many grammar errors and sentences which are not consistent with English writing conventions.","rephrased":"The paper contains several grammatical errors and could be revised to better adhere to English writing conventions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[540,568,"Not concerning"],[1174,1276,"Not concerning"]],"Comments":[]}
{"id":"SJlMo5m9nm","text":"This paper is poorly written, and looks like it was not proof-read. \nPresentation of the problem at hand is presented over so many times that it becomes confusing.\nAuthors ought to better define the image description space of the objects and the haptic space. \nMore interesting would have been a good explanation of the different sensors used in the anthropomorphic hand  and the vector built to represent the different sensed objects.\nThe most expected contribution of this work is barely explained: how the haptic sensors' values\/object labels vectors were built and fed to the predictor network, what their values looked like for the various objects, how these vectors clustered for the various objects etc.\n\nAmong the many evident weaknesses:\n- Domain specific concepts and procedures of most importance to this work are not explained: \"... measure various physical properties of objects using the bio-tac sensor using five different exploration procedures (EP)\".  Page 3, Paragraph 1. Bio-tac sensor and most importantly exploration procedures (EP) should be presented more clearly.\n- Incomplete and out of nowhere sentences are common: \"The SHAP procedure\nwas established for evaluating prosthetic hands and arms. With this idea in mind, prior work (?)\nbuilt a prosthetic arm which could ...\" Page 4, Paragraph 1.\n- Many references are not well introduced and justified: \"We then trained the network using\nADAM (Kingma & Ba (2014)) with an initial learning rate set to 1e-4.\" Page 4, Paragraph 6. In the same paragraph,  authors explain using \"The groundtruth predictions were per-channel averaged haptic forces\" without having defined those channels (that one can guess but shouldn't). Concepts have to be clearly defined prior to their use.\n\n\n","sentences":[{"sentence_type":"2","sentence":"This paper is poorly written, and looks like it was not proof-read.","rephrased":"The paper could benefit from additional proofreading to enhance its clarity and structure."},{"sentence_type":"2","sentence":"Among the many evident weaknesses:","rephrased":"The paper has several areas that could be strengthened, such as:"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[0,67,"Maybe"],[69,163,"Missed Maybe"],[712,746,"Confirmed"]],"Comments":[]}
{"id":"vXG3_v-WfcH","text":"Strength:\nThis work propose to achieve multi-object position prediction with only using visual information like images without ground truth positions as supervision.\n\nWeakness:\n1 In general, this work is a patchwork of a condition-based generative model and a raw image preprocessing method at the input and output ends, leading to insufficient novelty. \n   1) For key point detection, Jakab et al. (2018) thoughts are followed.\n   2) The initial graph Gt with its nodes and edges is built through widely used operations, e.g., visual+position; distance\n   3) Why the approximate posterior is conditioned on the graph at next step? There is no interpretation, but this design is seem as some condition-VAE-based multi-agent prediction methods [1,2], while the only difference is that existing works infer the agents' dynamics but KINet infers the graph representation.\n   4) The message passing is not novel.\n   5) The forward prediction with a skip connection is not novel.\n\n2 Why do you use the contrastive loss? The interpretation is not clear; why it helps to learn actionable object-centric representation? How to build the negative G-?\n\n3 As for the experiments, I do not think the dataset matches the authors' claim: hard to annotation\/detection and complex scenes.\n   1) The objects and scenes are quite simple. I suggest to test the methods on some real-world dataset like SDD and ETH-UCY, which have top-view image and scene information like obstacles.\n   2) In the proposed dataset, I notice that there are very large `+' object, but the method only determines a few key points for each object. So how to simulate the positional constraints imposed by the shape of an object？\n\n\n\n[1] It Is Not the Journey But the Destination: Endpoint Conditioned Trajectory Prediction (ECCV2020)\n[2] Contextually Plausible and Diverse 3D Human Motion Prediction (ICCV 2021)","sentences":[{"sentence_type":"2","sentence":"In general, this work is a patchwork of a condition-based generative model and a raw image preprocessing method at the input and output ends, leading to insufficient novelty.","rephrased":"While the integration of a condition-based generative model and a raw image preprocessing method is interesting, the paper could benefit from a clearer demonstration of novelty beyond these existing approaches."},{"sentence_type":"2","sentence":"Why the approximate posterior is conditioned on the graph at next step? There is no interpretation, but this design is seem as some condition-VAE-based multi-agent prediction methods [1,2], while the only difference is that existing works infer the agents' dynamics but KINet infers the graph representation.","rephrased":"It would be helpful if the authors could provide a more detailed interpretation of why the approximate posterior is conditioned on the graph at the next step, and how this approach differs significantly from existing condition-VAE-based multi-agent prediction methods."},{"sentence_type":"2","sentence":"The message passing is not novel.","rephrased":"The message passing technique used in the paper appears to be similar to existing methods; it would be beneficial to highlight any unique aspects of your approach."},{"sentence_type":"2","sentence":"The forward prediction with a skip connection is not novel.","rephrased":"The use of forward prediction with a skip connection is a known technique; the authors could strengthen their contribution by discussing any innovative applications or modifications they have made to this method."},{"sentence_type":"1","sentence":"Why do you use the contrastive loss? The interpretation is not clear; why it helps to learn actionable object-centric representation?","rephrased":"Could you please clarify the rationale behind using contrastive loss and how it aids in learning an actionable object-centric representation?"},{"sentence_type":"2","sentence":"As for the experiments, I do not think the dataset matches the authors' claim: hard to annotation\/detection and complex scenes.","rephrased":"Regarding the experiments, it would be helpful if the authors could further justify how the dataset used aligns with their claims of difficulty in annotation\/detection and complexity of scenes."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[179,353,"Maybe"],[560,868,"Not concerning"],[875,908,"Not concerning"],[915,974,"Not concerning"],[978,1111,"Not concerning"],[1145,1272,"Not concerning"]],"Comments":[]}
{"id":"izgCF_V64LO","text":"The paper aims at providing experimental evidence to support the Coherent Gradients Hypothesis (CGH), that was published previously. The hypothesis suggests that the ability of large neural networks to generalise comes from the aligned gradients of the examples in the dataset. Once SGD follows common gradients, ignoring the rare directions, the model will generalise better. For the experimental evidence the authors present two algorithms for approximate smoothing insignificant gradient directions for large scale networks and datasets, as opposed to the original CGH paper, where experiments were performed for MNIST and one hidden layer network. The proposed techniques allow for large-scale experiments and show a decreased generalisation gap compared to vanilla SGD. The authors also propose to analyse “easy” (ones that are learned first) and “hard” (require lots of training) examples. The claim is that the easy examples are the ones having coherent gradients, while hard ones push the network to rare directions.\n\nThe paper is clearly written, but contains some informal claims and formulations (more details in minor comments), that makes it difficult to follow the idea. The main goal of the paper is formulated as finding scalable evidences for CGH to be true, and the central part is the algorithms and experiments using them. The authors also proposed an “orthogonal” set of experiments, as compared to the original CGH paper, based on comparing generalisation on easy and hard examples. The authors provide the code and detailed descriptions of all the experiments.\n\nThe idea of CGH was already published, while the further step from my point of view should be trying to find more rigorous formal justification of similar gradients and their connection to the generalisation, rather than providing additional experiments, that are still just an indication that CGH might be true. If the proposed algorithms are considered to be a practical contribution for better generalising training, then the results should be compared to related techniques (for example, batch normalisation). Also, I would be highly interested in comparing the original winsorization approach to get rid of the insignificant gradient directions to the median robustness approach used here. Are they equivalent in the effect? Also, for easiness of computation, the algorithm calculates medians coordinate-wise - I wonder if from formal perspective this leads to something completely different than what was intended (since the original theory is introduced for the whole vectors up to my understanding). The discussion on the benefits of median compared to average reads too vague. Finally, the discussion on the complexity of learned network (section 4.4) is extremely informal and confuses more than it provides insights. \n\nI would recommend the paper for rejection, because from my point of view it does not contain sufficient novel contributions for a conference publication.\n\nMinor comments:\n\n1 - sloppiness in SGD definition (as compared to mini batch GD): stochastic gradient descent is commonly used when the training is done without mini batches, i.e., updates are happening after each example seen\n\n2 - sloppiness in gradient update definition (sum (in abstract) or average (later)?)\n\n3 - algorithmic stability citation, Kuzborskij&Lampert - it is told they do not take training data into account, what does it mean? Their work is exactly about data dependent stability of SGD. I guess the problem is in wording - data dependency considers distributions, while dataset dependency considers properties of a particular dataset at hand. \n\n4 - The claim that “any generalisation analysis that does not take into account dataset has to be vacuous” is somehow too strong. There are indications for it, but it cannot be claimed certainly.\n\n5 - The gradients of examples are named to be a similarity measure between examples that does not change with training - but it does. Also, claim that label noise will always reduce any similarity measure between examples - what if only input part is taken into account for measuring similarity?\n\n6 - the first experiment claims that hardship in learning label noise affected examples supports CGH - I cannot really agree with that. The added noise will make the network learn worse, that does not provide any evidence for aligned gradients being the reason for good generalisation. Moreover, in further experiments, one can see that vanilla SGD constantly outperforms the proposed methods on pristine examples (figure 3a) - does it mean that removing insignificatant directions hurts performance in some sense?\n\n7 - figure1, c and d - are there any pristine examples when the level of noise is 100%?\n\n8 - the first sentence in paragraph3.1 is poorly formulated\n\n9 - it feels like the main point of the plots to all the experiments is to show the difference in final achieved accuracy\/loss. If it is the case - why overload the reader with the full training development of the values? I would suggest to report it in more concise form.\n\n10 - figure2 and 4 is extremely hard to read, too small\n\n11 - easy and hard examples experiments: does the originally trained network, with vanilla SGD, generalise better on easy examples than on hard examples?","sentences":[{"sentence_type":"1","sentence":"The discussion on the benefits of median compared to average reads too vague.","rephrased":"The discussion on the benefits of using the median over the average could be elaborated further for clarity."},{"sentence_type":"2","sentence":"I would recommend the paper for rejection, because from my point of view it does not contain sufficient novel contributions for a conference publication.","rephrased":"I would suggest that the paper may need to highlight its novel contributions more clearly to meet the conference's criteria for publication."},{"sentence_type":"2","sentence":"The discussion on the complexity of learned network (section 4.4) is extremely informal and confuses more than it provides insights.","rephrased":"The discussion in section 4.4 regarding the complexity of the learned network could benefit from a more formal approach to enhance clarity and insight."},{"sentence_type":"1","sentence":"The claim that \\","rephrased":"The statement that 'any generalisation analysis that does not take into account dataset has to be vacuous' might be perceived as overly definitive. It could be beneficial to present this as a hypothesis supported by certain indications rather than a conclusive claim."},{"sentence_type":"1","sentence":"The gradients of examples are named to be a similarity measure between examples that does not change with training - but it does.","rephrased":"It may be worth noting that the use of gradients as a similarity measure between examples is subject to change throughout training, contrary to what is suggested in the paper."},{"sentence_type":"1","sentence":"The first experiment claims that hardship in learning label noise affected examples supports CGH - I cannot really agree with that.","rephrased":"The interpretation of the first experiment's results, which suggests that difficulty in learning label noise-affected examples supports CGH, could be reconsidered or further substantiated."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2593,2670,"Not concerning"],[2815,2968,"Not concerning"],[3836,3965,"Not concerning"]],"Comments":[]}
{"id":"4l-KK7n1_WF","text":"pros:\n\n+ The paper positions itself as using data reweighting to simultaneously address class-imbalanced learning and learning with noisy labels. This problem is interesting (although authors failed in experimentally validating the method on this problem).\n\n+ Learning per-instance weights is a reasonable approach to address either imbalanced learning or learning with noisy labels.\n\n\nBelow are some summarized cons, followed by detailed comments.\n\n- Due to such a position (as simultaneously addressing class-imbalanced learning and learning with noisy labels), the paper failed to justify the method in this experiments. In contrast, the paper studies the two problems separately.\n\n- While class-imbalanced learning can be improved by learning per-instance weights, the paper did not fully survey the literature of class imbalanced learning. For example, [ref1] is missing in the paper that shows a rather simple method greatly improves class-imbalanced learning. Given this, it is natural to question why the paper misses an important baseline -- using [ref1] and data reweighting to simultaneously solve imbalanced learning with noisy labels.  [ref1] Decoupling Representation and Classifier for Long-Tailed Recognition, ICLR 2020\n\n\n- The paper is incremental in terms of techniques. It improves over Meta-Weight-Net [23] by incorporating class-level weights learning. Perhaps because of this, the method is called *generalized* data reweighting; however, the method is incremental rather than *generalized*.\n\n\n- There are many parts of the paper hard to follow, as detailed below.\n\nFirst, as the paper positions itself as \"simultaneously mitigate label noise and class imbalance\" (Line6), the paper fails to justify whether the proposed method can do it because experiments study the two subproblems separately. Furthermore, it looks quite non-trivial how to exploit class-level weights in front of noisy labels and imbalanced classes. For example, it is not clear how to weight data with noisy labels from rare classes, should the model give a large weight on them because they are from rare classes, or a small weight because they have noisy labels? Authors should delve into this aspect to better support the position of the paper.\n\nLine35: The sentence is confusing \"Due to the MLP, MWNet has better scalability on large datasets compared with INSW\". It is not clear what INSW does, and why MLP improves MWNet. Authors should improve the writing.\n\nLine37: The sentence is confusing -- \"they can not fully utilize class-level information within each instance\". What do authors mean by \"fully utilize class-level information\"? Why \"they can not\"? What did \"they\" do such that \"they can not\"? Authors should clarify. This makes the paper hard to follow.\n\nLine39: It is confusing -- what is the classifier for computing gradients? Does this classifier compute gradients from \"not X\" in terms of class-X?\n\nLine42: What are the \"three kinds of information\"? The authors did not define the \"three kinds of information\". It is hard to understand the paper.\n\nLine43: It is confusing -- \"downweighting the \"not bird\" gradient flow is a waste of information.\" What do authors mean by \"a waste of information\"? Can authors clarify?\n\nFigure 1: It is confusing -- \"Although the gradient flows for \"dog\" and \"not cat\" contain harmful information...\" What do authors mean by \"harmful information\"? Can authors clarify?\n\nLine66: It is unclear what the authors mean by \"To the best of our knowledge, we are the first to propose class-level weighting on gradient flows.\" Because it is not clear what the difference is between gradient reweighting and loss reweighting. Can authors clarify?\n\nSection 2.2: There is one missed citation that is important [ref1]. Authors should carefully survey the literature.\n[ref1] Decoupling Representation and Classifier for Long-Tailed Recognition, ICLR 2020\n\nLine87: Although tt is evocative to say \"meta-learning methods view instance weights as hyper-parameters and dynamically update them via a meta set to avoid hyper-parameter tuning.\" Did the authors consider the hyperparameters in the meta-learning? What are the learning rates, momentum, schedules of learning rates and initialization in meta learning? In the paper, authors did not provide such details.\n\nLine94: What is \"dynamic regularization\"? Can authors define it?\n\nLine127: It is not straightforward to understand how D1 is derived. Necessary derivations are needed. \n\nLine136: What do authors mean by \"retain Softmax-CrossEntropy loss structure after the manipulation\"? What is structure? What will happen if one does not \"retain\" the structure? Authors should improve writing the make the paper readable.\n\nLine140: What do the authors mean by \"messes the structure\"? What structure and how it \"messes the structure\"? \n\nEq.(4): The authors proposes a zero-mean constraint (Line143), but from what the authors did, it seems that this is factually not a constraint but an assumption with which the authors simply drop the second term. Authors should be careful in writing the statements.\n\nLine213: The authors explain \"GLC estimates the label corruption matrix well and thus performs the best\", but why GLC does not estimate label corruption matrix well in other noise levels? Authors should provide insights or analysis.\n\nLine229: As authors did not define \"non-target weights\", \"true-target weights\" or \"non-target\", I cannot understand this part. Authors should improve the writing quality.\n\nLine261: The definition of the imbalanced factor is inconsistent. In plain words, it is defined as \"the number of instances in the largest class divided by that of the smallest\", that said, the factor should be no less than 1. However, authors states the factor is in (0,1). Authors should correct this inconsistency.\n\n\n\n\n\n\n\n----------- post rebuttal --------------\n\nI appreciate the authors' feedback! The answers largely addressed most my confusions, though I still have some below.\n\nFirst, I think the explanation in the rebuttal is much clearer than the paper! Therefore, I'd upgrade the rating to \"5: Marginally below the acceptance threshold\". While this is not a recommendation for accepting the current version of the paper, I encourage the authors to incorporate the new results to polish the paper for the next submission.\n\nImportantly, it is still confusing to connect the position of the paper and the proposed methods. Concretely, the position of the paper is \"to simultaneously mitigate label noise and class imbalance\" (line6 in the abstract) because \"Label noise and class imbalance are two major issues coexisting in real-world datasets\" (line1 in the abstract). This is a very good problem setup, but the authors only study this setup in the rebuttal.\n\nBecause this is a novel problem setup, thoughtful baselines should be compared, such as combining noisy training atop of a state-of-the-art (SOTA) class-imbalanced learning method [ref1] and combining class-imbalanced learning atop of a SOTA noisy training method. I'm not satisfied by the authors argument \"it is not our duty to consider it as a baseline for comparison\" -- this will hurt the paper. I have some background of long-tailed recognition, as a reader, I would think such a combination as the first method to try out to solve this novel problem, rather than rushing to any complicated methods.\n\nOn the other hand, in the rebuttal, the authors make another argument by \"Should GDW perform better than this combination, the soundness of the comparison itself would be suspected\", implying that the authors are reluctant to compare these straightforward baselines to address the novel problem setup. If the authors really want to sell the method, then authors can change the position of the paper -- instead of proposing a novel problem setup, authors can directly start by methods without emphasizing the problem.\n\nLastly, I do encourage the authors to make a thoughtful revision of the paper by considering the new experiment results, position of the paper, and comparisons to other baselines.","sentences":[{"sentence_type":"2","sentence":"although authors failed in experimentally validating the method on this problem","rephrased":"although the experimental validation of the method on this problem could be strengthened"},{"sentence_type":"2","sentence":"the paper failed to justify the method in this experiments","rephrased":"the paper could provide a more robust justification for the method in these experiments"},{"sentence_type":"1","sentence":"Given this, it is natural to question why the paper misses an important baseline","rephrased":"It would be beneficial for the paper to include an important baseline such as [ref1] to strengthen its argument"},{"sentence_type":"2","sentence":"the method is incremental rather than *generalized*","rephrased":"the method appears to be more incremental in nature, and further clarification on its 'generalized' aspect would be helpful"},{"sentence_type":"3","sentence":"I'm not satisfied by the authors argument \"it is not our duty to consider it as a baseline for comparison\" -- this will hurt the paper.","rephrased":"The authors' argument that 'it is not our duty to consider it as a baseline for comparison' may not fully address the expectations for comprehensive baseline comparisons, which could be critical for the paper's reception."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[175,254,"Not concerning"],[564,622,"Not concerning"],[967,1047,"Not concerning"],[1461,1512,"Not concerning"],[7023,7158,"Not concerning"]],"Comments":[]}
{"id":"Baze9ERxAZ5","text":"It is known that disentangling based on decorrelation or statistical independence cannot work when the true factors of variation are in fact correlated \/ dependent in some domain. This paper provides a very clear analysis of disentangling under correlation shifts using a simple linear Gaussian model. It is shown using this toy example that even when supervised data is available, robust disentanglement may fail, in the sense that when correlation patterns shift, performance degrades. Adding a mutual information minimization loss does not mitigate the issue and in fact can make it worse, but using conditional MI does resolve the issue. This idea is applied to the CelebA faces dataset (with artificially added correlations between attributes) using an adversarial approach for CMI minimization, and promising results are obtained.","sentences":[{"sentence_type":"1","sentence":"It is known that disentangling based on decorrelation or statistical independence cannot work when the true factors of variation are in fact correlated \/ dependent in some domain.","rephrased":"While it is a common understanding that disentangling methods based on decorrelation or statistical independence face challenges when the true factors of variation are correlated or dependent, this paper provides valuable insights into how these issues manifest in certain domains."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[0,179,"Not concerning"]],"Comments":[]}
{"id":"ryxuvOt6YN","text":"This paper improves performance in two modern semi-supervised learning (SSL) models which utilize batch-norm in cases where the models train on unlabeled data from a different distribution than labeled data.  Their simple technique consists of calculating separate statistics for the unlabeled and labeled data in batch-norm.  \n\nThe paper, which appears to be largely motivated by Section 4.4 of Oliver et al, flushes out the class mismatch problem presented in the aforementioned paper and also tests performance under domain shift. The choices for domain shift perturbations seem reasonable, if not totally realistic. \n\nAlthough the paper clearly demonstrates improved performance in models with batch-norm, I think that the discussion presented in Section 3.3  warrants additional investigation in future work. \n\nAll in all, the paper's hypothesis was clearly defined and tested with thorough experiments and explanation. In addition, the problem definition and proposed solution, though fairly narrow, fits neatly into the workshop format. \n\nEditing comment: \n- “which we select 20 randomly classes as the supervised dataset.”","sentences":[{"sentence_type":"1","sentence":"The choices for domain shift perturbations seem reasonable, if not totally realistic.","rephrased":"The choices for domain shift perturbations are reasonable, although further work could explore more varied real-world scenarios."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[534,619,"Not concerning"]],"Comments":[]}
{"id":"r1e-hTxAKH","text":"For the low-resource pair English-Amharic, the authors propose to combine context-based machine translation (CNMT), which is built by using a bilingual dictionary and then connecting the resulting n-grams, with a neural MT system. The source sentence, as well as the CNMT output, are used as inputs to the RNN-based translation system.\n\nI vote for rejection because the paper makes some unfounded claims, misses important related work, has some methodological issues and presents unconvincing results.\n\nThe paper claims that CBMT is a new approach, but it dates from 2006. The authors say that it outperforms other MT approaches, but a more recent reference would be needed. While neural machine translation may sometimes struggle with rare words, using sub-word units may help alleviate the issue (Sennrich et al. Neural machine translation of rare words with subword units). The claim that RNNs learn from their previous mistakes is also unclear. It's true in the sense that backpropagation is learning from errors, but using previous reference outputs can cause exposure bias (Ranzato et al. Sequence Level Training with Recurrent Neural Networks).\n\nThe paper fails to cite related work, in particular on low-resource NMT (e.g. Gu et al. Universal Neural Machine Translation for Extremely Low Resource Languages) and unsupervised translation (e.g. Artetxe et al. Unsupervised Neural Machine Translation).\n\nThe CBMT system is built on top of the Google Translate English-Amharic system. However, that model may have seen the test data during training.\n\nBy combining CBMT with NMT, the authors obtain better results than NMT alone, but worse than with CBMT only. As such, the usefulness of the approach in a very low-resource scenario is unclear.\n\nMinor points:\n\nSome typos could be corrected: BLUE -> BLEU, Loung -> Luong, weather -> whether","sentences":[{"sentence_type":"2","sentence":"I vote for rejection because the paper makes some unfounded claims, misses important related work, has some methodological issues and presents unconvincing results.","rephrased":"I recommend reconsideration after addressing certain issues such as substantiating the claims made, including relevant related work, refining the methodology, and strengthening the results presented."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[337,501,"Not concerning"]],"Comments":[]}
{"id":"NOT-FvD_N4","text":"Summary: \nModified dice loss with weights computed based on Euclidean distance transform is proposed to improve segmentation of fissures between lung lobes. The weighted dice loss is presented as a novel contribution and is used to train a 3D Unet. Experiments compare performance to a baseline model and with Unet trained without weighted dice loss. \n\nStrengths:\n+ Weighting based on Euclidean distance transform is a useful idea. \n\nWeakness:\n- Presenting the weighting strategy as a novel idea is a bit of a stretch. The paper could be strengthened with more thorough validation and discussion of the improvements due to weighting. \n- The results are not convincing. While weighting dice loss shows improvement to Unet performance, it is still similar to the baseline method. There is no acknowledgement or further discussion about this. ","sentences":[{"sentence_type":"2","sentence":"- Presenting the weighting strategy as a novel idea is a bit of a stretch.","rephrased":"The paper would benefit from a more detailed exploration of the novelty of the weighting strategy, as it may overlap with existing methods."},{"sentence_type":"2","sentence":"- The results are not convincing.","rephrased":"The results would be more compelling with additional evidence to distinguish the improvements from the baseline method."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[444,518,"Not concerning"],[635,668,"Not concerning"]],"Comments":[]}
{"id":"SJlkRDV6ur","text":"The paper explores how focal loss can be used to improve calibration for classifiers. Focal loss extends the cross-entropy loss, which is -log(p_label), with a multiplicative factor equal to (1 - p_label)^gamma. Intuitively, this downweights the loss for elements where the probability of the correct label p_label is close to 1, relatively increasing the weight of the misclassified examples.\n\nSomewhat surprisingly, this tends to improve the calibration of the model. I say surprisingly because the focal loss is not a bregman divergence for all values of alpha so in general the expected minimizer of the focal loss for a fractional label is not the fractional label (i.e. the minimizer wrt x of - p (1-x)^gamma log(x) - (1-p) x^gamma log (1 -x) is not in general p).\n\nThe paper shows somewhat thorough experiments on many datasets justifying this observation, but the theoretical part is rather weak since it doesn't seem to address this issue with the focal loss.\n\nIt's also not very clear from reading the paper what the p0 should be when using the rule to automatically select the gamma of the focal loss.\n\nI'd support accepting the paper if the calibration properties of the focal loss itself was better analyzed on a simpler setup (linear models, or single parameter models) so it's easier to understand how it's helping calibration in the deep network setup and if the algorithm for choosing per-example gammas was more clearly stated out.","sentences":[{"sentence_type":"2","sentence":"The paper shows somewhat thorough experiments on many datasets justifying this observation, but the theoretical part is rather weak since it doesn't seem to address this issue with the focal loss.","rephrased":"While the paper presents comprehensive experiments across various datasets to support this observation, it would be beneficial to strengthen the theoretical discussion to address the specific characteristics of the focal loss more clearly."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[772,968,"Not concerning"]],"Comments":[]}
{"id":"Bkl6ds5G2m","text":"i take reviewing very seriously, and it often takes hours per paper. this paper, however, has many typos, grammatical errors, and seems to have been submitted last minute.  therefore, i have read the paper quickly.\nthat said, i do not understand the results.\nclearly, many discretization methods have previously been described, as alluded to by citing the taxonomy paper on the subject.  the authors state they have developed a better approach.  however, i do not see a comparison to the state of the art in the simulations, and i do not follow the results of Table 2, which columns correspond to which particular algorithms? in either case, the proposed approach does not seem to improve the empirical results, nor have theoretical guarantees, so i am not particularly impressed with the results either.","sentences":[{"sentence_type":"2","sentence":"this paper, however, has many typos, grammatical errors, and seems to have been submitted last minute.","rephrased":"While the paper contains several typos and grammatical errors, it would be beneficial to address these to enhance the clarity and professionalism of the manuscript."},{"sentence_type":"2","sentence":"therefore, i have read the paper quickly.","rephrased":"Given the issues noted, I may have missed some nuances during my review, and a more thorough revision could help ensure that all details are properly assessed."},{"sentence_type":"1","sentence":"i do not understand the results.","rephrased":"The results section could benefit from additional clarification to aid in understanding the outcomes of the study."},{"sentence_type":"2","sentence":"i am not particularly impressed with the results either.","rephrased":"The results did not meet my expectations based on the current state of the art, and I would encourage a comparison with existing methods to highlight the proposed approach's contributions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[69,171,"Confirmed"],[173,214,"Maybe"],[226,258,"Not concerning"],[748,804,"Not concerning"]],"Comments":[]}
{"id":"Vm9Cy42vPDq","text":"1.\tIt is not clear how the adversarial attack algorithms that are commonly used for discrete data are applied to event-based data in this work. Which are the design choices that are done to develop\/modify these methods? Since these modifications constitute the main contributions of this work, they should be comprehensively discussed in the main manuscript, rather than in the supplementary material. The description in Sections 2.1 and 2.2 does not contain sufficient details.\n2.\tIn this work, the novelty is low because the authors use already existing methods applied to an unexplored system.\n3.\tThe experimental setup is not clear. Details like training hyperparameters, ANN-SNN conversion parameters, and HW-level constraints of the neuromorphic chip that has been considered in the implementation.\n4.\tIt is ok to keep anonymous the name and brand of the in-house neuromorphic chip on which the experiments have been conducted, but the experiments can also be conducted on publicly available neuromorphic chips, to ease the comparison with related works.\n5.\tFor all the attacks, in particular for the universal attack, the stealthiness, i.e, how much the adversarial examples are noticed by the human eye, should be discussed.\n6.\tThe results can be extended with experiments in which adversarial defenses, such as adversarial training or noise filter, are applied to improve the robustness against the attacks.\n","sentences":[{"sentence_type":"2","sentence":"In this work, the novelty is low because the authors use already existing methods applied to an unexplored system.","rephrased":"While the authors have applied established methods to a new system, further elaboration on the innovative aspects of this approach would enhance the perceived novelty of the work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[482,596,"Not concerning"]],"Comments":[]}
{"id":"SgWeb3JDpxq","text":"**1. Summary and Contributions**\n\nThe paper considers considers causal discovery (or induction), that is, learning the underlying causal relations of our data's variables using said data. Specifically, it builds upon several previous works including continuous optimization and soft ranking for DAG learning, revealing a new method that leverages the computational advantages of taking a permutahedron perspective. The paper provides an empirical investigation justifying the newly proposed bi-level optimization formalism and corroborating on the proposed time and memory complexities.\n\n**2. Strengths**\n\nThe paper has several strengths, considered one-by-one in the following list (the list is ordered in correspondence to the paper presentation):\n\n* The grand problem of causal discovery is essential to human cognition and thus to science and engineering, and all its instances, and tackling specific sub-problems - as done in this work - is determining for developing next generation learning systems.\n* The guarantee of a directed, acyclic graph (DAG) by construction opposed to pragmatically obtaining it through heuristic procedures.\n* A comprehensive and extensive landscape of many relevant works for DAG learning is being presented.\n* They propose quasi-linear and linear time and memory complexities respectively (at least practically for the investigated settings).\n* The notation is being compactly presented a-priori, in support of the overall clear manner of presentation.\n\n**3. Weaknesses**\n\nThe paper suffers from several disadvantages (ranging in importance from minor to more fundamental) that however IMHO can be improved upon mostly quickly. Thereby, the following list - again one-by-one - aims to provide specific pointers with improvement suggestions if applicable (please note, the list is unordered):\n\n* To avoid clutter in the presentation for instance when re-citing certain works several times within the introduction on p.1, the authors might want to consider directly referencing key aspects of a given reference.\n* The presentation of the proposed formalism (Eqs.7,8) might significantly benefit from for instance color highlighting alongside a corresponding legend when explaining components. It might also significantly benefit from an improvement of the key Figure (Fig.1) using for instance a comprehensive caption or by extending it with an illustrative\/motivating example (since as of now, the figure only provides a notion of dependency\/order within the components of the approach). Furthermore, the authors might want to consider referencing the key Figure earlier than p.3 (since Fig.1 appears on p.2).\n* Reisach et al.'s main claim is that using simulated DAGs with score-based methods like NOTEARS or Golem is misleading since standardizing the data leads to degenerated performances at the same level of random guessing (suggesting that said methods exploit the sortability of the variance of the data). Since this is an arguably important aspect to be discussed within the community (since it has major consequences for the future of this research direction), the authors should consider elaborating whether their proposed approach can counteract difficulties that might be in common with the formerly mentioned methods.\n* Consider writing $\\mathbb{R}^n$ as the domain for $l$ in Eq.1\n* Consider removing the $d$ in $d < i < j$ for Eq.2\n* Since time complexity is a severely limiting factor in methods (like NOTEARS) that make use of a continuous acyclicity constraint as they scale (e.g. cubically) in the number of nodes (where we might observe in relevant, real-world settings like social networks large numbers of nodes), the authors should consider providing a more detailed, rigorous analysis of asymptotic time complexity.\n\n**3. Correctness, Clarity, and Literature**\n\nNo contradictions or any sort of relevant mistake have been detected in the paper. The clarity of the paper is an advantage. Existing bodies of work are being referenced accordingly at the end of the paper.\n\n**4. Reproducibility, Code Release, and Assumptions**\n\nSufficient details for reproduction are being provided. Unfortunately, without actual code. All key assumptions for the method are being pointed out explicitly.","sentences":[{"sentence_type":"2","sentence":"The paper suffers from several disadvantages (ranging in importance from minor to more fundamental) that however IMHO can be improved upon mostly quickly.","rephrased":"The paper presents several areas for improvement, which range in importance from minor to more fundamental, and could be addressed effectively with further work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1509,1663,"Not concerning"]],"Comments":[]}
{"id":"Q-Kz-5gCR64","text":"This paper tackles the problem of estimating snapshot Covid-19 incidence rates in locations where the official figures are believed to be unreliable. They utilize an indirect survey method to collect data from respondents which has the benefits of preserving their privacy and mitigating bias due to age or education level. They modify the Network Scale Up Method by fixing the number of close contacts in their survey. They validate their approach by estimating for the UK and Australia using the English version of the indirect survey and present results from China.\n\nI think this is well-written paper describing the methods, data collection strategy and prior related work in adequate detail. By comparing their estimates for the UK and Australia with the official figures, they show the validity of their estimates in China where the official figures might conceal the true rates of hospitalizations and mortality. The results are very interesting as they show a general agreement with the official vaccination rates while showing wide disparity in the estimates for deaths and cases.\n\nThe data pre-processing steps weeds out inconsistent and\/or outlier responses. This whittles down the sample size from 1000 to 469. This affects the ability to reliably estimate for cities, especially considering the population size. I was wondering if there was a way to preserve some of the inconsistent responses by making expert adjustments and how that would affect the results?\n\nLastly, they compute the Cronbach's Alpha coefficient on the responses of the indirect surveys for the UK and Australia, which suggests that the indirect survey method is reliable. I believe the methods in this paper are well thought-out and the results are worth a close look. I await the outcome of their future work.","sentences":[{"sentence_type":"2","sentence":"The data pre-processing steps weeds out inconsistent and\/or outlier responses. This whittles down the sample size from 1000 to 469.","rephrased":"The data pre-processing steps are rigorous and help ensure the quality of the data by filtering out inconsistent and\/or outlier responses, although this reduces the sample size from 1000 to 469. Could you elaborate on the potential impact of this reduction on the reliability of city-level estimates?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1091,1222,"Not concerning"]],"Comments":[]}
{"id":"SkxSd5_otS","text":"Impact of the latent space on the ability of GANs to fit the distribution\n\nThis paper purports to study the behavior of latent variable generative models by examining how the dimensionality of the latent space affects the ability of said models to reconstruct samples from the dataset. The authors perform experiments with deterministic autoencoders and WGAN-GP on CIFAR, CelebA, and random noise, and measure MSE and FID as a function of the dimensionality of z.\n\nMy take: This paper does not offer any especially intriguing insights, and many of the conclusions the authors draw are, in my opinion, not supported by their experiments. The paper is confusingly written and hard to follow—throughout my read I struggled to determine what the authors meant, and it was not clear to me what this paper is supposed to contribute. The potential impact of this paper is very low, and I argue strongly in favor of rejection.\n\nNotes:\n\nMy most critical complaint is the central experiment set of the paper: measuring MSE and FID as a function of Dim-Z for two models. First of all, the authors assume that the reduction in MSE as a function of dim Z is indicative of increased memorization in the GAN models. I disagree that this is the case; since the GAN-based reconstruction is done via optimization it is unsurprising that increasing dim Z increases the reconstruction quality, as you are literally giving the model more degrees of freedom with which to fit the individual samples. This is glaringly evident in Figure 8, where increasing dim Z renders the model better able to reconstruct a sample of pure noise, which is almost certainly not in its normal output distribution, (or if it is, is in there with staggeringly low probability). The fact that the higher dim-z models are better able to reconstruct the noise supports the notion that it is merely the number of degrees of freedom that matter in these experiments, rather than what the model actually learns.\n\nSecond, it is important to note that FID can be easily gamed by memorization, and for an autoencoder (which has direct access to samples) with an increasingly large bottleneck it is unsurprising that increasing dim-Z tends to decrease the FID, and equally unsurprising that increasing the dim-Z for the GAN does not tend to improve results, since this does not really allow the model increased memorization capacity (not to mention the relationship between performance and dim-Z has been explored before in GAN papers).\n\nThird, the organization of the experimental section makes it very difficult to infer what the authors are trying to conclude from these experiments. The noise experiment is presented, but no insights or conclusions are drawn, other than (a) noting that the model has a harder time reconstructing the noise than training samples and (b) that lower dim models have a harder time reconstructing the noise, both of which are just restatements of the information presented in the figure rather than an actual insight or conclusion.\n\n-I’m not really sure what the experiment in section 3 is supposed to show. This experiment is poorly described and lacking details. First of all, what is the loss function used there? Is this the output of the discriminator or the MSE between the output and a target sample? How is z* found and what does it represent—is it just a randomly sampled latent, or is it the latent that corresponds to the z-value which minimizes some MSE loss for a target sample? If it’s the latter, why is this notation not introduced until section 4? If it’s a latent, why are you calling it a data point? Why are there no axes and no scales on these plots? How is it clear that there is an optimization path from z0 to z*; is that supposed to be inferred from z0 having a higher value than z* or appearing to be directly uphill from z*, because it’s not clear to me that that is the case in Figure 2a. In general I did not find this experiment to support the conclusions the authors draw.  \n\n-Figure 4: It is important to note that FID can be trivially gamed by memorizing the dataset, and an autoencoder is much more well-suited to memorizing the dataset as it has direct access to samples (whereas a GAN must get them through the filter of the discriminator). Authors should test interpolation or hold-out likelihood for the  autoencoder, these models are not directly comparable in this manner.\n\n-The presentation of this paper is, in general, all over the place. The authors should focus on writing such that each point follows the next, building progressively towards their results and insights, and making it easy for a reader to follow their train of thought.\n\n“In this work, we show that by reducing the problem to a compression task, we can give a lower bound on the required capacity and latent space dimensionality of the generator network for the distribution estimation task.” At what point is this lower bound (either in terms of model capacity or latent space dimensionality) specified in the paper? Is Figure 3 supposed to be this lower bound, because to me it only indicates that the autoencoder tends to have a lower MSE, not that it conclusively lower bounds the memorization capacity of the GAN. Wouldn't a method like GLO which directly optimizes for memorization be a better lower bound for this, anyhow?\n\n“We rely on the assumption, that less capacity is needed to reconstruct the training set, than to reconstruct the entire distribution” What does this phrase mean? Are the authors referring to the entire distribution of natural images, of which the training set is assumed to be a subset? Or do they mean the output distribution of the generator? This was not clear to me.\n\n\nMinor:\n\n-“ style transfer by Karras et al. (2018),”, and “anomaly detection (Shocher 2018).” StyleGAN is not a style transfer paper, and InGAN  is not about anomaly detection. Please do not incorrectly summarize papers.\n\n-“Trained GAN newtworks” While amusing, this is a typo. Please thoroughly read your paper and correct all typos and grammatical mistakes, like “combiniation.”\n\n-“…that an accurate reconstruction of the generator manifold is possible works using first order methods”  The word “works” seems to be out of place here. Again, please thoroughly proofread your paper.\n\n-The legend in Figure 2 has a white background, making the white x corresponding to z0 invisible. Please fix this, and add appropriate axes to this plot.\n\n-Figure 7 and 8 may in fact have error bars, but they are not described (are they 1 std or another interval?) or referenced, and in Figure 8 (if these are error bars) they are nearly invisible. \n\n","sentences":[{"sentence_type":"2","sentence":"This paper does not offer any especially intriguing insights, and many of the conclusions the authors draw are, in my opinion, not supported by their experiments.","rephrased":"While the paper presents a novel approach, the insights could be further developed, and it would be beneficial if the authors could provide additional evidence to support their conclusions."},{"sentence_type":"2","sentence":"The paper is confusingly written and hard to follow","rephrased":"The paper could benefit from clearer writing and a more structured presentation to enhance its readability and flow."},{"sentence_type":"3","sentence":"The potential impact of this paper is very low, and I argue strongly in favor of rejection.","rephrased":"To strengthen the paper's impact, it would be helpful if the authors could further clarify the significance of their findings and how they advance the field."},{"sentence_type":"2","sentence":"I'm not really sure what the experiment in section 3 is supposed to show.","rephrased":"The purpose of the experiment in section 3 could be made clearer by providing more details and a better explanation of its relevance to the study's objectives."},{"sentence_type":"2","sentence":"The presentation of this paper is, in general, all over the place.","rephrased":"The organization of the paper could be improved to ensure a logical flow of ideas and a coherent presentation of the results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[474,636,"Not concerning"],[637,688,"Maybe"],[827,918,"Confirmed"],[4396,4462,"Confirmed"]],"Comments":[]}
{"id":"Byl906NbqE","text":"In the paper, the authors suggest modifying various VAE bounds (ELBO, IWAE) by replacing logarithm by q-logarithms. The paper is missing a few steps to be satisfying in my opinion - at its heart, it takes a lower bound to the true data evidence, and upper bounds it using a q-logarithm with q<1.0. While the new estimate would be 'tighter' it if it was still a lower bound, the authors provide no guarantee that the resulting qELBO are still in fact lower bounds; maximizing them may therefore not make sense. \nThe q values used are very close to 1, which suggests the q-logarithm is used a mild hyperparameter to smooth the objective function; gains on experimental data are minor.","sentences":[{"sentence_type":"2","sentence":"The paper is missing a few steps to be satisfying in my opinion","rephrased":"The paper could benefit from additional steps to enhance its clarity and completeness."},{"sentence_type":"1","sentence":"gains on experimental data are minor.","rephrased":"The experimental data show modest improvements, which could be further explored."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[116,179,"Not concerning"],[645,682,"Not concerning"]],"Comments":[]}
{"id":"G3apA7TLzsG","text":"1. Equation (1),(4) is called the Performance Difference Lemma. Equation (3) is called the Simulation Lemma. See e.g. Lemma 1.16 and Lemma 2.2 of this textbook [https:\/\/rltheorybook.github.io\/rltheorybook_AJKS.pdf]. These are standard tools for analyzing model-based RL, and you can also find them in almost every theoretical model-based RL paper, so I don't know what's surprising or new about Theorem 1...\n\n2. Regarding the 1st remark below Theorem 1, the easiest way to estimate $J(P',\\pi)-J(P,\\pi)$ is to just run $\\pi$ in both $P$ and $P'$... The variance of $J(P',\\pi)$, thus the amount of data needed to estimate it accurately, is strictly smaller than the variance of the quantity inside the expectation on the RHS of equation (3).\n\n3. The experimental results show only marginal improvement over PPO, especially since each iteration of RPO and RPTO collect twice the amount of data than PPO (one trajectory in $P$ and one trajectory $P'$).","sentences":[{"sentence_type":"2","sentence":"so I don't know what's surprising or new about Theorem 1...","rephrased":"Could you please clarify what distinguishes Theorem 1 from the standard tools mentioned, as it seems to overlap with well-established concepts?"},{"sentence_type":"2","sentence":"The experimental results show only marginal improvement over PPO, especially since each iteration of RPO and RPTO collect twice the amount of data than PPO (one trajectory in $P$ and one trajectory $P'$).","rephrased":"The experimental results suggest a modest improvement over PPO. It would be helpful to discuss the implications of the increased data collection by RPO and RPTO in comparison to PPO."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[348,407,"Confirmed"],[744,948,"Not concerning"]],"Comments":[]}
{"id":"HklYg8l93X","text":"The paper works with the modularization of PPLs with natural inspiration for the successful modularization recently introduced in all deep learning softwares. \n\n* Within your so-called probabilistic modules you package dedicated inference methods that are tailored for this particular class of problems and argues that this will perform better than using a general purpose solver. For each specific case this does of course make a lot of sense. However, when it comes to the relevant case (especially within probabilistic programming) when we have a (often complex) combination of several probabilistic modules, how do you then leverage the tailored solvers? What is it that guarantees that these are relevant in the new combined construction? \n\n* Related to the above you write in your conclusion that \"Once an inference algorithm is chosen, it remains the same across a probabilistic model. However, given a specific probabilistic model, e.g., a conjugate model, a specialized inference algorithm that exploits the mathematical properties of that particular model will always produce inference results that are as good or better than the generic inference in terms of both accuracy and efficiency.\" This is of course true and it is also part of some existing PPLs, for example Birch via their so-called \"delayed sampling\": \nhttp:\/\/proceedings.mlr.press\/v84\/murray18a\/murray18a.pdf\nThe implementation there is very different from what you propose. As far as I can understand you require hard-coding of each specific model, whereas in the paper mentioned above they seem to automate att conjugate gradient calculations to a much greater extent. Why is it better to insist on hard-coding this for each probabilistic module? and how can you guarantee smooth functioning when several probabilistic modules are combined in complex ways?\n\n* In the inference method that you briefly sketch in Section 3 you make use of VI and the intractable integrals that results are then handled using Monte Carlo. What is the gain of using VI + Monte Carlo compared to direct use of Monte Carlo? Via direct use of some kind of Monte Carlo method you would be able to guarantee performance and do proper analysis, whereas with VI you loose that capability. However, VI does of course have other pros, but my question arises due to the fact that you end up using Monte Carlo anyway.\n\n* You write that \"In PPLs, a probabilistic model is often presented as a graph of random variables...\". This is certainly true and the word \"often\" is very important in this sentence. At the same time, is not one of the key reasons for using PPLs compared to probabilistic graphical models that it offers a richer model class compared to probabilistic graphical models? While I perfectly respect you choice to specifying models in MXFusion using using probabilistic graphical models I do find this quite restrictive and it seems to miss some of the key possibilities with PPLs.\n\n* In your BLR example (which is very instructive by the way) you compute the solution via MAP. This is also find rather puzzling since that removes another great feature of PPLs, namely to work with probability distributions throughout the entire inference stage. The user can then of course choose to extract whatever point estimate might be needed in the end. Why do you remove this possibility by insisting on a specific point estimate? or is this just a particular choice of this example and not a general design choice?\n\n\nThe paper contains a lot of issues related to the use of the English language and would benefit from proper proofreading.\n","sentences":[{"sentence_type":"2","sentence":"The paper contains a lot of issues related to the use of the English language and would benefit from proper proofreading.","rephrased":"The paper would benefit from additional proofreading to address issues related to the use of the English language."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[3469,3590,"Maybe"]],"Comments":[]}
{"id":"I2JdYsSoOYA","text":"This paper proposes to learn the sub-graph patterns from a collection of training graphs. The key idea is to partition each graph into segments and enforce a global clustering of the subgraphs. The partitioning is also guided through contrastive learning, i.e., subgraphs should have a larger similarity with the graph it is drawn from, compared with other graphs. The learned GNN (that generates node embedding) will then be used to some downstream learning tasks with or without further fine-tuning. \n\nThe notation of the paper is very hard to follow. For example, no where is N defined, which I assume is the number of sug-graphs. Capital latters S_i’s represent vector (not sure if my guess is correct), as lower-case letter q_j’s, which somewhat affects the reading. Also the definition of n_i, and n_{i,s} is not quite following the custom of matrices. Furthermore, what is the relation between s_i and S_i (both board), and what is the difference between S (bold) and S (not bold)? The h_i is defined but not used, and in equation (7) g_i is used, which I assume is the summary embedding vector for graph G_i; in (7) s_i seems to be subgraph embedding vector, and this makes me more confused about the s_{j,k} appearing in the beginning of section 3.2 which is defined as the cosine similarity between subgraph j and motif k. The E[G_i] is with bold E somewhere and non-bold letter E elsewhere. Altogether, there are S (bold), S(not bold), s_{j,k} (bold) that seems to be a similarity measure, and s_i (bold) which seems to represent subgraph vector. It’s quite confusing to me. Can authors clearly define these symbols when they are used, and make sure they are consistent throughout the paper, and explicitly mark their dimensionality to avoid confusion? Usually upper-case letters are for matrices and lower-case bold letters for vectors.  \n\nThe idea of partitioning graphs into sub-graphs are a useful idea in breaking the complexity of graph-structured objects and exploring the potential hierarchical organizations of the graph. Using contrastive learning as a self-supervision may further improve the partitioning of each graph. However, the grouping part and the contrastive part may conflict with each other in that some sub-graphs are shared among different graphs, which can be quite common in chemical compounds. \nUnder (5), it is mentioned that spectral clustering is used to partition the graphs; is it done end-to-end and if so where is the loss function corresponding to this operation?\n\nIn (6), (s,t) in g(i,j): What is g(i,j) in particular? a threshold eta is used in the indicator function and how to choose eta (considering that it is used directly on a set of variables)? Is (6) end-to-end optimizable?     \n\nIn Figure~2, what is meant by the blue and red markers (like + and -)?\n\nExperimental results are quite strange in that the transfer learning setting (which further finetunes the learned GNN based on a small set of labels, as in Table 1) leads to even worse performance than the feature extraction setting (in which no fine-tuning is performance, as shown in Table2) and the gap can be as huge as 15% in accuracy!  \n","sentences":[{"sentence_type":"2","sentence":"The notation of the paper is very hard to follow.","rephrased":"The notation in the paper could be clarified for better understanding."},{"sentence_type":"2","sentence":"Experimental results are quite strange in that the transfer learning setting leads to even worse performance than the feature extraction setting and the gap can be as huge as 15% in accuracy!","rephrased":"It is unexpected that the transfer learning setting results in lower performance compared to the feature extraction setting, with a significant difference in accuracy. Could the authors provide insights into this outcome?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[504,553,"Not concerning"]],"Comments":[]}
{"id":"QlTq2A3S3il","text":"Authors study the problem of representation learning in Deep RL where they look at representations are affected by\ni) choice of learning method such as TD learning\nii) also the way in which they are trained (i.e stop gradient)\nThey discuss conditions where TD and Monte-carlo representations are same\/different as per the cumulant matrix G. \n\nTo analyse which approach leads to better representation, they learn the representation and then perform policy evaluation using this representation. They then study how representations are dependent on the auxiiary task characterized through cumulant matrix. As a particular case, they study random cumulants, which is of practical importance.\n\nOverall the paper is well-written, the concepts are explained in a good way and they dive deep into this problem with interesting potential directions. My expertise in this area is limited to give a more refined judgement.","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"AfhlzMbOFd","text":"This paper is well written, the methods are appropriate, sufficient detail is provided to enable replication, and the results are presented clearly. This paper could be improved by expanding on the motivation for this work, including information about how ground truth labels were obtained, and contextualizing this study with previous literature.\n\nDetailed comments:\n\nNo motivation is given for how better classification of these subtypes would improve patient outcome.\n\nThe rationale for the two stage approach seems to be to incorporate features learned on the low-resolution space in learning the high-resolution space, and for using information from multiple scales to classify the patient. This approach is appropriate for the domain (pathological analysis) and is explained clearly and completely here. However I wonder why other approaches that use information from multiple domains, such as U-Net, were not considered.\n\nDid all the images come from the same hospital? At what micron-per-pixel resolution were images digitized?\n\nAn important missing piece of this manuscript is a description of how the image class labels were determined. If this was done by an objective method, such as molecular analysis, there is no problem and a statement explaining the label origin can be added. However, if the class labels were based on morphological analysis, there is the problem that the labels are not true ground truth. If the ground truth labels are obtainable, such as through a molecular test, motivation needs to be provided for why this study is necessary.\n\nWith unbalanced classes, measures such as sensitivity and specificity or true positive rate and true negative rate should be reported instead of accuracy.\n\nThere are multiple methods for calculating AUC in a multi-class problem. The authors should state the method they used.\n\nThe authors state that their method outperformed the baseline method. This is only true in the slide-level case. I agree with the authors implicit assumption that patch-level metrics are less clinically important than slide-level metrics, but this should be made explicit and justified. \n\nThe conclusions of this work, that the two-stage method is better than conventional approaches, would be strengthened by referencing past publications that reported worse performance in this task.","sentences":[{"sentence_type":"1","sentence":"An important missing piece of this manuscript is a description of how the image class labels were determined.","rephrased":"The manuscript would benefit from a description of how the image class labels were determined to provide clarity."},{"sentence_type":"2","sentence":"However, if the class labels were based on morphological analysis, there is the problem that the labels are not true ground truth.","rephrased":"If the class labels were based on morphological analysis, it would be helpful to discuss the implications for considering them as ground truth."},{"sentence_type":"1","sentence":"The authors state that their method outperformed the baseline method. This is only true in the slide-level case.","rephrased":"It should be noted that the method's outperformance over the baseline method is observed at the slide-level case."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1037,1146,"Not concerning"],[1294,1424,"Not concerning"],[1845,1957,"Not concerning"]],"Comments":[]}
{"id":"B1xVuu6aKr","text":"The authors extend the existing work SGC [1] to a nonlinear version, which addresses the limitations of dealing with nonlinear feature. It further extends the theoretical finding in [1] about the low-pass filtering functionality of graph convolutional networks and shows its advantage in dealing with graph signal processing problem. Evaluation of the proposed method is performed on 7 datasets for node classification task.\nPros:\n1. This work goes into detail of the theoretical finding of SGC.\n2. Authors conduct extensive experiments on multiple datasets.\nCons:\n1. The proposed graph neural network mode is an extension of the existing model SGC, which address the limitation of SGC to model the node feature nonlinearity. It is a good extension, but the novelty is limited.\n2. Authors further extend the theoretical finding in [1] and verify the fact that low-pass filtering functionality of graph neural network provide better noise robustness than two layer MLP. It has some novelty, but the novelty is incremental.\n3. In the experiment, the performance gap between SGC and gfNN is very small on noise robustness study and traditional node classification. The performance gap between GCN and gfNN is also small on noise robustness study is also small, which can not support the conclusion \"GCN has a risk of overfitting to the noise\"\n4. The paper has the problem of notation missing, e.g on page 2, Fig1 is never mentioned; on page 7, the notation of \"LG\" is missed in Fig 5.\n5. The code link is given but no code is missing.\n[1]Wu, Tianyi Zhang, Amauri Holanda de Souza Jr., Christopher Fifty, Tao Yu, and Kilian Q.Weinberger. Simplifying graph convolutional networks. ICML2019\n","sentences":[{"sentence_type":"2","sentence":"The proposed graph neural network mode is an extension of the existing model SGC, which address the limitation of SGC to model the node feature nonlinearity. It is a good extension, but the novelty is limited.","rephrased":"The proposed graph neural network model builds upon the existing SGC model, enhancing its ability to model node feature nonlinearity. While this is a valuable extension, the degree of novelty could be further articulated."},{"sentence_type":"1","sentence":"It has some novelty, but the novelty is incremental.","rephrased":"The work introduces some novel aspects, although they appear to be incremental advancements."},{"sentence_type":"2","sentence":"The performance gap between SGC and gfNN is very small on noise robustness study and traditional node classification. The performance gap between GCN and gfNN is also small on noise robustness study is also small, which can not support the conclusion \"GCN has a risk of overfitting to the noise\"","rephrased":"The performance differences between SGC and gfNN, as well as between GCN and gfNN, are modest in the noise robustness study and traditional node classification tasks. This suggests that further evidence may be needed to fully support the conclusion that 'GCN has a risk of overfitting to the noise'."},{"sentence_type":"1","sentence":"The paper has the problem of notation missing, e.g on page 2, Fig1 is never mentioned; on page 7, the notation of \"LG\" is missed in Fig 5.","rephrased":"The paper could be improved by addressing missing notations, such as the reference to Fig1 on page 2 and the notation 'LG' in Fig 5 on page 7."},{"sentence_type":"2","sentence":"The code link is given but no code is missing.","rephrased":"While a link to the code is provided, it appears that the actual code is not available at the link. Ensuring the code is accessible would be beneficial for reproducibility and transparency."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[568,777,"Not concerning"],[969,1021,"Not concerning"],[1343,1481,"Not concerning"],[1485,1531,"Not concerning"]],"Comments":[]}
{"id":"141LpOkuuxm","text":"The authors propose an extension to label smoothing, where the smoothing parameter is determined based on the miscalibration of the validation set. They then compare the performance of their method in terms of calibration under domain shift to a small set of baselines. \n\nI have 3 main concerns regarding missing baselines, missing experiments and only marginal benefits over state-of-the-art.\n\nMy first main concern is that the authors limit their comparison to rather dated baselines (2018 and older), when there has been a lot of active research in this field in the past year. In particular, I am disappointed that while the authors cite recent work on MixUp showing its benefits for calibration (Thulasidasan et al., NeurIPS 2019) they do not include MixUp as baseline (where also inputs are smoothed rather than labels only). Other notable recent work that should be included as baseline is Verified Uncertainty Calibration, Kumar et al., NeurIPS 2019, which has been shown to be superior to Temperature Scaling.  In addition, a baseline which also exploits links between calibration and adversarial, Stutz et al., ICML 2020, should be included as prior work.\nAnother aspect of the presented work is the exploration of constructing an ensemble of neural nets trained with label smoothing. In light of this, it is crucial to also compare the presented approach to Mix-n-Match, Zhang et al., ICML 2020, who present work on ensemble methods for uncertainty calibration using label smoothing. \n\n My other main concern is a whole set of missing experiments investigating calibration in truly OOD scenarios. Snook et al, on whose work this paper heavily builds, point out that in addition to the domain drift scenarios explored by the authors, it is crucial to investigate performance in truly OOD scenarios, where the test data is drawn from a distribution far a way from the training distribution. Since the model is per definition not able to make a correct prediction, in this scenario entropy is used to quantify model the quality of the predictive uncertainty. The authors should add these experiments for all datasets. \nIn this context, it would also interesting to investigate the quality of predictive uncertainty of OOD detection methods. While such comparisons are not always meaningful, a model strongly related to label smoothing\/MixUp is Hendrycks et al., ICLR 2019, where a GAN is trained to learn OOD samples, where in MixUp inputs are smoothed to generate OOD samples. A comparison to this approach would also be interesting. \n\nFinally, even though important baselines as well as experiments for truly OOD scenarios are missing, benefits over a simple ensemble of vanillas remain unclear. For large-scale data (i.e. Imagenet), ensemble of Vanilla perform consistently better than the proposed method in terms of ECE under domain shift. For CIFAR-10, performance is comparable to deep ensembles and only for AR-AdaLS of Ensemble for CIFAR-10 there is a marginal improvement for a subset of perturbation strengths. I would have liked to see also evaluation of ECE under domain shift for CIFAR-100 and SVHN. Also missing is an evaluation of AR-AdaLS of Ensemble for Imagenet. Finally, results for non-image data, e.g. using a recurrent architecture (as in Snoek et al) are missing. \n\nOther concerns and open questions include: \nAlthough the authors explain the hyperparameters they use in the appendix, a detailed sensitivity analysis is missing to understand how sensitive the method is with respect to alpha and R. \n\nThe authors use „Ensemble of Vanilla“ as baseline - however, Snoek et al. have shown that it is actually deep ensembles that perform best; in addition to the ensemble effect they are also trained using adversarials. What is the performance of actual deep ensembles rather than ensemble of vanilla?\n\nA conceptual concern is that in the proposed approach the validation set becomes part of the training set since it is used during training to update epsilon and thus is not anymore the independent set that may be necessary to tune other hyperparameters\/for early stopping; I wonder whether this data leak may lead to problems related to overfitting?\n\nPlease report a proper scoring rule in addition ECE (e.g. Brier score).\n\nA minor point ist that different colors are used for AR-AdaLS  and Ensemble of Vanilla in figure 3 and figure 4.\n\nUnfortunately the authors do not provide any code, which make reproducibility difficult. \n\n\n\n####post rebuttal####\nThe contribution of this paper is marginal only. The link between adversarial robustness and calibration has been explored previously: Snoek et al. NeurIPS 2019 have shown that adversarial training as part of deep ensembles leads to better calibration under domain shift. Unfortunately the authors do not compare their approach to these deep ensembles, but only an ensemble of differently initialised vanilla networks without adversarial training, which they call deep ensembles (section 5.1). Also in terms of label smoothing the contribution is marginal: in their rebuttal the authors show that MixUp training - a different implementation of label smoothing combined with input smoothing - has a better performance than their method (ECE of 1.8 MixUp vs 2.3 their method for CIFAR-100); they do show that further post-processing improves their method, but this is likely true for MixUp too (results not shown). For ImageNet results for MixUP are not shown, nor for calibration under domain shift where MixUp is likely to perform well too.\n Taken together, this suggests that the link between adversarial robustness and calibration is mainly a link between OOD samples and calibration: generating OOD samples with input smoothing in MixUp works very well compared to the proposed approach, as does adversarial training in deep ensembles (both of which was shown in prior work). In summary, the proposed approach lacks novelty and performs worse than baselines for complex datasets.\n\nLack of code during the reviewing phase means it is not possible to review reproducibility of results.","sentences":[{"sentence_type":"2","sentence":"In particular, I am disappointed that while the authors cite recent work on MixUp showing its benefits for calibration (Thulasidasan et al., NeurIPS 2019) they do not include MixUp as baseline.","rephrased":"It would be beneficial if the authors could include MixUp as a baseline in their comparison, especially since they acknowledge its benefits for calibration in recent work (Thulasidasan et al., NeurIPS 2019)."},{"sentence_type":"2","sentence":"Finally, even though important baselines as well as experiments for truly OOD scenarios are missing, benefits over a simple ensemble of vanillas remain unclear.","rephrased":"It would be helpful to clarify the benefits of the proposed method over a simple ensemble of vanilla models, particularly since some important baselines and experiments for truly OOD scenarios have not been included."},{"sentence_type":"2","sentence":"Unfortunately the authors do not provide any code, which make reproducibility difficult.","rephrased":"Providing the code would enhance the reproducibility of the study and allow for a more thorough evaluation."},{"sentence_type":"3","sentence":"The contribution of this paper is marginal only.","rephrased":"The paper could benefit from a clearer demonstration of its unique contributions to the field."},{"sentence_type":"3","sentence":"In summary, the proposed approach lacks novelty and performs worse than baselines for complex datasets.","rephrased":"The authors may consider further emphasizing the novel aspects of their approach and comparing its performance with baselines on complex datasets to strengthen their contribution."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2545,2705,"Not concerning"],[4370,4458,"Not concerning"],[4485,4533,"Not concerning"],[5864,5967,"Not concerning"]],"Comments":[]}
{"id":"BylSI7T6qr","text":"This paper introduces a simple measure of tunability that allows to compare optimizers under varying resource constraints. The tunability of the optimizer is a weighted sum of best performance at a given budget. The authors found that in a setting with low budget for hyperparameter tuning, tuning only Adam optimizer’s learning rate is likely to be a very good choice; it doesn’t guarantee the best possible performance, but it is evidently the easiest to find well-performing hyperparameter configurations.\n\nComments:\n\nThe paper is easy to follow. The motivation of defining tunability of optimizer is a very interesting question, however, the study seems to preliminary and the conclusion is not quite convencing due to several reasons:\n\nIn section 3.2, to characterize its difficulties of finding best hyperparameters or tunability, the authors seem to try to connect the concept of “sharpness” of a minima in loss surface to the tunability of an optimizer, which is similar to comparing the loss landscape of minimums. However, while the authors made intuitive explanation about the tunability in section 2.2, I did not see the actual plot of the true hyperpaparameter loss surface of each optimizer to verify these intuitions. Can the author be more specific about the x-axis in the illustration 1.a and 1.b? If I understand correctly, they are not the number of trails.\n\nIn addition, the proposed stability metric seems not quite related with the above intuitions, as the illustrations (1.a and 1b) define the tunability to be the flatness of hyperparameter space around the best configurations, but the proposed definition is a weighted sum of the incumbents in terms of the HPO budgets. \n\nThe definition of the tuning budgets is not clear, is it the number of trials or the time\/computation budgets? The authors seems interchangeably using “runs” and “iterations”, which makes the concept more confusable. \n\nThe authors further proposed three weighting schemes to emphasize the tunability of different stage of HPO. My concern is that is highly dependent  on the order of hyperparameter searched, which could impact the tunability significantly. For instance, in case of grid search HPO and 0.1 is the best learning rate, different search order such as [10, 1, 0.01, 0.1] and [0.1, 0.01, 1, 10] could results in dramatic different CPE and CPL. \n\nMy major concern is the hyperparameter distributions for each optimizer highly requires prior knowledge. A good prior of one optimizer could significantly affect the HPO cost or increase the tunability, i.e., the better understanding the optimizer, the less tuning cost. My major concern is that the authors assume the hyperparameters to be independent (section 3.2), which is not necessarily true. Actually hyperparameters are highly correlated, such as momentum, batch size and learning rate are correlated in terms of effective learning rate [1,2], so as weight decay and learning rate are [3], which means using non-zero momentum is equivalent to using large learning rate as long as the effective learning rate is the same. This could significantly increase the tunability of SGDM. Another concurrent submission [4] verified this equivalence and showed one can also just tune learning rate for SGDM. The assumption of independent hyperparameters might be fine for black box optimization or with the assumption that practitioners have no knowledge of the importance of each hyperparameter, then the tunability of the optimizer could be different based on the prior knowledge of hyperparameter and their correlations. But it is not rigorous enough to make the conclusion that Adam is easier to tune than SGD.\n\n\nThe author states their method to determine the priors by training each task specified in the DEEPOBS with a large number of hyperparameter samplings and retain the hyperparameters which resulted in performance within 20% of the best performance obtained. Could the authors be more specific on the hyperparameters searched? Is this process counted in the tunability measurement?\n\n[1] Smith and Le, A Bayesian Perspective on Generalization and Stochastic Gradient Descent, https:\/\/arxiv.org\/abs\/1710.06451\n\n[2] Smith et al, Don't Decay the Learning Rate, Increase the Batch Size, https:\/\/arxiv.org\/abs\/1711.00489\n\n[3] van Laarhoven et al, L2 Regularization versus Batch and Weight Normalization, https:\/\/arxiv.org\/abs\/1706.05350\n\n[4] Rethinking the Hyperparameters for Fine-tuning\n https:\/\/openreview.net\/forum?id=B1g8VkHFPH\n","sentences":[{"sentence_type":"2","sentence":"The study seems to preliminary and the conclusion is not quite convencing due to several reasons:","rephrased":"The study appears to be in its early stages, and the conclusion could be strengthened with further evidence for the following reasons:"},{"sentence_type":"2","sentence":"The definition of the tuning budgets is not clear, is it the number of trials or the time\/computation budgets? The authors seems interchangeably using \runs\" and \"iterations\", which makes the concept more confusable.","rephrased":"The definition of the tuning budgets could be clarified. Is it the number of trials or the time\/computation budgets? The terms \"runs\" and \"iterations\" appear to be used interchangeably, which could lead to confusion."},{"sentence_type":"1","sentence":"My major concern is that the authors assume the hyperparameters to be independent (section 3.2), which is not necessarily true.","rephrased":"One point of concern is the assumption in section 3.2 that hyperparameters are independent, which may not always hold true."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2626,2753,"Not concerning"]],"Comments":[]}
{"id":"HJgKV__a2X","text":"# Review for \"Neural Belief Representations\"\n\n\n\nThe authors argue in the favor of belief representations for partial observable Markov decision processes. The central argument is that uncertainty needs to be represented to make optimal decision making. For that aim, three belief representations based on sufficient statistics of the future are evaluated and compared in a set of disective studies. Those studies find that predicting the future results in uncertainty being represented in the state representations, although they differ in quality.\n\nI found the paper hard to follow for various reasons. \n\n- NCE is reviewd, while CPC is not. I would have found a review of CPC as well to help my understanding, especially to draw the line between CPC and CPC|Action.\n- In 2.1., $b_t$ is defined as a probability, while it is the output of a neural network later. This is formally incompatible, and I found  the connection not well explained. From my understanding, $b_t$ is a vector that represents the sufficient statistics if learning works. The probability interpretation is thus stretched.\n- The architecture description (starting from the second paragraph on page 4) feels cluttered. It was clearly written as a caption to Figure 1 and hence should be placed as such. Still, stand alone texts are important and in my humble opinion should be augmented with equations instead of drawings. While the latter can help understanding, it lacks precision and makes reproduction hard.\n- The MLP to predict the ground truth is not sufficiently described in the main text. I think it needs to go there, as it is quite central to the evaluation.\n\nSince the manuscript is half a page under the limit, such improvements would have been feasible.\n\nApart from the quality of the manuscipt, I like the fact that a disective study was done in such a way. \n\nHowever, I would have liked to see more comparisons, e.g. in $(x, y, \\theta)$ environments it is also possible to obtain quite good approximations of the true posterior via particle filtering. Also, other more straightforward approaches such as MDN-RNNs can represent multiple maxima in the probability landscape; this would have enabled to examine the benefit of conditioning on actions in a different context.\n\nRight now, it is unclear what the paper is about. On the one hand, it does a focused disective study with well controlled experiments, which would be a good fit if many different models were considered. On the other hand, it advertsises CPC|Action; but then it falls short in evaluating the method in more challenging environments.\n\nTo sum it up, I feel that the paper needs to be clearer in writing and in experimental structure. The currently tested hypothesis, \"does CPC|Action perform better than CPC and FP in a set of well controlled toy environments\" is, imho, not of broad enough interest.","sentences":[{"sentence_type":"1","sentence":"I found the paper hard to follow for various reasons.","rephrased":"The paper could be made more accessible by addressing a few areas that were challenging to follow."},{"sentence_type":"2","sentence":"This is formally incompatible, and I found  the connection not well explained.","rephrased":"The connection between the formal definition and the neural network output could be better explained to resolve the apparent incompatibility."},{"sentence_type":"1","sentence":"The architecture description (starting from the second paragraph on page 4) feels cluttered.","rephrased":"The architecture description could be more organized for clarity, perhaps by integrating it with the main text and supporting it with equations."},{"sentence_type":"2","sentence":"Right now, it is unclear what the paper is about.","rephrased":"Clarifying the main focus of the paper would help readers understand the scope and contributions more effectively."},{"sentence_type":"1","sentence":"To sum it up, I feel that the paper needs to be clearer in writing and in experimental structure.","rephrased":"In summary, enhancing the clarity of the writing and the experimental structure would benefit the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[550,603,"Not concerning"],[863,941,"Not concerning"],[1096,1188,"Not concerning"],[2258,2307,"Not concerning"],[2591,2688,"Not concerning"]],"Comments":[]}
{"id":"MAdvbBTgu3o","text":"Definition:\n\n- In the definition of the diversity, there is a $\\tau$. What does that mean? What is the probability space? Does it mean when you sample a point from the input distribution, with probability $\\tau$ you have the lower bound? But you should also quantify based on the weights. Am I missing something? For instance when you have a multilayer, the events are not independent so the statement of Theorem 4 is difficult to understand for me. \n\n- It would be nice if the authors can provide some sufficient conditions under which we can have the desired lower bound on the diversity. \n\nMotivation behind the diversity method:\n- In the definition of the diversity we want that the output of activations are not close to each other. However, is it sufficient? what if the weight vectors of the next layer basically \"kill\" this diversity? In general, what is the impact of the weights on the diversity?\n\nComparison with Dropout method:\n- Empirical comparison: My understanding of the dropout is that it also has a very similar impact as your method on learning. I appreciate it if you could compare the performance of your method with the dropout method.\n-Computation Comparison: \nWhat is the difference of the dropout and your method in terms of computational cost?\n\nTheorem 4: \n\nWhat is the intuition behind the Tau^p? what is the dependence of your bound on depth and width and how does it compare with Golowich et al paper?\n\nA Note regarding the references:\n\nIn many places in the manuscript, the citations do not match with the content. \nFor instance on Page 2, before definition 1, almost all of the citations are wrong. PAC learning is not from Hanneke'16. VC dimension is not from those papers you cited, and the same for Rademcher complexity.\n\n","sentences":[{"sentence_type":"2","sentence":"In many places in the manuscript, the citations do not match with the content.","rephrased":"I noticed some discrepancies between the citations and the content in various sections of the manuscript."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1467,1545,"Not concerning"]],"Comments":[]}
{"id":"fHAPVO7dCU","text":"This work tackles a challenging problem: inhale-to-exhale CT lung registration.\nBased on the work of Heinrich and FlowNet, the authors propose to use a correlation layer to generate a displacement field. \n\nPros:\n- the paper is clear and easy to read\n- reducing the computation cost by using keypoints is an interesting approach\n- evaluation shows partial but promising results \n\nCons:\n- the authors resort to the Foerstner interest operator. How many keypoints are required?\n- there is no comparison with Heinrich's method or other recent deep learning approaches","sentences":[{"sentence_type":"1","sentence":"the authors resort to the Foerstner interest operator. How many keypoints are required?","rephrased":"It would be helpful if the authors could clarify the number of keypoints needed when using the Foerstner interest operator."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[387,474,"Not concerning"]],"Comments":[]}
{"id":"HFmdjb8IsI","text":"The authors propose to extend the UNIT model for image-to-image translation and apply this to synthesis of non-contrast CT images from contrast-enhanced CT images. Subsequent experiments show that aortic calcifications can be automatically identified in the synthetic non-contrast images, but not in the original contrast images.\n\nStrengths\n-\tIt’s very strong that the authors not only perform image-to-image translation, but also evaluate the effect of this translation on a subsequent segmentation task.\n-\tGood experiments, comparing to a situation without image translation, and one with single subspace image translation. Quantitative results are convincing.\n-\tResults suggest that the proposed approach would allow automatic aortic calcium scoring in contrast-enhanced images without the need for annotated training data in these images.\n\nWeaknesses\n-\tQuite information dense paper, it’s not entirely clear what was exactly the contribution of the authors is, e.g. subspace clustering seems to have been proposed previously, as has the UNIT model.\n-\tThe individual models could have been explained a bit better, a diagram would have been useful. \n-\tIt’s unclear what the contribution of the small patches is, it would be interesting to visualize the subspaces using these small patches. Moreover, it’s unclear how the number of patches N is determined.\n-\tSome typos: ‘for simplicty’, ‘one or more subspace’.","sentences":[{"sentence_type":"2","sentence":"Quite information dense paper, it's not entirely clear what was exactly the contribution of the authors is, e.g. subspace clustering seems to have been proposed previously, as has the UNIT model.","rephrased":"The paper is rich in information, but it would be helpful to clarify the authors' specific contributions, particularly in relation to the previously proposed subspace clustering and the UNIT model."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[857,1052,"Not concerning"]],"Comments":[]}
{"id":"bQchaZkK6C","text":"Strengths \n* Interesting application of simulated annealing to solve the network compression problem.\n* Detailed overview and motivation for pruning algorithms and simulated annealing.\n\nWeaknesses\n* The limited scale and scope of the experiments puts the significance of the results into question. Experiments are conducted on MNIST and FashionMNIST and appear to be single seed, with no clear comparisons to baselines. This is a much smaller scale than similar research published e.g. lottery ticket hypothesis papers. Conducting more detailed comparison to baselines would greatly strengthen the paper.\n* The organization of the paper could be improved. There is too much space spent on discussing related work and details of the simulated annealing algorithm, which can be deferred to the appendix. This leaves less room for detailing the actual method and experiments, which come off less clearly as a result. It took me some time to understand that one-shot and gradual pruning \n* There are minor grammatical papers throughout the paper. ","sentences":[{"sentence_type":"2","sentence":"The limited scale and scope of the experiments puts the significance of the results into question.","rephrased":"Expanding the scale and scope of the experiments could enhance the significance of the results and provide a more comprehensive evaluation."},{"sentence_type":"2","sentence":"There is too much space spent on discussing related work and details of the simulated annealing algorithm, which can be deferred to the appendix.","rephrased":"Consider reallocating some of the space dedicated to related work and algorithm details to the appendix to allow more focus on the method and experiments in the main text."},{"sentence_type":"1","sentence":"There are minor grammatical papers throughout the paper.","rephrased":"There are minor grammatical errors throughout the paper that could be corrected for improved clarity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[199,297,"Maybe"],[656,801,"Not concerning"],[986,1042,"Not concerning"]],"Comments":[]}
{"id":"BkxVOiAz9E","text":"This work aims to create handwritten digit data like MNIST in other languages. The authors started with open fonts dataset and then applied image augmentation techniques to add distortions. Finally, the authors collected real handwritten digit data, and trained with BGAN to generate more handwritten like images with labels. The authors showed that direct training on the synthetic dataset gets 60-76% accuracy, and adding a small amount of real-world data gets a substantial improvement.\n\nPros:\n1. It's clearly written and easy to follow.\n2. The authors showcase a working example of synthetic-to-real transfer learning, which could be interesting to the broader ML community.\n\nCons:\n1. Ablation study missing. What would the results be if we just use the GAN generated part, and what if we only use the rest?\n\nOverall I think this paper is intersting, but I don't consider it to be very relevant for this Deep Generative Models for Highly Structured Data workshop, since it's a direct application of GAN and might be more relevant for OCR venues.","sentences":[{"sentence_type":"2","sentence":"Overall I think this paper is intersting, but I don't consider it to be very relevant for this Deep Generative Models for Highly Structured Data workshop, since it's a direct application of GAN and might be more relevant for OCR venues.","rephrased":"While the paper presents interesting work, its focus on direct application of GANs may align more closely with OCR-related venues rather than the specific theme of the Deep Generative Models for Highly Structured Data workshop."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[813,1049,"Not concerning"]],"Comments":[]}
{"id":"Y-wwY5GZ-DF","text":"The paper is clearly written. However, the results are rather a straightforward extension of the existing work by Martins et al. (2020; 2021), in which finite-dimensional exponential families and their deformed variants are used to formulate the continuous attention mechanism. In Section 4, some conditions for the finiteness of integration are introduced for the kernel-based model. These results may be important as a fundamental property of kernel-based models. However, this paper does not reveal the significant advantage of kernel-based modeling as an ingredient of continuous attention mechanism. As the author pointed out, the numerical integration required in the proposed method is the problem that should be resolved. The current form of the proposed method is far from practical usage. \n\n\nSome questions: \n- How can one choose the parameter alpha in the deformed exponential family? It would be nice to show a data-dependent method of selecting the deformation parameter.\n- To compute the context c, Is a resampling method such as the Metropolis-Hastings algorithm an efficient approach? \n\n","sentences":[{"sentence_type":"2","sentence":"The current form of the proposed method is far from practical usage.","rephrased":"The practical applicability of the proposed method could be further clarified and enhanced."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[730,798,"Not concerning"]],"Comments":[]}
{"id":"HJgte88Knm","text":"To generate a sequence of high-level visual elements for recreation or translation of images, the authors propose differentiable \"canvas\" networks and \"drawer\" networks based on convolutional neural networks. One of the main ideas is the replacement of the \"canvas\" networks instead of non-differentiable \"renderer\" to end-to-end train the whole model with mean-squared error loss. It seems to be a novel approach to optimize drawing actions. It is reasonable to use separate networks to approximate the behavior of renderer and to fix the parameters of the \"canvas\" networks to maintain the pretrained rendering capability.\n\nIntegrating the high-level visual constructs for recreation or translation of images is to eliminate or attenuate visual artifacts and blurriness, as mentioned in the introduction of the paper. Qualitative comparison with the other state-of-the-art methods is shown in Figure 6f; however, it fails to show significant improvement over them. Quantitative results do not include in the comparison, but only for the ablation study to determine the proposing method. Although the paper proposes an interesting approach to enhance an image generation task, the provided evidence is weak to support the argument, which should be useful for their criteria.\n\nMoreover, experimental details fall short to ensure the validity of experiments. How do you split the dataset as train\/val\/test? Are the reporting figures (L2 loss) from test results? How are the statistics of the datasets you used?\n\nIn Related Work, the authors describe \"reinforcement learning methods can be unstable and often depend on large amounts of training samples.\" Many RL methods use various techniques to stabilize the learning, and this argument alone cannot be the grounding that the supervised approach is better than RL. Unsupervised learning also needs a large amount of data. What is the point of this paragraph (the second paragraph in Related Work)?\n\n\nQuality: \n  Figure 1-3 are taking too much space, which might lead to exceeding 8 pages. \n\nClarity:\n  The experimental procedure is not clear. Please clarify the issues mentioned above. It is not hinder to understand the content; however, the writing can be improved by proof-reading and correcting a few grammatical errors.\n\nOriginality and significance:\n  Using the differentiable \"canvas\" networks to avoid non-differentiable \"renderer\" is a novel approach as far as I know. \n\nPros:\n  Differentiable drawing networks are underexplored in our community.\n\nCons:\n  It failed to show the excellency over pixel-wise generation methods and limited to simple visual elements, line drawings or box generations. This work does not explore \"brush strokes\" in paintings.\n\n\nMinor comments:\n\n- In Related Work, the inline citation should be \"Simhon & Dudek (2004)\" instead of \"(Simhon & Dudek, 2004)\", and this may apply to the others.\n\n- In Figure 2, the Hint should be x_n, the current state, or target image X for regeneration (X' for translation)?\n\n- In 4.1, a typo, \"Out state consists of\" to \"Our state consists of\".","sentences":[{"sentence_type":"2","sentence":"however, it fails to show significant improvement over them.","rephrased":"however, it would be beneficial to demonstrate more clearly how this method improves upon existing ones."},{"sentence_type":"2","sentence":"the provided evidence is weak to support the argument, which should be useful for their criteria.","rephrased":"the provided evidence could be strengthened to more convincingly support the argument."},{"sentence_type":"2","sentence":"Moreover, experimental details fall short to ensure the validity of experiments.","rephrased":"Moreover, additional experimental details would be helpful to fully ensure the validity of the experiments."},{"sentence_type":"2","sentence":"It failed to show the excellency over pixel-wise generation methods and limited to simple visual elements, line drawings or box generations.","rephrased":"The study could further explore the advantages over pixel-wise generation methods and expand beyond simple visual elements, line drawings, or box generations."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[906,966,"Not concerning"],[1178,1275,"Not concerning"],[1277,1357,"Not concerning"],[2515,2655,"Not concerning"]],"Comments":[]}
{"id":"xFRsZBz39yj","text":"In the very beginning, you say that no optimization algorithm can guarantee global optimum in general. It almost sounds like you say that your solution can. Do the authors agree with this?\nAlso, Bayesian optimization *in theory* can guarantee global optimization, but in practice probably not.\n\nI would like the authors to give concrete ideas of how the space G looks. Does it contain usual optimizers such as Adam? And different levels of momentum etc. \nIs it always a good idea to just make this space so high-dimensional?\n\nOn page 4 you say you extend the \"Bayesian treatment\". Can the authors expand on what they mean? Do you use more then Bayes theorem?\n\nWhy does MCMC lead to degenerate solutions? My belief is that MCMC in general is more accurate than variational inference, so is there something to worry about here?\n\nThe first equality in (4) is not the ELBO. The KL distance here is the difference between the ELBO and the marginal log likelihood.\nCan the authors do the computations in the second equality for me?\n\nCan I use the variation in g to conclude when convergence has happened? \n\nYou mention, but only very briefly, warm-starting theta. How is this done in practice? And how good is the solution immediately after warm-starting? In other words, how much improvement is done after this warm-start?\n\nI found the experiment section very difficult to read, and therefore I am not convinced of the method's superiority over the compared methods. \nAlso, in future versions, I think a comparison with some hyper-parameter optimization is necessary. \n\n","sentences":[{"sentence_type":"2","sentence":"I found the experiment section very difficult to read, and therefore I am not convinced of the method's superiority over the compared methods.","rephrased":"I suggest clarifying the experiment section for better readability, which would help in evaluating the method's advantages over the compared methods."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1319,1461,"Maybe"]],"Comments":[]}
{"id":"QyGEJ3Xyjh","text":"The paper presents a method to localise and label intervertebral discs in spinal MRIs. The method takes in a sagittal slice of a T1-weighted MRI and produces gaussian heatmaps of possible disc locations. The paper is a bit vague in terms of how the heatmaps are labelled; do you assume the topmost heatmap is always the C2-C3 IVD or do you predict separate heatmap channels for each IVD?","sentences":[{"sentence_type":"1","sentence":"The paper is a bit vague in terms of how the heatmaps are labelled;","rephrased":"The paper could provide more clarity on how the heatmaps are labelled;"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[204,271,"Not concerning"]],"Comments":[]}
{"id":"HJenDaCGcN","text":"This paper proposes to construct word embeddings from a histogram over context words, instead of as point vectors, which allows for measuring distances between two words in terms of optimal transport between the histograms. On sentence similarity and word entailment tasks, the method is competitive with previous approaches, although not by a huge margin. \n\nThe paper proposes a method to augment representation of an entity (such as a word) from standard \"point in a vector space\" to a histogram with bins located at some points in that vector space. In this model, the bins correspond the context objects, the location of which are the standard point embedding of those objects, and the histogram weights correspond to the strength of the contextual association. The distance between two representations is then measured with, Context Mover Distance, based on the theory of optimal transport, which is suitable for computing the discrepancy between distributions. \n\nPros\n- Mathematically elegant method to represent words as distributional estimates of context words.\n- Novel idea to use wasserstein barycenter to measure sentence similarity\n- Novel idea to use Wasserstein distance for hypernym detection.\n\nCons:\n- Results do not show significant improvement over baselines.\n- Potentially complicated for practitioners in the community. Computing CMD and wasserstein barycenters is not trivial and can be inefficient. For this method to be practically useful (and see wide adoption), I believe there has to be a compelling use case for using distributional estimates as oppose to standard point estimates, which isn't demonstrated in the paper. Nevertheless, I believe this paper makes an important contribution. ","sentences":[{"sentence_type":"2","sentence":"Results do not show significant improvement over baselines.","rephrased":"While the results show improvement over baselines, the extent of the improvement could be more substantial to highlight the method's advantages."},{"sentence_type":"1","sentence":"Potentially complicated for practitioners in the community.","rephrased":"The method's complexity could pose challenges for practitioners in the community to adopt it widely."},{"sentence_type":"2","sentence":"Computing CMD and wasserstein barycenters is not trivial and can be inefficient.","rephrased":"The computation of CMD and Wasserstein barycenters may require optimization to enhance efficiency and ease of use."},{"sentence_type":"2","sentence":"For this method to be practically useful (and see wide adoption), I believe there has to be a compelling use case for using distributional estimates as oppose to standard point estimates, which isn't demonstrated in the paper.","rephrased":"To encourage practical utility and broader adoption, the paper could further demonstrate compelling use cases for distributional estimates over standard point estimates."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1219,1278,"Not concerning"],[1281,1340,"Maybe"],[1341,1421,"Not concerning"],[1421,1649,"Not concerning"]],"Comments":[]}
{"id":"HQ0eU9uYqir","text":"I found this paper straightforward to read although I have several large concerns.\n\nMy first concern is that the exposition is overly complicated even though the key idea of the paper is extremely simple. The proposed model DART can be derived by just taking the known rank estimator by Jin et al (2003) and swapping out the inner product in their equation (2.1) with a neural net, and then just train using minibatch gradient descent instead of linear programming. In other words, much like how Faraggi and Simon (1995) swapped out the inner product in the semiparametric Cox model to be a neural net to come up with the same neural net model as DeepSurv (Katzman et al 2018), this paper does the same thing with the already existing semiparametric AFT model (which already was known before the Jin et al (2003) paper but the optimization procedures in estimating the regression coefficients were not optimal). From a technical novelty\/innovation perspective, there is very little that is conceptually new. Instead, the paper is motivated in a way that spends way too much emphasis\/text on describing standard results from survival analysis (e.g., what is a Cox model, what is an AFT model, why one would use standard Cox PH vs AFT, that the Cox model can be made time-dependent, that AFT models can be specified in both parametric or semiparametric forms, etc). I'd suggest perhaps having your background instead focus on existing semiparametric AFT literature, that you're simply doing a straightforward neural net extension (replace inner product with neural net), and comparing your model with DRAFT and DATE (I found Figure 1 very helpful). I'd suggest reducing the amount of text spent on explaining what hazards models are or why one should use hazards models over AFT models as this is a very old debate at this point (from what I can tell it really just depends on the data). Of course, a Weibull regression model is both a hazards model and an AFT model.\n\nMy next concern is that the experimental results are inconsistent with existing literature. As is, the experimental results presented make it seem that DART is not a clear winner over top-performing baselines. However, once we consider that some of the numbers are quite off from literature, how good DART is seems even more suspect. For example, your reported DeepHit $C^{\\text{td}}$ number for the KKBox dataset is dramatically off from Kvamme et al (2019)---basically according to what they get, DeepHit gets 0.888 which is higher than DART 0.867. Some of your IBS numbers across methods also seem off. Some explanation of these discrepancies would be helpful.\n\nThere is another exposition issue: early on in the paper, the text makes it seem like the Cox model does not make a linear assumption whereas AFT does. This isn't true. Cox assumes the partial log likelihood is linear. AFT assumes the log survival time is linear. In other words, both make linearity assumptions, just for different quantities.\n\nReferences:\n- David Faraggi and Richard Simon. A neural network model for survival data. Statistics in Medicine 1995.\n- Zhezhen Jin, D. Y. Lin, L. J. Wei, Zhiliang Ying. Rank-based inference for the accelerated failure time model. Biometrika 2003.\n- Jared L. Katzman, Uri Shaham, Alexander Cloninger, Jonathan Bates, Tingting Jiang, and Yuval Kluger. DeepSurv: personalized treatment recommender system using a Cox proportional hazards deep neural network. BMC Medical Research Methodology 2018.\n- Håvard Kvamme, Ørnulf Borgan, Ida Scheel. Time-to-Event Prediction with Neural Networks and Cox Regression. JMLR 2019.","sentences":[{"sentence_type":"2","sentence":"From a technical novelty\/innovation perspective, there is very little that is conceptually new.","rephrased":"While the paper builds upon existing models, further elaboration on the unique contributions and innovations of the DART model would enhance the paper's impact in the field."},{"sentence_type":"2","sentence":"However, once we consider that some of the numbers are quite off from literature, how good DART is seems even more suspect.","rephrased":"It would be beneficial to reconcile the discrepancies with the literature to strengthen the credibility of DART's performance claims."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[84,204,"Missed Maybe"],[912,1007,"Maybe"],[2177,2300,"Maybe"]],"Comments":[]}
{"id":"3WmZtXlhIq","text":"pros: This paper tries to discuss if the GAN-based data augmentation could improve the bone segmentation from ultrasound images.\n\ncons: 1) The paper fails to give detail about why and how the visual inspection is introduced. According to the authors, the inspectors only make sure the ultrasound looks real, then store them as snapshots. How do these snapshots improve the segmentation performance? Are the generated images have been checked with the ground truth label images?\n2) GAN is dynamically updated and balanced during the training. I do not see a strong motivation to add human interaction to augment the dataset.","sentences":[{"sentence_type":"2","sentence":"The paper fails to give detail about why and how the visual inspection is introduced.","rephrased":"The paper could provide more detail on the introduction and rationale behind the visual inspection process."},{"sentence_type":"2","sentence":"I do not see a strong motivation to add human interaction to augment the dataset.","rephrased":"It would be beneficial if the paper could further clarify the motivation for incorporating human interaction in the dataset augmentation process."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[139,224,"Confirmed"],[542,623,"Not concerning"]],"Comments":[]}
{"id":"SJlrME_6Yr","text":"This paper studied the effectiveness of Conditional Entropy Bottleneck (CEB) on improving model robustness. Three tasks are considered to demonstrate its effectiveness; generalization performance over clean test images, adversarially perturbed images, and images corrupted by various synthetic noises. The experiment results demonstrated that CEB improves the model robustness on all considered tasks over the deterministic baseline and adversarially-trained classifiers. \n\nThe proposed idea is simple, easy to implement, and generally applicable to various classification networks. I especially enjoyed the nice experiment results; indeed, it has been widely observed that many existing approaches on adversarial training sacrifice the classification performance to improve the robustness over adversarial examples [1]. The proposed approach sidesteps such a problem since it does not require adversarial retraining. It is surprising to see that the proposed method is still able to achieve stronger robustness than the models based on adversarial training.\n\nOne of my major concerns is that it has a large overlap with Fischer (2018) in terms of methodology, experiment settings, and empirical observations, which limits the general contribution of the paper. Fischer (2018) first proposed CEB objective and showed its effectiveness in various tasks, including the adversarial defense. Although this paper extends the results on adversarial defense to CIFAR 10 dataset and includes additional ablative experiments and experiments on other types of input noises, it ends up confirming very similar observations\/conclusions in Fischer (2018). Although Fischer (2018) is an unpublished work, I think that it is fair to consider that as a prior work since it is properly cited in the paper.   \n\nMy other concern is that the experiment misses comparisons against other adversarial defense approaches, which makes it difficult to understand the degree of robustness this model can achieve. The current comparisons are mostly focused on deterministic and VIB baselines, which are useful to understand the core argument of the paper, but insufficient to understand how useful CEB could be in the purpose of adversarial defense. Especially, I believe that some recent approaches that do not require adversarial training, such as [A2], are worth comparisons.  \n\nBelow are some minor comments\/questions on the paper.\n1. Section 3.2: For this experiment, BN is removed from the classification network; it would be still beneficial to see the baseline performance with BN (deterministic model) to better compare the classification performance on clean test data.\n2. Section 3.3: The performance on both baseline and the proposed model on clean data is far lower than the SOTA models. Some clarification would be helpful.\n3. It would be great to see further clarifications of improvement in CEB over VIB; currently, it is very simply justified that it is because CEB optimizes tighter variational bound on Eq.(3) than VIB. But it would also be great to see justifications from various angles (e.g. in the context of adversarial defense).  \n","sentences":[{"sentence_type":"2","sentence":"One of my major concerns is that it has a large overlap with Fischer (2018) in terms of methodology, experiment settings, and empirical observations, which limits the general contribution of the paper.","rephrased":"While the paper builds on the methodology, experiment settings, and empirical observations similar to Fischer (2018), I would encourage the authors to highlight more distinct contributions and differentiators of their work to enhance the perceived novelty and impact."},{"sentence_type":"1","sentence":"Although Fischer (2018) is an unpublished work, I think that it is fair to consider that as a prior work since it is properly cited in the paper.","rephrased":"Even though Fischer (2018) is an unpublished work, it is appropriate to acknowledge it as prior work given its proper citation in the paper, and this should be taken into account when discussing the novelty of your contributions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1060,1261,"Not concerning"],[1643,1788,"Not concerning"]],"Comments":[]}
{"id":"r1pn22FeG","text":"The paper adresses an important task to build a data-driven model traffic forecasting model. The paper takes into consideration the spatio-temporal autocorralation and tackles this with a diffusion process for convolutional recurrent neural networks. The paper lacks a comparison to other models that aim to include spatio-temporal dependencies used for this problem - namely Gaussian Processes, spatial k-NN.\nThe paper motivates the goal to obtain smooth traffic predictions, but traffic is not a smooth process, e.g. traffic lights and intersections cause non smooth effects. therefore it is difficult to follow this argumentation. Statements as 'is usually better at predicting start and end of peak hours' (caption of Figure 6) should be supported by statistical test that stress significance of the statement.\nThe method performs well on the presented data - in comparison to the models that do not consider autocorrelation. This might be because tests were not performed with commonly used traffic models or the traffic data was in favour for this model - it remains unclear, whether the proposed method really contributes better predictions or higher scalibility or faster computation to the mentioned problem. How does the proposed model behave in case of a shift in the traffic distribution? How do sudden changes (accident, road closure, etc.) affect the performance?","sentences":[{"sentence_type":"1","sentence":"The paper lacks a comparison to other models that aim to include spatio-temporal dependencies used for this problem - namely Gaussian Processes, spatial k-NN.","rephrased":"The paper would be strengthened by including a comparison with other models that account for spatio-temporal dependencies, such as Gaussian Processes and spatial k-NN."},{"sentence_type":"2","sentence":"The paper motivates the goal to obtain smooth traffic predictions, but traffic is not a smooth process, e.g. traffic lights and intersections cause non smooth effects. therefore it is difficult to follow this argumentation.","rephrased":"While the paper aims for smooth traffic predictions, it may be beneficial to consider the inherent non-smooth nature of traffic due to elements like traffic lights and intersections, and address how the model accounts for such irregularities."},{"sentence_type":"2","sentence":"This might be because tests were not performed with commonly used traffic models or the traffic data was in favour for this model - it remains unclear, whether the proposed method really contributes better predictions or higher scalibility or faster computation to the mentioned problem.","rephrased":"It would be helpful to clarify whether the proposed method offers improvements in predictions, scalability, or computation speed over commonly used traffic models, as the current tests do not fully address this comparison."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[251,409,"Not concerning"],[410,633,"Not concerning"],[930,1217,"Not concerning"]],"Comments":[]}
{"id":"X6H5onfBi7R","text":"POST-REBUTTAL FEEDBACK\n\nI like to thank the authors for their clarifications, some of which should be incorporated into the revised paper to ease readability. I have the follow-up questions on their response, but I am not expecting the authors to answer them with the limited time remaining. The authors can consider them for their revised paper.\n\nA1 : For the portfolio optimization problem, what exactly is the constraint that you have imposed on the portfolio's risk (i.e., standard deviation of the return)? How would the results vary by relaxing\/tightening this constraint, depending on the risk attitude of the investor? \nAlso, I understand that there are a number of works that have considered this problem in their experiments, such as the following work considering value at risk and variants in Bayesian optimization and the references therein:\n\nBayesian optimization of risk measures. NeurIPS 2020.\n\nIt is not clear why the proposed approach would be qualitatively and quantitatively better than the existing approaches like the above in this problem involving risk. The authors can consider expounding on this, which will help in the motivation of their work.\n\nA3 : The authors say that \"While one could design a heuristic acquisition function that puts extra weight on exploring infeasible points, this has not been previously proposed in the literature.\" Would this be a trivial modification? If so, the authors are encouraged to perform empirical comparison in this regard.\n\nA4 : The authors say that \"Our paper focuses on problems where the costs of sampling do not vary significantly across the domain.\" Can the authors provide the motivation of their problem in this regard? For example, why does the portfolio optimization problem adhere to this assumption?\n\nA6 : I would encourage the authors to add this assumption to their problem setting so that a reader knows when to prefer their proposed approach.\n\nA12: But delta remains strictly positive based on your proposed sequence. Wouldn't it miss sampling the global optimum then?\n\nPRIOR FEEDBACK\n\nLines 50-52: The authors say that \"This approach [1] requires an extremely large amount of computation to approximate the multi-step lookahead policy well, especially in problems with more than a few dimensions. This limits its applicability.\" This argument appears problematic in three ways: (1) What specific real-world applications have the authors motivated and performed in their experiments requiring higher computational efficiency, considering that the function evaluations in BO problems are typically costly? (2) Would the approach of [1] still be expensive if it is reduced to the context of 2-step lookahead? (3) Does the approach of [1] not trade off well between optimization performance and computational efficiency?\n\nHow can the proposed method be extended to one that is a truly batch mode where the second stage involves a batch of also q points to be evaluated?\n\nIt would be preferable that the authors specify exactly the form of the posterior distributions for E_0 and E_1 in the equation after line 152 to ease understanding. For example, the E_0's on the LHS and RHS do not appear to correspond to the same posterior distribution, albeit conditioned on D.\n\nPage 4: Can the authors explain why do the formulations for constructing 2-OPT-C(X_1) not consider (...)^+ like that of EI? \n\nLine 157: By setting delta > 0 in the theoretical analysis, isn't it possible that the proposed acquisition function would miss sampling the global optimum?\n\nCan the authors provide a time complexity analysis for optimizing 2-POT-C?\n\nSection 6: There is a lack of description of the three benchmark problems: Do the unconstrained conventional and non-myopic BO algorithms perform poorly in them?\n\nSection 6.1: Can the authors give the mathematical expression of the median utility gap? \n\nLines 293-296: Do the authors mean that they follow the setup of [1] by penalizing infeasibility of recommended point?\n\n\nThe following references on conventional and batch BO with multi-step lookahead are missing:\n\nSequential Bayesian optimisation for spatial-temporal monitoring. UAI 2014.\n\nGaussian process planning with Lipschitz continuous reward functions: Towards unifying Bayesian optimization, active learning, and beyond. AAAI 2016.\n\nNonmyopic Gaussian process optimization with macro-actions. AISTATS 2020.\n\n\n\nMinor issues\n\nLine 75: difficulties requiring created by\n\nLine 147: italicize D","sentences":[{"sentence_type":"1","sentence":"This argument appears problematic in three ways:","rephrased":"This argument could be further strengthened by addressing three key points:"},{"sentence_type":"1","sentence":"Wouldn't it miss sampling the global optimum then?","rephrased":"Is there a risk that this approach might miss sampling the global optimum?"},{"sentence_type":"1","sentence":"The authors say that \"This approach [1] requires an extremely large amount of computation to approximate the multi-step lookahead policy well, especially in problems with more than a few dimensions. This limits its applicability.\"","rephrased":"The authors mention that \"This approach [1] requires a significant amount of computation to approximate the multi-step lookahead policy well, particularly in higher-dimensional problems, which may limit its applicability.\""}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1999,2049,"Not concerning"],[2080,2310,"Not concerning"],[2311,2359,"Not concerning"]],"Comments":[]}
{"id":"HyeQ676ktV","text":"Summary: This paper has an interesting investigation of significance testing for RL, however I am skeptical about whether significance testing is appropriate for comparing RL experiments.  \n\nNotes: \n  -Abstract asserts that checking statistical significance is the first step towards reproducibility, which seems somewhat debatable to me.  \n  -Paper should probably just say that it’s about statistical significance in the title.  \n\nComments: \n  -This is a matter of judgement, but I feel like statistical significance is useful for cases where there is a tiny effect size, and we want to make sure that it isn’t just random noise.  For example, one of the earliest uses for statistical significance was for studying the sex difference observed in the number of newborn babies (like 50.00001% are male).  In this case it’s important to know if this result is statistically significant or just random noise.  In the case of different RL algorithms, I’d be hard-pressed to imagine a situation where we’d want to publish a new algorithm where the improvement isn’t obviously statistically significant, especially because the power of the statistical test can easily be improved just by running more trials.  \n  -I can think of one exception to this, which is if we ran our RL algorithm in the real-world, and then we had a breakdown of many different evaluation categories, and then we wanted to identify which categories had significant or non-significant improvements.  \n  -One useful outcome of this is determining the sample sizes needed for certain levels of significance, which could be helpful for determining how many trials to run for RL experiments.  \n  -Some interesting recommendations are also made regarding the choice of significance tests.  \n","sentences":[{"sentence_type":"1","sentence":"This paper has an interesting investigation of significance testing for RL, however I am skeptical about whether significance testing is appropriate for comparing RL experiments.","rephrased":"This paper presents an intriguing investigation of significance testing for RL. It would be beneficial to further explore and clarify the appropriateness of significance testing for comparing RL experiments."},{"sentence_type":"1","sentence":"Abstract asserts that checking statistical significance is the first step towards reproducibility, which seems somewhat debatable to me.","rephrased":"The abstract suggests that checking statistical significance is a key step towards reproducibility, an assertion that invites further discussion and examination."},{"sentence_type":"1","sentence":"Paper should probably just say that it’s about statistical significance in the title.","rephrased":"It might be clearer if the title of the paper explicitly mentioned that it focuses on statistical significance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[9,187,"Not concerning"],[202,338,"Not concerning"],[344,429,"Maybe"]],"Comments":[]}
{"id":"irZpjz7H3fF","text":"## Clarity\n\nThis paper and proposed method is easy to follow.\n\n## Quality\n\nThe analysis is well-motivated and fully delivered the idea.\n\n## Originality\n\nThis is original work with interesting problem.\n\n## Significance\n\nThe work is significant.\n\n## Pros:\n\n- Well-written, and clearly delivers the ideas, proposed method, and results.\n    \n- The analysis is interesting to me.\n    \n- The authors are well aware of the limitations of the proposed method.\n    \n\n## Cons:\n\n- The way authors get feature importance is not clear.\n    \n- Authors may consider using different methods for multivariate time-series forecasting such as MLP, LSTM, …\n    \n- Authors did not include similar analysis for the univariate case to highlight the benefit of the multivariate model, although authors remove some features based on the performance of univariate models.\n    \n- The variance for future forecasting results are high, then the conclusion is a bit uncertain (besides the mentioned factors like political changes, economic fluctuations, …)","sentences":[{"sentence_type":"1","sentence":"The variance for future forecasting results are high, then the conclusion is a bit uncertain (besides the mentioned factors like political changes, economic fluctuations, \n)","rephrased":"While the variance in future forecasting results is high, it would be beneficial to discuss how this impacts the reliability of the conclusions, taking into account external factors such as political changes and economic fluctuations."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[853,1026,"Not concerning"]],"Comments":[]}
{"id":"y-kuAlzILgo","text":"The authors find that different representations and models give different performance, which is not surprising. This is a known fact - in practice, domain specific models are generally trained tailored to the task at hand. These models encode implicit biases needed for the task. For vision tasks, convnets are trained and for NLP, transformers are used. Researchers are aware of this, and the conclusions of this paper add no value in my opinion. Furthermore, the experiments are performed only on MNIST with minimal architectural choices, and the results are not conclusive in any form. I recommend strongly rejecting the paper.","sentences":[{"sentence_type":"2","sentence":"The conclusions of this paper add no value in my opinion.","rephrased":"While the conclusions of this paper may be known to some in the field, it would be beneficial to discuss how they might still contribute to the broader research community or to specific applications."},{"sentence_type":"3","sentence":"I recommend strongly rejecting the paper.","rephrased":"Based on the scope and results of the experiments, I would recommend a revision to address the limitations before considering publication."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[0,111,"Missed by Model"],[386,447,"Maybe"],[448,588,"Missed by Model"],[589,630,"Not concerning"]],"Comments":[]}
{"id":"wmp9BxX3dEV","text":"This paper presents a Transformer-based model for aspect-based sentiment analysis, intended to support the unsupervised induction of constituents within the Transformer forward pass. Their evaluations demonstrate that their model can match (and in some cases improve upon) models which depend upon explicit dependency parse information in the input, and reliably exceed parse-free models.  \n\nI strongly vote for rejection, largely on grounds of quality, elaborated below.  \n\nPros: The paper begins with an interesting idea and implementation, and the results support the claim that their architecture may replicate some of the contribution of dependency parse information.\n\nCons: The presentation is unclear on the concept of \"constituent\" and the motivation of the model. The later iterations of the model become rather complicated and don't seem well-motivated. The qualitative evaluations don't strongly support the claims of the paper.  \n\nQuality\n\n1. The design of the model and the use of the word \"constituent\" seems conceptually problematic to me. What do you take the word \"constituent\" to mean for your motivation and model design? It seems to me that it might be sufficient to call the ConsTrans model a \"spatial attention smoothing\" model. Why isn't this a sufficient description? What does the concept \"constituent\" add?This question is relevant because the later model iterations are developed on further syntactic ideas (typed\/labeled relations, syntactic \"distance\"). But if the model doesn't have a necessary syntactic framing, it's not clear these are the correct model improvements to consider.\n2. The qualitative evaluations are far too light, testing only a small amount of the model performance.\n  a. Grammar induction: In particular, I would appreciate a far more in-depth evaluation of the inferred constituent structures. How do they compare to gold and silver dependency parses of within-domain sentences? The current evaluation checks for model inferences on just one short span of text (the aspect term). This is probably one of the easiest terms for the model to recognize as a constituent, too, since the aspect terms are known to be constituents and have verbatim copies in the input sentence. The current evaluation is also only performed on Twitter17 --- why?\n  b. Interpreting learnt relation labels: I found this evaluation extremely confusing, involving an ad-hoc dependency parsing algorithm built upon an a posteriori fact discovered in model analysis (that relation embedding L2 norm indicates inverse syntactic distance). The resulting parse in Figure 5 is almost entirely incorrect and commits many basic mistakes (for example, not linking the determiner \"the\" with its immediately adjacent noun). The claim about linking adjectives and nouns is not particularly interesting to me, since this is far less ambitious than the motivation of the model --- if it were, the model could have been quite a bit simpler, I think.\n3. Significance results are given (thanks!) but with a strangely high significance threshold (0.15 at one point and 0.2 at another). This is not a reasonable significance threshold in my view.  \n\nClarity\n\nSome minor comments:\n\n1. The constituent derivation algorithm is not clear. Eqn 3 suggests that constituent probabilities are a function of token pairs, but Algorithm 1 line 11 suggests that they can be indexed by a single token position. Is something missing from the algorithm presentation?\n2. Eqn 3 first condition should be i <= j, I think.\n3. Figure 4 is not a complete sentence. There's no verb. There's also no clear sentiment (aspect-based or otherwise) that we could talk about for this sentence. A different sentence could serve as both a motivating example for constituency and as a more revealing example of the model's syntactic knowledge.\n\n## Post-rebuttal response\n\nI have read the other reviews and the authors' responses, and do not wish to change my review. The proposed model seems quite complex with somewhat unclear conceptual motivations, and does not clearly demonstrate impressive performance gains despite the complexity. I would suggest that the authors attempt to change one of these things in a later paper, either by revisiting the model design, or task choice and evaluation (to better motivate the model).","sentences":[{"sentence_type":"2","sentence":"I strongly vote for rejection, largely on grounds of quality, elaborated below.","rephrased":"I recommend rejection based on concerns about the quality, which I will detail below."},{"sentence_type":"2","sentence":"The qualitative evaluations don't strongly support the claims of the paper.","rephrased":"The qualitative evaluations could be strengthened to better support the claims of the paper."},{"sentence_type":"3","sentence":"The resulting parse in Figure 5 is almost entirely incorrect and commits many basic mistakes.","rephrased":"The parse presented in Figure 5 appears to have several inaccuracies that could be addressed."},{"sentence_type":"2","sentence":"The claim about linking adjectives and nouns is not particularly interesting to me, since this is far less ambitious than the motivation of the model.","rephrased":"The claim about linking adjectives and nouns could be more closely aligned with the model's ambitious motivation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[392,471,"Not concerning"],[864,939,"Not concerning"]],"Comments":[]}
{"id":"BJgFjR-CKS","text":"Contribution:\n\nThis paper proposes two methods building upon MADDPG to encourage collaboration amongst decentralized MARL agents:\n - TeamReg: the agents are trained with an additional objectives of predicting other agents' actions, and make their own action predictable to them\n - CoachReg: the agents use a form of structured dropout, and at training time a central agent (the \"coach\") predicts the mask dropout mask that should be applied to all of the agents. An additional loss is provided so that the agent learn to mimic the coach's output from their own input so they can still apply the dropout at test time, when the coach is not available anymore.\n\nThese two methods are evaluated in 4 different MARL environments, and compared against their ablations and vanilla MADDPG.\n\n\nReview:\n\nThe paper is well written and easy to follow. It generally motivates well the design choices, both intuitively and experimentally, using numerous ablations. It includes the analysis and explanations of the failure modes, which is valuable in my opinion.\n\nThe two main limitations of the work are the following:\n - Limited scale of the experiments. The majority of the experiments contain only 2 agents, and the last one merely contains 3. It is unclear whether the additional losses proposed in this work would still perform correctly with more agents, since the regularization pressure will increase.\n - No comparison to SOTA MARL methods. The only baseline method presented here is MADDPG, upon which this work is built. Recent work tend to show that it is easily outperformed, hence comparison to stronger baselines (QMIX, COMA, M3DDPG, ...) would be advisable to assess the quality of the policy found.\n\n\nAbout the policy masks:\n- what are the value chosen for K and C?\n- Is there a reason why this particular form of dropout was chosen? Since it occurs after a fully-connected, it should be equivalent and more straight-forward to mask out C contiguous values.\n\n\nFinally, it seems to me that the two methods presented here (TeamReg and CoachReg) are not mutually incompatible. Is there a reason why you didn't to apply both of them simultaneously?\n","sentences":[{"sentence_type":"1","sentence":"The majority of the experiments contain only 2 agents, and the last one merely contains 3.","rephrased":"While the experiments provide valuable insights, extending them to scenarios with more than 2 or 3 agents could help in evaluating the scalability of the proposed methods."},{"sentence_type":"2","sentence":"Recent work tend to show that it is easily outperformed, hence comparison to stronger baselines (QMIX, COMA, M3DDPG, ...) would be advisable to assess the quality of the policy found.","rephrased":"Considering recent advancements, it would be beneficial to compare the proposed methods with stronger baselines such as QMIX, COMA, M3DDPG, etc., to further validate the effectiveness of the policies developed."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1141,1231,"Not concerning"],[1516,1699,"Not concerning"]],"Comments":[]}
{"id":"3A9WwuZoedA","text":"\nThis paper aims to deal with the learning of noisy\/corrupted labels based on the small loss criterion. If I understood well the idea is to consider a new loss function on the Wasserstein space to learn the certain and uncertain data distributions. This loss function is based on kind of penalty term ensuring that the uncertain labels lies in a Wasserstein ball for which the radius is automatically tuned to get the best possible result. This construction crucially relies on the use of the Wasserstein gradient flow associated with Gaussian distributions. To conclude, a series of experiments show that the new methodology proposed in the paper leads to state-of-art results.\n\nI think that the idea is nice and was very impressed by the numerical results reported by the authors. However, it took me a while to just understand the problem and the setting considered by the authors! My second main criticism concerns the theoretical results presented in this paper. While I think that it is important that methods are justified by rigorous results, the one presented in this paper are just not understandable by most people. Two of the main underlying issues in my opinion are that the notion and objects which are used in the paper are not introduced very much rigor (or even not at all) and the result lack of clarity. To be honest, I did not catch half of the sentences of the paper.\n\nI advise the authors to make a in-depth revision of their paper, introducing more carefully their method so it can be understand by a broader audience. One solution in my opinion, is to reduce the theoretical notion and results  to their strict minimum. I think that a lot of them are unnecessary for the introduction of the proposed methodology.   ","sentences":[{"sentence_type":"2","sentence":"While I think that it is important that methods are justified by rigorous results, the one presented in this paper are just not understandable by most people.","rephrased":"While it is important for methods to be supported by rigorous results, the presentation in this paper could be made more accessible to a wider audience."},{"sentence_type":"2","sentence":"To be honest, I did not catch half of the sentences of the paper.","rephrased":"I found some sections of the paper challenging to follow, which suggests that further clarification may be beneficial for readers."},{"sentence_type":"1","sentence":"One solution in my opinion, is to reduce the theoretical notion and results  to their strict minimum.","rephrased":"One approach could be to streamline the theoretical concepts and results to the essentials, which might make the methodology more accessible."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[968,1126,"Not concerning"],[1323,1388,"Maybe"],[1542,1643,"Not concerning"]],"Comments":[]}
{"id":"ulVoEpr_3vV","text":"Strengths: \n1. The paper is easy to follow and the authors clearly highlight the problems with prior approaches when measuring the importance of a unit.\n2. The experimental analysis corroborates these problems nicely and shows that they can be solved by the proposed feature entropy approach.\n\nConcerns:\n1. The advantage of feature entropy over the three baseline approaches is illustrated by conducting two tests (rescaling and randomness) and observing the behaviours. However, the comparisons mostly represent a sanity-check and do not illustrate the importance and practical benefit of the proposed approach. \n2. Previous approaches that measure the importance of a given node have often been compared in pruning scenarios. Is there a reason, why feature entropy can not be used in this setting?\n3. The method is compared to relatively old baselines. For instance, [1] and [2]  address a similar task of measuring neutron importance (in a pruning setting).\n\nMinor:\n- It is not quite clear from the start, what is meant my “status” of a unit. Maybe “importance” of a unit will be clearer.\n- Consider adding Model BA in Table 4 to improve clarity.\n\n[1] R. Yu, A. Li, C.-F. Chen, J.-H. Lai, V. I. Morariu, X. Han, M. Gao, C.-Y. Lin, and L. S. Davis. NISP: Pruning networks using neuron importance score propagation. In CVPR, 2018.\n[2] Y. He, P. Liu, Z. Wang, Z. Hu, and Y. Yang. Filter pruning via geometric median for deep convolutional neural networks acceleration. In CVPR, 2019.","sentences":[{"sentence_type":"2","sentence":"However, the comparisons mostly represent a sanity-check and do not illustrate the importance and practical benefit of the proposed approach.","rephrased":"While the comparisons provide a good sanity-check, it would be beneficial to further demonstrate the importance and practical advantages of the proposed approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[471,612,"Not concerning"]],"Comments":[]}
{"id":"rkxqrA8jFV","text":"This paper draws connections between pPCA and linear VAEs. I would like to argue that part is straighforward, due to the following facts:\n1. The exact pPCA posterior is a Gaussian whose mean depends linearly on x.\n2. The variational family is also linear on x; therefore it includes the exact posterior.\n3. Variational inference minimizes the KL between the variational family and the exact posterior.\n4. The expectations in the ELBO can be analytically computed.\nGiven these points, it is easy to conclude that variational inference will find the variational distribution that matches the posterior exactly, therefore recovering pPCA.\n\nThe rest of the paper uses the insights from the first part to analyze mode collapse in non-linear VAEs. I found that part more interesting than the former.\n","sentences":[{"sentence_type":"1","sentence":"I would like to argue that part is straighforward, due to the following facts:","rephrased":"The connections between pPCA and linear VAEs seem to be well-supported by the following observations:"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[59,137,"Not concerning"]],"Comments":[]}
{"id":"SyxHVDhDF4","text":"This work proposed to use gaze information in order to reduce the sample complexity of a model and the needed labeling effort to get a target performance. The proposed method uses an attention layer and adds a penalty to reduce the gap between downsampled human attention maps and class activation maps. The experimental results show an improvement especially for middle sized samples, and a higher effect for harder tasks.\n\nThe idea and method is overall interesting, and would be interesting to discuss. One direction to build on this work, other than extending the experiments to more complex, larger scale applications, is to try to leverage more information from the human attention maps, as downsampling throws away some of the information that can be interesting for training.","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"HJl3xM52tr","text":"This work tries to predict the protein functional activation on a tissue by combining the information from amino acid sequence, and tissue-specific protein-protein interaction network. The authors claim that with this joint representation, their model outperforms current methods (Omhnet) on 10 out of 13 tissues by a larger margin(19% on average).\n\nNotations:\nThe notations in experiment is a little bit confusing. In Table 1, the authors refer to different representations with Ohmnet128, Ohmnet64, Ohmnet-Unirep, etc. However, these are not consistent to the ones introduced in Section 4.1: Ohmnet, Ohmnet64-Unirep64, etc. And \"0-pad\" is introduced in section 3.3 while they denote one method as \"Ohmnet64-0Padded\" in section 4.1. It would be difficult for the reader to infer the meaning of these abbreviations.\n\nMethod:\n\n--amino acid sequence representation:\nIt would be better to report the explained variance when using Principle Component Analysis (PCA) to project the 1024-dimensional output vector of SeqVec to 64 dimensional space.  And the authors can show us more results of different projected dimensions (with different explained variance of the PCA).\n\nExperiments:\n\n--model:\nMaybe the authors can provide us more information about the model they use. For classification, what exactly the linear model is? For learning representation, is there any modification of the structure and hyperparameter of UniRef, SeqVec and OhmNet? And is there any regularization? Showing training details like batch size, epochs would be helpful, too.\n\n--data:\nIt would be better to show the details of the data this paper uses, like what the data looks like, what is the size, the distribution, and the pre-processing. What's more, since validation set is used for tuning, it would be better to report the results on test set.\n\n--result:\nIn the second paragraph of Section 4.1, it would be more clear to use a table instead of words to show the results. What's more, what's exactly the 13 tissues this paper is using? Why they are chosen? Exactly what is the AUROC of each protein in each tissue?  What the learning curves look like?\n\nAnother big issue is, what \"current methods\" is this paper comparing its result with? It seems like the authors are comparing their implementation of Ohmnet-SeqVec + linear model with Ohmnet + linear model, and report that the former one is of 19% higher AUROC than the latter. But how about the results of other models\/methods on the same task in the literature. Is there anyone using similar joint representation and what is their results? \n\n--conclusion:\nSince the proposed methods only achieve best results  in 10 out of 13 tissues, it is improper to claim \"… we make consistently better tissue-specific function predictions in 13 complex tissues …\".\n\nIn conclusion, I find this is an interesting paper, that the authors tries to combine amino acid sequence representation and tissue information to predict the activation of protein on specific tissue. However, the authors should perform more rigorous experiment, and show us more implementation details. What's more, comparing results with the start-of-art methods on the same task setting is important, too.\n\n","sentences":[{"sentence_type":"2","sentence":"Since the proposed methods only achieve best results  in 10 out of 13 tissues, it is improper to claim \". we make consistently better tissue-specific function predictions in 13 complex tissues \".","rephrased":"While the proposed methods show promising results in 10 out of 13 tissues, it would be more accurate to state that the method improves tissue-specific function predictions in a majority of the tissues studied, rather than all 13."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2589,2785,"Not concerning"]],"Comments":[]}
{"id":"r1o4FsqgM","text":"The main issue is the scientific quality. What the authors call \"intelligent mapping and combining system\" for the proposed system is simply a fully connected neural network. Such systems have been largely investigated in the literature. The use of genetic algorithms has also been considered. Moreover, mapping features to some appropriate feature space has been widely investigated, including the choice of appropriate mapping. We didn't find anything \"intelligent\" in the proposed mapping. \n\nThere are many spelling and grammatical errors.\n","sentences":[{"sentence_type":"2","sentence":"We didn't find anything \"intelligent\" in the proposed mapping.","rephrased":"The term \"intelligent\" in the proposed mapping could be further substantiated with unique features or novel approaches that distinguish it from existing methods."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[42,174,"Confirmed"],[430,492,"Confirmed"]],"Comments":[]}
{"id":"lRdMrcaXwmR","text":"This paper studies the top singular vector of the feature space learned by supervised and unsupervised deep learning models on CIFAR datasets. The hypothesis of converging feature spaces is interesting (converging both in terms of different models, and in terms of training epochs), but the conclusion from the current experiment results is overstretching.\n\n1. While the authors emphasize the convergence of subspaces, the P-vector defined in the paper is actually the top singular vector of the feature space, so it's actually about the convergence of the 1-dimensional principal subspace. A subspace refers to an arbitrary dimensional space in general. In the context of SVD, the literature often studies the top-$k$ dimensional subspace, which is represented by the $k$ top singular vectors, and the approximation error of the top-$k$ dimensional subspace: $E=\\|X - U_k \\Sigma_k V_k^T\\|_F^2$, where $X$ would be the feature matrix in this paper, and $U_k, V_k$ are the first $k$ columns in the result of SVD. The authors didn't measure $E$, so the readers won't know how well the top-1 dimensional subspace represents the feature matrix. I recommend looking at $E$ as a function of $k$, and use some criteria to determine how closely you want the subspace to approximate the feature matrix. For example, we can say we want to keep the top-$k$ dimensional subspace such that $E < 0.1 \\|X\\|_F^2$. This way, you can rule out the possibility that the P-vector is a trivial vector that every model will converge to.\n(As an analogy for a trivial vector, we can consider the top-1 eigenvector of the similarity matrix defined in the classical spectral clustering method called Normalized Cut. No matter how the edge weights in a graph is defined, the similarity matrix used in Normalized Cut always has an all-one vector as the top-1 eigenvector.)\nAnd to measure the angle between general subspaces, many methods are available including classical ones (e.g. Åke Björck and Gene H. Golub, Numerical Methods for Computing Angles Between Linear Subspaces, 1973).\n\n2. This paper tries to emphasize the P-vectors found in the features from different deep learning models are very close (for example, \"no matter what type of DNN architectures or whether the labels have been used to train the models, the P-vectors of different models would converge to the same one\"). Actually it seems the angle typically converges to 10 to 20 degrees. It may be better to lower the tone, or quantify better (compared to the angles obtained by ..., the angles between P-vectors are smaller).\n\n3. The data in Fig. 7 looks quite noisy, though p-value shows statistical significance of the correlation. p-value can guide our findings but is not always meaningful. For example, comparing Fig.7(e) and Fig.7(l), we may argue the latter has a better correlation but the former has a much smaller p-value. It seems the very small p-value in Fig.7(e) results from some outliers. Intuitively I don't quite understand why the raw data and the features should have a correlated linear principal subspace, given that the neural network layers that generate the feature from the data are highly nonlinear.\n\nThe only convincing data I found is in Table 1, which shows P-vectors can serve as an indicator of the model performance. But overall the readers would need more evidence as explained in #1 above.","sentences":[{"sentence_type":"2","sentence":"but the conclusion from the current experiment results is overstretching.","rephrased":"However, the conclusions drawn from the current experimental results may be too far-reaching and could benefit from additional supporting evidence."},{"sentence_type":"2","sentence":"The only convincing data I found is in Table 1, which shows P-vectors can serve as an indicator of the model performance.","rephrased":"The data in Table 1 is particularly compelling, demonstrating that P-vectors can serve as an indicator of model performance. It would be beneficial to see more data of this nature to strengthen the overall findings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[283,356,"Not concerning"],[3169,3290,"Not concerning"]],"Comments":[]}
{"id":"YJscYpR5Psu","text":"The paper is tackling the problem of labeling cost in Machine Reading comprehension.\nThe paper uses an uncertainty-based approach in the context of extractive machine reading to choose the point to annotate.\nIn addition, the paper uses an adaptive loss minimization schema that consists of penalizing large moves in the parameter space which strongly related trusted region types of approaches[1].\nThe authors compare to 6 baselines with mitigated results.\nWhile the paper is well-written with reasonable experiments on two machine reading datasets, I can mention three limitations for acceptance which are \n\n(1) the lack of strong novelty beyond uncertainty-based active learning applied to MRC: In its current status, the paper is proposing to measure uncertainty as entropy over the probability distribution of each token to be the start and end token of the contiguous string constituting the answer. I find this proposition pretty interesting but trivial compare to uncertainty based active learning literature applied to text [2, 3]. \n\n(2) lack of significant improvement on the considered datasets: First, the results are difficult to compare to SoA results (https:\/\/rajpurkar.github.io\/SQuAD-explorer\/) as the amount of data-point is different (Table 1). Second, the difference between the baseline methods and the proposed approach doesn't seem significant (Figure 4). Furthermore, it is currently not possible to precisely assess the result significance as the variance of the results isn't reported.\n\n(3) lack of numeral results justifying the use of the adaptive loss in this context: unfortunately, the authors proposed a second contribution related to the loss function (section 2.2) which is not evaluated with an ablation study to assess its possible utility.\n\nRefs\n[1] Trust Region Policy Optimization, Schulman and al, 2015\n[2] Uncertainty-based active learning with instability estimation for text classification, Zhu and al, 2017\n[3] Active Learning Using Uncertainty Information, Yang and al, 2017\n","sentences":[{"sentence_type":"2","sentence":"I find this proposition pretty interesting but trivial compare to uncertainty based active learning literature applied to text [2, 3].","rephrased":"While the approach of measuring uncertainty as entropy is interesting, it may benefit from a more distinct differentiation or advancement from existing uncertainty-based active learning literature in text analysis [2, 3]."},{"sentence_type":"2","sentence":"unfortunately, the authors proposed a second contribution related to the loss function (section 2.2) which is not evaluated with an ablation study to assess its possible utility.","rephrased":"It would be beneficial for the authors to include an ablation study to evaluate the impact and utility of the proposed contribution related to the loss function (section 2.2)."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[905,1039,"Not concerning"],[1597,1775,"Not concerning"]],"Comments":[]}
{"id":"UWfJPtWYDPW","text":"The proposed idea of using gradient-based scoring for de-biasing seems novel and effective. I have the following concerns and questions. \n\nThis work is based on the hypothesis that the “gradients have remarkable differences between samples generating prejudice and the others”. By observing that the label noise can degrade the performance of the proposed gradient-based model, they added the de-noising module to alleviate this issue. However, I’m not convinced if the noisy label is the only critical factor that can negatively affect the performance when using the proposed gradient-based scheme. I wonder what other factors (e.g., adversarial attacks) can degrade the performance and how to tackle them. Can you add more analysis and discussion on this? \n\nFigure 4 is drawn using the Colored MNIST. This result may be useful to illustrate the proposed hypothesis, but it may not be enough to show the generality because the dataset has a very simple structure and variation. I wonder how the plots for more natural datasets would look like, and if any theoretical analysis can be included.  \n\nThe model assumes that the biased samples make up the majority of the training set. The experiments are also based on this assumption, and the proportions of the unbiased (minority) samples in the experiments are 5% or less in all the experiments. I wonder how realistic this scenario is and how the proposed method performs on a dataset that contains a higher portion of unbiased (minority) training data (e.g., 10%, 20%, 30%,…). \n\nIn Table 2, comparing the accuracies for the Minor group, which I think is more important in the performance comparison, the performance of the proposed model “with de-noising”, compared to the case without it, is improved at the 99%\/10% setting, but not for the remaining cases of 99%\/5% and 99%\/0% (except for Watermarked MNIST, 99%\/5%, showing very low accuracy). Therefore, this result is not sufficient to validate the proposed de-noising idea. More experiments and\/or analyses should be provided. \n\nMinor comments:\n\n- Figure 3: |m|\/|D| -> |M|\/|D|\n- Page 6, Section 4.2: “From the harmonic-mean property has a higher value” (need to revise)\n- In Table 2 - 99%\/5% - Without de-noising – Major M: \n-- Colored MNIST: LfF performance is written as 00.00. Should it be 100.00?\n-- Watermarked MNIST: the performance from “Ours” is 33.26, which is much lower than the other methods (over 90). Is it a typo or any reason for this?   \n- In Table 1, the method names of “Proposed” and “Ours” are both used. It’s better to make it consistent. \n- Page 9, Section 6.2\n-- ... an accuracy similar to that o the major case. -> … an accuracy similar to that of the major case.\n-- de-basing -> de-biasing\n","sentences":[{"sentence_type":"2","sentence":"Therefore, this result is not sufficient to validate the proposed de-noising idea.","rephrased":"To strengthen the validation of the proposed de-noising idea, it would be beneficial to include additional experiments or analyses."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1897,1979,"Not concerning"]],"Comments":[]}
{"id":"kRNvgwA5qd","text":"This paper proposes an interesting and still new application of domain adaptation, image registration. The purpose is to adapt a network trained to estimate the displacement on MRI T1 patches to T2 patches. The proposed network has access to pairs of patches in the source domain, with their displacement label. In the target domain, it only has access to displaced patches. The idea to make displacement \"similar\" in the source and target domain is to match the histograms of displacements. For this end, a projected Earth Mover’s distance metric is proposed and compared to Wasserstein distance.\n\nThe ideas our straightforward. Nonetheless, a more friendly introduction to histogram distances could have been proposed. For example, it could have been beneficial to show histograms, and the resulting Wassertein distance versus the proposed one. \nA results table comparing baseline without adaptation, Wassertein, and proposed method could have been produced for clarity. The results\/ discussion section is limited, so the paper could be better organized.\n\nOverall the idea is nice and the application still new.","sentences":[{"sentence_type":"2","sentence":"The ideas our straightforward.","rephrased":"The ideas are clearly presented."},{"sentence_type":"2","sentence":"The results\/ discussion section is limited, so the paper could be better organized.","rephrased":"Expanding the results and discussion section could enhance the paper's organization and clarity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[599,629,"Not concerning"],[973,1056,"Not concerning"]],"Comments":[]}
{"id":"Ivf4OF0X2I","text":"This paper proposed a risk-based ring vaccination method that achieves better performance than the existing no-prioritization ring method and random method.\n\nStrength:\n1. Good motivation: The idea of risk-based vaccination allows more effective vaccine distribution.\n2. The experience showcases the effectiveness of the proposed risk-based ring vaccination method.\n\nWeakness:\n1. Only one experiment setup is used in experiments for evaluation. Another experiment for other diseases, or at least one other model, is more useful to better showcase the proposed method.\n2. The vaccine budget (50\/100\/200) seems a little random. A better budget based on real-world Ebola vaccine production rate is more useful to showcase the effectiveness of the proposed method in the application","sentences":[{"sentence_type":"1","sentence":"The vaccine budget (50\/100\/200) seems a little random.","rephrased":"It would be beneficial to align the vaccine budget (50\/100\/200) with real-world data on Ebola vaccine production rates to enhance the applicability of the proposed method."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[570,624,"Not concerning"]],"Comments":[]}
{"id":"Bkx7i9i1KH","text":"The paper proposes a new goodness of fit measure for generative models, and uses it to get insight into GAN's. While this is an important topic and a novel approach, I do not think the paper delivers on what it promises.\n\nI think this paper should be rejected. First, while it claims to be a general method for generative models it, it is limited to only  GANs and even for GANs it is limited. Second, most of the observations are nice but trivial, e.g. larger latent space leads to larger image.\n\nDetailed remarks:\n- The main point that the training set points x must have p(x)>0 under the model is naturally satisfied for almost all models except GANs such as VAEs, autoregressive model and flow models with standard implementations as the support is the whole space. This is in contrast to the claim in the paper that \"its applications can be extended to other generative networks such as Variational Autoencoders.\".\n- Even for GANs as this measure only looks at the support and not the distribution it is not clear if this measure does more then evaluate mode collapse. While this is an important task, it falls short of the promises the authors claim.\n- The authors claim that \"We demonstrate that our measure being minimized is a necessary and sufficient condition to detect mode collapse.\" but only show that it is necessary.\n- Proposition 1 is a trivial statement.\n- The authors claim that \" mode collapse happens if P(x) > 0 but minz ||G(z) − x|| > 0\". This is a main point by the authors, but it ignores the probability and only looks at the support. It has been shown that mode collapse happens even in 2d distributions, e.g. veegan paper, where it is easy to get the support to be the whole distribution.\n- The results in sec. 5 are quiet obvious, with a larger latent space you can naturally get a larger support, same as with a mixture model.\n\n\nIn general the method only looks at the support, ignoring the distribution over the support and is therefore very limited in evaluating generative models.  \n\n\nminor details:\n- In eq. 3 the integration should be w.r.t dP(x) for it to be monte-carlo approximated as it is in eq. 4.\n- Not 100% I understand what the authors try to say here - \"we pick the latent variable z and error ||G(z) − x||2 that corresponds to the smallest error instead of picking the latent variable that Adam Kingma and Ba (2014) finds.\"","sentences":[{"sentence_type":"2","sentence":"I think this paper should be rejected.","rephrased":"I would recommend reconsidering this paper for acceptance."},{"sentence_type":"2","sentence":"most of the observations are nice but trivial, e.g. larger latent space leads to larger image.","rephrased":"While the observations are interesting, they may be considered intuitive by some, such as the correlation between larger latent space and larger image generation."},{"sentence_type":"2","sentence":"Proposition 1 is a trivial statement.","rephrased":"Proposition 1 may benefit from further elaboration to highlight its significance."},{"sentence_type":"2","sentence":"The results in sec. 5 are quiet obvious, with a larger latent space you can naturally get a larger support, same as with a mixture model.","rephrased":"The results in section 5 appear to align with expectations, as a larger latent space typically yields a broader support, akin to what is observed in mixture models."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[222,260,"Not concerning"],[402,496,"Not concerning"],[1335,1372,"Not concerning"],[1719,1856,"Not concerning"]],"Comments":[]}
{"id":"ijJP-XyEI8","text":"The authors evaluate the effect of data augmentation -- generated using a 15 fold pix-to-pix network -- in improving an Ultrasound Bone Segmentation Model.\nThey show while having data augmentation helps perse, the multifold aspect of it is not useful. \nThere are some major concerns with the paper which I will list as follows:\n1) the pix-to-pix network is not a generative model but rather an image translation model. There it's a one to one mapping network. There are variations of that model that augment the pix2pix with a stochastic variable which one can sample from. E.G Toward Multimodal Image-to-Image Translation.  I recommend the authors to include this model in the evaluation since its a simple modification to the pix2pix network. \n\n2) While the authors do evaluate the effect that data generation has on the downstream task (segmentation task) they do not evaluate the image translation models. This could be done qualitatively by showing, conditioned on a segmentation mask,  how the images from different image translation networks look like and what degrees of variation we can hope to achieve using the 15 fold framework.  \n\nBased on these comments I don't see the paper ready to be presented as is. I encourage the authors to improve the submission and try again. \n","sentences":[{"sentence_type":"2","sentence":"Based on these comments I don't see the paper ready to be presented as is.","rephrased":"Based on these comments, I believe there are areas that could be strengthened before the paper is ready for presentation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1144,1218,"Not concerning"]],"Comments":[]}
{"id":"54ddxKpqJa","text":"This work considers the problem of gradual domain adaptation, where a model should be gradually adapted from the source to the target domain. I found the idea of generating data (at a lower-dimensional space) from intermediate distributions interesting and appealing from a practical perspective. In the following, I present my major concerns, questions, and suggestions. \n\n\n- It is not clear from the manuscript why gradual domain adaptation is a setting that should be considered in cases where no samples from intermediate distributions are available. As far as I understand, gradual domain adaptation is a setting to be considered when the distribution yielding the data is evolving over time (Kumar et al. 2020) and the goal is to incorporate this knowledge about the problem structure in the model adaptation process. Given that, it is not clear to me why considering this setting in a case where the data distribution is not gradually shifting would make sense. If this is the case, why not directly use any other domain adaptation approach?\n\n\n - A major claim of this contribution is that by mixing-up representations of both source and target domains, examples from “intermediate” distribution would be generated. Although I can get a rough intuition of what an intermediate distribution could be (e.g. a mixture of source and target domains), there is no definition or discussion regarding this in the manuscript. I suggest the authors include in the manuscript a clear definition of what such distributions are, as well as include evidence that manifold mix-up is capable of generating samples from them. \n\n\n- Experiments\n  - The authors mentioned that the decrease in confidence\/accuracy observed on examples with higher levels of perturbation observed in \nFigure 2 confirms that the reason behind the success of iterative self-training is the implicit curriculum strategy. Although I understand that this observation indicates the existence of an implicit curriculum, it is not clear to me why it indicates it is the reason behind the success of iterative self-training.\n  - It is not clear to me whether the results presented in Tables 1 and 2 are good. Even though I understand that the goal of this work isn’t to achieve state-of-the-art results in benchmarks, it is hard to assess the merit of the improvements reported in these tables without knowing how established baselines would perform in such test cases. I strongly encourage the authors to include for comparison at least DANN and CDAN.\n  - In Table 3, the authors presented results obtained on two datasets. They mentioned that in the case of Camelyon17, hospitals 0, 1, and 2 were considered as source domains while hospital 3 was the target. However, in Table 3, it seems that only results with domain 0 as the source were reported. Why is it the case? Please clarify this and modify the text accordingly.\n   - It is hard to tell whether the results presented in Table 3 indicate a relevant improvement of self-training approaches and the proposed GIFT in comparison to the considered baselines. The authors did not report if more than one run was performed. In case only one run was performed, I don’t think it is possible to draw conclusions from these experiments since models adapted via DANN, for example, are known to be quite sensitive to the initialization. \n\n\n- In addition to the aforementioned concerns, this manuscript presents several presentation and clarity issues that make it difficult to understand. In the following, I outline the major issues:\n  - In Section 2, the authors introduced the considered setting but there are several missing points regarding the introduced notation. Please properly define $n_s$, $d$, $k$, and $n_t$. Moreover, the authors did not specify the underlying assumptions of the proposed approach, i.e., is the covariate assumption required? Is label shift allowed? \n  - Furthermore, in Section 2, the authors mentioned that “The goal is to bridge the domain difference and learn a good classifier for the target domain.” What exactly does “a good classifier” mean in this sentence? I believe the authors are considering the risk minimization setting from Ben-David et al. 2010, but please let this clear in the text.\n  - It is quite difficult to parse the information contained in Algorithms 1 and 2. Several variables were not introduced, and there is no comment to explain what each line is doing. Summing this up with the fact that there is barely any explanation about GIFT training procedure and the Label-based Random Alignment throughout the text, it is hard to properly understand what the main contributions of this work are really doing. Moreover, the clarity of the Algorithms and the aforementioned contributions should be improved to facilitate the reproduction of the reported results. \n\n\n- Minor\n  - It is hard to compare the results reported in Tables 1 and 2 because they are placed too far apart in the manuscript. I think it is possible to merge both into a single table.\n  - The symbols $P_s$ and $P_t$ are used to denote different objects in the text. In Section 2, they are referred to as the source and target domains, respectively, while in Algorithm 1 they denote source and target datasets, respectively. \n","sentences":[{"sentence_type":"1","sentence":"It is not clear to me why it indicates it is the reason behind the success of iterative self-training.","rephrased":"Could you please clarify how the observation in Figure 2 specifically indicates that the implicit curriculum strategy is the key to the success of iterative self-training?"},{"sentence_type":"1","sentence":"It is hard to tell whether the results presented in Table 3 indicate a relevant improvement of self-training approaches and the proposed GIFT in comparison to the considered baselines.","rephrased":"It would be helpful if the authors could provide additional context or benchmarks to better assess the significance of the improvements presented in Table 3 for self-training approaches and the proposed GIFT."},{"sentence_type":"2","sentence":"In addition to the aforementioned concerns, this manuscript presents several presentation and clarity issues that make it difficult to understand.","rephrased":"The manuscript could benefit from improvements in presentation and clarity to enhance understanding."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2889,3073,"Maybe"],[3349,3495,"Maybe"]],"Comments":[]}
{"id":"SJxA1dN9h7","text":"In this paper, authors propose a set of  control experiments in order to get a better understanding of different deep learning heuristics: stochastic gradient with restart (SGDR),  warmup and distillation. Authors leverage the recently proposed mode connectivity (which fits a simple piecewise linear curve to obtain a low loss path that connect two points in parameter space) and CCA is a way to compute a meaningful correlation of the networks activations. All the experiments are done using a VGG-16 networks on CIFAR10.\n\nFor SGDR, authors observe that the solutions found by SGDR or SGD does not appears to be in different basins. While this contradict previous claim, it goes in the same direction than recent works which  have similar observations for the small batch\/large batch case [1]. Authors also identify that warmup tends to avoid large change the top-layers at the beginning of training and that you can achieve similar effect than warmup by freezing the top-layer. Finally authors show that most of the benefit of distillation happen by impacting the last deep layers of a network.\n \nWhile I find all those findings valuable, it is not straightforward to see how they connect to a better understanding of training deep network and how significant they are. In particular,  it is still unclear to me why heuristics such as SGDR is successful in practice or why freezing the top layer of a network improve trainability in a large batch setting?\n\nDoing control experiments in order to better understand the current practice in deep learning is extremely important, however, I don’t think that the paper in its current shape is ready for publication. \n\n[1] Empirical Analysis of the Hessian of Over-Parametrized Neural Networks (Sagun et al., 2017).\n\n\n","sentences":[{"sentence_type":"2","sentence":"While I find all those findings valuable, it is not straightforward to see how they connect to a better understanding of training deep network and how significant they are.","rephrased":"While the findings are valuable, it would be beneficial to clarify how they contribute to a better understanding of training deep networks and to discuss the significance of these findings in more detail."},{"sentence_type":"1","sentence":"In particular,  it is still unclear to me why heuristics such as SGDR is successful in practice or why freezing the top layer of a network improve trainability in a large batch setting?","rephrased":"It would be helpful if the paper could provide more insights into why heuristics like SGDR are successful in practice and how freezing the top layer of a network improves trainability in a large batch setting."},{"sentence_type":"3","sentence":"I don't think that the paper in its current shape is ready for publication.","rephrased":"The paper could benefit from further development before it is ready for publication."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1100,1272,"Not concerning"],[1273,1458,"Not concerning"]],"Comments":[]}
{"id":"o3GgGCR6OcM","text":"Strengths \n1.This paper claims that they propose a general and much more efficient out-of-distribution detection model. \n2.This paper shows that a simple CVAE model can generate pseudo OOD data to assist the training phase.\n\nWeaknesses\n1.It is obvious that this paper applies CVAE to the OOD data detection. The question is why to select CVAE as the efficient model to generate the OOD data. What is the motivation?\n2.This paper claims that we can already produce comparable results to existing SOTA contrastive learning models but much more efficient. Why? The detailed explanation is necessary.\n3.The contribution is mainly the metrics. ","sentences":[{"sentence_type":"1","sentence":"It is obvious that this paper applies CVAE to the OOD data detection.","rephrased":"The paper applies CVAE to OOD data detection, but it would be helpful to clarify the reasons for choosing CVAE as the model for this purpose."},{"sentence_type":"2","sentence":"The contribution is mainly the metrics.","rephrased":"While the paper introduces new metrics, it would be beneficial to discuss how these contribute to the field in the context of existing literature."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[238,307,"Not concerning"],[599,638,"Not concerning"]],"Comments":[]}
{"id":"r1lz6H9sFN","text":"This paper presents a method for the stream-based active learning problem, which is a combination of active learning and one-shot learning.\nThe paper frame this problem as a reinforcement learning problem, and thus an AL-strategy (policy) is learned by an RL agent.\nThe main contribution of the proposed model is two-fold: equipping memory networks and a special sampling trick named Class Margin Sampling to deal with noisy initial samples.\n\nThe presentation of this paper is good. It would be very helpful to talk (with figures) about the overall workflow of the model at the beginning of Section 3 such that readers can have a big picture before they dive into the detailed solutions of each part.\nA running example is also necessary to explain the whole stream-based AL problem and the solution proposed by the authors.\n\nThe two contributions are not particularly innovative, and the distinctions between the proposed work and (Pang et al. 2018) could be illustrated more.\nThe experiments on other datasets and comparisons with more baseline methods (even non-stram-based AL methods) are necessary to evaluate the proposed method.\n\nI think this paper would become a strong paper after improving the presentations and experiments. But for now, I would say it is not that ready for publishing.","sentences":[{"sentence_type":"2","sentence":"The two contributions are not particularly innovative,","rephrased":"The contributions could be further differentiated from existing work to highlight their novelty,"},{"sentence_type":"2","sentence":"But for now, I would say it is not that ready for publishing.","rephrased":"With further development in the areas mentioned, the paper would be better positioned for publication."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[825,879,"Not concerning"],[1234,1295,"Not concerning"]],"Comments":[]}
{"id":"Syx7meRz54","text":"The authors propose to construct a generative model by training an autoencoder with a structured latent space. In this latent space, new datapoints can be generated by interpolating between existing datapoints, either linearly or by masking and replacing. They demonstrate that this model performs well at interpolating between data and that it can make use of supervised data attributes.\n\nMy main lingering question after reading the paper is about how exactly the method works theoretically. That is, is there a single objective which this method optimizes? Exactly what properties should we expect the latent space to have?\n\nMinor note: On the first line of text after Equation 3, it says lambda where I believe it was meant to say alpha.\n\nPros:\n- Good results\n- Strong empirical exploration\n\nCons:\n- Limited theory and complicated objective function sheds little light on the mechanism of the method's success\n","sentences":[{"sentence_type":"2","sentence":"Limited theory and complicated objective function sheds little light on the mechanism of the method's success","rephrased":"The theoretical grounding and the complexity of the objective function could be further clarified to enhance understanding of the method's success mechanisms."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[804,913,"Not concerning"]],"Comments":[]}
{"id":"B1eRnOfRYH","text":"This paper proposes a method for performing an SVD on a mean-subtracted matrix without having to actually subtract the mean from the matrix first. \n\nWhile the problem of calculating an SVD is fundamental, the paper’s idea and general problem it covers is a clear mismatch for ICLR in my opinion. The algorithm is an extension of a previous one. Since the idea is very simple, one would expect a lot of theory, but the main theoretical result in Section 4 can be copy-pasted from the previous algorithm since they share the same result. Three sources are cited, indicating either a very narrow view of the field, or overconfidence in the fundamental significance of the contribution.\n\nThe experiments show the technique works as advertised, but the importance of the result is low.","sentences":[{"sentence_type":"1","sentence":"The algorithm is an extension of a previous one.","rephrased":"The algorithm builds upon a previous one, which could be an opportunity to highlight how the current work advances the field."},{"sentence_type":"2","sentence":"Since the idea is very simple, one would expect a lot of theory, but the main theoretical result in Section 4 can be copy-pasted from the previous algorithm since they share the same result.","rephrased":"Given the simplicity of the idea, it would be beneficial to see a more robust theoretical framework, particularly in Section 4, to distinguish it from previous algorithms."},{"sentence_type":"3","sentence":"Three sources are cited, indicating either a very narrow view of the field, or overconfidence in the fundamental significance of the contribution.","rephrased":"Citing a broader range of sources could provide a more comprehensive context for the contribution and help demonstrate its significance within the field."},{"sentence_type":"2","sentence":"The experiments show the technique works as advertised, but the importance of the result is low.","rephrased":"While the experiments validate the technique, further discussion on the broader impact and potential applications could enhance the perceived importance of the results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[296,344,"Not concerning"],[345,535,"Confirmed"],[536,682,"Not concerning"],[684,780,"Maybe"]],"Comments":[]}
{"id":"c05HR_w4sJ","text":"Pros:\n- Well written\n- Clearly motivated\n- Quality and clarity of the presentation are great\n- Experiments are conducted on a very large dataset\n\nCons:\n- Unclarities in methodology (1): for n volumes, you end up with n-1 subtraction images. How can you multiply these elementwise with n volumes? \n- Unclarities in methodology (2): How is MC dropout applied, or where is dropout placed in the network?\n- Originality: The way the focus was put in this work forces me to question the novelty. I'd have loved to see more details and justifications on the design choices of the network input\n- Data (Minor): Why was T2 used instead of FLAIR?\n- How would one determine a threshold on uncertainty, which commonly is not between 0 and 1, on a test set for which training set uncertainties is not known?\n- What precisely is meant by \"at reference\"?\n- What exactly is the output of the 3D Unet? One segmentation volume, or 3 of them?\n- The reported metric: ROC and AUROC are not suitable for my point of view in this context. I'd assume that lesion and background pixels are heavily imbalanced, which calls for the Precision-Recall-Curve and the respective area under it.","sentences":[{"sentence_type":"2","sentence":"Originality: The way the focus was put in this work forces me to question the novelty.","rephrased":"Originality: It would be helpful to provide more details and justifications for the design choices to better understand the novel contributions of this work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[403,489,"Not concerning"]],"Comments":[]}
{"id":"CopCioX0eI","text":"\nClarity:\n---------\nMajor:\n******\nIt is not clear what the actor critic algorithm is. What is presented in Fig 1 seems to be policy iteration, and Theorem 1 seems to be stating policy iteration (yet $\\pi^{n+1}$ has not been defined). \n\nMinor:\n*****\n1) What is $V^{\\pi^n}$? Is it the value function of the policy $\\pi^n$.\n2) What is the difference between $\\pi^{*,n}$ and $\\pi^{n+1}$.\n3) What is $\\pi$ is eq(3)?\n\n\nQuality:\n-----------\n1) The argument following eq (15) is very informal: \"the number of samples in $\\mathcal{D}^{n+1}$ is only a little more than in $\\mathcal{D}^n$\".\n2) For the contraction property of the Bellman operator, the author can consider citing standard text books instead of \"https:\/\/towardsdatascience.com\/ mathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f\"\n\n\nSignificance:\n------------------\n1) The  authors claim \"We present a convergence analysis for actor-critic methods by Banach’s Fixed Point Theorem\" to be one of the contributions. The fixed point theorem here is to show that Bellman operator is a contraction operator (a well known fact).\n2) The experiments are on only 5 domains. \n\n\nOverall Feedback: Adding the KL based penalty is perhaps a useful idea (this may also not be an entirely new one). It will be great if a) the algorithm can clearly stated,  b) the novelty of the method pointed out clearly by comparing it with related works c) the ideas can be supported by formal theoretical statements.","sentences":[{"sentence_type":"2","sentence":"The argument following eq (15) is very informal: \"the number of samples in \\(\\mathcal{D}^{n+1}\\) is only a little more than in \\(\\mathcal{D}^n\\)\".","rephrased":"The argument following eq (15) could be made more rigorous. For instance, providing a clearer quantification of the sample sizes in \\(\\mathcal{D}^{n+1}\\) compared to \\(\\mathcal{D}^n\\) would strengthen this section."},{"sentence_type":"1","sentence":"For the contraction property of the Bellman operator, the author can consider citing standard text books instead of \"https:\/\/towardsdatascience.com\/ mathematical-analysis-of-reinforcement-learning-bellman-equation-ac9f0954e19f\"","rephrased":"For the contraction property of the Bellman operator, it would be beneficial to reference more authoritative sources or standard textbooks."},{"sentence_type":"1","sentence":"The experiments are on only 5 domains.","rephrased":"Expanding the experiments to include more domains could provide a more comprehensive evaluation of the proposed method."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[583,810,"Not concerning"],[1105,1143,"Not concerning"]],"Comments":[]}
{"id":"B1xV5ifgT7","text":"This paper is about CNN model compression and inference acceleration using quantization. The main idea is to use 'nest' clustering for weight quantization, more specifically, it partitions the weight values by recurring partitioning the weights by arithmetic means and negative of that of that weight clustering.\n\nI have several questions for this paper:\n\n1) the main algorithm is mainly based on the hypothesis that the weights are with Gaussian distribution. What happens if the weights are not Gaussian, such as skewed distribution? Seems the outliners will bring lots of issues for this nest clustering  for partitioning the weight values.\n\n2) Since the paper is on inference acceleration, there is no real inference time result. I think having some real inference time on these quantized models and showing how their inference time speedup is will be interesting.\n\n3) Activation quantization in Section 4 is a standard way for quantization, but I am curious how to filter out the outliner, and how to set the clipping interval?\n\n4) I am not sure what does the 'sparsity' mean in Table 2? Does this quantization scheme introduce many zeros? Or sparsity is corresponding to the compression ratio? If that is the case, then many quantization algorithms can actually achieve better compression ratios with 2 bits quantization.","sentences":[{"sentence_type":"2","sentence":"Seems the outliners will bring lots of issues for this nest clustering  for partitioning the weight values.","rephrased":"It would be helpful to address how the method handles non-Gaussian distributions, as the presence of outliers could potentially affect the nest clustering's partitioning of weight values."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[536,643,"Not concerning"]],"Comments":[]}
{"id":"ENuFZ4RneTa","text":"The paper proposes to reutilize pretrained MAML checkpoints for out-of-domain few-shot learning, combining with uncertainty-based adversarial training and deep ensembles.\n\nPros:\n\n1. The idea of combining meta-learning, uncertainty learning and adversarial training is well-structured. In particular, the related work part provides a clear introduction of background work.\n\n2. It is quite novel to leverage adversarial learning as data augmentation for meta-testing in MAML.\n3. The paper provides extensive and convincing experiment results over evaluating the proposed model’s robustness to the choice of base stepsizes.\n\nCons:\n\n1. It would be better if an optimization equation is provided, especially if there are generated adversarial examples.\n\n2. For the ablation study, the authors mention that the best absolute performance (Top-1) is always obtained through some use of adversarial training. Actually, it would be more convincing if they can discuss more choices of \\lambda_{AT} and \\lambda_{AUG} and \\lambda_{a} to present the sensitivity analysis of the hyper-parameters.","sentences":[{"sentence_type":"1","sentence":"Actually, it would be more convincing if they can discuss more choices of \\lambda_{AT} and \\lambda_{AUG} and \\lambda_{a} to present the sensitivity analysis of the hyper-parameters.","rephrased":"To strengthen the paper, a more detailed discussion on the choices of \\lambda_{AT}, \\lambda_{AUG}, and \\lambda_{a} could provide valuable insights into the sensitivity of the hyper-parameters."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[900,1081,"Not concerning"]],"Comments":[]}
{"id":"EPLZzu4SiA","text":"The paper introduces an inception based network to predict gaussians on the posterior intervertebral disks. This problem has important clinical application and the results are reasonable.  \nThere are papers on labeling vertebrae in CT scans and radiographs with very similar approaches. They estimate the vertebrae location and label them using gaussian functions or heat maps. The proposed method in this abstract could be compared to those relevant publications. \n\n1) Payer, Christian, et al. \"Integrating spatial configuration into heatmap regression based CNNs for landmark localization.\" Medical Image Analysis 54 (2019): 207-219.\n\n3) Bayat, Amirhossein, et al. \"Vertebral Labelling in Radiographs: Learning a Coordinate Corrector to Enforce Spinal Shape.\" Computational Methods and Clinical Applications for Spine Imaging: 39.\n\n4) Sekuboyina, Anjany, et al. \"Btrfly net: Vertebrae labelling with energy-based adversarial learning of local spine prior.\" International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2018.","sentences":[{"sentence_type":"1","sentence":"There are papers on labeling vertebrae in CT scans and radiographs with very similar approaches.","rephrased":"The paper could benefit from discussing how it builds upon or differs from existing work on labeling vertebrae in CT scans and radiographs, which also use similar approaches."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[190,286,"Not concerning"]],"Comments":[]}
{"id":"UXgz7Hss5R","text":"In this paper, authors proposed EDGI, method based on diffusion framework, which is equivariant with respect to the product of the spatial symmetry group SE(3), the discrete-time translation group ℤ, and the object permutation group 𝕊ₙ. Paper is well written (with good visuals for the main architecture), all the details are explained clearly (even for readers who are not familiar with the topic, as I am) and all the claims are aligned with the actual results. While the results in standard setting are on par with Diffuser, EDGI is superior in the generalization setting and has greater sample efficiency in low data regime. Thus, I believe that this work is a novel and valuable contribution. \n\nIn addition, I think it would be helpful to also add a comparison of inference and learning times versus baselines, so that the reader can understand how much overhead gives equivariance, as usually in robotics there are quite strict limitations to the inference speed.","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"rkgtvbuH9S","text":"This paper proposes a variant of adversarial learning to achieve some of the popular group fairness definitions. The main novelty is the idea of minimizing Wasserstein distance between the conditional distributions of classifier predictions given different values of the protected attribute.\n\nMy main concern is the approximation of a simple 1d Wasserstein distance with a neural network. Wasserstein distance between two discrete distributions in 1d can be computed in closed form (simple function of order statistics). That is, eq. (1) is simple to evaluate for two empirical distributions. There is no need to use a neural network for approximation, and even if authors choose to do so, some discussion on how well it approximates actual Wasserstein distance is needed. I think the proposed algorithm could be more interesting if authors can work out the optimization problem with the actual Wasserstein distance.\n\nOn the theoretical\/motivation side, it is not enough to say that demographic parity is achieved when the corresponding Wasserstein distance is 0. What is needed is that demographic parity difference is bounded from above by the corresponding Wasserstein distance (I don't know if it is true or not, but would like to know). Then minimizing Wasserstein distance to achieve demographic parity could be justified.\n\nFinally, the paper is quite poorly written. The description of fairness in the introduction is very vague. Authors essentially describe demographic parity as fairness, while it is simply one of the several definitions of group fairness. There is also individual fairness (the paper by Dwork et al. is cited, but not properly discussed) and prior work emphasizing certain deficiencies of group fairness [1] along with several recent papers studying individual fairness [2,3], some also utilizing Wasserstein distance [4].\nAuthors also provided incorrect definition of disparate impact. Equation in the bottom of page 2 corresponds to statistical parity difference, while disparate impact is the ratio.\n\"Equality of opportunity\" on the top of page 3 seems to be a typo\n\"the mathematical properties of the disparate impact measure are not favorable, in particular it lacks robustness and smoothness features which would be necessary to blend algorithmic practice and mathematical theory\" - I don't think this claim makes sense. There are many prior works studying disparate impact and proposing algorithms to achieve it, e.g. the cited work of Feldman et al. Authors should be more specific regarding what mathematical properties they consider not favorable.\n\nThere are a lot of typos and grammatical mistakes, e.g.\nin the 1st paragraph of section 2.2, the sentence \"Hence the aim in this case is to” is unfinished.\nin the 1st paragraph of section 3, the first sentence seems to be unfinished.\n\n[1] Kleinberg, J., Mullainathan, S., & Raghavan, M. (2016). Inherent trade-offs in the fair determination of risk scores.\n[2] Kearns, M., Roth, A., & Sharifi-Malvajerdi, S. (2019). Average Individual Fairness: Algorithms, Generalization and Experiments.\n[3] Jung, C., Kearns, M., Neel, S., Roth, A., Stapleton, L., & Wu, Z. S. (2019). Eliciting and Enforcing Subjective Individual Fairness.\n[4] Yurochkin, M., Bower, A., & Sun, Y. (2019). Learning fair predictors with Sensitive Subspace Robustness.","sentences":[{"sentence_type":"2","sentence":"Finally, the paper is quite poorly written.","rephrased":"Finally, the paper could benefit from improvements in clarity and structure."},{"sentence_type":"1","sentence":"There are a lot of typos and grammatical mistakes, e.g.","rephrased":"The paper contains several typos and grammatical errors that need to be addressed, for example,"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1330,1373,"Maybe"],[2587,2642,"Not concerning"]],"Comments":[]}
{"id":"rJlqb64qn7","text":"Summary of the paper:\nThe paper proposes an algorithm to find solution to the maximum likelihood problem that could generalize well. The paper argues from the point of view that purely optimizing over the likelihood could result in solution that corresponds to poor local minimum which does not generalize well. By introducing a certain prior on weight, there exists a solution that could generalize. The solution arrived by introducing the prior makes it stable under perturbations of the training data. Recurrent update rules are derived for computing the integrals and hence the solution could be calculated. The authors discuss about the convexity of the effective loss when the variance is large. \n\nThe paper itself is very bad in its presentation. In terms of technical presentation, it is missing a lot of details, which makes reading and understanding the paper very hard.\n1.\tIt does not come with any proper literature review and introduction to the formulation of the problem. \n2.\tThe presentation of the methodology is also missing a lot of the explanation for many of the details used in the method. For example, in section 2, I do not quite understand the reasoning behind setting the probability P(y|x,w) = (1+1\/T lnP(y|x,w))^T. Also, why R_t(w)\/Q_(t+1)(w) could be approximated by 1. \n3.\tThe theoretical results come in plain words without proper mathematical presentation and the proofs for the statements are not well organized. The correspondence between the proofs and statements are not clear.\n4.\tThere seems to be no experiments conducted to support the practical use of the method proposed in the paper.\n\nOverall, I feel the paper is not ready for publication as a conference paper. The lack of details especially for the technical presentation part make it very hard to read. And the presentation of the results seem to be short of clarity and organization. Further, no experiments showing the practicality of the method are included in the paper.\n","sentences":[{"sentence_type":"3","sentence":"The paper itself is very bad in its presentation.","rephrased":"The paper could benefit from improvements in its presentation."},{"sentence_type":"2","sentence":"Overall, I feel the paper is not ready for publication as a conference paper.","rephrased":"Overall, the paper may require further refinement before it is ready for publication as a conference paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[704,753,"Confirmed"],[1627,1704,"Not concerning"]],"Comments":[]}
{"id":"rkgI6MHnKB","text":"Summary\nThis paper propose an extention method of SGD, deep gradient boosting (DGB), which views the back-propagation procedure as a pseudo-residual targets of a gradient boosting problem. To apply DGB to the real CNNs, DGB is simplified to a input normalization layer, conditioned on the assumption that the convolution kernels should be small. After applying the input normalization layer to CNNs, the model could achieve comparable performance to the model with BN on CIFAR-10 and ImageNet recognition.\n\nThere are several concerns influencing my rating:\n* I cannot catch the advantages of this input normalization layer compared to BN. For example, could this input normalization layer help to address the problem that BN performs bad when batch size is small? The authors mention that this layer does not have additional parameters. But as I know, the parameter size of BN is small, which downgrades the significance of the proposed method. \n\n* In the CIFAR-10 and ImageNet experiments, only the VGG model is adopted, which obviously limits the application scope. Could the proposed method work well on ResNet, DenseNet or other more recent deep architectures?\n\n* In the DGB experiments, the improvements of DGB compared with SGD in four datasets all seem marginal, in which DGB is slower than SGD. \n\nOverall, I recognize the exploration of this method. But the advantages of DGB compared to SGD seem marginal.\n","sentences":[{"sentence_type":"1","sentence":"I cannot catch the advantages of this input normalization layer compared to BN.","rephrased":"It would be helpful if the authors could clarify the advantages of this input normalization layer compared to BN, such as whether it addresses the issue of BN's performance with small batch sizes."},{"sentence_type":"2","sentence":"But as I know, the parameter size of BN is small, which downgrades the significance of the proposed method.","rephrased":"Considering that the parameter size of BN is already small, it would be beneficial for the authors to further discuss how the proposed method's lack of additional parameters significantly contributes to its utility."},{"sentence_type":"2","sentence":"But the advantages of DGB compared to SGD seem marginal.","rephrased":"The authors might consider providing more evidence or discussion on the advantages of DGB over SGD, as the current results suggest that the improvements are not substantial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[559,638,"Not concerning"],[837,944,"Not concerning"],[1358,1414,"Not concerning"]],"Comments":[]}
{"id":"SGxIgulZM9","text":"The authors provide a clear summary of the paper. However, beyond that, I would expect at least one of two contributions to make sure the blog post adds value compared to just reading the paper: (a) a thorough introduction of the background and theory for non-experts; or (b) a critical assessment of the papers claims and comparison to related (possibly newer) literature. As far as I'm concerned, neither of the two is sufficiently provided in the blog post, which makes me question its usefulness compared to \"just\" reading the paper itself. Moreover, there are some technical statements that seem dubious (see below).\n\n**Major comments**\n- In graph signals on nodes, the domain for the functions $f_i$ is written as $\\mathbb{V}$, but then the functions are called as $f_i(t)$. Should the domain therefore be time?\n- In the same section, it says $f(t) = \\lbrace f_i(t) | i \\in \\mathbb{E} \\rbrace$ where I suppose it should rather say $i \\in \\mathbb{V}$?\n- In graph signals on edges, again it seems like the domain of $F$ should be time and not $\\mathbb{E}$\n- In gradients on graphs, the operator $\\nabla$ seems to take two node functions to yield one edge function, so should the domain rather be $L^2(\\mathbb{V}) \\times L^2(\\mathbb{V})$?\n- For the Laplace-Beltrami operator, it is entirely unobvious to be how the introduced matrix $L = D-A$ relates to the $\\Delta$ operator defined below\n- For the triangulated mesh, it would be useful to give some intuition for where the cotangent is coming from\n- The system of coupled equations at the bottom of the related work has two definitions of $y[\\cdot]$ and none for $x[\\cdot]$. I guess the second one should be $x$ instead of $y$?\n- In the description of the SDL, it is completely unclear what the function $g(\\cdot)$ is, that maps from nodes and edges to $w_{ij}$ parameters. Given that this is one of the main parts of the proposed method, I feel that it should be explained in a bit more detail.\n- Similarly, in the RGN section, the functions $\\phi^e$ and $\\phi^v$ are not very well explained.\n- In general, it would be nice to not only copy the experiments from the paper, but also provide some critical assessment of how well they test the proposed method and maybe describe some experiments that other (newer) papers have used that could be added.\n\n**Minor comments**\n- The post should be checked for spelling, e.g. \"characteristic ... are\" -> \"characteristics ... are\", \"core for Fourier transform\" -> \"core for the Fourier transform\", \"methods ... dates back\" -> \"methods ... date back\", \"donot\" -> \"do not\", etc.\n- The solar panel example is not entirely convincing. Surely, in practice, one would just take the past number of sunshine hours to choose a spot for solar panels. It is dubious whether a graph neural network could provide any better prediction than that as a decision criterion on the relevant time scales.","sentences":[{"sentence_type":"2","sentence":"As far as I'm concerned, neither of the two is sufficiently provided in the blog post, which makes me question its usefulness compared to \"just\" reading the paper itself.","rephrased":"I believe the blog post could be enhanced by providing a more thorough introduction of the background and theory for non-experts, or by offering a more critical assessment of the paper's claims and comparison to related literature, to add value beyond the original paper."},{"sentence_type":"2","sentence":"In the description of the SDL, it is completely unclear what the function $g(\\cdot)$ is, that maps from nodes and edges to $w_{ij}$ parameters.","rephrased":"The description of the SDL would benefit from a clearer explanation of the function $g(\\cdot)$, which maps from nodes and edges to $w_{ij}$ parameters, as it is a crucial part of the proposed method."},{"sentence_type":"2","sentence":"The solar panel example is not entirely convincing. Surely, in practice, one would just take the past number of sunshine hours to choose a spot for solar panels. It is dubious whether a graph neural network could provide any better prediction than that as a decision criterion on the relevant time scales.","rephrased":"The solar panel example could be strengthened by discussing how a graph neural network might offer advantages over traditional methods, such as using historical sunshine hours, for selecting solar panel locations."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[374,544,"Maybe"],[1685,1828,"Maybe"],[2576,2881,"Not concerning"]],"Comments":[]}
{"id":"f6Xv0t1NdJE","text":"Strengths:\n* Derives novel generalization bound for time-varying (learning rate \/ batch size) ratio.\n* Proposes a novel functional form for the generalization error w.r.t. the (learning rate \/ batch size) ratio, and empirically show that it is empirically realistic for image classification tasks.\n* Proposes a novel model-based hyperparameter optimization method, which outperforms Bayes optimization baselines that search over the uniform range.\n\nWeaknesses:\n* The proposed model-based hyperparameter optimization searches in uniform range --- I find the argument for using this rather than the logarithmic range baselines not convincing. I don’t see how searching in the uniform range is **more theoretically sound** than the logarithmic range. As for practical usefulness, the proposed method can only match the logarithmic-range baselines in final accuracy with slower convergence.\n\nQuestions:\n* To approximate the learning dynamics as an SDE, the learning rate needs to be small. However, in the experiments, the learning rates aren’t necessarily always small throughout training (e.g. 1\/(2^i) i=2,..., 12). Also, larger learning rate corresponds to poorly fitted parts of the models (figure 1). This seems to suggest the proposed hyperparameter optimization method won’t work very well for larger learning rate. Does that agree with your experiment results, and any ideas on how to solve this issue?\n* The model treats terms that contain t as constants (e.g. a0, a1, …, a4). This seems to assume the total number of training epochs to be fixed. However, in practice, early stopping is often needed for better generalization. How would the proposed method deal with potential early stopping?\n","sentences":[{"sentence_type":"2","sentence":"I don't see how searching in the uniform range is **more theoretically sound** than the logarithmic range.","rephrased":"Could you provide more justification for choosing to search in the uniform range over the logarithmic range? The theoretical advantages of this approach are not immediately clear."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[641,747,"Not concerning"]],"Comments":[]}
{"id":"r1edB9X53E","text":"This paper is quickly written by expert author(s) in order to take part in the ICAPS workshop and consequently in the conference (I guess). I am sympathetic with the idea of going to ICAPS hence I would not complain too much on the strong dependence of this paper from a last year paper to another ICAPS workshop.\n\nThe point of the object-centered representation is a good one and I would really encourage the authors to \"revise a bit\"  the paper in its final version adding a couple of pages of formal materials to make it more self-contained.\n\nI would also recommend them to situate the paper a bit more with the topic of the workshop.  Maybe they can mention in the intro as a minimum the work of GIPO and ItSIMPLE to create minimal connections instead of just having reference from the authors environment.\n\nIn general the paper is good for a \"non official proceedings\" workshop.","sentences":[{"sentence_type":"2","sentence":"This paper is quickly written by expert author(s) in order to take part in the ICAPS workshop and consequently in the conference (I guess).","rephrased":"The paper appears to have been prepared promptly by expert authors, likely to meet the ICAPS workshop submission deadline."},{"sentence_type":"2","sentence":"In general the paper is good for a \"non official proceedings\" workshop.","rephrased":"Overall, the paper is a solid contribution suitable for a workshop format."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,139,"Maybe"],[812,883,"Maybe"]],"Comments":[]}
{"id":"70eroWPIsWx","text":"**Summary**\n\nThis work considers the problem of learning skills that are useful for acting on multiple objects. They propose an intrinsic reward that is derived from counterfactual reasoning: if an agent observes a transition where two objects interact with each other (e.g., by stacking them), how does this transition differ from an imagined\/counterfactual world where one of the objects has been displaced or perturbed such that no interaction occurs? The difference between the observed transitions and counterfactual transitions (estimated with either a learned forward model or successor features) becomes an intrinsic reward signal (where more difference is better). The authors compare their intrinsic reward with several others from the literature and show that their method leads to a higher success rate in producing object-object interactions in environments without extrinsic reward: either stacking boxes on top of each other or magnetically connecting two objects together.\n\n**Relevance and significance**\n\nThis paper is very relevant and interesting to RRL because it tackles skill learning. The kind of object-object interaction skill developed by this work can be relevant for accelerating learning in downstream tasks that require some composition of objects, e.g., stacking blocks into a certain configuration or, to give an example in the real world, combining furniture components into a whole (example given by authors). \n\n**Quality and clarity**\n\nThe paper is well-written and clear.\n\n**Feedback**\n\nI would be interested in seeing an application\/fine-tuning of this work's learned skills to a downstream task (where there is an extrinsic reward), even something simple like rewarding the agent for stacking exactly 3 blocks. The reward accumulated in a downstream task would be able to measure how useful the learned skill is. In contrast, the current measure of success rate seems to be entangled with the proposed intrinsic reward and only seems to measure whether the intrinsic reward is working as expected\/desired.","sentences":[{"sentence_type":"2","sentence":"In contrast, the current measure of success rate seems to be entangled with the proposed intrinsic reward and only seems to measure whether the intrinsic reward is working as expected\/desired.","rephrased":"However, it would be beneficial to see how the current measure of success rate, which is closely related to the proposed intrinsic reward, translates to practical utility in downstream tasks with extrinsic rewards."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1851,2043,"Not concerning"]],"Comments":[]}
{"id":"Bye8oOS6Yr","text":"This submission proposes a continual density ratio estimation method and suggested its application to evaluate a continually learned generative model without requiring the previous training data. The basis of the continual density estimation is based on a recursive relationship between the density ratio at step t and that at t - 1. Continually estimating the density ratio without storing the raw data is an interesting topic and could be useful for continual learning. To my knowledge, I have not seen this in earlier publications.\n\nHowever, I give reject to this paper because of the following reason: \n\nThe writing of this paper is not easy to follow. \n\n- The beginning of section 3 (CDRE in continual learning), I found it difficult to understand why the model q needs to be updated (indexed by t) while p(x) is not dependent on t. As far as I know, under the continual learning setting the data distribution p(x) is also conditioned on t. I interpret it as a general introduction on how density ratio could be estimated continually.\n- The Lagrange multiplier and the bias \/ variance statements need elaboration, I don't understand how it is affecting the bias and variance.\n- In the second part of section 3, the continual learning setting is introduced (in equation 11), however, it is no longer reasonable to use the symbol r_t in equation 12 which was initially defined in equation 5. \n- A loss for continual VAE is proposed in seciton Feature generation for CDRE, however, the p(x) is again independent of t. And I'm also suspicious that equation 13 is the correct way of adjusting VAE's objective with VCL. In VCL, the KL divergence is on the parameter distribution, which could help prevent forgetting, however, here the KL is between VAE's approximate posteriors, which alone is not sufficient for keeping the information of previous tasks.\n- There's lack of analysis \/ interpretation of results for section 4.1, e.g. what is the motivation of the experiments and what is the conclusion.\n- Through out section 4.2 - 4.3, it is not explained what is the source of variance in the experiment results.\n","sentences":[{"sentence_type":"2","sentence":"However, I give reject to this paper because of the following reason:","rephrased":"However, I recommend rejection of this paper for the following reasons:"},{"sentence_type":"1","sentence":"The writing of this paper is not easy to follow.","rephrased":"The writing of this paper could be improved for clarity."},{"sentence_type":"1","sentence":"And I'm also suspicious that equation 13 is the correct way of adjusting VAE's objective with VCL.","rephrased":"I am also uncertain whether equation 13 is the appropriate method for adjusting the VAE's objective with VCL."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[536,605,"Not concerning"],[608,656,"Not concerning"],[1520,1618,"Not concerning"]],"Comments":[]}
{"id":"b_hjgIKX6U","text":"The paper proposes to improve results of echocardiography imagery segmentation using model averaging and augmented inference. These ideas are not particularly novel, but have proven to be valuable in multiple recent studies. \nIn particular, the authors claim that averaging the predictions from multiple models improves performance and avoid the spectacular failures the single model prediction may sometimes exhibit. Additionally, data augmentation at test time also improves the results making them more stable. \n\nThe authors have trained and evaluated their method on data from the CAMUS dataset. This dataset is pretty large and the data variability observed there is sufficient to evaluate the generalisation capabilities of the method proposed by the authors.\n\nUnfortunately, I find that the evaluation is not complete. First of all the authors only compare a randomly picked model from their 8-fold cross validation strategy with the average of the 8 fold. Would be interesting to see how a single model performs compared to an average of 2, 3, 4,..., 8 models. More importantly, it would be very good to see how the average of different architectures would work. \n\nAdditionally, the authors seem to state that test-time augmentation has been only done on one example, which is the one used for qualitative analysis and that is reported in figure. It would have been really great to see a formal comparison of the performance with and without test time augmentation for the whole test set. \n\nImportantly, the box plot visualisation of the results leaves too much to the imagination of the readers. It would have been much better to include a table with results. Through a table, it would have been possible to show results for more experiments, even though some visibility on outliers might be lost (compared to box plots).\n\nI have no doubt that the technique proposed in the paper is valuable. Given the length constraints of short papers I also understand the fact that the experimental evaluation is compact. I still think it could have been better, via a table and show different angles over the advantages brought by the proposed technique.  ","sentences":[{"sentence_type":"2","sentence":"Unfortunately, I find that the evaluation is not complete.","rephrased":"I suggest that the evaluation could be more comprehensive."},{"sentence_type":"1","sentence":"The authors seem to state that test-time augmentation has been only done on one example, which is the one used for qualitative analysis and that is reported in figure.","rephrased":"It would be beneficial for the study if the authors could expand the test-time augmentation to more examples beyond the one used for qualitative analysis in the figure."},{"sentence_type":"2","sentence":"The box plot visualisation of the results leaves too much to the imagination of the readers.","rephrased":"Enhancing the box plot visualisation with additional data representation, such as a results table, could provide a clearer understanding for the readers."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[767,825,"Not concerning"],[1187,1354,"Not concerning"]],"Comments":[]}
{"id":"3o7QaXDQOUB","text":"Strength:\n * Related work section is comprehensive.\n\nWeakness:\n * Weak and incomplete results. In Table 1, the model performance is quite similar to GA-DNN baseline. For $\\delta>0.4$, constrained GA (proposed method) is 5.53 while GA-DNN achieves higher logP improvement 5.93. The original benchmark proposed by Jin et al. 2019 also did molecular optimization for QED and DRD2, but authors did not report any results on these two properties.\n * Lack of novelty. The proposed method is a direct application of standard genetic algorithm. The only difference is that this paper applies a two-stage optimization procedure that enforces the similarity constraint first and then optimize the property. The cross-over operator is the same as GB-GA (Jensen 2019), and the mutation operation is based on SELFIES string (Krenn et al. 2020).\n* There is no ablation study of modeling choices. What's the benefit of two-stage procedure? Does that make a huge difference in model performance? The main claim of the paper (benefit of two-stage procedure) is not supported by empirical results.","sentences":[{"sentence_type":"2","sentence":"Weak and incomplete results.","rephrased":"The results could be strengthened and expanded upon."},{"sentence_type":"2","sentence":"Lack of novelty.","rephrased":"The novelty of the proposed method could be better highlighted and differentiated from existing approaches."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[66,94,"Not concerning"],[445,461,"Not concerning"]],"Comments":[]}
{"id":"HUaqQ2D7zeX","text":"The authors provide the first rigorous study of the action relative to Bregman Lagrangian and characterize (the non) minimality of Neterov's path. The clarity of this paper is good. I enjoyed reading the paper and learned a good deal from the discussion of prior work. The misconception that the authors point out is one that I also held myself, so I am glad to be corrected. I am also under the impression that the original authors of the Bregman Lagrangian work shared this misconception, so I imagine this work will serve to prevent the misconception from being propagated by them as well.\n\nHowever, after reading the paper, I am left with the feeling of \"so what\"? This work provides a valuable correction on how we interpret the prior analyses, but it doesn't invalidate any of the prior concrete results nor immediately inform us of what to do differently. The authors mention that the power of the variational framework lies almost completely in Noether Theorem. Perhaps fleshing this out would lead to, I suspect, a really interesting line of work. However, the paper, as is, I feel does not contain enough interesting content to be published at NeurIPS.\n","sentences":[{"sentence_type":"2","sentence":"However, after reading the paper, I am left with the feeling of \"so what\"?","rephrased":"However, after reading the paper, I am curious about the practical implications of this research and how it might inform future work."},{"sentence_type":"3","sentence":"However, the paper, as is, I feel does not contain enough interesting content to be published at NeurIPS.","rephrased":"However, I believe that the paper could benefit from further development of its core ideas to meet the publication standards of NeurIPS."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[594,668,"Not concerning"],[1057,1162,"Not concerning"]],"Comments":[]}
{"id":"6KMqOeRRQtj","text":"Summary:\nThis paper studies “overinterpretation”(provides a high-confidence decision without\nsalient supporting input features) of deep learning models. It modifies previous method Sufficient Input Subsets (SIS) (Carter et al., 2019) to scale to high-dimensional inputs. It detects overinterpretation on both CIFAR10 and ImageNet. In particular, when masking 90% of original pixels, the model can still achieve high accuracy. It then proposes two strategies (ensembles and dropout) to mitigate such overinterpretation artifacts.\n\n################################################\n\nReasons for score:\nThe paper is overall well-written and presents some interesting findings on the so-called “overinterpretation” of DNNs classifiers. The scaled version of SIS and the usage of ensembles \/ dropout to mitigate overinterpretation is intuitive although not novel. However, I have a concern regarding its experimental results and consequences.\n\n################################################\n\nPros:\n\n+mostly well-written\n\n+important topic and interesting findings\n\n+extensive experiments\n\n+code is provided\n\nCons:\n\n-No results are shown on training on sparse pixels and evaluating on full images\n\nThis is my biggest concern. This experiment seems important since otherwise it is not convincing that the model only uses those remaining pixels to make the decision. I am thus not fully convinced by the statement “We show misclassifications often rely on smaller and more spurious feature subsets suggesting overinterpretation is a serious practical issue”.\n\n-The consequence of the findings needs a bit more discussion. How can one benefit from reducing the “overinterpretation” in practice?\n\n-Only empirical results are presented and not enough discussions on the theoretical side.\n\n-Another minor concern is about the usage of mean SIS size for measuring semantic meaning. It seems to be a reasonable proxy. However, I think it might be more useful to look at the mean SIS size of those that are wrongly classified by humans. If an image is already correctly classified by humans (there are indeed some figures that show the semantic features of the original objects despite only 5-10% pixels showing up, see e.g. Figure 1 bottom row the third to last image shows the contour of a horse), the increase of SIS size may not add much more semantic meaning.\n\n################################################\n\nMinor:\n\n-last paragraph 1st page “although they propose differing explanations for the decisions of a model”, “differing” should be “different”\n\n-sec 3.2 ImageNet, the mask “M” is not defined\n\n################################################\n\nQuestions:\n\n-I am really surprised by the performance of training on 5% random and evaluating on 5% random (around 50% as shown in table 1). What can be a possible explanation here?\n\n-cifar10-c adds visual effect to images. It might be more interesting to also show the performance on spatially transformed images (those should be heavily influenced when only sparse original pixels are used).\n\n\n\n################################################\n\nPost-Rebuttal:\n\nThanks the authors for their detailed response! After reading the responses, I decide to maintain my initial assessment.\n\nThe statement \"full images are highly out-of-distribution for a model trained on images with only 5% unmasked pixel-subsets and hence such a model cannot properly generalize to fully unmasked images\" makes sense. However, I still feel that the authors need an experiment of this flavor to support their claim of “We show misclassifications often rely on smaller and more spurious feature subsets suggesting overinterpretation is a serious practical issue” as mentioned in my initial review as well as pointed out by R1.\n\nBesides, I also find the point \"the observed phenomenon is very model-dependent\" raised by R1 is a valid major concern. In the authors response, they did not add extra experiments to address it. \" We indeed find that models trained on 5% pixel-subsets can generalize to the corresponding 5% pixel-subsets of test images. \" - the stated experiment trains and tests on the same model so it does not address the concern that the observed phenomenon is model-dependent. In order to address this concern, the authors need to add some experiments on transferring across architectures (e.g. train on SIS of ResNet and test on SIS of VGG). \n","sentences":[{"sentence_type":"2","sentence":"This is my biggest concern. This experiment seems important since otherwise it is not convincing that the model only uses those remaining pixels to make the decision.","rephrased":"I believe it would be beneficial to include an experiment where the model is trained on sparse pixels and evaluated on full images. This could provide stronger evidence that the model relies predominantly on the remaining pixels for its decisions."},{"sentence_type":"1","sentence":"However, I think it might be more useful to look at the mean SIS size of those that are wrongly classified by humans.","rephrased":"It may be insightful to analyze the mean SIS size for images that are misclassified by humans, as this could offer a different perspective on the semantic meaning conveyed by the SIS."},{"sentence_type":"2","sentence":"However, I still feel that the authors need an experiment of this flavor to support their claim of \\","rephrased":"I would encourage the authors to consider conducting an additional experiment in line with the one suggested, to further substantiate their claim regarding the reliance on smaller and more spurious feature subsets for misclassifications."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1192,1358,"Not concerning"],[1904,2021,"Not concerning"]],"Comments":[]}
{"id":"bNqsHGM5L57","text":"This paper studies the pretraining strategies regarding the visual perception capabilities of RL\/IL agents for visual navigation tasks. It proposes to leverage a very large-scale dataset of rendered images from 3D scenes with recently proposed self-supervised learning techniques (i.e., DINO). The authors did a good job examining the key components of both their pretraining approach and the follow-up online fine-tuning process, with large improvements brought by their method. The specific dataset that is visually similar to the downstream tasks seems to be one of the keys besides good data augmentation strategies. However, while this method is proposed for visual navigation, how to do pertaining better for more complex Embodied AI tasks beyond navigation still remains an open question, as pointed out by another recent paper [1].\n\n\n[1] On Pre-Training for Visuo-Motor Control: Revisiting a Learning-from-Scratch Baseline ","sentences":[{"sentence_type":"1","sentence":"However, while this method is proposed for visual navigation, how to do pertaining better for more complex Embodied AI tasks beyond navigation still remains an open question, as pointed out by another recent paper [1].","rephrased":"However, while this method shows promise for visual navigation, exploring how to adapt and extend it to more complex Embodied AI tasks beyond navigation is an exciting area for future research, as also suggested by recent literature [1]."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[621,839,"Not concerning"]],"Comments":[]}
{"id":"BkeOzvDTFE","text":"This paper proposes a molecular generative model that generates molecules via a two-step process: 1) Generate a set of reactants from the latent space; 2) Predict the product of the generated reactants using a pre-trained reaction predictor. This two-step formulation provides synthesis routes of generated molecules, allowing end users to examine the synthetic accessibility of generated compounds. This approach is analogous to virtual screening approach in medicinal chemistry.\n\nThe proposed approach builds on a Wassarstein autoencoder. The encoder maps a set of reactants into a continuous vector using a gated graph neural network followed by a sum pooling. The decoder is a recurrent network that decodes the reactant molecules one by one. The output of the decoder is restricted to be a fixed set of reactant molecules, and the decoding process is modeled as generating a sequence of tokens (reactant ID).\n\nThis paper is well motivated. The reviewer agrees that the molecular recipe problem is important: the model should provide hints (e.g. one-step synthesis routes) of how generated molecules can be synthesized, so that chemists can synthesize the suggested compounds for experimental validation.\n\nMy concern of the proposed model is that it can only generate molecules that can be synthesized through a one-step reaction from a fixed reactant vocabulary (3180 reactants). This may imply that the proposed model can only cover a limited subset of chemical space. Another concern is lack of quantitive evaluation: For the local optimization experiment, the paper didn't compare with any previous approach (e.g., CVAE, GVAE). For retrosynthesis experiment, there is no quantitive evaluation at all. One suggestion is to conduct human evaluation: how often do the chemists think the suggested retrosynthesis plans make sense.\n\nNonetheless, the proposed method is interesting combination of generative modeling and chemical reaction prediction. The reviewer therefore votes for the acceptance of the paper.","sentences":[{"sentence_type":"1","sentence":"My concern of the proposed model is that it can only generate molecules that can be synthesized through a one-step reaction from a fixed reactant vocabulary (3180 reactants).","rephrased":"One area for potential improvement in the proposed model is its current limitation to generating molecules that can be synthesized through a one-step reaction from a fixed reactant vocabulary (3180 reactants). Expanding this capability could enhance the model's coverage of chemical space."},{"sentence_type":"1","sentence":"Another concern is lack of quantitive evaluation: For the local optimization experiment, the paper didn't compare with any previous approach (e.g., CVAE, GVAE).","rephrased":"It would be beneficial to include a quantitative evaluation for the local optimization experiment by comparing it with previous approaches (e.g., CVAE, GVAE)."},{"sentence_type":"1","sentence":"For retrosynthesis experiment, there is no quantitive evaluation at all.","rephrased":"Additionally, incorporating a quantitative evaluation for the retrosynthesis experiment would strengthen the paper's findings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1210,1384,"Not concerning"],[1475,1635,"Not concerning"],[1636,1708,"Not concerning"]],"Comments":[]}
{"id":"H1eOuKlwKB","text":"Summary: \nThe paper proposes behavioral repertoire imitation learning (BRIL) which aims to learn a collection of policy from diverse demonstrations. BRIL learns such a collection by learning a context-dependent policy, where the context variable represents behavior of each demonstration. To obtain a context variable, BRIL rely on user’s knowledge, where the user manually defines a feature space that describes behavior. This feature space is then reduced by using a dimensionality reduction method such as t-SNE. Lastly, the policy is learned by supervised learning (behavior cloning) with a state-context input variable and an action output variable. The method is experimentally evaluated on the StarCraft environment. The results show that BRIL performs better than two baselines: behavior cloning on diverse demonstrations and behavior cloning on clustered demonstrations. \n\nScore: \nThe weaknesses of the paper are novelty, clarity, and evaluation. Please see the detailed comments below. I vote for rejection. \n\nComments:\n- Novelty of the proposed idea. \nThe major issue of the paper is the lack of novelty. The idea of learning a context-dependent policy in BRIL closely resembles that of existing multi-modal IL methods (Wang et al., 2017, Li et al., 2017). The main difference is that, BRIL relies on a manually defined context variable (behavioral feature space). In contrast, the existing methods aim to learn the context variable from demonstrations. BRIL is too simple when compared to the existing methods. Moreover, using a manually specified feature space does not go well with the main principle of deep learning, which is to learn informative feature spaces from data end-to-end. I think that ICLR is not a suitable venue for this paper. \n\n- Clarity of the proposed method.\nThe second issue of the paper is clarity. Specifically, two important steps of BRIL is policy learning by supervised learning (behavior cloning) and dimensionality reduction by t-SNE. However, explanations of these two steps are vague and incomplete. For example, in Section 2.1, the paper describes IL as supervised learning, but does not mention the issue of covariate shift, which is well-known when treating IL as supervised learning (Ross et al., 2011). Also, it is incorrect to state that an IL agent cannot interact with the environment during training, since many IL methods such as GAIL require interactions with the environment during training. Meanwhile, in Section 2.4, it is unclear how probability distributions in t-SNE reflect similarity between data points. \n\n[1] Stéphane Ross, Geoffrey Gordon, and Drew Bagnell. A reduction of imitation learning and structured prediction to no-regret online learning. AISTATS, 2011.\n\n- Evaluation of the proposed method is too narrow.\nThe paper lacks important baseline methods in the experiment. Specifically, the paper does not compare BRIL against multi-modal IL methods (Wang et al., 2017, Li et al., 2017) which also learn a context-dependent policy. Moreover, BRIL is evaluated only on the StarCraft environment with only one kind of manually specified feature. This raises a question of generality and sensitivity against the choice of feature of BRIL. To improve the paper, I suggest the authors to compared the proposed method against multi-modal IL methods on different environment, and evaluate BRIL with different choices of the behavioral features.\n\n","sentences":[{"sentence_type":"2","sentence":"BRIL is too simple when compared to the existing methods.","rephrased":"While BRIL's approach to using a manually defined context variable is straightforward, it may benefit from incorporating more complex or automated methods to enhance its novelty and alignment with deep learning principles."},{"sentence_type":"3","sentence":"I think that ICLR is not a suitable venue for this paper.","rephrased":"The current contribution may not fully align with the expectations for novelty at ICLR, and the authors might consider strengthening the novel aspects of their work or exploring other venues where the methodological contributions are more in focus."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1465,1522,"Not concerning"],[1700,1757,"Not concerning"]],"Comments":[]}
{"id":"SJgS3s0I3Q","text":"Quality - poor\nThe highly complicated work is evaluated only on the simplest of benchmarks with no significant results. \n\nClarity - poor\nThe paper seems to amount to gobbledygook, many disparate terminology strung together. \n\nOriginality\nNo idea. \n\nSignificance \nNone. \n\ncons: the paper to me seems a hashing of citations to the main works in neuroscience and deep learning for which only the simplest network is demonstrated (single hidden layer MLP on MNIST) with results that do not exceed that of a standard MLP.\npros: the only pro I can think of for this work is that synaptic computing imo deserves more consideration, as real synapses are very complicated beasts, the functioning of which relatively little is known about. ","sentences":[{"sentence_type":"3","sentence":"The paper seems to amount to gobbledygook, many disparate terminology strung together.","rephrased":"The paper could benefit from clearer language and a more coherent integration of terminology."},{"sentence_type":"2","sentence":"No idea.","rephrased":"I am unable to assess the originality of the work without further analysis."},{"sentence_type":"2","sentence":"None.","rephrased":"The significance of the work is not immediately apparent and could be better articulated."},{"sentence_type":"2","sentence":"cons: the paper to me seems a hashing of citations to the main works in neuroscience and deep learning for which only the simplest network is demonstrated (single hidden layer MLP on MNIST) with results that do not exceed that of a standard MLP.","rephrased":"The paper appears to rely heavily on existing literature without providing substantial advancements, and the use of a simple network architecture does not demonstrate a significant improvement over standard models."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[15,120,"Missed by Model"],[137,223,"Confirmed"],[238,246,"Confirmed"],[263,268,"Not concerning"],[271,516,"Confirmed"]],"Comments":[]}
{"id":"Byg02cl9cS","text":"GraphNVP is the first paper to introduce the concept of \"invertible flow\", that is to construct the invertible mapping from latent vector z to the graph G. By constructing the mapping from G to z, GraphNVP first changes the discrete feature vector into continuous variables, then update this matrix representation by scaling and transforming functions (Eq. (2)-(5) in this GRF paper). In each iteration the matrix is only updated by one row (one slice for the tensor), while keep other rows intact. Then for constructing the inverse mapping, we can first sample a random vector and then apply the “inverse” of the update rule to recover the edge matrix and node matrix respectively.\n\nThe main contribution for GRF paper is to find a new update rule from the idea of ResNet. The author thinks that GraphNVP only update one row each time, which is less efficient, and the model can only cover a limited number of mappings. Then he proposed a new function for update (Eq. (6)-(7)), which updates all rows each time. The author shows how to approximate the determinant of the Jacobian matrix, and how to construct the inverse mapping from fixed-point iteration, as the mapping is Lipschitz. Lastly the author shows that GRF uses much less parameters than GraphNVP both theoretically and practically, which means that the new model is more expressive. However, the new model may output the same molecule for several times (shown by “Uniqueness\"), and it favors the striaght-chain molecules.\n\nAnother question related to the experiment is that how does the method compared to methods which first generate SMILES string and then convert to molecule graph? Eg. Dai Et al. ICLR 2018, Syntax-directed generative model for structured data. ","sentences":[{"sentence_type":"2","sentence":"The author thinks that GraphNVP only update one row each time, which is less efficient, and the model can only cover a limited number of mappings.","rephrased":"The author suggests that updating one row at a time as in GraphNVP may be less efficient and could potentially limit the number of mappings the model can represent."},{"sentence_type":"1","sentence":"However, the new model may output the same molecule for several times (shown by \\","rephrased":"However, there is a possibility for the new model to generate duplicate molecules, as indicated by the 'Uniqueness' section."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[774,920,"Not concerning"]],"Comments":[]}
{"id":"zJ-jdJJBiMb","text":"The report describes the efforts in replicating the results of \"Learning to Deceive with Attention-Based Explanations\", where it is shown how 1) attention weights can be manipulated without loss in performance and 2) humans can be deceived by the obtained attention weights. The report describes the efforts in replicating the first claim. The authors of the report used the code of the original paper to replicate the results, adding the transformer part and missing anonymization functions. Overall, the results have been extensively replicated and the experiments well described. There are however some parts not well written (e.g. typos, half-sentences, missing links),  with missing explanations (e.g. multi-class sentiment analysis, transformer, anonymization) and with critiques to the claims of the paper (e.g. importance of the user study, capabilities of deceiving of the attention weights) not supported by experiments. Overall, I think the reproduction effort has been well conducted, but the report needs to be improved (see weaknesses below) to be accepteded. Below I detail what I think are the strengths and the weaknesses of the report. \n\nStrengths:\n+ The authors managed to replicate all the quantitative results of the main paper (on public datasets) with fair efforts for the missing components they added.\n+ The experiments are very detailed, from the data splits to the hyperparameters used.\n+ Discussions on the difference between the reproduced and the original results are also thorough and well justified.\n\nWeaknesses:\n- Maybe it is due to the lack of time, but the report misses careful proofreading. There are Tables not well linked (e.g. lines 136,172) wrongly cited equations (Eq. 0, line 74), typos (e.g. \"Reproducability\", line 207), missing end of sentence points (line 182), upper case start of sentences (e.g. line 161), half-sentences (line 202). Proofreading the report is necessary to ensure its quality. \n\n- In Table 3 multiple numbers have an empty standard deviation for the A.M. column. Why is this the case? The table looks a bit weird with all the empty space after some +-, thus it would be good to add those values (preferably) or eliminate the +-.\n\n- Some parts and definitions are not clear. For instance, I was not able to find definitions for A.M. (Table 3-4) and I (equation \"0\"). Similarly, the report mentions an extension of the paper by performing multi-class sentiment analysis (line 89) that however is not detailed in the following section and is not reported in the results (since the comparison is with the values reported in the original paper). These details should be included to avoid misconceptions.\n\n- The attention weights \\alpha are computed from the dot product between QK^T  \"softmaxed\". However, line 54 reports the non-softmaxed version of the dot-product to compute the attention, which is inaccurate. I would suggest the authors\nto re-define the attention A by explicitly showing the contribution of \\alpha and how it is computed.\n\n- The difficulty of the reproduction due to 1) missing transformer code and 2) missing anonymization (lines 209-210) are not extensively described in the report. Since the report should highlight the encountered difficulties (if any) in reproducing the original results, I would extend section 2 to include a discussion of any components the authors needed to add to reproduce the results + every effort (e.g. missing libraries, dataset set up) that was required to reproduce them.\n\n- The scope of the report is to reproduce the quantitative results of the original work, without reproducing the user studies. While I agree that the three subjects of the original paper do not constitute a large set allowing drawing general conclusions, I do not think it is fair to say that 1) the human study is unnecessary and unfounded (lines 213-215) and 2) raising doubts on the capabilities to deceive of the model (line 218). These are personal thoughts with no scientific\/experimental grounds, since not results are shown to support that humans might not be deceived. I strongly suggest removing any claim not supported by 1) experiments 2) experience in the reproduction.\n\n- The sentence in lines 214-215: \"it added bulk to an unstructured paper, which in our minds, would have benefited from less individual projects\"  is non-sensical and not founded anyway since 1) the unstructured paper is the original one? (peer-reviewed and accepted to ACL 2020) 2) what are the individual projects?","sentences":[{"sentence_type":"2","sentence":"Maybe it is due to the lack of time, but the report misses careful proofreading.","rephrased":"It appears that the report could benefit from additional proofreading to address issues such as unlinked tables, incorrectly cited equations, and typographical errors."},{"sentence_type":"3","sentence":"The sentence in lines 214-215: \"it added bulk to an unstructured paper, which in our minds, would have benefited from less individual projects\" is non-sensical and not founded anyway since 1) the unstructured paper is the original one? (peer-reviewed and accepted to ACL 2020) 2) what are the individual projects?","rephrased":"The critique regarding the original paper's structure and the mention of 'individual projects' in lines 214-215 could be clarified, as it is not immediately apparent how these points relate to the structure of the peer-reviewed and accepted original work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1547,1627,"Not concerning"],[4175,4489,"Not concerning"]],"Comments":[]}
{"id":"PrpPm79xaQ","text":"This paper studies the personalization aspect of the federated learning problem. The authors propose a new framework in which they replace the common global model in the original federated learning formulation with a convex combination of the global model and a local model. They later introduce an adaptive optimization algorithm for their formulation and provide generalization bounds as well as convergence guarantees for both strongly-convex and nonconvex settings.  Finally, numerical experiments and comparison with other methods in the literature are provided to support the theoretical results.\n\nThe paper has a complete story. It provides generalization bounds, optimization results for both strongly convex and nonconvex functions, as well as experiments and comparison with other works.  \n\nHowever, I am slightly confused regarding the proposed formulation. In Section 2.1, for any agent $i$, and for a mixing weight $\\alpha_i$, $h_{loc,i}^*$ is defined as (I suppressed the hat notation over $h_{loc,i}^*$ and calligraphic font due to some compilation error here).\n\n$h_{loc,i}^* = argmin_{h \\in H} \\hat{L}_{D_i}(\\alpha_i h + (1-\\alpha_i) \\bar{h}^*).$\n\nThe authors then take $h_{\\alpha_i} := \\alpha_i h_{loc,i}^* + (1-\\alpha_i) \\bar{h}^*$ as the output, and claim that this is not the minimizer of $\\hat{L}_{D_i}$, since \"we optimize $h_{loc,i}^*$ with partially incorporating $\\bar{h}^*$.\" \n\nHowever, I am not sure if I follow the argument here, and it is not clear to me why $h_{\\alpha_i}$ is not the minimizer of $\\hat{L}_{D_i}$. Let's take $H = \\mathbb{R}^d$, as stated in Section 4. Also, let's denote the minimizer of $\\hat{L}_{D_i}$ as $h_{opt,i}$. Then, the solution to the minimization problem above would be\n\n$h_{loc,i}^* = (h_{opt,i} - (1-\\alpha_i) \\bar{h}^*) \/ \\alpha_i$\n\nwhich leads to having $h_{\\alpha_i} = h_{opt,i}$, the minimizer of $\\hat{L}_{D_i}$. \n\nI have the same confusion regarding Section 3 as well. There, the goal is to solve two minimization problems \n\n$ w^* = argmin_{w \\in \\mathbb{R}^d} \\frac{1}{n} \\sum_{i=1}^n f_i(w), \\quad v_i^* =  argmin_{v \\in \\mathbb{R}^d} f_i(\\alpha_i v+ (1-\\alpha_i)w^*),$\n\nand the output of the algorithm, for instance in Theorem 2, is $\\alpha_i v_i+ (1-\\alpha_i)w^*$ which is the minimizer of $f_i$. If this is the case, why we need to find $w^*$, and why not solving $argmin_{v \\in \\mathbb{R}^d} f_i(v)$ directly? \n\nIt is completely possible that I am missing something here. But I would appreciate it if authors provide a clarification on this.\n\nAs a second question, I am wondering if there is any connection between the sequence $\\alpha_i^{(t)}$ and the optimal $\\alpha_i^*$ derived in Section 2. In other words, for instance for the strongly convex case, does the sequence $\\alpha_i^{(t)}$ converge to any particular value close to $\\alpha_i^*$?","sentences":[{"sentence_type":"1","sentence":"It is completely possible that I am missing something here. But I would appreciate it if authors provide a clarification on this.","rephrased":"I may need further clarification to fully understand this section. Could the authors elaborate on this point?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[2385,2514,"Not concerning"]],"Comments":[]}
{"id":"B1ghB6sPFN","text":"* Content:\n\nThis paper introduces several methods to process experimental results on biological cells. These experiments are characterized by a high experimental variability, which makes difficult to process results. The proposed MELD algorithm maps hard group assignments (e.g. treatment\/control in {-1, 1}) to soft assignments (in [-1, 1]) thanks to a low-pass filtering based on a graph built using data related to each cell. This later allows the authors to cluster relevant groups of cells, leading to biological insights.\nNote that the paper is an excerpt of the bioRxiv paper of (Burkhardt et al.) (cited in the paper).\n\n* Comment:\n\nThis paper is quite dense and makes a heavy use of technical acronyms, but it remains understandable and is well written besides that.\n\nMy main concern is related to the experimental validation of the method by the authors, which appears quite qualitative to me. Indeed, the authors mainly observe that the proposed method allows them to gain biological insights on some past experiments. While this is interesting from a biological perspective, from a machine learning perspective a more thorough benchmarking of MELD would have been appreciated. Maybe using a synthetic model would help understand its possible weaknesses?\n\nDespite this concern, I would still vote in favor of acceptance for this paper, as methods removing \"noise\" from data to increase its \"signal\" ratio would probably be of interest to the LLD community.","sentences":[{"sentence_type":"2","sentence":"My main concern is related to the experimental validation of the method by the authors, which appears quite qualitative to me.","rephrased":"My main concern is with the experimental validation of the method by the authors, which seems to rely heavily on qualitative analysis."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[776,902,"Not concerning"]],"Comments":[]}
{"id":"ENI6FxHCwfm","text":"In this paper, the authors proposed a new method called Calibrated Q-learning and showed that a conservative value function is a necessary but not sufficient condition for fast online fine-tuning. They empirically demonstrated that methods based solely on conservativeness suffer from \"unlearning\" during fine-tuning, which negates all the advantages of offline initialization, while methods based on implicit constraints (such as IQL) have asymptotically slower learning. To mitigate the \"unlearning\", the authors proposed a solution based on the observation that learned estimates of conservative values are not calibrated, as consequence samples are wasted to correct the scale of Q-values during fine-tuning. Cal-QL fixes this by making Q-values conservative and calibrated, so that learned value estimates are larger than the ground truth return of policies that are worse than the offline initialization. \n\nThe resulting method is simple, has theoretical support, and shows good results on tested benchmarks, significantly outperforming the baselines (especially in terms of cumulative regret). The paper is detailed and clearly written. As a result, I believe this paper is a valuable and highly relevant contribution. I especially like the empirical motivation for the method in section 4.1, which gives the right intuition.\n\nminor comments:\n- while in the caption to the Figure 3 mentions that fine-tuning begins only at 50k steps, just from the figure alone, text can be confusing, i.e. text says “Note that the Q-values learned by CQL in the offline phase are much smaller than their ground-truth value as expected”, however starting values are on the same scale as ground-truth and without reading caption very carefully, it is hard to understand that I should look at the 50k on x-axis. I suggest adding visual hint - vertical line to indicate when offline-pretraining is ended.\n- “the learned Q-values are larger than the ground-truth return of policies worse than the offline initialization” can be hard to understand for non-native speaker. I suggest to add “of policies which are worse than”.\n- I think that claims in the introduction about offline initialization as “less dangerous” approach are not supported in the paper (or in the cited works), as such initialization does not guarantees safety of online fine-tuning in any way.\n\nquestions:\n- have you tried estimating the $Q^{\\mu}(s, a)$ with offline SARSA? It seems to me that such a way would be more accurate and more generalizable than the return-to-go estimation via monte-carlo and regression","sentences":[{"sentence_type":"1","sentence":"I think that claims in the introduction about offline initialization as \\","rephrased":"The paper could benefit from additional evidence or discussion to support the claims made in the introduction regarding the safety of offline initialization for online fine-tuning."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"5Vzo0k93Y6I","text":"The paper is not in the adequate format for the workshop. The authors provide in the main part of the paper a general Bayesian formulation of problems in causal learning and inference. However, this formulation does not come with a general solution. More specifically, they show that a causal query can be solved by estimating its posterior given in Eq. 2.3, but it cannot be always estimated. One particular tractable implementation is proposed in Appendix A, but if this is the actual contribution of the paper, it should be the focus of the paper and explained in detail in the main part.\n\nMoreover, the authors claim in line 102 that this view  “subsumes and generalises causal discovery and reasoning into a unified framework”. I strongly disagree with that. How can they claim that the proposed approach is more general if they only propose a solution for the class of causally sufficient nonlinear additive Gaussian noise models? An efficient approach that integrates causal discovery, causal inference, and experimental design is extremely desirable, but the paper does not propose a *general* solution for that.  The current “two-stage” approach of causal discovery followed by causal inference has indeed a lot of room for improvement, but it can be general in the sense that no strong assumptions about the model are necessary. For example, FCI accounts for the existence of unmeasured confounders and does not make any parametric or distributional assumptions about the model. Causal effect identification can then be determined from the learned Markov equivalence class (a PAG, in this case), thus accounting for all models that are compatible with the observed conditional independences in the data. To claim subsumption, the proposed framework should be able to solve this general class of models. \n\nMinor: The description of the induced causal diagram in line 71 is incomplete as it does not explain the existence of dashed bidirected arrows between endogenous variables with a common exogenous parent. \n","sentences":[{"sentence_type":"1","sentence":"I strongly disagree with that.","rephrased":"I have reservations about this claim."},{"sentence_type":"2","sentence":"How can they claim that the proposed approach is more general if they only propose a solution for the class of causally sufficient nonlinear additive Gaussian noise models?","rephrased":"It would be helpful if the authors could clarify how the proposed approach is more general, considering it focuses on a specific class of models."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[733,763,"Not concerning"],[764,936,"Maybe"]],"Comments":[]}
{"id":"HkxY9HPIKN","text":"This short paper investigates weak supervision for neural-based topic modelling (NTM) by modifying both the priors and the posteriors, in a VAE setting.\n\nThe priors are modified to using the logits of the probability for each topic to appear in a document. The use of the logits is meant to strengthen \"ground truth\" information given by a user (supervision), while not penalizing the probability for another topics to appear in a document which would not have been labelled by the user (weak supervision).\nOn the one hand, his part of the work is quite clear, and the authors justify this as a way to make a NMT better align with the semantic of the user.\nOn the other hand, the explanation about the generative process is unclear, and would benefit of a longer explanation.\nI understood that, in addition to the normal setting of a VAE, two other posteriors have been tested: the Concrete approximation to Bernouilli, and the use of a logit-normal distribution.\nThe all section about the comparison of the two is really confusing and it becomes hard to clearly follow authors' reasoning.\n\nIn their experiments, the authors have used three sources of multi-labelled dataset. Topic modelling is not my domain of expertise, but could the authors have not used other datasets to evaluate their approach against (e.g. 20NewsGroups and RCV1-v2 datasets, similarly to original NVDM (Miao et al., 2016))? What's the motivation for using BibTeX, Deliicious and AAPD?\nBased on table 3, both the NVDM-o (with logit-normal posterior), and Bernouilli (columns 2 and 3) are quite similar for at least two of the metrics, but this point is not discussed by the authors, at all.\n\n* other comments\/questions about the paper *\n- latent Dirichlet allocation (LDA) => Latent [...];\n- Often times => Oftentimes;\n- The integration of table 1 could be better;\n- Why is Wikipedia mentioned?\n- what's the difference between P-NPMI and NPMI? It's not clear;\n- due the => due to the;\n- W_{K} => W_{k}  (Bernouilli decoding computing the word distribution), compared to \"W_{k} refers to\";","sentences":[{"sentence_type":"2","sentence":"The all section about the comparison of the two is really confusing and it becomes hard to clearly follow authors' reasoning.","rephrased":"The section comparing the two approaches could be clarified further to enhance the reader's understanding of the authors' reasoning."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[964,1089,"Maybe"]],"Comments":[]}
{"id":"YlWzSMllSkY","text":"Strengths:\n\n1. This study addresses a valid problem; because although neuromorphic systems have the obvious advantage of low-power usage, regarding the performance, existing neuromorphic solutions are not at par with traditional methods.\n\n2. Authors clearly explain how they transform the original WaveNet architecture to their SNN architecture, WaveSense, to realize an efficient neuromorphic system. I think that the experimentation configurations are also detailed sufficiently for reproducibility of the results. Authors will open source their code as well.\n\n3. Performance evaluations are comprehensive by testing on three different public datasets, and by comparing against both existing SNN and ANN methods. The results adequately support the performance claims of the proposed model.\n\n4. Discussion section is quite informative.\n\n\nWeaknesses:\n\n1. I think the main weakness of this paper is the limited evaluations regarding the efficiency. I understand that neuromorphic hardware is by nature low-power compared to classical digital processors, and thus we may accept that they are always efficient. However, authors do not compare the efficiency of their method with respect to previous SNN models, except the model size and parameter count in Table 1. As efficiency is the selling point, it is desirable to see the comparison against the SNN models given in Table 2 as well. Also, it would be helpful if authors can elaborate more on if neuron and parameter counts are directly comparable across different neuromorphic systems.\n\n2. Authors often use the term “spatio-temporal”, as in “... we focus on audio tasks as spatio-temporal tasks…”. I don't quite understand the use of this term in the context of this paper because there is no spatial domain with a single channel audio. Authors should clarify this issue.\n\n3. Authors obtain 0.95 FAPH with a 0.8% FRR, while (Coucke et al., 2018) obtains FRR 0.12% for a fixed FAPH of 0.5, on the HeySnips dataset. Authors say that their results were slightly worse. However, it is not easy to compare these numbers since authors do not fix their FAPH score. Authors need to explain how they reach that conclusion based on these numbers. A plot of FAPH versus FRR could be helpful.\n","sentences":[{"sentence_type":"1","sentence":"I think the main weakness of this paper is the limited evaluations regarding the efficiency.","rephrased":"The paper could be strengthened by expanding the evaluations on efficiency."},{"sentence_type":"1","sentence":"Authors say that their results were slightly worse.","rephrased":"The authors acknowledge a slight underperformance in their results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[855,947,"Not concerning"],[1967,2018,"Not concerning"]],"Comments":[]}
{"id":"fzRqAN1nl0","text":"This work proposed an algorithm called action guidance that trains the agent to eventually optimize over sparse rewards while maintaining most of the sample efficiency that comes with reward shaping. The authors examine three sparse reward tasks with a range of difficulties to prove the effectiveness of action guidance.  However, I don't think this paper is fully prepared for submission as the method is not novel enough and there exist some possible issues that need to be discussed and resolved. \n\nBelow are the detail comments. \n\nAbout the method. The key idea behind action guidance is to create a main agent that trains on the sparse rewards, and creating some auxiliary agents that are trained on shaped rewards. And the main agent follows the instructions of auxiliary agents in the initial stage and the probability of it decreases during the following training. A concern is that if there exist several auxiliary agents, how do you arrange the shaped rewards to each auxiliary agent? If there is a conflict between the shaped rewards for the training and guidance of the agent, will the main agent still be trained well? Besides，the method itself is like using imitation learning to obtain initial policy parameters and continues to optimize using sparse reward, the novelty of the method is not sufficient enough.\n\nAbout the experiments. The baselines use PPO to train agents with sparse rewards or shaped rewards respectively and there are no other SOTA methods designed for sparse rewards compared in the experiments, which is not convinced. Besides, in the environment ProduceCombatUnits, the shaped rewards include the reward for each combat unit the agent produces, which is exactly the sparse reward. Is it means that the agent using shaped rewards has the same optimization direction as the one using sparse rewards? I'm not sure if this is fair enough as the effectiveness of action guidance is not clear in this setting. Lastly, the random opponents in the experiments are not strong, I'm wondering about the agent's performance in a harder setting.\n\nAbout the writing. The paper is well-written and self-contained. However, the figures to show the typical learned behavior of agents are not clear enough. For example, it's a little bit hard to recognize the enemy units as the blue borders are too thin.\n\nOverall, I vote for a  rejection. \n\n\n","sentences":[{"sentence_type":"2","sentence":"However, I don't think this paper is fully prepared for submission as the method is not novel enough and there exist some possible issues that need to be discussed and resolved.","rephrased":"However, I believe the paper could be strengthened by further discussing the novelty of the method and addressing some potential issues before submission."},{"sentence_type":"2","sentence":"Besides, in the environment ProduceCombatUnits, the shaped rewards include the reward for each combat unit the agent produces, which is exactly the sparse reward. Is it means that the agent using shaped rewards has the same optimization direction as the one using sparse rewards? I'm not sure if this is fair enough as the effectiveness of action guidance is not clear in this setting.","rephrased":"Additionally, in the ProduceCombatUnits environment, the shaped rewards seem to mirror the sparse rewards, which raises questions about whether the optimization direction for agents using shaped rewards is aligned with those using sparse rewards. Clarifying this could help better demonstrate the effectiveness of action guidance in this context."},{"sentence_type":"1","sentence":"Lastly, the random opponents in the experiments are not strong, I'm wondering about the agent's performance in a harder setting.","rephrased":"Lastly, it would be informative to see the agent's performance against more challenging opponents to better understand its capabilities in a harder setting."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[323,500,"Not concerning"],[1557,1942,"Not concerning"],[1943,2071,"Not concerning"]],"Comments":[]}
{"id":"9U5Xx29qJj","text":"Summary\n\nThe paper describes a model to predict unseen verb-noun compositions from a fixed set of verbs and nouns, given a training set of seen compositions. For an image with incomplete sentence, the model learns to select a set of relevant examples from the train set to serve as reference pairs of image-sentence mapping, and then uses these pairs to draw distribution over potentially unseen verb-noun pairs.\n\n\nStrengths\n- The problem is well-motivated\n- The model is shown to perform well both quantitatively and qualitatively, along with different experimental setups such as validity, low-data\n\n\nWeaknesses and concerns\n\n- Hanging notations and unexplained variables:  Unfortunately this is a bottleneck for me to understand the paper thoroughly\n    - Equation 2\n        - What is $a$?\n            - $a$ is used as a function within the softmax expression - $\\exp a()$, but $a$ is also used as a subscript $c_a$, and since I cannot find any reference for $a$, I’m unclear as to what it actually is\n        - The leftmost expression marginalizes out $j$ to yield $c_a^m$, but where does $i$ go? Are $a$ and $i$ related?\n        - What is $k$? Is $k$ the cardinality of the set of all analogy pairs?\n    - Equation 8 - Triplet loss\n        - What is $v_i$?\n- Results:\n    - Potential non-determinism\n        - You mentioned that for each test sample, you randomly pick 200 examples and then select top-K examples from them (ref: Section 2.2). Now if I understood this correctly, this introduces non-determinism in your results. Is it fair to say that your results should report standard deviations along with the numbers currently stated? Are the improvements statistically significant then?\n    - Lack of ablation\n        - Frequency bias in predictions? What’s the accuracy when you pick the most common verb, noun, and verb-noun pair?\n        - Choice of K in Top-K\n            - The Appendix (Implementation details) mentions that you pick K as 3. Why? What happens when you increase or decrease the value. Is there any insight to be gained from here?\n        - Accuracy numbers for nouns and verbs separately\n            - Again, this is an attempt to uncover biases in your predictions. You mark a prediction correct if both verb-noun pair gets correctly classified, but which one of them gets more wrong? Is there something to be learned here?\n    - Trends in Table 1\n        - BERT pre-trained v\/s scratch: Why is there a reverse trend in top-1 and top-5 accuracy? Is there a conclusion to be drawn here?\n\n- Misc\n    - Number of objects (visual tokens) and words (lingual tokens) in an image?\n        - What is the distribution of number of object and words in the dataset for an image-sentence pair?\n    - Figure 3 - Attention over visual\n        - What is “ref1_full_img”, “ref2_full_img”? Are complete images also included in analogy pairs along with objects?\n    - Section 3.4\n        - “We annotate the validity accuracy for 8400 Top-1 verb-noun compositions” How many people were involved? What does the distribution look like?\n    - Reasoning module:\n        - (e.g. “washing carrot” = “washing apple’ + “cutting carrot” - “cutting apple”)\n            - Is this arithmetic observed in predictions?\n\n\nMinor concerns (suggestions, typos, etc.)\n- Section 3.4: grammatical errors\n\n\nPreliminary Rating and its justification\n\nThe current version of the paper seems to have a couple of loose ends in terms of clarity and completeness of experiments. However, I’m open to changing my rating if the above concerns are addressed to some extent.\n","sentences":[{"sentence_type":"2","sentence":"Unfortunately this is a bottleneck for me to understand the paper thoroughly","rephrased":"Clarifying these notations and variables would greatly enhance the paper's comprehensibility."},{"sentence_type":"1","sentence":"Now if I understood this correctly, this introduces non-determinism in your results.","rephrased":"Could you please clarify if the random selection of examples introduces variability in your results?"},{"sentence_type":"2","sentence":"The current version of the paper seems to have a couple of loose ends in terms of clarity and completeness of experiments.","rephrased":"Addressing the clarity and completeness of the experiments could strengthen the current version of the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[676,752,"Not concerning"],[1448,1532,"Not concerning"],[3340,3462,"Not concerning"]],"Comments":[]}
{"id":"wjjXBUrcFz","text":"This paper is well written and easy to follow. Malignancy estimation of pulmonary nodules is a relevant problem and indeed, growth is the most important risk predictor for cancer so using multiple scans is very relevant. In this paper, the authors proposed a two-stream CNN which takes two 32x32x32 volumes and has a classification head on top to produce a nodule malignancy. The authors nicely outlined how they trained the model and how the data was acquired. In the end, they show a substantial performance improvement over a single timepoint model.\n\nPros:\n- Dataset with good reference standard set by pathology or 2 years of follow-up\n- Good comparison with single timepoint models\n\nCons:\n- Small dataset (30% of 161 cases means only 48 cases in the test set, of which approx 2\/3 is malignant)\n- It is not reported what the average size of the lesions at T1 and T2, and what the range and median of times between the two scans is. This is important information.\n- No comparison with human performance on this dataset.\n- No ROC analysis.","sentences":[{"sentence_type":"1","sentence":"Small dataset (30% of 161 cases means only 48 cases in the test set, of which approx 2\/3 is malignant)","rephrased":"While the dataset is limited in size (30% of 161 cases, resulting in 48 cases for the test set), further research could explore the implications of a larger dataset, particularly considering the proportion of malignant cases."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[696,798,"Not concerning"]],"Comments":[]}
{"id":"DrdT1lEXTD","text":"The paper evaluates the performance of a model based on a UNet pre-processor followed by a ResNeXt classifier for survival prediction in head and neck cancer patients. The proposed model uses a 2 channel input consisting of corresponding slices from CT and PET volumes from a publicly available dataset. \n\nThis is a well-written paper, and the descriptions of the method and experimental setup are clear and unambiguous. The results apparently outperform the state-of-the-art for this application and the model uses fewer parameters. Overall I am happy for this paper to be accepted but there are a few questions that need clarifying.\n\nFirst, in Table 1, there is a reduction in performance of 5% AUC between the Diamant et al method and the basic ResNeXt model. The obvious question is whether this is due to the different architecture or the different input (i.e. GTV masked CT slice and full CT slice). Can the authors comment on this?\n\nAlso regarding Table 1, and depending on the answer to the first question, would it be possible to get even better results by combining the Diamant et al model with the UNet pre-processor and\/or the PET data as input?\n\nOther specific suggestions:\n•\tTitle: “Convolutionnal” should be “Convolutional”\n•\tSection 3, paragraph 2: “the the” - remove repetition\n•\tSection 3, paragraph 2: “can be considered can be considered” – remove repetition\n","sentences":[{"sentence_type":"1","sentence":"The results apparently outperform the state-of-the-art for this application and the model uses fewer parameters.","rephrased":"The results seem to outperform the state-of-the-art for this application, and the model also benefits from using fewer parameters."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[421,533,"Not concerning"]],"Comments":[]}
{"id":"H1e4ESkYKB","text":"This paper introduces a GAN-based text generation approach, where the authors propose to directly optimize a weighted version of JSD replacing p_data with its empirical distribution. I find the theoretical analysis of the approach confusing, thus would like to get clarification from the authors. The experiments largely rely on automatic evaluation, which is known to be unreliable for text generation. I'd like to see human evaluation of the generated sentences, and at least some example outputs should be shown (even if it's cherry-picked). Given that both the theory and the empirical results are not solid in the current version, I intend to reject the submission.\n\n=== Theoretical analysis ===\n1. Main question: based on Equation 2, the optimal solution p_G^* is the empirical data distribution. It's unclear if p_G^* goes to the real data distribution when N goes to infinity.\n2. Given the definition of the generalized JSD in Equation y, when \\pi = 0 and \\pi = 1, JSD_\\pi is both 0. How does it control the balance between forward and reverse KL? I'm also wondering what's the connection between Proposition 2 and the interpolation between forward and reverse KL (which is implied in the text).\n3. In the proof of Proposition 2, what is H? Also in Equation 8, second line, how does the second term disappear? Would be good to have complete proof in the appendix.\n\n=== Empirical results ===\n1. The description of NLL_test and NLL_oracle is very brief. Could you specify what are the language model and data used in each case?\n2. In Table 2, all numbers are pretty close, are they significantly different? It would be really helpful to show some qualitative results as well.\n3. Is there evidence that \\pi is controlling the tradeoff between quality and diversity? From the experiments it's mainly controlled by the temperature.","sentences":[{"sentence_type":"2","sentence":"Given that both the theory and the empirical results are not solid in the current version, I intend to reject the submission.","rephrased":"The current version of the paper could benefit from strengthening both the theoretical framework and the empirical results to support the submission."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[545,670,"Maybe"]],"Comments":[]}
{"id":"SylOb8hgaX","text":"This work addresses the problem of learning a policy-learning-procedure, through meta-learning, that can adapt quickly to new tasks. This work uses MAML for meta-learning, and with this choice, the problem can be broken down into two loops: \n\n1) inner loop: adapting a policy \\pi_phi based on unseen rollouts, where initial parameters phi were provided by the meta-trainer in the outer loop \n2) outer loop: the meta-trainer tries to learn parameters phi on batches of tasks that provide good initial parameters \n\nIn prior work on meta-reinforcement learning via MAML, both the outer as well as inner objective attempt to minimize a RL objective, leading to an algorithm that has very high sample-complexity. This work uses imitation learning for the outer loop procedure, to significantly decrease sample-complexity.\n\nTechnical Contribution:\n-----------------------\nThe idea of using imitation learning for reinforcement learning is well explored in the literature, and so using this idea in itself is not real contribution. There are several issues with the presentation of this work, that make it incredibly difficult to identify a technical contribution:\n\n1. overreaching statements without details to backup: you are writing the paper as if you are learning a \"RL algorithm\" that can be used to quickly learn new tasks. your manuscript does not really provide a description for this \"algorithm\". After re-reading several other papers I concluded that what you mean is that you learn an initial set of policy parameters that can quickly adapt to new related tasks and an update rule with which you update these parameters. However, standard MAML uses SGD as an update rule so there is really nothing to be learned here. Unfortunately, your paper provides zero detail on these claims of learning a \"RL procedure\", so for now I have to assume that you are simply learning a good initial set of policy parameters through meta-learning. If that is the case, then using imitation learning in this setting is really not novel, this has been done by a lot of other people before (you're just using MAML to learn \"better\" initial parameters).\n2. you're technical section (section 4) provides some details on the technical challenges of using demonstrations to perform the outer loop optimization step. Unfortunately, you are not putting your work in the context of existing work ([1], [2]), that discuss and address the importance\/issue of sampling in meta-rl with MAML. So it's impossible to know whether there is any new insight here\n\nExperimental Evaluation:\n-------------------------\nThe experimental evaluation is very \"thin\", other than the original MAML-RL and pure imitation learning no other more recent baselines ([1], [2]) have been compared to. And only 2 relatively simple simulation settings are tested. \n\nSummary:\n-----------\nVery minor contribution, a manuscript that is lacking important details and does not relate it's technical section to existing work, with very thin evaluation. \n\n\n[1] The Importance of Sampling in Meta-Reinforcement Learning, NIPS 2018\n[2] CONTINUOUS ADAPTATION VIA META-LEARNING IN NONSTATIONARY AND COMPETITIVE ENVIRONMENTS, ICLR 2018","sentences":[{"sentence_type":"2","sentence":"The idea of using imitation learning for reinforcement learning is well explored in the literature, and so using this idea in itself is not real contribution.","rephrased":"While the application of imitation learning within reinforcement learning is a well-explored concept in the literature, it would be beneficial to clarify how this approach provides a distinct contribution in the context of your work."},{"sentence_type":"2","sentence":"There are several issues with the presentation of this work, that make it incredibly difficult to identify a technical contribution:","rephrased":"The presentation of the work could be improved to more clearly highlight the technical contributions, which would help in understanding the advancements made."},{"sentence_type":"2","sentence":"Unfortunately, your paper provides zero detail on these claims of learning a \"RL procedure\", so for now I have to assume that you are simply learning a good initial set of policy parameters through meta-learning.","rephrased":"The paper would benefit from additional details on the claims of learning a 'RL procedure' to support the assumption that the work extends beyond learning an initial set of policy parameters through meta-learning."},{"sentence_type":"2","sentence":"If that is the case, then using imitation learning in this setting is really not novel, this has been done by a lot of other people before (you're just using MAML to learn \"better\" initial parameters).","rephrased":"If the approach is focused on using imitation learning to obtain better initial parameters via MAML, it would be helpful to discuss how this method differs from or improves upon existing strategies in the field."},{"sentence_type":"3","sentence":"Very minor contribution, a manuscript that is lacking important details and does not relate it's technical section to existing work, with very thin evaluation.","rephrased":"The contribution could be more clearly articulated, and the manuscript would benefit from a more detailed technical section that relates to existing work, as well as a more robust experimental evaluation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[866,1024,"Maybe"],[1025,1157,"Confirmed"],[1723,1935,"Confirmed"],[1936,2137,"Maybe"],[2836,2995,"Confirmed"]],"Comments":[]}
{"id":"S1eIEPFXcS","text":"---SUMMARY---\nThis paper gives two methods for improving an existing differentially private model. Both methods assume a source of unlabeled data that requires no privacy guarantees. The two methods make different uses of this public data to augment the original private model. Both preserve (a degree of) privacy for the original model.\n\nThe first method is DiversePublic. DiversePublic only post-processes the original private model M -- in particular, it does not touch the original data -- and so its privacy is immediate. At a high level, DiversePublic works by picking the \"best\" unlabelled data points for augmenting M. First, it applies M to the unlabeled data and then applies PCA to the result. Next, it selects highly \"uncertain\" points, projects them onto the top k principal components, and clusters the results. Finally, it selects samples from each cluster and uses them to augment M. This augmenting process, called FineTune, is left as a black box.\n\nThe second method is NearPrivate. The given motivation for NearPrivate is that the public dataset may have a different distribution than the original private training data. To address this, NearPrivate uses DP-PCA (a pre-existing technique for differentially private PCA) on the private dataset and projects both the private and public data onto the top k principal components. Then it compares uncertain points in the public and private dataset projections and only augments M (again using the black box FineTune) using uncertain public examples with many nearby uncertain private samples. Intuitively, this should select for points that are not too different than the original private training data.\n\nThe paper then evaluates these algorithms with experiments on MNIST and SVHN under reasonable privacy parameters (I think -- see below). These experiments compare the performance of DiversePublic and NearPrivate, where both train M using vanilla DP-SGD [Abadi et al. 2016]. DiversePublic and NearPrivate trade performances on MNIST and SVHN, but NearPrivate does (as might be expected) better when the public dataset is polluted.\n\nIn summary, the paper suggests DiversePublic and NearPrivate as useful ways to augment a given differentially private model M using public data, and their experiments suggest this is reasonable.\n\n---DECISION---\nReject.\n\nThis is an empirical paper. It proposes some algorithms and justifies these algorithms through experiments. However, the paper makes a confusing omission: it does not mention PATE [1, 2].\n\n[1] \"Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data\". Papernot et al. 2017.\n[2] \"Scalable Learning with PATE\". Papernot et al. 2018.\n\nI am more of a pure differential privacy researcher and am therefore less familiar with this line of mostly empirical work. But as far as I can tell PATE works in the same setting as that of this paper: there is a private dataset, a public unlabelled dataset, and the goal is to train a model with a differential privacy guarantee for the private dataset. As a result, PATE seems directly relevant. In particular, the claim that \"there are no published examples of a differentially private SVHN classifier with both reasonable accuracy and non-trivial privacy guarantees\" seems wrong, as the PATE papers include just that.\n\nMoreover, PATE appears at least competitive with the algorithms here. For example, the comparison given as Table 1 in [2] suggests that PATE can get 98-99% accuracy on MNIST for privacy parameters at least as low as those used here with only a few hundred new labelings. In contrast, if I understand the experiments here, they are using thousands of new labelled examples to get the same accuracy and privacy. Similarly, on SVHN the experiments here get to 84% accuracy with 10,000 new labelled examples, whereas the same Table 1 puts PATE at 90% with almost identical privacy parameters and thousands fewer new labelled examples.\n\nThat comparison is my main concern. Perhaps I am missing a reason why PATE is not comparable. If it is, it should certainly appear in the experiments. If PATE is indeed comparable, then the main improvement contributed by this paper is the post-processing aspect: PATE is a way to train a private model from scratch, but these methods work on an existing model. Even then, the question of how exactly the existing model is modified (the FineTune method) is unclear.\n\nMore broadly, there are several parts of this paper that could be much clearer. I am sympathetic to paper length limitations, but I am certain many or all of these issues can be addressed in 8 pages.\n\n1. DiversePublic description: What does it mean to \"obtain the 'embeddings'...E_{public}\"? How is k picked?\n2. How does the private point-public point assignment in NearPrivate work? Is it just random? How many points do we pick? \n3. In general, how is FineTune meant to work? I understand it is meant to be an abstract black box in the algorithm descriptions, but the experiment description doesn't explain it either. How does FineTune work in the experiments?\n4. What does 'headroom' mean in Section 4.2?\n5. The way privacy parameters are specified at various points in the experiment section makes things hard to read. A concise table summarizing privacy parameters, accuracy, and additional labels would help.\n\nBut overall, I am most interested in the PATE comparison. \n\n---EDIT AFTER AUTHOR RESPONSE---\nI missed the data-dependent aspect of PATE's privacy guarantee. That is a point in favor of this paper. As such, I've increased my score from reject to weak reject.\n\nI actually think a revised version of this paper could reasonably appear in ICLR or similar venues. However, I think the necessary revisions are too large\/numerous to accept the paper in its current form, even with promises of revisions. Here are a few revisions that I think would make the paper a much better submission to future conferences:\n\n1. Add discussion of PATE. The data-dependence of their privacy guarantees is well-taken. But it is not clear that data-dependent privacy guarantees are as \"trivial\" as the paper currently claims with \"there are no published examples of a differentially private SVHN classifier with both reasonable accuracy and non-trivial privacy guarantees\" suggests. (In fact, I find it confusing that one of the PATE authors agrees with this claim -- they think their own work is trivial?). I agree that data-independent privacy guarantees are preferable, but this should certainly be discussed. As the authors themselves note, the original PATE paper was well-received, so if this paper wants to claim its privacy guarantees are somehow meaningless or even just unsatisfactory, that claim needs to be defended.\n\n2. Elaborate on the fine-tuning process. Perhaps \"fine tuning\" is indeed \"super standard in the object recognition literature\", but as all three reviews here indicate, the presentation of fine tuning is unclear in this paper. The author responses also seem to simultaneously claim that fine tuning is  both \"super standard\" and \"[not] obvious\". \n\n3. To make room for the text above, it's not clear that the material about data pollution or even presenting both methods is necessary. I would prefer to see a thorough explanation of the active learning\/post-processing paradigm through one algorithm. The authors seem to want to claim that active learning is a useful private approach because it gets data-independent privacy guarantees and performance similar to algorithms with data-dependent privacy guarantees. A paper that focuses on and thoroughly defends that claim actually sounds pretty good! ","sentences":[{"sentence_type":"2","sentence":"Reject.","rephrased":"After careful consideration, I recommend rejection."},{"sentence_type":"1","sentence":"Moreover, PATE appears at least competitive with the algorithms here.","rephrased":"Additionally, it would be beneficial to consider how PATE compares with the algorithms presented in this paper, as it appears to have competitive results."},{"sentence_type":"1","sentence":"But overall, I am most interested in the PATE comparison.","rephrased":"However, my primary interest lies in a more detailed comparison with PATE."},{"sentence_type":"1","sentence":"I actually think a revised version of this paper could reasonably appear in ICLR or similar venues.","rephrased":"I believe that with substantial revisions, this paper has the potential to be considered for ICLR or similar venues."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2312,2319,"Not concerning"],[3301,3370,"Not concerning"],[5316,5373,"Not concerning"],[5575,5674,"Not concerning"]],"Comments":[]}
{"id":"DJE2LYjDrer","text":"Overview: The authors examine deep learning from the perspective of kernel methods and demonstrate that convolution layers in these architectures can make DNNs a form of composite kernel learning.\n\nSignificance: Understanding and interpreting neural networks is an important problem in general; similarly extracting good features key to downstream performance of a neural network. Hence the paper tries to address some important and relevant problems in the field, however, I'm not fully convinced as to whether their procedure is  any more interpretable than existing methods or extracts features optimally.\n\nQuality and Clarity: While the work provides sufficient details to understand prior work and the method itself, the key contribution section of the paper needs more work. \n\nNovelty: There are many works that focus on understanding neural networks and learning features for downstream prediction from the perspective of kernels. The novelty in this work is limited to allowing gating functions to adapt during training, such that the learnt gates can perform better than random gates.\n\nPros:\n1) Paper presents a potential solution to a relevant problem\n2) Paper provides good overview of an existing method that form the basis of the approach.\n\nCons:\n\n1) The most significant weakness of this paper is lack of thorough discussion about what the kernels actually mean in terms of understanding what the neural network is doing. How are these kernels learnt? For this, I think the authors need to make concrete comparisons with methods that are deeply rooted in kernels such as GPs or BNNs. For instance, does using a particular composite kernel structure give you the same predictive performance as when using a GP? Can we directly interpret such models as forms of BNNs or GPs? How does this work compare to more classic work that uses composite kernels in support vector machines? \n\n2) I would have also liked to have seen a better exposition of the interpretability of the method. How does using these composite kernels together compare to other approaches for interpreting deep neural networks like for instance layerwise relevance propagation?\n\n3) There is hardly any reference material which suggests the authors need to include a more thorough description and comparison of related work.","sentences":[{"sentence_type":"2","sentence":"I'm not fully convinced as to whether their procedure is any more interpretable than existing methods or extracts features optimally.","rephrased":"I would like to see further clarification or evidence on how their procedure offers improved interpretability over existing methods and optimizes feature extraction."},{"sentence_type":"2","sentence":"The most significant weakness of this paper is lack of thorough discussion about what the kernels actually mean in terms of understanding what the neural network is doing.","rephrased":"The paper would benefit from a more thorough discussion on the implications of the kernels for understanding neural network operations."},{"sentence_type":"2","sentence":"There is hardly any reference material which suggests the authors need to include a more thorough description and comparison of related work.","rephrased":"The authors should consider expanding the reference section to provide a more comprehensive description and comparison with related work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1264,1435,"Not concerning"],[2161,2302,"Maybe"]],"Comments":[]}
{"id":"SyniKeceM","text":"unsupervised neural machine translation\n\nThis is an interesting paper on unsupervised MT. It trains a standard architecture using:\n\n1) word embeddings in a shared embedding space, learned using a recent approach that works with only tens of bilingual word papers.\n\n2) A encoder-decoder trained using only monolingual data (should cite http:\/\/www.statmt.org\/wmt17\/pdf\/WMT15.pdf). Training uses a “denoising” method which is not new: it uses the same idea as contrastive estimation (http:\/\/www.aclweb.org\/anthology\/P05-1044, a well-known method which should be cited). \n\n3) Backtranslation.\n\nAll though none of these ideas are new, they haven’t been combined in this way before, and that what’s novel here. The paper is essentially a neat application of (1), and is an empirical\/ systems paper. It’s essentially a proof-of-concept that it is that it’s possible to get anything at all using no parallel data. That’s surprising and interesting, but I learned very little else from it. The paper reads as preliminary and rushed, and I had difficulty answering some basic questions:\n\n* In Table (1), I’m slightly puzzled by why 5 is better than 6, and this may be because I’m confused about what 6 represents. It would be natural to compare 5 with a system trained on 100K parallel text, since the systems would then (effectively) differ only in that 5 also exploits additional monolingual data. But the text suggests that 6 is trained on much more than 100K parallel sentences; that is, it differs in at least two conditions (amount of parallel text and use of monolingual text). Since this paper’s primary contribution is empirical, this comparison should be done in a carefully controlled way, differing each of these elements in turn.\n\n* I’m very confused by the comment on p. 8 that “the modifications introduced by our proposal are also limiting” to the “comparable supervised NMT system”. According to the paper, the architecture of the system is unchanged, so why would this be the case? This comment makes it seem like something else has been changed in the baseline, which in turn makes it somewhat hard to accept the results here.\n\nComment:\n* The qualitative analysis is not really an analysis: it’s just a few cherry-picked examples and some vague observations. While it is useful to see that the system does indeed generate nontrivial content in these cases, this doesn’t give us further insight into what the system does well or poorly outside these examples. The BLEU scores suggest that it also produces many low-quality translations. What is different about these particular examples? (Aside: since the cross-lingual embedding method is trained on numerals, should we be concerned that the system fails at translating numerals?)\n\nQuestions:\n* Contrastive estimation considers other neighborhood functions (“random noise” in the parlance of this paper), and it’s natural to wonder what would happen if this paper also used these or other neighborhood functions. More importantly, I suspect the the neighborhood functions are important: when translating between Indo-European languages as in these experiments, local swaps are reasonable; but in translating between two different language families (as would often be the case in the motivating low-resource scenario that the paper does not actually test), it seems likely that other neighborhood functions would be important, since structural differences would be much larger.\n\nPresentational comments (these don’t affect my evaluation, they’re mostly observations but they contribute to a general feeling that the paper is rushed and preliminary):\n\n* BPE does not “learn”, it’s entirely deterministic.\n\n* This paper is at best tangentially related to decipherment. Decipherment operates under two quite different assumptions: there is no training data for the source language ciphertext, only the ciphertext itself (which is often very small); and the replacement function is deterministic rather than probabilistic (and often monotonic). The Dou and Knight papers are interesting, but they’re an adaptation of ideas rather than decipherment per se. Since none of those ideas are used here this feels like hand-waving.\n\n* Future work is vague: “we would like to detect and mitigate the specific causes…” “we also think that a better handling of rare words…” That’s great, but how will you do these things? Do you have specific reasons to think this, or ideas on how to approach them? Otherwise this is just hand-waving.","sentences":[{"sentence_type":"2","sentence":"The paper reads as preliminary and rushed, and I had difficulty answering some basic questions:","rephrased":"The paper could benefit from additional detail and clarification to help address some fundamental questions:"},{"sentence_type":"2","sentence":"The qualitative analysis is not really an analysis: it's just a few cherry-picked examples and some vague observations.","rephrased":"The qualitative analysis would be strengthened by including a broader range of examples and more detailed observations."},{"sentence_type":"2","sentence":"That's great, but how will you do these things? Do you have specific reasons to think this, or ideas on how to approach them? Otherwise this is just hand-waving.","rephrased":"It would be helpful if future work could outline specific methods or preliminary ideas for detecting and mitigating the causes, as well as for better handling of rare words."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[981,1076,"Maybe"]],"Comments":[]}
{"id":"HkxHiJvg3N","text":"The paper presents a review of literature about learning methodologies as a support KE of planning domain models.\n\nThe paper is not easy to read, somehow verbose.\n\nThe topic in itself is adequate to the workshop, but I am not sure of the actual contribution provided here.\n\nExcepted for the Section \"Considerable Issues\", the paper aims I think at organizing the existing literature, at presenting and commenting it and so on, to give some added value to the sum of surveyed works or to provide directions of future deployments.\n\nBut is this \"added value\" that it is difficult to grasp in this paper. I would suggest, at least in the presentation, to insist more on the \"rational\" behind the surveying activity, more than on the extensive description of surveyed works.\n\nSome more specific comments:\n\n- Abstract: please explain or remove 'AP' (defined only later in the Introduction)\n\n- Introduction: \"The correctness of the planner reasoning depends fundamentally on the quality of the domain knowledge...\" This is too generic. I see what you mean, but I think correctness of planning relates to the capability of deriving correct plans wrt what is actually modeled in the domain, not correct plans wrt what the modeler wanted to model.\n\n- p2, Temporal Planning: \"Generally, the objective of modelling temporal constraints is a minimization of the plan makespan\". Again too generic. Temporal Constraints are modeled for millions of reasons. To minimize the makespan can be an objective in some problems, but not the most important in general. In most of the cases, temporal constraints are modeled just because they exist for instance, and have to be satisfied. Or to express concurrency, resource allocation and so on...\n\n- P3, Hybrid Planning. The planetary rover example is a bit \"naive\" like it is reported, even in such a generic context. The issue here comes mostly for the need of casting such a scenario into an action-base paradigma, not the most suitable for controlling such an asset. Check on the various literature around on the NASA's Mars2020 mission as an example, on the timeline-based planning approaches used in practice to control these rovers.\n\n- p3,c1, r-7: expressivlely: maybe expressivity?","sentences":[{"sentence_type":"2","sentence":"The paper is not easy to read, somehow verbose.","rephrased":"The paper could benefit from more concise language to enhance readability."},{"sentence_type":"2","sentence":"But is this \"added value\" that it is difficult to grasp in this paper.","rephrased":"I would encourage the authors to clarify the added value that the survey brings to the field."},{"sentence_type":"2","sentence":"The planetary rover example is a bit \"naive\" like it is reported, even in such a generic context.","rephrased":"The planetary rover example could be elaborated upon to better reflect the complexities involved in such scenarios."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[115,162,"Not concerning"],[530,600,"Not concerning"],[1747,1844,"Not concerning"]],"Comments":[]}
{"id":"Skg8yoJdYN","text":"\nPaper Summary\n\nThis paper proposes using hierarchies of Self-Taught Associative Memory (STAM) modules to solve the Unsupervised Continual Learning  (UCL) problem, wherein salient representations must be learned from a stream of unlabeled data that can be used for classification with a small amount of labeled data provided at a later time.  Importantly, the stream is assumed to be non-stationary in the sense that the number of classes in the stream varies with time and carries no associated prior that is known to the modeler.  The paper describes the STAM approach and presents compelling evidence that the representations it learns are well-suited for few-shot classification when compared with reasonable baselines.\n\n\nQuality (Pros)\n(1) The UCL problem is clearly described\n\n(2) The STAM architecture represents an interesting method for learning a representation that takes advantage of hierarchical receptive fields in a similar manner to CNNs, but is adaptable to changing data distributions by design via the online clustering and outlier pruning steps.  \n\n(3) The association of learned representations with different classes is accomplished in a reasonable way\n\n(4) Experimental results suggest that the STAM method consistently outperforms the CAE baseline \n\n\nLimitations (Cons) and Questions\n(1) Additional motivation for the UCL problem would be welcome, as well as experiments on additional datasets that would demonstrate a wider variety of use cases\n\n(2) It is unclear how such hyperparameters as the number of standard differences used in the novelty detector, the number of clusters chosen at each level in the hierarchy, and the allegiance value at which centroids are removed at the classification stage affect performance.  How much computational effort is required to find these values?  And how much does performance depend on them?\n\n(3) Computational efficiency is not touched upon; from a systems standpoint, what is the cost of this model relative to the CAE baseline?\n\n(4) I would suggest adding N = 1,000, 10,000 numbers to Figure 3 -- it is currently hard to read and contextualize.  It would also help to show the difference between 1,00 and 10,000 on a single graph, perhaps, as it is difficult do see the relative changes as currently presented\n\n(5) A point that I found confusing was exactly how the outliers are detected in the second paragraph under equation (5).  Specifically, from my reading, I was under the impression that y_{i+1,m} would be equivalent to c_i(y_{i+1,m}) except for any differences caused by averaging with other overlapping patches.  Is this averaging with overlapping patches then the reason that y_{i+1,m} and c_i(y_{i+1,m}) could be different?  Or have I misunderstood?  Regardless, some clarifying language around this point could be helpful to the reader.\n\n\nClarity\n\nThe presentation is generally clear and well-written, modulo the above suggestions.\n\n\nSignificance\n\nThe STAM approach seems to be a compelling method to solve the UCL problem based on the analysis presented, and comparison to baselines seems reasonable.  This method could be useful in a number of machine learning applications.\n","sentences":[{"sentence_type":"1","sentence":"A point that I found confusing was exactly how the outliers are detected in the second paragraph under equation (5).","rephrased":"The explanation of outlier detection in the second paragraph under equation (5) could be clarified further."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[2286,2402,"Not concerning"]],"Comments":[]}
{"id":"BJgXi3WG3N","text":"The paper is about domain model learning in planning. It is not a research paper, there is no novel contribution. The paper can be best characterised as a survey, but honestly, I am not sure what is being surveyed. After reading the paper, I still cannot say what its purpose is. It is not a survey of domain model learning techniques, just a few of them are mentioned, no recent approaches such as  FAMA or LOUGA are covered, no critical comparison is presented. Actually, I have found many references quite old and only very few very recent works are referenced so there is a question of up-to-date content. The authors claim that the text is targeted to students, but I cannot recommend it to students as the text is very hard to follow. The structure is clutter, the used notions are not introduced, only experts can follow the text as the reader must be familiar with a lot notions used but never introduced in the paper. Just to give an example the text never says what domain model learning is.\nI think the paper requires complete rewriting, the mission must be clear, the notions must be introduced to be accessible by non-experts (if targeted to students), the survey should be perhaps more focused (if length is restricted). What is added value? What does the reader take away after reading the paper?","sentences":[{"sentence_type":"2","sentence":"The paper can be best characterised as a survey, but honestly, I am not sure what is being surveyed.","rephrased":"The paper appears to be a survey, but it would be helpful to clarify the specific focus of the survey."},{"sentence_type":"2","sentence":"The authors claim that the text is targeted to students, but I cannot recommend it to students as the text is very hard to follow.","rephrased":"The paper is intended for students, yet it could be made more accessible by simplifying the language and improving the structure."},{"sentence_type":"2","sentence":"The structure is clutter, the used notions are not introduced, only experts can follow the text as the reader must be familiar with a lot notions used but never introduced in the paper.","rephrased":"The paper would benefit from a clearer structure and an introduction to the key concepts to ensure that it is comprehensible to a broader audience."},{"sentence_type":"3","sentence":"I think the paper requires complete rewriting, the mission must be clear, the notions must be introduced to be accessible by non-experts (if targeted to students), the survey should be perhaps more focused (if length is restricted).","rephrased":"The paper could be significantly improved by clarifying its objectives, introducing the relevant concepts for non-experts, and possibly narrowing the focus of the survey for conciseness."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[114,214,"Maybe"],[610,740,"Not concerning"],[741,926,"Confirmed"],[1002,1234,"Not concerning"]],"Comments":[]}
{"id":"BJgNadIjh7","text":"The authors present a biologically-inspired neural network model based on the excitatory and inhibitory ion channels in the membranes of real cells.  Unfortunately, the paper is structured incoherently, making it nearly impossible to appreciate the authors' contribution.  The introduction references neuroscience alongside ResNets, FinTech, surprisal spaces, Bose-Einstein statistics, and topological conjugacy without adequately motivating or defining any of the above.  The fundamental definition of the model synapse as a conditional probability (Eq. 1) is not guaranteed to be non-negative, casting serious doubt on any of the subsequent conclusions.   Figure 1 conveys no further information about the proposed model.  There is no explicit related work or background section.  The single experiment offers no comparison to alternative methods.   I suggest the authors invest serious effort into rewriting the paper to clarify the presentation and explicitly state their contributions in the context of existing work on biologically-inspired learning models.  This is indeed a subfield of machine learning worthy of more investigation. ","sentences":[{"sentence_type":"2","sentence":"Unfortunately, the paper is structured incoherently, making it nearly impossible to appreciate the authors' contribution.","rephrased":"The paper could benefit from a clearer structure to better highlight the authors' contributions."},{"sentence_type":"2","sentence":"The fundamental definition of the model synapse as a conditional probability (Eq. 1) is not guaranteed to be non-negative, casting serious doubt on any of the subsequent conclusions.","rephrased":"The definition of the model synapse as a conditional probability (Eq. 1) should ensure non-negativity to strengthen the subsequent conclusions."},{"sentence_type":"1","sentence":"Figure 1 conveys no further information about the proposed model.","rephrased":"Figure 1 could be improved to provide more information about the proposed model."},{"sentence_type":"1","sentence":"The single experiment offers no comparison to alternative methods.","rephrased":"Including a comparison to alternative methods in the experiment section would be beneficial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[150,271,"Maybe"],[473,655,"Confirmed"],[658,723,"Not concerning"],[783,849,"Not concerning"]],"Comments":[]}
{"id":"IdSf90F0X_D","text":"This paper concerns the problem of learning from single-label supervision, when this label is known not to be the truth. This is called complementary label learning. Some loss functions are proposed that are claimed to have the same theoretical minimizer as the one for standard labelling. \n\nThe research agenda of the paper looks reasonable, even if it can be seen as a very specific instance of partial label learning (where one just considers the complement of the complementary label and tries to learn from it). A positioning with this latter approach therefore seems necessary. Also, after reading the paper, there are some unclarities left about the authors claim. Below are some more specific comments about that:\n\n* Introduction: it is claimed that getting complementary label is easier than getting true labels, however complementary labels have to be certainly false, and while there are indeed theoretically more wrong labels than right ones, it is not entirely clear whether getting certainly false labels is easier than getting true ones in practice. Are there applications or empirical studies demonstrating that? Most mentioned papers do not appear to have actually applied the setting. \n\n* Connection to partial label learning: the current framework can be seen as a peculiar case of partial label learning, as if I take a complementary label $\\overline{y}$, then its complement $\\mathcal{Y}\\setminus\\overline{y}$ is a partial label certainly containing the truth. It would then be necessary to connect the current work to this trend, for instance to Cour et al. \"Learning from partial labels\" (JMLR 2011) or the more recent works of, e.g., X Wu, ML Zhang \"Towards Enabling Binary Decomposition for Partial Label Learning.\". \n\n* Definition 2: I do not really follow definition 2. First, are \\theta^* and \\theta arbitrary parameters values? Why call it \\theta^* (suggesting some kind of optimality)? If   \\theta^* is a minimizer of one of the two losses, then either the premise or the conclusion is a tautology (making the definition kind of meaningless). \n\n* Proof of Theorem 1: I have some trouble with this definition. First, Equation (13) seems trivial if \\theta^* is the finite sample optimal model (also, why not identifying the search space with the space of parameters?). I also do not really follow the next line, as it is unclear how realistic it is to modify the parameters for just one instance? It is also unclear what is to be proven here, as \\inf \\sum \\geq \\sum \\inf, thus allowing for instance-specific parameters would always give something better than a global minimizer. In summary, I am not really convinced by this proof. \n\n* In the experiment, I wold expect a comparison with other approaches (complementary but also partial label learning), but more importantly with the optimal models obtained on learning from the initial true labels, if only to demonstrate that the proposed theorems are valid. The asymptotic accuracies displayed are also very far from state-of-art standards (less than half of it) for CIFAR 10, which seems to contradict the fact that complementary labels have the same minimizer (hence comparable performances) as the one obtained with true labels? \n\n* Finally, the paper contains an important numbers of typos or questionable grammatical structures. For instance in the first two pages only:\n- \"supper\" --> super\n- \"A complementary-label is only specific that the pattern\"\n- \"in some questions refer to private.\"\n- \"the best hyper-parameter by empirical risk since\" (by empirical risk minimisation)\n- \"can be summary as\"","sentences":[{"sentence_type":"1","sentence":"The research agenda of the paper looks reasonable, even if it can be seen as a very specific instance of partial label learning.","rephrased":"The research agenda of the paper is a valuable contribution, though it may benefit from further discussion on how it fits within the broader context of partial label learning."},{"sentence_type":"1","sentence":"I do not really follow definition 2.","rephrased":"Definition 2 could be clarified further to enhance understanding."},{"sentence_type":"1","sentence":"I have some trouble with this definition.","rephrased":"I find this definition challenging and would appreciate additional clarification or examples."},{"sentence_type":"2","sentence":"In summary, I am not really convinced by this proof.","rephrased":"The proof presented could be strengthened with more detailed explanations or supporting evidence to fully convince the reader of its validity."},{"sentence_type":"2","sentence":"The asymptotic accuracies displayed are also very far from state-of-art standards (less than half of it) for CIFAR 10, which seems to contradict the fact that complementary labels have the same minimizer (hence comparable performances) as the one obtained with true labels?","rephrased":"It would be helpful to see how the asymptotic accuracies compare to state-of-the-art standards for CIFAR 10, as this could provide further insight into the effectiveness of the proposed method with complementary labels."},{"sentence_type":"2","sentence":"Finally, the paper contains an important numbers of typos or questionable grammatical structures.","rephrased":"The paper would benefit from a thorough proofreading to correct the numerous typos and grammatical issues, which would enhance its overall clarity and professionalism."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[292,419,"Not concerning"],[1760,1796,"Not concerning"],[2097,2138,"Not concerning"],[2607,2659,"Not concerning"],[2938,3211,"Not concerning"],[3216,3313,"Not concerning"]],"Comments":[]}
{"id":"kivlhk3kuY","text":"The authors presented in this submission a nice novel idea of building a tree ensemble in a cascading style so that any positive predictions are decided and explained by the first tree predicting them positively. The reviewer finds this idea very interesting and clearly elaborated in this paper. However, more theoretical and empirical justification is crucially necessary in order to make the claims in the submission convincing. The issues listed here are some questions that the reviewer believes should have been discussed or answered in the paper.\n\nMajor issues:\n \nDespite the fact that the focus of cascading decision trees (CDTs) is a short explanatory path, my major concern here is that it is very hard to justify them as a proper statistical model. \n\n1.\nPractically,  there are very simple adversarial cases that the cascading decision trees will fail to build. Consider this example that X ~ Unif([0,1]^2) and Y|X == 1 if X \\in [1\/3, 2\/3]^2 otherwise 0. If we apply the algorithm in the paper, using depth=2 trees and a mixed node threshold theta = 0.5 (which I believe are a reasonable choice), the positive-focused CDTs will almost fail to construct the first tree with a decently large sample, let alone the cascading subsequence. On the other hand, since depth=2 trees can cover all rectangles (0,0) - (a,b) \\in R^2,  the counterpart random forests or GBDTs are universal approximators. \n\nBy also checking the negative predictions there might be ways to mitigate this issue. However relevant discussions are lacking in this paper in its current shape. \n\nFrom a more abstract perspective regarding the CDTs depth: in a d-dim sample space, to separate out a d-dim cube, we are likely in the need of 2d splits. There might be fewer splits needed when the cube is touching the boundary of the support or there are other nodes made before as in an ensemble. But in general we should not make such assumptions, and it would be better if we could have more discussions in the paper. \n\n2\nClassic classification trees are asymptotically bayesian classifiers, whereas we can imagine asymptotically CDTs assign the positive label to a region only when the true positive rate theta* within the region is larger than the constant threshold theta, which means CDTs are intrinsically inaccurate - more specifically, low recall as mentioned by the authors. This situation is further worsened as CDTs will take positive examples off from the sample. The fact that CDTs are theoretically incapable of finding all positive examples is harming their credibility of giving short explanations to positive predictions. A bandage here might be to use adaptive thresholds, but no discussions are currently present in the submission.\n\nMinor issues:\n\n1. Classic CARTs are very sensitive towards outliers. The \"split one example out each time\" scenario being analyzed in the paper is likely to cause overfitting, chasing the outliers, and instability. It should be avoided. \n2. CARTs default greedy building algorithm uses entropy or Gini index which are indifferent towards both positive and negative examples. Since the focus in the paper is on positive predictions, it is worth discussing how the algorithm should be changed accordingly.\n3. It would be better if there were instructions in the paper regarding choosing the mixed node threshold theta, the tree depth, and hopefully the ensemble size. \n4. Since CDTs are still a tree ensemble, their capacity is expected to be larger than a single decision tree which can even be a bit deeper. The results pertaining to the accuracy, precision and recall in the empirical study session are therefore slightly unfair comparison - it would be better to benchmark against decision tree ensembles or rule-based models [1]. \n\n[1] Wang, Fulton, and Cynthia Rudin. \"Falling rule lists.\" Artificial Intelligence and Statistics. 2015.\n","sentences":[{"sentence_type":"2","sentence":"it is very hard to justify them as a proper statistical model.","rephrased":"Justifying them as a proper statistical model may be challenging and requires further exploration."},{"sentence_type":"2","sentence":"The fact that CDTs are theoretically incapable of finding all positive examples is harming their credibility of giving short explanations to positive predictions.","rephrased":"The theoretical limitations of CDTs in identifying all positive examples could affect their credibility in providing concise explanations for positive predictions, and this warrants further discussion."},{"sentence_type":"2","sentence":"The \"split one example out each time\" scenario being analyzed in the paper is likely to cause overfitting, chasing the outliers, and instability. It should be avoided.","rephrased":"The 'split one example out each time' approach analyzed in the paper may lead to overfitting, chasing outliers, and instability, and exploring alternative strategies could be beneficial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[697,759,"Not concerning"],[2449,2611,"Not concerning"],[2794,2961,"Not concerning"]],"Comments":[]}
{"id":"AhB8PgRSyc1","text":"[Strengths]\n\n* The idea to embed data-driven\/learned sparsity in a meta-learning framework is really interesting. These methods have been shown to improve robustness, are open to continual learning and have been shown to enable learning independent mechanisms. It is a nice idea and this is backed up by competitive performance of the algorithm compared to original instantiations of MAML.\n\n* The paper is well written and clear. As the reviewer of this paper, I feel that I have sufficient information and understanding to implement it myself\n\n[Weaknesses]\n\n* I find the methodological advances proposed in the manuscript too incremental for publication at ICLR. The SLWTA method proposed within appears to be the method of Panousis et al. (2021) (cited in text) but adapted to the MAML paradigm.\n\n* The probabilistic model introduced by the authors bares many simiilarities with other data-driven sparsity models that are inline with Panousis et al. (2021). There is:\n1. https:\/\/arxiv.org\/abs\/1805.10896 - Adaptive Network Sparsification with Dependent Variational Beta-Bernoulli Dropout\n2. https:\/\/arxiv.org\/abs\/1912.02290 - Hierarchical Indian Buffet Neural Networks for Bayesian Continual Learning\nBoth who learn modularity with a similar ELBO as proposed by the authors. \n\n* I think there are too few competiting baselines. Why were more recent gradient-based ML algorithms not considered such as Bayesian MAML (https:\/\/arxiv.org\/abs\/1806.03836) which first framed MAML in a Bayesian perspective?\n\n\n","sentences":[{"sentence_type":"2","sentence":"I find the methodological advances proposed in the manuscript too incremental for publication at ICLR.","rephrased":"The methodological advances proposed in the manuscript seem somewhat incremental and may benefit from further differentiation or development to stand out for publication at ICLR."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[561,663,"Not concerning"]],"Comments":[]}
{"id":"1NB-T2kWRV5","text":"The authors have extended Barreto's work (SF) to a more general case that does not require the assumption that reward functions are not linearly decomposable. They propose the use of a xi function, which provides a guarantee of convergence. The xi function can be applied to a range of tasks that differ only in terms of their reward functions.\n\nExperimental results demonstrate that the proposed model achieves higher returns than other methods with smaller number of tasks training.\n\nAlthough the paper briefly mentions the complexity reduction achieved through the use of the xi function, further explanation and clarification on this point would be benefical.\n\n","sentences":[{"sentence_type":"1","sentence":"Although the paper briefly mentions the complexity reduction achieved through the use of the xi function, further explanation and clarification on this point would be benefical.","rephrased":"The paper could be strengthened by providing a more detailed explanation and clarification of the complexity reduction achieved through the use of the xi function."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[486,663,"Not concerning"]],"Comments":[]}
{"id":"r1eHYs0wFE","text":"Pros:\n- extensive and thorough experimentation\n- interesting and original idea\n- proposed an approach that is complimentary to previous approaches and helps improve SOTA results\n- comprehensive supplementary\n\nCons:\n- not immediately clear how this work relates to the limited labels setting","sentences":[{"sentence_type":"1","sentence":"not immediately clear how this work relates to the limited labels setting","rephrased":"It would be helpful to clarify how this work relates to the limited labels setting."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[217,290,"Not concerning"]],"Comments":[]}
{"id":"r1eaHySCFr","text":"The authors propose a model-based reinforcement algorithm in which the model is a sequential latent variable model and the actions planned with a cross-entropy method (CEM) planner. The model is learnt by maximizing a lower bound on the mutual information between the latent states and their successor observations (instead of the classical sequential ELBO). The authors argue that the latter objective function yield robustness to distraction in visual scenes. The algorithm, named MIRO, is experimented on 4 simulated environments.\n---\nOverall I did not find the paper particularly clear and easy to read. The method is only introduced in the 5th page and no ablation study is conducted. \nIt is still not obvious to me why maximizing the MI in the objective function would reduce the influence of potential distractors.` \nFurthermore, the paper overlooks a good part of the related work on extending VAEs to sequence data, published in the last 3 years and does not draw links to similar architectures. \nThe experiments are in my opinion not convincing, as the approach is only experimented on 2 non trivial -yet not particularly challenging- environments (Finger and Half Cheetah). \n\nMinor: in the equation of the ELBO, page 3, the parameters \\theta and \\phi are swapped. \n","sentences":[{"sentence_type":"2","sentence":"Overall I did not find the paper particularly clear and easy to read.","rephrased":"The paper could benefit from improved clarity and readability, particularly in the introductory sections."},{"sentence_type":"2","sentence":"The experiments are in my opinion not convincing, as the approach is only experimented on 2 non trivial -yet not particularly challenging- environments (Finger and Half Cheetah).","rephrased":"The experiments could be strengthened by testing the approach on a wider variety of environments, including some that are more challenging."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[538,607,"Not concerning"],[1006,1184,"Not concerning"]],"Comments":[]}
{"id":"VccYGUKD94","text":"This short submission describes the author's attempts to reproduce Yue et al. (2020)'s \"Interventional Few-Shot Learning\" results. It focuses on one dataset (miniImageNet) and two methods (meta-transfer learning and simulated information bottleneck) that the original paper proposes can be augmented with the interventional strategy (IFSL). Using author-provided code, this submission reports that including IFSL does improve the model's performance, though not to the same extent reported in the original paper. A baseline discrepancy on the meta-transfer learning experiment was also observed.\n\nUnfortunately, the submission includes very few details--it is essentially just the reproducibility summary--which limits the potential value of this work. The author obtained the best results using Yue et al.'s  hyperparameters; for all runs \"the results were much worse\" when these parameters were optimized by the author. However, the significance of this claim is tough to assess because no methodological details or quantitative results were reported in this submission. The only results are reported in Table 1 and 2 and these are unclear: over how many runs was the average taken? What is indicated after the ± (SD, SE, etc)? \n\nThe manuscript does not include any exploration or explanation of the results reported here, nor is the original method tested outside of the original framework. References to the broader literature (and the original paper!) are missing, and the writing could be more polished.\n\nI regret that I cannot be more positive, but I do not believe the work is ready for publication. ","sentences":[{"sentence_type":"2","sentence":"Unfortunately, the submission includes very few details--it is essentially just the reproducibility summary--which limits the potential value of this work.","rephrased":"While the submission provides a useful reproducibility summary, including more details could significantly enhance the value of this work."},{"sentence_type":"2","sentence":"I regret that I cannot be more positive, but I do not believe the work is ready for publication.","rephrased":"Although the work presents interesting findings, further development and additional details are needed before it is ready for publication."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[597,752,"Maybe"],[1511,1607,"Not concerning"]],"Comments":[]}
{"id":"SJlYWS2hYB","text":"The paper provides an empirical study of regularization in policy optimization methods in multiple continuous control tasks. The paper focuses on the effect of conventional regularization on performance in training environments, not generalization ability to different (but similar) testing environments. Their findings suggest that L2 and entropy regularization can improve the performance, be robust to hyperparameters on the tasks studied in the paper. \n\nOverall, the paper is well written. However, I am leaning to reject this paper because (1) the experimental finding is not well justified (2) the experiments are missing some details and do not provide convincing evidence.  \n\nFirst, the paper does not well justify why regularization methods improve performance in training environments. One potential reason is discussed in Section 7: regularization can improve generalization to unseen samples. However, the improvement can simply due to better hyperparemer optimization. When we introduce more hyperparemers and computation compared to baselines, it’s not surprising to see a better performance, especially in deep RL where using a different seed or using a different implementation can have significant difference in performance [1]. Moreover, it is unclear that inability to generalize to unseen samples is a problem in the continuous control tasks evaluated in the paper. I think the paper should demonstrate that this is indeed a problem. If it is not a problem, why would you expect regularization to help?\n\nThere are some missing details which makes it difficult to draw conclusion:\n1. How was \\sigma_{env,r} computed? Is it the standard error of the mean return, or the standard deviation of the return? \n2. What does the average rank mean (in Table 2 and 3)? the average ranking over 5 seeds and all environments? If so, does it make sense to compare these numbers? e.g. Algorithm A with rank 1, 1, 7, 7 and Algorithm B with rank 4, 4, 4, 4 have the same average rank, but totally different performance. \n3. The experiment in Figure 3 seems very interesting, however, what’s the conclusion here? \n4. Why do you use difference hyperparamer ranges (lambda for L2, L1 and entropy regularization) for different algorithms in appendix A? \n\nMinor comment which does not impact the score:\n1. It would have been better if there’s a brief description of each algorithm (before section 4 or in appendix). \n\n[1] Reproducibility of Benchmarked Deep Reinforcement Learning Tasks for Continuous Control\n","sentences":[{"sentence_type":"2","sentence":"However, I am leaning to reject this paper because (1) the experimental finding is not well justified (2) the experiments are missing some details and do not provide convincing evidence.","rephrased":"However, I have reservations about accepting this paper because (1) the experimental findings could be better justified, and (2) the experiments could include more details to provide more convincing evidence."},{"sentence_type":"1","sentence":"Moreover, it is unclear that inability to generalize to unseen samples is a problem in the continuous control tasks evaluated in the paper.","rephrased":"Additionally, it would be beneficial for the paper to clarify whether the inability to generalize to unseen samples is a significant issue in the continuous control tasks evaluated."},{"sentence_type":"1","sentence":"I think the paper should demonstrate that this is indeed a problem.","rephrased":"It would strengthen the paper if it could demonstrate that this is indeed a challenge that needs addressing."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[494,680,"Not concerning"],[1246,1385,"Not concerning"],[1386,1453,"Not concerning"]],"Comments":[]}
{"id":"VCoNR_r6lme","text":"=============================================================================================================\n\nSummary:\nThe paper starts from the Linear Symmetry-Based Disentanglement (LSBD) in [1]. The existing approaches to evaluate disentanglement require the supervision of the dataset and it is impossible for the unlabeled data. In this regard, the authors propose the new quantifying metric for disentanglement under the 'limited supervision' setting. Also, under this metric, authors provide a VAE-based framework that exploits limited supervision for the proposed metric.\n\n==============================================================================================================\n\nReason for score:\n\nOverall, I vote for clear rejection. I was hooked by the title and abstract. However, I could not find any novelty and insights to compare several measures for the disentanglement score. Furthermore, experiments are not enough to support the proposed method (see cons). I suggest the resubmission with more experiment results and justifications of their proposed methods. \n\n=============================================================================================================\n\nStrong points (pros) :\n\n(1) Mathematical definitions to interpret disentanglement are clear (but complex). The quality of writing is not bad.\n\n(2) I like the trial to quantify disentanglement under a limited-supervised setting since it could be applied to real-world settings.\n\n==============================================================================================================\n\ncons : \n\n(1) The comparison with the other disentanglement metrics under supervised data is crucial. The proposed metric which can be applied under a weakly supervised setting should have a certain amount of consensus with other metrics. The authors need to show through experiments and provide justification by pointing out similarities and differences with the other metrics. This part is very important to persuade reviewers and readers. \n\n(2) I was caught off guard at the experiments since there doesn't exist any baselines in Figure 4. The authors need to add baselines to compare with $\\Delta VAE$.\n\n(3) The idea underlying paper is quite overlapped with [2]. As a baseline, [2] can be used to analyze the performance of $\\Delta VAE$. Also, the authors need to emphasize the novelty of their method by comparing it with [2].\n\n=====================================================================================================\n\nMinor :\n\nThe word \"limited supervision\" is quite confusing. Instead, I suggest \"weakly-supervised\". \n\n======================================================================================================\n\nAfter rebuttal :\n\nThank you for the responses. I'm not sure why the authors didn't perform the experiments on the correlation between the previous factor-based disentanglement scores and the proposed disentanglement score in the limited supervised setting. For example, if there are 5 factors, I propose to evaluate the proposed disentanglement score for every possible pair of the factors (10 pairs) and average the scores. I believe this paper handles the valuable topic but it is not enough to be accepted since the experiments, which are crucial I believe, are omitted (comparison with the other disentanglement score, baselines to $Delta$VAE, comparison with [2]). Also, I concerned that other readers might be confused with the (\"factor-based\" disentanglement and \"symmetric-based\" disentanglement ) and (limited-supervision and weakly-supervision) (a new section should be added to handle these topics if this paper should be accepted). Furthermore, discussion with the related works is not enough.\n\n\nI lower my confidence rate to 3 (5->3) and vote for weak reject (3->4). But, I hope this paper would be accepted after revisions in the future.\n\n============================================================================================================\n\nReferences \n\n[1] beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework, ICLR 2017.\n\n[2] Weakly-Supervised Disentanglement Without Compromises, ICML2020.","sentences":[{"sentence_type":"2","sentence":"Overall, I vote for clear rejection.","rephrased":"Overall, my assessment leads me to recommend rejection at this stage."},{"sentence_type":"2","sentence":"I could not find any novelty and insights to compare several measures for the disentanglement score.","rephrased":"The paper would benefit from a clearer presentation of its novel contributions and a more detailed comparison with existing measures for the disentanglement score."},{"sentence_type":"2","sentence":"Furthermore, experiments are not enough to support the proposed method (see cons).","rephrased":"The paper could be strengthened by providing more comprehensive experimental support for the proposed method."},{"sentence_type":"2","sentence":"I was caught off guard at the experiments since there doesn't exist any baselines in Figure 4.","rephrased":"The experiments in Figure 4 would be more informative if they included comparisons with established baselines."},{"sentence_type":"2","sentence":"The idea underlying paper is quite overlapped with [2].","rephrased":"The paper seems to have considerable overlap with [2], and it would be beneficial to more clearly distinguish the novel aspects of the proposed method."},{"sentence_type":"2","sentence":"I'm not sure why the authors didn't perform the experiments on the correlation between the previous factor-based disentanglement scores and the proposed disentanglement score in the limited supervised setting.","rephrased":"It would be helpful if the authors could include experiments that explore the correlation between the previous factor-based disentanglement scores and the proposed score in the limited supervised setting."},{"sentence_type":"2","sentence":"I believe this paper handles the valuable topic but it is not enough to be accepted since the experiments, which are crucial I believe, are omitted.","rephrased":"While the paper addresses a valuable topic, I recommend further development, particularly in the experimental section, which is essential for a more robust submission."},{"sentence_type":"2","sentence":"Also, I concerned that other readers might be confused with the (\"factor-based\" disentanglement and \"symmetric-based\" disentanglement ) and (limited-supervision and weakly-supervision) (a new section should be added to handle these topics if this paper should be accepted).","rephrased":"To avoid potential confusion among readers regarding 'factor-based' versus 'symmetric-based' disentanglement and 'limited-supervision' versus 'weakly-supervision', it may be beneficial to add a section clarifying these concepts."},{"sentence_type":"2","sentence":"Furthermore, discussion with the related works is not enough.","rephrased":"Expanding the discussion on related works could provide a more comprehensive context for the study."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[713,749,"Not concerning"],[799,899,"Not concerning"],[900,982,"Not concerning"],[2035,2129,"Not concerning"],[2199,2254,"Not concerning"],[2777,2986,"Not concerning"],[3400,3673,"Not concerning"],[3674,3735,"Not concerning"]],"Comments":[]}
{"id":"V8GxZEqsUqJ","text":"This paper develops a MLR based on hyperbolic geometry. The idea is based on well-known concept of horocycle and horospheres which are known to be hyperbolic counterpart of line and plane in Euclidean geometry (see Coxter). Then the authors show the universal approximation which kind of follows similarly from the Euclidean counterpart. In fact we can probably conject that this universal approximation holds for any manifolds with constant sectional curvature.\n\nStrength: To the best of my knowledge, this is the first paper to deal with linear models on hyperbolic spaces by borrowing geometric tools like horocycles.\n\n\n\nMajor weakness:\n\nThe ideas are borrowed from well-known geometric tools, although this is not a weakness but the theorems closely follow Euclidean counterpart. This essentially reduces the ``````\"novelty\" of the paper. Moreover, the experiments are ``\"synthetic\", there is no motivation to use such a construction in real experiment. It will be good to see the authors discuss in which real cases we need to use such a hyperbolic MLR.\n\n1) The work should be better motivated, for example what is the motivation of using Horocycle layer and Poisson neuron layer?\n2) In section 6.2, the 2D output after 4 convolutional layers seems very less expressive, why not increase the dimension? Also what is the motivation to map it to H^2?\n3) In Theorem 2, eq. 9, why the inner product is Euclidean instead of hyperbolic? \n4) The universal approximation theorem in Theorem 2 almost follows from the Euclidean counterpart, e.g., see https:\/\/cbmm.mit.edu\/sites\/default\/files\/publications\/CBMM-Memo-054.pdf\n5) What is the additional consequence of Corollary 1 other than showing we can approximate any function, similar as Theorem 2?\n6) The statement in section 6.3 stating \"t is the best hyperbolic geometry related MNIST classifier\" does not carry much weight, e.g., what is the motivation of using MNIST images for MLR using hyperbolic geometry? \n7) There is not much point for section 6.4. In most practical cases, the 1-dimensional reduction is not meaningful as it can not carry much information.\n8) Section 6.5 seems very rushed including the Fig. 8 and experiment of Flowers. This section seems more like placeholder.","sentences":[{"sentence_type":"2","sentence":"This essentially reduces the ``````\"novelty\" of the paper.","rephrased":"While the application of well-known geometric tools is clear, it would be beneficial for the paper to further emphasize the novel aspects of the approach in the context of hyperbolic geometry."},{"sentence_type":"2","sentence":"Moreover, the experiments are ``\"synthetic\", there is no motivation to use such a construction in real experiment.","rephrased":"Additionally, it would be advantageous for the paper to include more motivation for the practical application of the proposed construction, perhaps by incorporating real-world data in the experiments."},{"sentence_type":"2","sentence":"There is not much point for section 6.4.","rephrased":"Section 6.4 could be improved by providing more context or examples to illustrate the significance and potential applications of the 1-dimensional reduction."},{"sentence_type":"2","sentence":"This section seems more like placeholder.","rephrased":"This section could be further developed to provide a more comprehensive understanding of the experiments and their implications."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[784,842,"Not concerning"],[843,957,"Maybe"],[1964,2004,"Not concerning"],[2195,2236,"Not concerning"]],"Comments":[]}
{"id":"ryeFpZd6_V","text":"Summary: The paper proposes to use the well-known technique of entropy regularization to de-bias the training set. The classes in the training set are assumed to come from biased mixtures of true classes. By penalizing low-entropy prediction of the model, combined with new labels from an oracle or inferred from prediction probabilities, the procedure can reduce the class bias in the noisy dataset. Experiments on MNIST, CIFAR-10 and CIFAR-100 validates the utility of the proposed scheme, showing that the bias decreases after the procedure.\n\nStrengths:\n1. The use of entropy penalty to de-bias noisy dataset is novel to the best of my knowledge.\n2. Experimental results on MNIST, CIFAR-10, and CIFAR-100 are convincing and validate the claim in the paper.\n\nWeaknesses:\n1. Bias is never defined. I take it to mean class imbalance in the mixture class. I recommending elaborating on the set up and the context where this setting makes sense.\n2. The experimental procedure isn't clear. What are mixture classes? Why does it make sense to construct mixture classes as such? What kind of real scenario are these experiments simulating?","sentences":[{"sentence_type":"2","sentence":"Bias is never defined.","rephrased":"The paper would benefit from a clear definition of 'bias', which seems to refer to class imbalance in the mixture class."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[776,798,"Not concerning"]],"Comments":[]}
{"id":"S1gDXsKIsN","text":"The paper presents a scheduling method for satellite observations, specifically for NASA's ECOSTRESS mission aiming at measuring how much water plants need and how plants respond to stress. In particular, the algorithm is an adaptation of the CLASP system that has been used for the same purpose. The results indicate good performance of the proposed method as the number of observations as well as coverage increased.\n\nThe problem is well specified and motivated. I like the part that discusses uncertainty as it is one of the important aspect to deal with when a plan, or a schedule has to be executed\/applied in real world. \n\nMy only critical comment concerns results and their (lack of) discussion. For example, Figure 10 shows that enforcing \"ring buffer\" constraints has a little effect to performance and the text just summarized the figure. I would expect at least a brief discussion about why the \"ring buffer\" constraints have such a little performance effect. Analogously, the results of the second experiment could have been explained in more detail. \n\nThe Discussion section is rather unclear as it refers to a bug, which is mentioned earlier in the text. I understand that fixing the bug onboard might be too risky and hence updating the software of the ground is a viable option. However, the sentence \"This experience has shown us that planning and scheduling work isn't finished at launch\" is confusing and perhaps needs a bit more elaboration.  ","sentences":[{"sentence_type":"2","sentence":"My only critical comment concerns results and their (lack of) discussion.","rephrased":"I would suggest expanding the discussion on the results, particularly in areas where it seems to be limited."},{"sentence_type":"1","sentence":"The Discussion section is rather unclear as it refers to a bug, which is mentioned earlier in the text.","rephrased":"The Discussion section could benefit from greater clarity, especially regarding the bug mentioned earlier in the text."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[629,702,"Not concerning"],[1065,1168,"Not concerning"]],"Comments":[]}
{"id":"HygOPyIfqr","text":"The paper is interested in music generation, leveraging a 2D representation of the music data. \n\nThe idea of using a 2D representation is quite good, though here very specific of the considered type of music. The authors might want to discuss related approaches , considering 2D general representations of music [1, 2]. The originality of the proposed approach is to use dilated convolutions to capture the long range dependencies in a GAN framework. \n\nThe paper however looks premature for publication at ICLR, for several reasons:\n\n* The thorough discussion of the dataset might be put in supplementary material. Instead, the reader would like to know whether the authors considered data augmentation of their relatively small dataset (820 tunes). Likewise, the description of the architecture could be put in a supplementary section, or on github for reproducibility.\n\n* The authors did not justify the choice of the specifics of the architecture, such as the number of filters, layers or the presence \/ absence of batch normalization (part 3.1). The reviewer would like to see how the results vary with respect to those parameters. It would also be interesting to see what the generated images look like before the tanh (part 3.1.2).\n\n* The assessment of the results is hard to interpret; the reasons why the Frechet distance varies depending on the models and the phrases combinations should be discussed.\n\n* The gold standard for evaluating music is based on the human assessment of the generated music (involving naive, advanced and expert people), as done in [3], cited; having a human being evaluate and compare the tunes would help to gain insight into the generation. In the same perspective, it would be appreciated to put the results on a website for the reader to assess the quality of the generated music. \n\n* The contraction of the support (as displayed in Fig. 3) suggests that there might be some mode dropping with the GAN; this should be studied in depth. \n\n* The authors consider Magenta and FolkRNN as baselines; the reviewer suggests to also consider e.g. [4]  (although not not exploiting the specifics of the style), to comparatively assess the proposed approach.\n\n[1] \"Onsets and Frames: Dual-Objective Piano Transcription\", Hawthorne et al., 2017.\n[2] \"TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) Pipeline for Musical Timbre Transfer\", Huang et al., 2018.\n[3] \"DeepBach: a Steerable Model for Bach Chorales Generation\", Hadjeres et al., 2017\n[4] \"Music Transformer\", Huang et al., 2018.","sentences":[{"sentence_type":"2","sentence":"The paper however looks premature for publication at ICLR, for several reasons:","rephrased":"The paper could benefit from further development before being considered for publication at ICLR, for several reasons:"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[453,532,"Not concerning"]],"Comments":[]}
{"id":"Hkg0A3UJ67","text":"Unfortunately, the work does not introduce new contributions, with the point of the paper provided in the introduction:\nIn our experiments, we show that best performing approaches currently available for object detection\non natural images can be used with success at OCR tasks.\n\nThe work is applying established object detection algorithms to OCR. While the work provides a thorough experimental section exploring trade offs in network hyper-parameters, the application of object detection to the OCR domain does not provide enough novelty to warrant publication.\n","sentences":[{"sentence_type":"2","sentence":"Unfortunately, the work does not introduce new contributions,","rephrased":"The work could be strengthened by highlighting more distinct contributions beyond the application of existing techniques."},{"sentence_type":"3","sentence":"the application of object detection to the OCR domain does not provide enough novelty to warrant publication.","rephrased":"The application of object detection to the OCR domain could be further developed to emphasize the novelty and potential impact, which would make the case for publication stronger."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,61,"Not concerning"],[454,563,"Not concerning"]],"Comments":[]}
{"id":"Hyl2WZpf5H","text":"This paper considers the problem of having compact yet expressive KD code for NLP tasks. The authors claim that the proposed differentiable product quantization framework has better compression but similar performance compared to existing KD codes.The authors present two instances of the DPQ framework: DPQ-SX using softmax to make it differentiable, and DPQ-VQ using centroid based approximation. While DPQ-SX performs better in terms of performance and compression, DPQ-VQ has the advantage in scalability.\n\n- Significance\nIt's understandable that the size of the embedding is important, but there's been a lack of explanation as to why this should be done only through KD codes. Hence, it is doubtful how big the impact of the proposed framework is.\n\n- Novelty\nJust extending and making Chen et al., 2018b's distilling method to be differentiable has limited novelty.\n\n- Clarity\nThe paper is clearly written in most places, but there were some questions about the importance and logic of statements.\n\n- Pros and cons\nCompared to Chen et al., 2018b, there is no need to use expensive functions, and performance is better. But, the baseline consists only of algorithms using KD codes; there might be many disadvantages compared to other types of algorithms.\n\n- Detailed comments and questions\n1. It is true that the parameters for embedding make up a large part of the overall parameters, but I would like some additional explanation of how important they are to learning. It is usually not necessary to train the entire embedding vector on GPU, so it would not be a big issue in the actual learning process.\n2. In a similar vein, it would be nice to show which of the embedding vector size or the LSTM model size contributes significantly to performance improvements. If LSTM model size contributes more, the motivation would be weakened.\n3. It would be nice to add more baselines such as Nakayama 2017 as well as the standard compression\/quantization methods used in other deep networks. And please explain why we should use KD codes to reduce embedding size. Also, why the distilling in Chen et al., 2018b is a problem?\n4. Did you run all experiments just one time? There is no confidence interval.\n5. DPQ models have different compression ratios depending on the size of K and D. It would be great to show the change in PPL according to the compression ratio of DPQ models.\n6. Can we apply it to pre-trained models like BERT?","sentences":[{"sentence_type":"2","sentence":"It's understandable that the size of the embedding is important, but there's been a lack of explanation as to why this should be done only through KD codes. Hence, it is doubtful how big the impact of the proposed framework is.","rephrased":"While the importance of embedding size is clear, the paper could benefit from further elaboration on the exclusive use of KD codes for this purpose. It would be helpful to understand the broader impact of the proposed framework."},{"sentence_type":"2","sentence":"Just extending and making Chen et al., 2018b's distilling method to be differentiable has limited novelty.","rephrased":"The work appears to build upon the distilling method of Chen et al., 2018b by introducing differentiability. It would be beneficial to highlight additional novel aspects that differentiate this approach from previous work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[526,753,"Not concerning"],[765,871,"Maybe"]],"Comments":[]}
{"id":"Ap7AKp8yKlP","text":"# Summary of the paper\nIt is motivated from a perspective that a model should be decomposed into independent modules\/mechanisms, such that the model is robust to data distribution shift. A TIM layer is proposed to replace the Transformer encoder layer, where a mechanism competition is introduced to suppress all but one group. Experiments are conducted on different Transformer architectures with a replacement of encoder layers by TIM layers in a) autoregressive image generation with Image Transformer, b) speech enhancement with a customized Transformer and c) BERT on language modeling. \n\n# Pros\nThe idea that grouping the hidden activations by multiple mechanisms is a promising inductive bias towards out-of-distribution generalization. It is an interesting attempt to integrate this idea to Transformers. \n\n# Cons\n1. The presentation is terrible: the method description is basically throwing the code (Algorithm 1) to the audience without much explanation. It is hard to understand the TIM layer if neither diagrams nor equations are supplied. \n2. I didn't get what does \"mechanism\" mean in Algorithm 1. The competition will for sure suppress some activations but how can you guarantee that different groups will learn different behaviors or achieve disentanglement? \n3. Experiments only demonstrate n_s = 2 mechanisms. Is n_s > 2 even working? All results suggest that TIM can make some neurons focusing on the foreground, which isn't that surprising as this is most attention based models aiming at. Do you have results showing that TIM can learn diverse functionalities from data which can be interpreted as mechanisms?  \n4. Figure 1 is confusing: how can we know the difference between \"head-wise self-attention\" and \"Mechanism-wise Self-Attention and Inter-mechanism Attention\", which are all represented by a blackbox. What is the competition patterns? How are they computed? \n5. Algorithm 1: functions such as GroupLinear(), Attention() are used before defining. \n6. Figure 2 (middle): what do you mean \"TIM learn to specialize over the two sides of the image\"? Also, what are these figures showing? ","sentences":[{"sentence_type":"3","sentence":"The presentation is terrible: the method description is basically throwing the code (Algorithm 1) to the audience without much explanation.","rephrased":"The presentation could be improved: the method description would benefit from a more detailed explanation beyond the provided code (Algorithm 1)."},{"sentence_type":"1","sentence":"I didn't get what does \"mechanism\" mean in Algorithm 1.","rephrased":"The term \"mechanism\" in Algorithm 1 could be more clearly defined to enhance understanding."},{"sentence_type":"2","sentence":"Experiments only demonstrate n_s = 2 mechanisms. Is n_s > 2 even working?","rephrased":"It would be informative to see experiments demonstrating the case where n_s > 2 mechanisms are used to assess the scalability of the approach."},{"sentence_type":"2","sentence":"Figure 1 is confusing: how can we know the difference between \"head-wise self-attention\" and \"Mechanism-wise Self-Attention and Inter-mechanism Attention\", which are all represented by a blackbox.","rephrased":"Figure 1 could be clarified to better illustrate the difference between \"head-wise self-attention\" and \"Mechanism-wise Self-Attention and Inter-mechanism Attention\"."},{"sentence_type":"2","sentence":"Algorithm 1: functions such as GroupLinear(), Attention() are used before defining.","rephrased":"In Algorithm 1, it would be helpful if functions like GroupLinear() and Attention() were defined before their usage."},{"sentence_type":"2","sentence":"Figure 2 (middle): what do you mean \"TIM learn to specialize over the two sides of the image\"? Also, what are these figures showing?","rephrased":"Could you please clarify what is meant by \"TIM learn to specialize over the two sides of the image\" in Figure 2 (middle)? Additionally, an explanation of what these figures represent would be beneficial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[825,964,"Confirmed"],[1056,1111,"Not concerning"],[1279,1352,"Not concerning"],[1636,1832,"Not concerning"],[1894,1977,"Not concerning"],[1982,2114,"Not concerning"]],"Comments":[]}
{"id":"TBfp1faS0M","text":"Summary:\nThis paper proposed the combination of two techniques for improved learning with unlabelled data: 1)  Positive-Unlabelled (PU) classifier, and 2) class-conditional GAN (cGAN). The idea is that the PU classifier can help produce more accurate pseudo labels for training of a cGAN, and with the improved cGAN, the generated images can be used in turn to further improve the PU classifier. The idea looks interesting and the empirical results verified its effectiveness. \n\nThe major weakness of this paper is the presentation. \n1. The paper is hard to read. The problems are not well defined and connected. The exact learning setting is vague. What is the main problem the authors try to solve here? The classification problem or the generation problem? \n2. The technical contribution to PU classification is very limited. The proposed learning pipeline is basically: 1) training PU classifier, 2) using the classifier do something else, then 3) retraining the classifier with more data. This does not seem to be a solid contribution.\n3.  On the other hand, what is the contribution to generative modelling with extra unlabelled data? Using a more accurate predictor (PU classifier) to obtain high-quality pseudo labels is also trivial.\n4. Why the proposed approach helps learning with out-of-distribution data? How does OOD data help GAN learning? In other words, what is the goal of OOD GAN?\n5. Why PU data is a practical way for using web data?  Why not simply use a pre-trained models to do pseudo labelling, along with open-set or OOD learning strategies? The experiments were only run on small datasets MNIST, Fashion MNIST and CIFAR-10. I am not convinced what the authors proposed in this paper is useful for dealing with real-world web data like WebVision. \n6. Is PU Acc a fair performance metric for baseline methods? \n7. Many typos needed to be fixed.\n\nComments after rebuttal:\n-------------\nThank the authors for the clarifications. I will raise my score to 5. Theoretical analysis of the proposed method is nice. But I still think the proposed approach was not well justified or motivated. Why is it the best option? And how are other simple baselines for improving both (not standalone) settings? ","sentences":[{"sentence_type":"2","sentence":"The paper is hard to read.","rephrased":"The paper could be more reader-friendly."},{"sentence_type":"2","sentence":"This does not seem to be a solid contribution.","rephrased":"The contribution to PU classification could be more clearly defined and substantiated."},{"sentence_type":"2","sentence":"Using a more accurate predictor (PU classifier) to obtain high-quality pseudo labels is also trivial.","rephrased":"The use of a more accurate predictor (PU classifier) to obtain high-quality pseudo labels could be further elaborated to highlight its novelty."},{"sentence_type":"2","sentence":"I am not convinced what the authors proposed in this paper is useful for dealing with real-world web data like WebVision.","rephrased":"It would be beneficial if the authors could provide additional evidence or arguments to demonstrate the applicability of their proposal to real-world web data like WebVision."},{"sentence_type":"2","sentence":"But I still think the proposed approach was not well justified or motivated.","rephrased":"However, I believe that further justification and motivation for the proposed approach would strengthen the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[537,563,"Not concerning"],[994,1040,"Not concerning"],[1141,1242,"Not concerning"],[1650,1771,"Maybe"],[2032,2108,"Not concerning"]],"Comments":[]}
{"id":"EOmxry_k5z","text":"Pros:\nThe proposed method uses CNN for image classification on Chest X-rays and CNN-RNN structure is then applied to generate reports. Different strategy is applied for normal\/abnormal cases. For abnormal cases, localized abnormal areas extracted from the first CNN is used for CNN-RNN to generate reports.  The result shows good improvement and many state of the art methods are compared. \nCons:\nDuring the second CNN-RNN step, for abnormal cases, localized abnormal areas and the global image is sent to the network separately, so for the normal global image part, the generated sentence may conflict the first step prediction.\n\n","sentences":[{"sentence_type":"1","sentence":"During the second CNN-RNN step, for abnormal cases, localized abnormal areas and the global image is sent to the network separately, so for the normal global image part, the generated sentence may conflict the first step prediction.","rephrased":"In the second CNN-RNN step for abnormal cases, it might be beneficial to consider integrating the localized abnormal areas with the global image to avoid potential discrepancies between the generated sentence and the initial prediction."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[397,629,"Not concerning"]],"Comments":[]}
{"id":"6DHJPfMICZ","text":"In this work, the authors present an LSTM-based model to predict the probability of successful embryo implantation based on time-lapse images of the developing embryo in an in-vivo environment. The results are very promising and discussed very well, the work is eagerly embedded within the field.\nThe overall impression of the paper is very good. The scientific background is profund and the description of the methods is clear. One minor concern is the description of the data set used, as I got a bit confused by the 8,789 data points of which only a subset is used as only these were labeled. Additionally, the presence of two different sets of expert panels was a bit confusing as well. These parts could be explained more clearly.\nHowever, the authors put a lot of effort into creating a sufficient data set with a comparison to the clinical state-of-the-art and hence deliver a very good and reliable study. I recommend to accept this paper for MIDL 2020 and am sure that there will be interesting discussions during the conference!","sentences":[{"sentence_type":"1","sentence":"One minor concern is the description of the data set used, as I got a bit confused by the 8,789 data points of which only a subset is used as only these were labeled.","rephrased":"One suggestion for improvement is to clarify the description of the dataset used. It would be helpful to understand why out of the 8,789 data points, only a subset was used due to labeling."},{"sentence_type":"1","sentence":"Additionally, the presence of two different sets of expert panels was a bit confusing as well.","rephrased":"Additionally, it would be beneficial to provide more details on the rationale for having two different sets of expert panels to avoid any confusion."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[429,595,"Not concerning"],[596,690,"Not concerning"]],"Comments":[]}
{"id":"DhbRigmnzwQ","text":"The paper suggests a neural network architecture (combining capsules, attention, and LSTM) to perform cell type classification for single-cell RNA-seq data. The authors claim that their method performs well and is interpretable -- more so than the competitors.\n\nI found the paper difficult to understand, classification results not convincing, and interpretability claims greatly overstated. Unfortunately I believe this is a clear reject.\n\nDisclaimer: I have heard about attention and capsules but do not know how they work. However, I think this paper can be assessed even if one treats the model as a black box. Also, I do work with single-cell RNA-seq data all the time.\n\n\nMAJOR COMMENTS\n\n* The authors claim that their method is \"interpretable\" (it's right in the title) but then does not demonstrate how it can be interpreted in practice. How is it more interpretable than a fully-connected network, a SVM, or a random forest (that have similar classification performance: Tables 1-2)? Unclear.\n\n* The authors claim that their method performs well, but in fact it does not perform better than a fully-connected network (Table 3), which does not use either attention, or capsules, or LSTM.\n\n* The paper is hard to follow, e.g. I could not fully understand what exactly is shown in Figures 2 and 3. Figures do not have meaningful captions, subplots and axes are not labeled, surrounding text is hard to read.","sentences":[{"sentence_type":"2","sentence":"I found the paper difficult to understand, classification results not convincing, and interpretability claims greatly overstated. Unfortunately I believe this is a clear reject.","rephrased":"The paper could benefit from clearer explanations, and the classification results and interpretability claims would be more compelling with additional evidence. Based on the current version, I would lean towards rejection, but I am open to reconsidering if improvements are made."},{"sentence_type":"2","sentence":"The paper is hard to follow, e.g. I could not fully understand what exactly is shown in Figures 2 and 3. Figures do not have meaningful captions, subplots and axes are not labeled, surrounding text is hard to read.","rephrased":"The paper would be easier to follow if Figures 2 and 3 were clarified with more descriptive captions, and if subplots and axes were labeled. Improving the readability of the surrounding text would also be beneficial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[262,439,"Confirmed"],[1198,1412,"Maybe"]],"Comments":[]}
{"id":"T4qv5ktf3g1","text":"SUMMARY\n\nThis paper presents a text generation model conditioned on desired structures. The proposed method is essentially a translation model from structure information (represented with multiple sequences of tokens) to a text. This study converts a text into structure information such as part of speech (POS) and participial construction (PC). Then, this paper proposes Structure Aware Transformer (SAT), which is essentially the same as the Transformer architecture. The experiments use datasets of Chinese lyrics and English Penn Treebank. This paper reports that giving structure information improved the performance in PPL and BLEU compared with GPT-2.\n\nPROS\n\nIt was nice to confirm that we can control language generation from POS and PC.\n\nCONS\n\nThe proposed method presented in Section 3.3 is identical to Transformer except that:\n\n+ An input consists of multiple sequences of structure information (e.g., pos and pc)\n\n+ Input embeddings are sums of structure embeddings (Equation 7)\n\nFor this reason, I do not think Structure Aware Transformer (SAT) is a novel proposal. If this explanation is sufficient, I think that the descriptions in Section 3.1 and 3.3 are redundant.\n\nBecause structure sequences (POS and PC) are obtained from sentences in the test set, it is not surprising to see performance improvements of language models. In other words, predicting word sequences with some hints (POS and PC) is much easier than doing without any hint (GPT-2). For this reason, the findings in this paper are not convincing.\n\nQUESTIONS\n\nCould you explain the major difference between the proposed method and Transformer (excluding minor differences in how input embedings are computed and hyper-parameters such as the number of layers)?","sentences":[{"sentence_type":"2","sentence":"For this reason, I do not think Structure Aware Transformer (SAT) is a novel proposal.","rephrased":"While the Structure Aware Transformer (SAT) shares similarities with the Transformer architecture, it would be beneficial to clarify the aspects that contribute to its novelty."},{"sentence_type":"2","sentence":"For this reason, the findings in this paper are not convincing.","rephrased":"The methodology for obtaining structure sequences from the test set could be further elaborated to strengthen the convincingness of the findings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[994,1080,"Maybe"],[1081,1183,"Missed by Model"],[1467,1530,"Not concerning"]],"Comments":[]}
{"id":"e0CrrbNMzTH","text":"I have serious concerns about the paper, as listed below: \n\n- The paper writing is very poor. There are numerous language and grammar errors. At many places, the expressions are not clear. The quality of the figures is low. \n\n- Overall, the novelty is low. Transformer architecture is modified in a straightforward way. Even the semi-supervised learning approach is the simple adaption of MLM-like unsupervised pre-training. \n\n- Benchmarking is employed and presented very poorly. For comparison models like TabNet, XGBoost etc., it is not clear how the hyperparameter tuning is done and what parameters are included in the search space. The authors should clearly describe which parameters were tuned and what validation reward is used. Otherwise, the outperformance conclusions are not convincing at all.\n\n- How do you do hyperparameter tuning in semi-supervised regime? It is unclear how semi-supervised validation data is used.\n\n- The results are presented in AUROC but what is the training objective? If the training objective is not AUROC, how do you ensure the metric mismatch is not dominating? \n\n- What is the significance of Fig. 5? How can you convince the readers that SALT has learned attention patterns that are meaningful?\n\n- The difference between supervised learning results is very low across different models. It is unclear whether the results are statistically significant. \n\n- No ablation studies are presented for the major constituents of the claims, such as the benefit of sharing attention layers. ","sentences":[{"sentence_type":"2","sentence":"The paper writing is very poor.","rephrased":"The paper could benefit from improvements in writing clarity and grammar."},{"sentence_type":"2","sentence":"Overall, the novelty is low.","rephrased":"The paper could more clearly highlight the novel aspects of the proposed modifications to the Transformer architecture."},{"sentence_type":"2","sentence":"Benchmarking is employed and presented very poorly.","rephrased":"The benchmarking section would benefit from a more detailed presentation, including clarity on hyperparameter tuning and the parameters included in the search space."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[62,93,"Confirmed"],[94,223,"Missed by Model"],[228,256,"Confirmed"],[257,425,"Missed by Model"],[429,480,"Confirmed"],[738,806,"Missed by Model"],[873,931,"Missed by Model"],[935,1005,"Missed Maybe"],[1006,1103,"Missed by Model"],[1107,1237,"Missed Maybe"],[1329,1394,"Missed by Model"],[1398,1522,"Missed by Model"]],"Comments":["Harsh, blunt."]}
{"id":"y5iurqPbA82","text":"Topic\n\nUsing a residual-based network to the performance of another DL-based network.\n\nContributions:\n\nUsing a residual-based network for estimating the computing performance of DL applications on a variety of models-framework-accelerator configurations, which enables the users to explore the hardware\/software design space.\nUsing three-phase performance modeling to estimate computation time.\n\nWeakness\n\n1, The main problem is the lack of Novelty and technical contributions. Using a DL-based model to predict the performance is not novel. Many NAS methods using the same trick to estimate the performance of one architecture ahead of running it directly on the hardware.\n\n2, Using a DL-base regression is better than normal regression when the sample size is large. The experiment results are not surprising.\n\n3, Box-cox transformation is a common technique in regression. That is not new.\n\n4, Need to prepare the dataset using a lot of samples, i.e. 100000, which is computationally heavy. \nRequire huge storage space to keep the samples for even one platform.\nThus the whole method is not efficient. It is hard to generalize it to other hardware\/platform.\n\n5, Besides, the method only considers some common operations such as conv, pooling, and FC-layer. However, more operations should be considered for example ROI Pooling, NMS, Spatial-to-depth. Those operations are also commonly used in tasks such as detection and SR. \n\n","sentences":[{"sentence_type":"2","sentence":"The main problem is the lack of Novelty and technical contributions.","rephrased":"The paper could benefit from a clearer articulation of its novel technical contributions, as the current approach of using a DL-based model to predict performance is well-established in the field."},{"sentence_type":"2","sentence":"The experiment results are not surprising.","rephrased":"The experimental results align with expectations given the large sample size typically required for DL-based regression models."},{"sentence_type":"2","sentence":"Thus the whole method is not efficient. It is hard to generalize it to other hardware\/platform.","rephrased":"The method's efficiency and generalizability to other hardware\/platforms may be a concern due to the computational and storage demands of preparing a large dataset."},{"sentence_type":"1","sentence":"Besides, the method only considers some common operations such as conv, pooling, and FC-layer.","rephrased":"The method might be further improved by considering a wider range of operations, such as ROI Pooling, NMS, and Spatial-to-depth, which are prevalent in tasks like detection and SR."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[409,541,"Confirmed"],[769,811,"Confirmed"],[876,892,"Missed by Model"],[1065,1160,"Maybe"],[1165,1259,"Not concerning"]],"Comments":[]}
{"id":"5sqpEDt1Om9","text":"The proposed method is a very appealing method for generating synthetic datasets and is based on a very neat observation regarding the Bayes error of distributions transformed using an invertible map. The main question is whether the proposed procedure can be used to evaluate how close the SOTA on various standard problems is to the true Bayes error. This is not the case, as pointed out by the authors themselves. Thus, in my view, the submission needs to be rewritten a bit, making it clearer that the procedure is primarily \"just\" a method for generating realistic synthetic datasets for which the Bayes error can be computed, and focussing the experiments on comparing state-of-the-art methods on synthetic datasets generated using the method (extending the experiments in Section 4.2 of the current version of the paper). The results regarding dataset difficulty in Table 1 do not seem particularly useful because we do not know how close the Bayes error of the NF model is to the true Bayes error.\n\nSection 4.2 (particularly regarding the results in Figure 4): it would be very useful to know what happens when the amount of training data is increased beyond 60,000.\n\nTable 1: The test NLL is not particularly interpretable. It would be much more useful to compute the classification error of the flow-based models for reference. (The current process used in the submission may have to be changed for this so that the labels in the test data are not used for hyperparameter tuning: Equation 16 requires labels, so the NLL on the test is computed based on labels and the model is chosen by considering the labels.)\n\nWhat are the sizes of the test sets for the datasets in Table 1?\n\nTable 1: In several cases, the SOTA error is lower than the Bayes error, even on three *MNIST datasets! This reinforces the point made above.\n\nTypos, etc.:\n\nThe term \"ConvNet\" suddenly appears in the text without any previous discussion or a reference.\n\n\"a benchmark datasets\"\n\n\"the distribution ... concentrate\"\n\n\"still substantial gap\"\n\n\"To this end\"?\n\n\"For example, a singular...\" -- incomplete sentence\n\n","sentences":[{"sentence_type":"2","sentence":"The results regarding dataset difficulty in Table 1 do not seem particularly useful because we do not know how close the Bayes error of the NF model is to the true Bayes error.","rephrased":"The utility of the results regarding dataset difficulty in Table 1 could be enhanced by providing insights into how the Bayes error of the NF model approximates the true Bayes error."},{"sentence_type":"1","sentence":"Table 1: In several cases, the SOTA error is lower than the Bayes error, even on three *MNIST datasets! This reinforces the point made above.","rephrased":"Table 1 shows that the SOTA error is lower than the Bayes error for several datasets, including three *MNIST datasets, which suggests a need for further discussion on this observation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[829,1005,"Maybe"],[1689,1830,"Confirmed"],[1846,1941,"Missed by Model"]],"Comments":[]}
{"id":"bFsZeXosPQF","text":"Summary: \nThis paper discusses the large undertaking of collecting, processing, and reporting COVID-19 data from the Ohio State University. This paper makes note of the challenges and missteps faced in data processing, and the lessons learned from this experience during the pandemic. \n\n\nClarity: This paper was clear and easy to follow. \n\nTo improve upon the clarity, I would suggest the following: \n\n--Ensure that the “aims” listed are discussed in later sections in the paper. The first aim of “tracking the positivity rate” is not mentioned at any other point in the paper. It is not clear from this paragraph which positivity rate is being tracked (university affiliates?), and whether any weighting scheme was applied to the data. Similarly, the second aim is “contact tracing” however there is no further discussion of how contact tracing was done and\/or recorded. It is unclear whether this is really an aim of the data component, or whether this is considered too far downstream. If both of these were aspects of the data framework, they should be expanded on in the implementation section. \n\n--In the figure 2 schematic, it would be helpful to highlight the data processing \/ management steps or programs used to convert from the gold test results to the dashboard and contact tracing app. Additional details could be added to this figure.\n\n--The term, “human infrastructure” is bolded in section 7.4, yet this term is not defined. It would be beneficial to define what this term means in the context of this paper, as this term may not be familiar to many readers. \n\nMinor comments on clarity: \n\n\n--In the “implementation section” and in figure 2, a number of abbreviations are used that are never spelled out. Writing out these abbreviations would clarify the paper and the data schematic (e.g., IDM, SIS, STFP, TDAI).\n\n\n--The discussion surrounding issues with salesforce data is unclear. The authors mention “user generated heterogeneity” and “version control issues”, however the link between those issues and what is causing gaps in data is not fully apparent. \n\n--Figure 1 is not mentioned at all in the paper. It would be useful to include a discussion of who is using \/ viewing the dashboard and how frequently it was used.  That would give an indication of how the data was being used by the community \/ decision makers at OSU. \n\n\n\nOriginality:  The work is original in that it is the only paper to describe the data-driven processes occurring at the Ohio State University. However, many of the points made are not unique, and seem to highlight issues with this data management system. Lessons such as the need to “minimize manual data entry”, work with experts in “every relevant domain”, and following ethical guidelines regarding data privacy are not ideas original to this project. To highlight the originality of this work, it would be helpful to have a small review of literature section that discusses how this project improves or differs from similar undertakings at large universities. \n\n\n\nSignificance: The significance of this paper could be improved by including more actionable messages to future data systems and teams. Significance could also be improved by noting how this data was used for decision making. One of the goals listed in section 3 is to “support daily policy decisions”. However, throughout the paper there is little indication of how the data that has been acquired, processed and presented informs decision making. Including additional examples of how this data was used would be very beneficial. The significance would also be boosted by discussing how individual COVID-19 testing data was integrated (if at all) with wastewater data and\/or genomic data to inform university policy. \n\n\n\nPros:\n\n--Well written paper\n\n--Concisely and clearly presents aims of a data-driven framework\n\n--Clearly explains many of the pitfalls that can occur in data management, and acknowledges that during the pandemic, some best-practices (such as recording all steps along the way) were not followed due to the need to provide numbers to decision makers.\n\n-- Provides nice examples of when microtrends were useful.\n\n\n\nCons:\n\n--Paper does not provide many actionable steps for using data, or a data-driven approach. Instead, rather broad generalizations are made as to what would be useful (e.g., less manual data entry). \n\n--The implementation section is not informative enough. It would be beneficial to provide more information about the programs used for sorting data, and for moving from one health system to another. \n\n--The figures presented seem disconnected from the text of the paper. Figure 1 should be discussed in the paper, and figure 2 should be expanded to be more descriptive. \n","sentences":[{"sentence_type":"2","sentence":"However, many of the points made are not unique, and seem to highlight issues with this data management system.","rephrased":"While the paper addresses several important points, it would be beneficial to further distinguish the unique aspects of this data management system and its specific challenges."},{"sentence_type":"2","sentence":"Paper does not provide many actionable steps for using data, or a data-driven approach.","rephrased":"The paper could be strengthened by providing more detailed, actionable steps for employing a data-driven approach."},{"sentence_type":"2","sentence":"The implementation section is not informative enough.","rephrased":"The implementation section would benefit from additional details to enhance its informativeness."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1835,1901,"Missed Maybe"],[2494,2605,"Not concerning"],[4162,4356,"Confirmed"],[4360,4413,"Maybe"]],"Comments":["So sassy! Right on the line"]}
{"id":"SygmXDIftV","text":"The authors present a framework in which an auto encoder (E, D) is regularized such that its latent representation to share mutual information with a generated latent space representation. This generated latent representation is an output of a generator network (G) that produces its latent variables based on a given random noise variable (z) plus a categorical input (c). The mutual information is maximized using another network (C, classifier network) that tries to map generated latent representations  to the categorical input (c) of the generator network. Moreover two discriminator networks (S, D_i) are used to ensure that the generated images come from the same distribution as the data.\n\nTo the best of my understanding the presented scheme performs, in an unsupervised manner, a clustering to a pre-defined number of clusters, that are defined by the one hot encoding categorical (c) input of G, while at the same time G disentangles the inter-cluster variability to the random noise variable (z).\n\nThe language of the text is clear and the methodology is described in details. I have however a few comments concerning the presentation of the main claim.\n\n1. According to the description of the proposed scheme, I find it difficult to understand how a disentangled representation is learned by the encoder (z_e). I understand that it is possible to generate a latent representation using the G network with c and z as inputs, yet this does not prove that the generated representation z_g (~z_e) are also disentangled.\n\n2. Unfortunately the experimental setup does also not support the disentanglement claim in the auto-encoder representation space. An experiment on how the generated image looks when interpolating samples within the auto-encoder representation would be more insightful.\n\n","sentences":[{"sentence_type":"2","sentence":"Unfortunately the experimental setup does also not support the disentanglement claim in the auto-encoder representation space.","rephrased":"The experimental setup could be further improved to provide stronger support for the disentanglement claim in the auto-encoder representation space."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1534,1660,"Not concerning"]],"Comments":[]}
{"id":"Zrwgwm_GFH6","text":"The paper proposes a defense against adversarial examples. The idea of the defense is to counteract transformation generated by PGD attack. This is done by running one step of PGD on network input several times (and using different target labels) and then average the result.\n\nAs described below, I think there are multiple serious flaws in the evaluation and the defense likely won’t work. Thus I recommend rejecting the paper.\n\nIssues with the paper:\n* Experiment section is lacking rigor which is necessary to properly evaluate defense against adversarial examples. Points below explain it in more detail.\n* One clear indication of a problem with evaluation is the fact that accuracy under attack is increasing (see table 2) when seemingly stronger attack is used. [i.e. PGD with larger number of steps]\n* The whole premise of the defense idea is to counteract very specific thing which PGD does, thus it’s unlikely to help against more sophisticated attacks or simply different attacks.\n* Evaluation procedure implies that the attacker has no knowledge about the defense and even no ability to query the defended model. Which is very strong restrictions on the attacker, moreover they are impractical from security standpoint [even in black box case attacker usually has an ability to query the model]\n* Authors cite (Carlini & Wagner, 2017) to justify oblivious-box attack setup. However  (Carlini & Wagner, 2017) actually proposes white-box attack and provides justification why white-box should be used.\n* https:\/\/arxiv.org\/pdf\/1802.00420.pdf (which authors cite) shows how to break defenses based on input transformations. Nevertheless authors do not address why the proposed defense (which is also input transformation) is not broken.\n* Authors use Guo et al.’s (2018) as one of the baselines, despite that this is a broken defense (per https:\/\/arxiv.org\/pdf\/1802.00420.pdf )\n* No comparison with adversarial training, in particular authors should consider comparing to  A. Madry’s paper https:\/\/arxiv.org\/pdf\/1706.06083.pdf which also performs experiments on CIFAR dataset.\n\n\nFeedback on how to improve paper:\n* The evaluation should be performed in the assumption that adversary is either aware of the attack (white-box case) or able to query the defended model (black box attack).\n* Use https:\/\/arxiv.org\/abs\/1902.06705 as a guide on how to properly evaluate models for adversarial robustness. And redo evaluation following this guide.\n* In particular, consider running gradient free attacks on the whole model (baseline model + defense on top of it) and try to make an attack which will break the proposed defense.\n","sentences":[{"sentence_type":"2","sentence":"Thus I recommend rejecting the paper.","rephrased":"Therefore, I would suggest major revisions before considering the paper for acceptance."},{"sentence_type":"2","sentence":"The whole premise of the defense idea is to counteract very specific thing which PGD does, thus it’s unlikely to help against more sophisticated attacks or simply different attacks.","rephrased":"The defense mechanism seems to be tailored to counteract a specific aspect of the PGD attack, which raises concerns about its effectiveness against a broader range of attacks."},{"sentence_type":"2","sentence":"Evaluation procedure implies that the attacker has no knowledge about the defense and even no ability to query the defended model. Which is very strong restrictions on the attacker, moreover they are impractical from security standpoint [even in black box case attacker usually has an ability to query the model]","rephrased":"The evaluation procedure seems to assume that the attacker lacks knowledge of the defense and cannot query the defended model, which are significant constraints that may not align with practical security scenarios."},{"sentence_type":"2","sentence":"Nevertheless authors do not address why the proposed defense (which is also input transformation) is not broken.","rephrased":"It would be beneficial if the authors could provide a rationale for why their proposed defense, which also relies on input transformation, is resilient to the types of attacks that have compromised similar approaches."},{"sentence_type":"2","sentence":"Authors use Guo et al.\n2018) as one of the baselines, despite that this is a broken defense (per https:\/\/arxiv.org\/pdf\/1802.00420.pdf )","rephrased":"The authors might reconsider the use of Guo et al. (2018) as a baseline, given recent findings that suggest vulnerabilities in that defense strategy."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[391,428,"Confirmed"],[809,990,"Not concerning"],[993,1305,"Maybe"],[1631,1743,"Confirmed"],[1746,1884,"Missed by Model"]],"Comments":[]}
{"id":"sjVWdaWJqw","text":"The authors presented an unsupervised learning approach for segmenting bones in artificial SPECT images. A recurrent neural network is used to produce a binary segmentation. The model is trained using a loss derived from the Chan and Vese active contours model. As such, it does not require manual segmentations for training. Authors also introduced an additional loss to use when ground truth labels are available, to train the model in a semi-supervised way. The experimental evaluation is performed on a series of simulates SPECT images to segment bones, in a sort of ablation study in which they trained the model in an unsupervised way, fine-tuning the model with ground truth labels and in a semi-supervised way. Results indicate that the best results are obtained using the semi-supervised approach.\n\nPros:\n* Modelling an active contour approach using neural networks is definitely a promising line of research, specially for application in which active contours have proven to be useful (e.g. vessel segmentation in CT scans).\n\nCons:\n* I am not sure if the proposed approach would be applicable to other problems. In the simulated SPECT images used in the paper it is clear that the background class is definitely black, and that the target class has a mean value higher than that. Then the loss function seems appropriate, because that is the most contrastive statistic between the two classes. In other problems it might be more difficult than that. It would be nice if the authors can at least ellaborate on how to extrapolate the method to other more challenging segmentation problems. Perhaps crafting new features might be a solution, as long as the computation of the features is differentiable. \n* The paper lacks a comparison between the proposed approach and another simple baseline (e.g. region growing or even Otsu thresholding). Since the results of the unsupervised model are not so accurate (Mode 1 in Table 1), it is definitely necessary to analyze them in the context of other unsupervised segmentation methods.\n* Using means and stds of DSC does not give us a full picture of the distribution of the DSC values. Please, replace Table 1 by a box plot.\n* The paper includes some statements that are not supported by references or experiments, or that are quite hard. In my opinion this is probably due to the lack of a more in-depth \nrevision of the text. I would recommend the authors to double check the following sentences:\n--> The statement \"several months to a(n) year\" is quite relative. Depending on the target problem, segmenting an image might be much easier to do.\n--> \"Solely rely on the statistics of intensities in a given image\". Most of the segmentation methods are based only on the intensities in the image! I wouldn't pose this as a disadvantage of the method. It would be different if you mention for instance the fact that the image features have to be manually crafted.\n\n\nQuestions:\n* What is the motivation of using a RNN instead of a classical U-Net? U-Nets are know to require not so many training images, which is relevant in the context of pushing towards an unsupervised segmentation approach.\n* Using a PReLU activation as the final activation function of the network seems quite odd. Could you please elaborate a little bit more about this decision? Did you try using a sigmoid function? Is it related with the fact that the loss function requires to have a binary segmentation to compute the intensity statistics?\n* Is the loss stable during training? I'd like to see the evolution of the training\/validation losses per iteration or epoch.\n\n\nSome other minor comments:\n* Avoid repetitions in the text (e.g. \"methods\" and \"method\" in line 9 page 1). Statements like \"A great deal\" should be avoided as well.\n* The use of English can be improved, perhaps with the help of a native English speaker.","sentences":[{"sentence_type":"2","sentence":"The paper includes some statements that are not supported by references or experiments, or that are quite hard.","rephrased":"The paper could be strengthened by providing additional references or experimental support for certain statements, which would help clarify their basis."},{"sentence_type":"2","sentence":"In my opinion this is probably due to the lack of a more in-depth revision of the text.","rephrased":"I suggest a more thorough review of the text to ensure all statements are well-supported and clearly presented."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2179,2290,"Confirmed"],[2291,2379,"Confirmed"]],"Comments":[]}
{"id":"fPgrizr4Ycs","text":"The authors introduce a wealth of changes to the standard HER agent and obtain a performance improvement in 3 multi-goal tasks. The main observation made by the paper is that relabeled experiences may be very off-policy \/ out-of-distribution, and so value estimates for such experiences will be bad. \n\nTo help with this the authors propose the following:\n- apply K-means to cluster real (state, goal) tuples. \n- estimate the likelihood of a given (state, goal) tuple X by finding the closest cluster center in real experience, sampling n real experiences Y^i in that cluster, and taking the minimum of 1\/d(X, Y^i). \n- they change the Bellman targets in case the likelihood estimate is low. In particular they change it to a lower bound based on some nearby real experience minus the distance times Lipschitz constant.\n- they use relative goals (g_original - g_current) instead of absolute goals (g_original).\n- there is some kind of curriculum on goal relabeling\n\nThis paper is hard to follow. The word usage and sentence structure is unnatural, and I find myself guessing at what exactly the authors mean. This carries through to the math. I think I understand what the modified Bellman backup above equation (6) is doing, but I'm still not entirely sure. I'm also not really following the Section that includes equation (8). As a result, the contributions are a bit unclear. \n\nTheorem 1 is not trivial and there is indeed doubt in my mind. A proof should be provided upon revision. \n\nThe related works section can be greatly improved. You should be relating the related work to your own.\n\nAn appendix was not provided, despite being referenced, and so the paper is missing additional results (the 3 environments are insufficient), implementation details, and hyperparameter details. Without these, this paper cannot be reimplemented and is not in a publishable state.\n\nNits:\n- Isn't Equation (5) just the definition of Lipschitz continuity, so I'm confused by what is meant by \"it's reasonable to claim that [it] holds\".\n- ","sentences":[{"sentence_type":"2","sentence":"This paper is hard to follow. The word usage and sentence structure is unnatural, and I find myself guessing at what exactly the authors mean.","rephrased":"The paper could be more accessible. Clarifying the word usage and sentence structure would help readers grasp the authors' intended meaning more easily."},{"sentence_type":"2","sentence":"Without these, this paper cannot be reimplemented and is not in a publishable state.","rephrased":"To facilitate reproducibility and meet publication standards, the paper should include the missing appendix with additional results, implementation details, and hyperparameter information."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[964,1106,"Confirmed"],[1537,1589,"Maybe"],[1591,1784,"Missed Maybe"],[1785,1869,"Confirmed"],[1879,2022,"Missed by Model"]],"Comments":[]}
{"id":"HkgRSG1t3X","text":"Recently, the implicit bias where gradient descent converges the max-margin classifier was shown for linear models without an explicit regularization.\nThis paper tries to extend this result to ReLU network, which is more challenging because of the non-convexity.\nMoreover, a similar property of stochastic gradient descent is also discussed.\n\nThe implicit bias is a key property to ensure the superior performance of over-parameterized models, hence this line of research is also important.\nHowever, I think there are several concerns as summarized below.\n\n1. I'm not sure about the significance of the ReLU model (P) considered in the paper.\nIndeed, the problem (P) is challenging, but an obtained model is linear defined by $w$.\nTherefore, an advantage of this model over linear models is unclear.\n\nMoreover, since the max-margin in this paper is defined by using part of dataset and it is different from the conventional max-margin, the generalization guarantees are not ensured by the margin theory.\nTherefore, I cannot figure out the importance of an implicit bias in this setting (, which ensures the convergence to this modified max-margin solution).\nIn addition, the definition of the max-margin seems to be incorrect: argmin max -> argmax min.\n\n2. Proposition 1 (variance bound) gives a bound on the sum of norms of stochastic gradients.\nHowever, I think this bound is obvious because stochastic gradients of the ReLU model (P) are uniformly bounded by the ReLU activation.\nCombining this boundedness and decreasing learning rates, the bound in Proposition 1 can be obtained immediately.\nMoreover, the validity of an assumption on $w_t$ made in the proposition should be discussed.\n\n3. Lemma F.2 is key to show the main theorem, but I wonder whether this lemma is correct.\nI think the third equation in the proof seems to be incorrect.\n","sentences":[{"sentence_type":"1","sentence":"However, I think there are several concerns as summarized below.","rephrased":"While there are several areas that could be improved, as summarized below."},{"sentence_type":"2","sentence":"Therefore, I cannot figure out the importance of an implicit bias in this setting (, which ensures the convergence to this modified max-margin solution).","rephrased":"It would be helpful if the paper could more clearly articulate the importance of an implicit bias in this setting, particularly in relation to the convergence to the modified max-margin solution."},{"sentence_type":"2","sentence":"However, I think this bound is obvious because stochastic gradients of the ReLU model (P) are uniformly bounded by the ReLU activation.","rephrased":"The bound might seem straightforward given that the stochastic gradients of the ReLU model (P) are uniformly bounded by the ReLU activation."},{"sentence_type":"1","sentence":"I think the third equation in the proof seems to be incorrect.","rephrased":"There appears to be a potential error in the third equation of the proof that may need to be addressed."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[491,555,"Not concerning"],[731,799,"Maybe"],[1004,1157,"Confirmed"],[1347,1482,"Maybe"],[1782,1844,"Not concerning"]],"Comments":[]}
{"id":"nu8Kh4_ziy7","text":"For the proposed dataset, more examples are expected given for each of the two classes. The definition of ‘legs moved inwards’ is not rigorous or clear. The same for ‘legs stretched out’.  For example, for Peeky, does it mean as long as one pair of legs moving to the center of the body? Or both have to. How to determine which two nodes belong to a pair. Why not the upper left and upper right. Also, the definition of ‘legs moved inwards’ should be defined like angle or something like that more rigorously in math.\n\nWhat is the main feature? The four ‘body posture (bending and three rotation angles), position, animal color (from red to blue), blocks’ shape (from cubes to spheres), and background color (from red to blue)?’. Are they continuous or discrete? For this sentence,\n‘A single scalar encodes the legs’ position.’, is ‘legs’ position’ is a feature? How to measure it? Or is there any visualization showing what 0 or 1 look like?\n\nI’m a little confused with this statement. ‘we sampled the block’s shape in a non-predictive biased fashion. For very stretched legs’ positions (Stretchy), the data distribution was biased towards round blocks, while for more retracted legs’ positions (Peeky), most blocks were cubic.’ If two classes are sampled from different distributions, shouldn’t it be predictive?\n\nFor ‘We generated the concepts using layer 342 (from a total of 641).’, what is layer 342?\n\nFor the user study, what task the online workers are asked to do. What’s the question to ask so that they are asked to identify the class-relevant features. Or is there an interface example?\n\nAre there any statistics for the user study, like time spent? Maybe this can reflect if the task is hard, an evidence for the argument in section 5.1.\n\nThe first line under section 5.3, ‘As stated iWe automatically’. iWe? Just a typo?\n\nOne paper that uses a similar synthetic dataset. Maybe useful for the concerned task in this paper.\nYuxin Chen, Oisin Mac Aodha, Shihan Su, Pietro Perona, Yisong Yue’ Near-Optimal Machine Teaching via Explanatory Teaching Sets’","sentences":[{"sentence_type":"1","sentence":"What is the main feature?","rephrased":"Could you please clarify what the main feature is?"},{"sentence_type":"1","sentence":"I'm a little confused with this statement.","rephrased":"This statement is a bit unclear to me."},{"sentence_type":"1","sentence":"The first line under section 5.3, 'As stated iWe automatically'. iWe? Just a typo?","rephrased":"There appears to be a typo in the first line under section 5.3; 'iWe' should probably be 'We'."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[88,187,"Missed by Model"],[519,544,"Not concerning"],[944,986,"Maybe"],[1388,1406,"Missed Maybe"],[1408,1473,"Missed Maybe"],[1752,1834,"Confirmed"]],"Comments":[]}
{"id":"Skgk0KR9FV","text":"\nThis paper tries to incorporate label distribution into model learning, when a limited number of training instances is available. \nIntuitively, the output label distribution could be wrongly biased, and the prior information like label distribution could be helpful. \nTo handle this problem, the authors propose two different techniques, the first regulate the output distribution and the second regularize the constructed representation. \nPerformance comparison demonstrated the effectiveness of the proposed method when only a limited number of instances are available. \n\nI think the studied problem is interesting and the proposed solution is novel and reasonable. \nMy main concern is about the assumption of the algorithm. \nThe proposed learning algorithm assumes that the algorithm can access a relative accurate label distribution, and the output distribution regularization depend on this term. \nBut for real world applications, it could be hard to get such knowledge, since in order to get the required annotation (as described in Appendix), the user needs to have a good understanding of the real distribution or annotate all instances in that batch. \nBesides, I noticed that in the experiment results, the proposed method sometimes achieves worse performance than baselines when all training data is available. \nThis phenomenon seems to me implies that the proposed method cannot fully leverage the additional information, as intuitively, with more information, it should perform better. \n","sentences":[{"sentence_type":"2","sentence":"But for real world applications, it could be hard to get such knowledge, since in order to get the required annotation (as described in Appendix), the user needs to have a good understanding of the real distribution or annotate all instances in that batch.","rephrased":"For real-world applications, obtaining the necessary knowledge for accurate label distribution may present challenges. As outlined in the Appendix, this often requires the user to have a comprehensive understanding of the actual distribution or to annotate all instances in the batch, which could be a limitation in practical scenarios."},{"sentence_type":"2","sentence":"This phenomenon seems to me implies that the proposed method cannot fully leverage the additional information, as intuitively, with more information, it should perform better.","rephrased":"This observation suggests that there may be room for improvement in how the proposed method utilizes additional information, as one would expect performance to enhance with more data."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[904,1160,"Not concerning"],[1323,1498,"Not concerning"]],"Comments":[]}
{"id":"w9OVBQ-UpA","text":"In the paper, the authors presented clear goals and well-designed experiments. Both, experiments and methods are well described and easy to follow.  The paper proposed a multi-resolution approach that is using two DL models and shared weights. The proposed approach is interesting.  The authors achieved decent results with the Kappa score equal to 0.8. \nAdding the following information could be useful for readers: \n-\tHow many areas were annotated per slide?\n-\tHow the random forest classifier was trained (on which dataset)?\n-\tMissing references to the Lanczos filter.\n","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"HJlsoiwNtB","text":"The paper proposes a new sentence embedding method. The novelty is to use dependency trees as examples in the self-supervised method based on contrastive learning. The idea to use linguistic knowledge in the design of sentence embeddings is attractive. The sentence representation is computed by a bi-LSTM and dependency tree representations are computed by Tree LSTM. The softmax classifier is trained using the negative log-likelihood loss.\n\nIn my opinion, the paper could not be accepted. As said before, the idea is attractive but the paper lacks motivations for the choice of dependency trees as additional linguistic knowledge. Indeed, the goal of the proposed algorithm should be made more precise. It is, in my opinion, very difficult to do better than existing sentence embedding methods and the proposed method should be used for specific downstream tasks where the structure of sentences is meaningful. Moreover, the proposed method do not scale well and empirical results on classical downstream tasks are not convincing. Last, in my opinion, the redaction of the paper should be improved and the bibliography should be updated. For instance, the best up-to-date sentence embedding methods are not cited (ELMO and BERT).\n\nDetailed comments.\n\n* Abstract and introduction. The description of the contribution is not precise enough. Please make precise what are \"multiple views\", \"different linguistic views\". Please explain why you choose dependency trees and explain why their use can improve sentence embeddings. \n* Related work. Please consider only word embeddings and sentence embeddings because the literature is sufficiently large in the last few years. Please update your related work with methods such as ELMO and BERT and subsequent work. Also recent papers study how BERT embeddings embed structural information and these should be discussed as you consider dependency trees in the construction of sentence embeddings.\n* The method does not scale well. The paper does not propose ideas to solve this problem. Why don't you consider the approach used in Logeswaran et al. \n* The qualitative analysis shows that similar sentences have a similar structure. This is not surprising because dependency trees are used for learning. But this should give ideas of downstream tasks for which the approach could be fruitful.\n* Many typos.","sentences":[{"sentence_type":"2","sentence":"In my opinion, the paper could not be accepted.","rephrased":"While the paper presents an interesting idea, I believe there are areas that need further development before it can be considered for acceptance."},{"sentence_type":"2","sentence":"Moreover, the proposed method do not scale well and empirical results on classical downstream tasks are not convincing.","rephrased":"Additionally, it would be beneficial to address the scalability of the proposed method and provide more compelling empirical results for classical downstream tasks."},{"sentence_type":"1","sentence":"Last, in my opinion, the redaction of the paper should be improved and the bibliography should be updated.","rephrased":"Finally, I suggest enhancing the clarity of the paper's writing and updating the bibliography to include recent developments in sentence embedding methods."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[444,491,"Maybe"],[914,1033,"Maybe"],[1034,1140,"Not concerning"],[1942,2091,"Missed by Model"],[2337,2348,"Missed Maybe"]],"Comments":[]}
{"id":"Hke-a03-6m","text":"The paper presents an approach to infer optimal strategies by learning the payoff function of 2 player games with a neural network Q(s, a), where a are the agent actions and s the context (e.g., action of the other player). The strategy is inferred by considering the inputs as free variables at test time and maximizing the learnt Q over its input variables by backpropagation.\n\nThe structure of the neural network in itself is not particularly original. The originality of the paper is to show that experimentally, in some 2-player games (and small sequential games, using an RNN), the policy that is inferred is close to a Nash equilibrium. While this is an interesting result in itself, the games used in the experiment are pretty easy to solve with existing algorithms, so the experimental evidence that this approach can work in practice in difficult cases is weak.\n\nThe motivation and intuition fail to be convincing. There is an excessive usage of analogies with intelligence and life in general that are not particularly enlighting (e.g., \"Even though its hardware is damaged, the software in\nthe cloud (or the eternal soul, arguably) of the mosquito [...]\", the value of the analogy between the cloud and the soul is unclear), and in the end there is no clear explanation of why it should work in practice. \n\nI think the paper in its current form is not ready for publication. More formal arguments and\/or stronger experimental evidence are necessary.\n ","sentences":[{"sentence_type":"2","sentence":"The motivation and intuition fail to be convincing.","rephrased":"The motivation and intuition could be further strengthened to enhance the paper's persuasiveness."},{"sentence_type":"2","sentence":"I think the paper in its current form is not ready for publication.","rephrased":"The paper would benefit from additional formal arguments and\/or stronger experimental evidence before it is ready for publication."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[380,455,"Missed Maybe"],[873,924,"Confirmed"],[925,1040,"Missed by Model"],[1319,1461,"Maybe"]],"Comments":[]}
{"id":"ncWhjtl_h_r","text":"The overall thesis here is very interesting, however there are numerous concerns:\n\nOne of the main claims of this paper is that dynamic retinal input combined with recurrent processing is key to how the brain manages to do hyperacuity.  The results of Table 1 seem at first glance to support this.  However none of the baseline models considered the most important control:  what if you just feed in a series of static images without motion to the DRC-FE?  As is, all that we can conclude from this paper is that a recurrent network in the early stages somehow helps, but it is not clear that the motion in the input image has anything to do with this.  In fact, if the motion did help, it would beg even more questions.  The 8x8 images were created by downsampling from the 32x32 images with bicubic interpolation - essentially smoothing or lowpass filtering.  If you simply move and resample a lowpass filtered image, there is no new information that can be exploited by later information processing, assuming that it was lowpass filtered below the nyquist rate for an 8x8 image (which presumably it was, an important detail that is missing) - this is given by basic signal processing.   It seems plausible that recurrent computation in the early layers helps - it is essentially like making a deeper network - but it would appear the effect has nothing to do with the motion in the input.\n\nThe paper seems motivated by neuroscience and psychophysics, but there is very little attempt to tie anything about the neural architecture of the model to substrates in the brain.  For example it is mentioned that neurons exhibit temporal dynamics with phasic responses, but none of this is incorporated in the model.  This seems like run of the mill deep convnet engineering as opposed to neuroscience.  I'm not sure what we learn here from a neuroscience point of view.\n\nThere is no overall theory presented as to how the brain could benefit from motion of the sensor in building a higher acuity representation enabling tasks such as hyperacuity.  There is much verbal reasoning in the introduction, however there is now much engineering and mathematical know-how about how such problems can be solved - e.g., super-resolution.  These works are mentioned at the end in the discussion, but then almost immediately dismissed because they reconstruct the image rather than doing recognition.  This is a shame because the theory behind these models is exactly what the authors need to implement their idea.  Instead, all of the requisite established theory is tossed aside and the authors resort to training a neural network to solve the problem, yielding a non-transparent solution providing little insight into how the brain might actually solve this problem.\n\nThe introduction does not properly attribute prior work.  First, Rucci et al have been writing and talking about the benefits of image motion for more than a decade now, but you wouldn't know this by reading the intro.  Although Rucci is cited, it is about drift motion in general and not with regard to his theory of *why* image motion is helpful, which is well known in the vision science community.  Burak's (2010) important earlier work is cited but misattributed as providing an account for how how drift motion could improve acuity, which is wrong.  Burak's model shows how the cortex could disentangle shape from motion from retinal spike trains so as to recover shape information on the retina, but does not address the question of why the motion may be beneficial to begin with.  Also missing in the intro is any mention of Ratnam et al. (2017) and Anderson et al. (2020).  Those works are brought up in discussion at the end, but given the high degree of relevance of these prior works to the authors' thesis it is baffling why they are not brought up earlier, especially with regard to what the authors hope to do here that goes beyond or improves upon this prior work.\n","sentences":[{"sentence_type":"2","sentence":"This seems like run of the mill deep convnet engineering as opposed to neuroscience.","rephrased":"The approach taken in this paper appears to be more aligned with conventional deep convolutional network engineering rather than innovative neuroscience research."},{"sentence_type":"2","sentence":"I'm not sure what we learn here from a neuroscience point of view.","rephrased":"It would be beneficial if the paper could further clarify the neuroscience insights that can be gained from this research."},{"sentence_type":"3","sentence":"Instead, all of the requisite established theory is tossed aside and the authors resort to training a neural network to solve the problem, yielding a non-transparent solution providing little insight into how the brain might actually solve this problem.","rephrased":"It would be advantageous if the authors could integrate established theories into their methodology, which could provide a more transparent solution and potentially offer greater insight into the brain's problem-solving mechanisms."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,80,"Missed Maybe"],[299,372,"Missed Maybe"],[1393,1711,"Missed by Model"],[1713,1797,"Confirmed"],[1799,1865,"Confirmed"],[1867,2042,"Missed by Model"],[2500,2753,"Confirmed"],[2755,2811,"Missed by Model"],[2813,2973,"Missed by Model"],[2975,3156,"Maybe"],[3158,3542,"Missed Maybe"],[3544,3636,"Missed by Model"],[3638,3935,"Missed by Model"]],"Comments":[]}
{"id":"OHiT4xE5n29","text":"Summary:\nThis paper makes a theoretical contribution of three \"surrogate objectives\" for the information bottleneck principle, followed by empirical results on MNIST, CIFAR-10 and ImageNette (a subset of 10 easily classified classes from ImageNet). The objectives assume we add a single simple of zero-entropy noise to each sample of the output z of the stochastic encoder p(z|x), and then give estimators on an upper bound of the information bottleneck objective.\n\nEvaluation:\nOverall, this is a fine paper - the introduction is especially well-written and I appreciated the inclusion of all the information plane images of training trajectories. However, the contributions are not sufficiently novel for acceptance at ICLR; this paper is mostly a duplicate of prior work in this area.\n\nI am not convinced that their theoretical contribution is novel - it seems to be a variant (or a specific case) of prior work on Conditional Entropy Bottleneck (CEB) given in Fischer 2020 (https:\/\/arxiv.org\/pdf\/2002.05379.pdf). Their initial insight (Proposition 1) that recognizes that the information bottleneck objective I(XZ) - beta * I(YZ) can be rewritten as H(Y|Z) + beta' * I(XZ|Y), is exactly the insight given in CEB. This paper bounds the I(XZ|Y) term by assuming Z has zero-mean Gaussian noise (which can be chosen such that it is also zero-entropy noise). In contrast, the CEB paper gives a variational bound on the rewritten objective, and when optimizing this bound you sample from the encoder and use the samples to parameterize a distribution (where a gaussian is the simplest choice of distribution). It seems like this paper is producing a special case of CEB for gaussian assumptions on that distribution family.\n\nIn addition, the empirical contributions are decidedly not novel. They claim to present \"the first successful evaluation of IB objectives on CIFAR-10 and ImageNette\", but prior work contains these evaluations: Fischer 2020 (linked above) contains CIFAR-10 results and Fischer and Alemi 2020 (https:\/\/arxiv.org\/pdf\/2002.05380.pdf) contains robustness results on CIFAR-10 and ImageNet, on larger ResNets than the experiments in this paper.","sentences":[{"sentence_type":"2","sentence":"However, the contributions are not sufficiently novel for acceptance at ICLR; this paper is mostly a duplicate of prior work in this area.","rephrased":"However, the contributions may not meet the threshold of novelty required for acceptance at ICLR, as they appear to overlap significantly with prior work in this area."},{"sentence_type":"2","sentence":"I am not convinced that their theoretical contribution is novel - it seems to be a variant (or a specific case) of prior work on Conditional Entropy Bottleneck (CEB) given in Fischer 2020.","rephrased":"I would like to see a clearer distinction of how their theoretical contribution differs from the variant or specific case of the Conditional Entropy Bottleneck (CEB) as presented in Fischer 2020."},{"sentence_type":"2","sentence":"In addition, the empirical contributions are decidedly not novel.","rephrased":"Additionally, the empirical contributions seem to have precedents in the field, which may impact their novelty."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[648,786,"Maybe"],[788,1015,"Confirmed"],[1722,1787,"Confirmed"]],"Comments":[]}
{"id":"zIBK9biYSdK","text":"Strengths: The problem faced by the paper is interesting and timely and the proposed approach seems reasonable. The article is well written, the method is clearly described, and the overall quality is good. The authors also provide the source code to facilitate experimental replication.\n\nWeakness: \n1.\tRegarding the adaptive masking part, the authors' work is incremental, and there have been many papers on how to do feature augmentation, such as GraphCL[1], GCA[2]. The authors do not experiment with widely used datasets such as Cora, Citeseer, ArXiv, etc. And they did not compare with better baselines for node classification, such as GRACE[3], GCA[2], MVGRL[4], etc. I think this part of the work is shallow and not enough to constitute a contribution. The authors should focus on the main contribution, i.e., graph-level contrastive learning, and need to improve the node-level augmentation scheme.\n2.\tIn the graph classification task, the compared baseline is not sufficient, such as MVGRL[4], gpt-gnn[5] are missing. I hope the authors could add more baselines of graph contrastive learning and test them on some common datasets.\n3.\tI am concerned whether the similarity-aware positive sample selection will accelerate GNN-based encoder over-smoothing, i.e., similar nodes or graphs will be trained with features that converge excessively and discard their own unique features. In addition, whether selecting positive samples in the same dataset without introducing some perturbation noise would lead to lower generalization performance. The authors experimented with the transfer performance of the model on the graph classification task, though it still did not allay my concerns about the model generalization. I hope there will be more experiments on different downstream tasks and across different domains.\nRemarks: 1. The authors seem to have over-compressed the line spacing and abused vspace. \n2. Table 5 is collapsed.\n\n\n[1] Y. You, T. Chen, Y. Sui, T. Chen, Z. Wang, and Y. Shen, “Graph contrastive learning with augmentations,” Advances in Neural Information Processing Systems, vol. 33, 2020.\n[2] Y. Zhu, Y. Xu, F. Yu, Q. Liu, S. Wu, and L. Wang, “Graph contrastive learning with adaptive augmentation,” arXiv preprint arXiv:2010.14945, 2020.\n[3] Y. Zhu, Y. Xu, F. Yu, Q. Liu, S. Wu, and L. Wang, “Deep graph contrastive representation learning,” arXiv preprint arXiv:2006.04131, 2020.\n[4] Hassani, Kaveh, and Amir Hosein Khasahmadi. \"Contrastive multi-view representation learning on graphs.\" International Conference on Machine Learning. PMLR, 2020.\n[5] Hu, Ziniu, et al. \"Gpt-gnn: Generative pre-training of graph neural networks.\" Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2020.\n","sentences":[{"sentence_type":"2","sentence":"I think this part of the work is shallow and not enough to constitute a contribution.","rephrased":"This aspect of the work could be deepened to better highlight its contribution, especially in the context of existing literature on feature augmentation."},{"sentence_type":"1","sentence":"The authors seem to have over-compressed the line spacing and abused vspace.","rephrased":"The formatting of the document, particularly the line spacing, could be improved for better readability."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[674,759,"Confirmed"],[1834,1910,"Confirmed"]],"Comments":[]}
{"id":"BygktHtDY4","text":"The authors propose an alternative framework for applying the mixup method of [2]. To the best of my knowledge, this framework has not been propose before, hence the manuscript does offer some original ideas. That being said, the proposed framework is very related to established techniques, in particular to the practice of taking the average of the output of the classifier over a set of augmented version of a testing sample. The main practical contribution of the manuscript is the application of this technique: (a) for mixup and (b) at training time, too. On the downside, the reported results offer inconclusive evidence that this monte carlo sampling in training time can be a beneficial approach for classification. Generally, my main criticism is that I think that the experimental setup should have covered additional configuration combinations, so that the proposed framework is evaluated against suitable alternatives (details follow in the \"Cons\" section). In terms of clarity, I feel that the main ideas could have been presented briefly in a simpler language, before delving into the mathematical analysis. \n\nProns:\n1. In addition to their experiments in CIFAR10 and CIFAR100, the authors briefly discuss the results on a simple synthetic dataset, which IMO illustrates nicely some potential dangers with mixup and it provides a rather clear motivation for this line of work.\n\n2. Derivation of some theoretical results, which are interesting in their own right.\n\nCons:\nIMO, there are quite a few methodological shortcomings:\n\n1. The authors offer no justification of their choice of S=500 at testing time. I would expect a posteriori plot of how the testing accuracy changes for different values of S_testing given at least one training setting. As a related note when it comes to clarity, I assume that this sampling involves 500 cases from the training set, even at testing time. This is not made clear in the manuscript.\n\n2. The main technique used by the paper (averaging the output of the classifier over a set of samples at both training and testing time) is rather orthogonal to mixup, to my understanding at least. In fact, the practice of generating augmented version of a given testing sample and taking the average of the output of the classifier over all the augmented versions is a well-known practice that has been shown to improve the testing performance in many practical scenarios (as an example, [1]). Therefore, I think that this method should have been applied to and compared with other augmentation methods, in addition to mixup. For example, what happens if the hypothesis classes is enriched with augmented versions of the same sample using more standard transformations (rotations, translations, etc) ?\n\n3. It is my understanding that S=1 corresponds more or less to standard mixup, at training time at least. Thus, the difference of the configuration \"Mixup (alpha=1)\" and \"DIP(alpha=1, S=1, label-mixing)\" is only at testing time, with the sampling over the 500 mixup pairs that takes place in the second case. Since the experiments show that S=1 is the most performant configuration in most experiments, the value of the proposed monte carlo sampling at training time is not fully supported by the reported results, IMO. This should be discussed in the \"Conclusion\" section of the manuscript.\n\n4. Dropout should have been used in the no-mixup baseline, as in the mixup paper [2].\n\n5. I have the feeling that this work is only partially relevant to the scope of the workshop. \n\nNitpicking: I would like to mention a specific orthographic error that should be corrected: \"monte carlo\" is spelled \"monte calro\" for most of the manuscript.\n\n[1] Jamaludin, Amir, Timor Kadir, and Andrew Zisserman. \"SpineNet: Automated classification and evidence visualization in spinal MRIs.\" Medical image analysis 41 (2017): 63-73.\n\n[2] Zhang, Hongyi, et al. \"mixup: Beyond empirical risk minimization.\" arXiv preprint arXiv:1710.09412 (2017).","sentences":[{"sentence_type":"2","sentence":"I have the feeling that this work is only partially relevant to the scope of the workshop.","rephrased":"While the work presents interesting ideas, it may benefit from further alignment with the core themes of the workshop to enhance its relevance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1545,1761,"Missed by Model"],[3428,3518,"Not concerning"]],"Comments":[]}
{"id":"H1eSu7BLFN","text":"This paper shows how to use flow models for unpaired image to image translation, by leveraging the invertbility of flows, by sharing a common latent space between two models which map from this latent space into the two domains of interest.\n\nPros:\n  * some nice guarantees due to the invertbility properties of flows\n  * good empirical results - showing some of the baselines in the cycleGAN paper.\n  * building on top of prior work which uses adversarial training to train flows.\n\nCons:\n   * RNVPs require more computation to achieve high quality samples, due to the local structure of the model and the reliance on checkerboard and channel alternating patterns. There is no discussion on the model size in AlignFlow and that required by CycleGAN. \n  * lacking some of the most impressive results from cyclegan.\n\nQuestion for the authors:\n  * in my experience, RNVPs are quite fiddly to train. I expect that when adversarial training is added to the mix, things get even more fiddly. What did you do to stabilize your model?\n  * how sensitive is the model to the choice of 'lambda_a and \\lambda_b? I could not find any discussion on that - nor the values for \\lambda_a and \\lambda_b in the paper.","sentences":[{"sentence_type":"2","sentence":"lacking some of the most impressive results from cyclegan.","rephrased":"It would be beneficial to include some of the more impressive results from CycleGAN for a comprehensive comparison."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[664,748,"Missed by Model"],[754,812,"Maybe"]],"Comments":[]}
{"id":"S1eIP8MpYB","text":"-- This paper seeks to combine several ideas together to propose an approach for image classification based continual learning tasks. In this effort, the paper combines previously published approaches from generative modeling with VAEs, mutual information regularization and domain adaptation. \n\nI am a making a recommendation for reject for this paper with the main reason being that I believe the primary derivations for their method appear flawed. \n\n--In the main section describing the approach (Section 4), the authors start with a claim that Equation 1 and 2 are equal; I don’t believe 1 and 2 are equal.\n\n--In Section 4.1, it appears that they are instead making a claim about Equation 2 being a bound for equation 1; but even this derivation appears to have a problem. The following is the concern:\n\n--In the second line of Equation 5, the KL term appears to be measuring a distance between distributions on two different variables; z|c and c|z. If one were to interpret the second one as the unnormalized distribution on z defined via the likelihood for c given z; even this has an issue because then the expression for KL where we plug the unnormalized density in place of the normalized need not be positive which is something they need to derive their bound.\n\n--Another issue is that the regularization lambda should apply to both the terms in the bound but in Equation (7) only appears selectively for one of the two terms. \n\nIt is also not clear how the loss function proposed differs from that of the CDVAE, etc.  If the novelty is in applying to continual learning and new datasets, it is not clear that this is sufficient.\n\nAdditional feedback for authors (not part of the main decision reasoning):\n\n- What is dt in Algorithm 1 description?\n\nFigure 1:\n-typo “implmented”\n-What’s the 3d plot supposed to represent?\nDoesn't the classification loss have a dependency on the input condition?\n\n--What does a \"heavy classifier\" imply concretely? \n\n--“Redundant weights” seems like not a very strong constraint especially for a small cardinality label space (like 10, in the case of this paper).\n\n--The notation for the proposed parameters theta, theta’, phi, phi’ are not consistent with the notation in the intro section, where phi was used for the encoder and theta for the decoder. In later sections they use theta and theta’ for encoder\/decoder resp.\n\n-- “When the encoder and decoder networks are sufficiently complex, it is enough to implement each the prior and classification network as one fully-connected layer” → what do the authors mean “when … networks are sufficiently complex” or do they actually mean when the “when the problem is simple enough”?\n","sentences":[{"sentence_type":"2","sentence":"I am a making a recommendation for reject for this paper with the main reason being that I believe the primary derivations for their method appear flawed.","rephrased":"My recommendation is to reject this paper, primarily because there seem to be issues with the derivations of the method that need to be addressed."},{"sentence_type":"1","sentence":"--\nWhat does a \"heavy classifier\" imply concretely?","rephrased":"Could you please clarify what is meant by a \"heavy classifier\" in concrete terms?"},{"sentence_type":"2","sentence":"--\nRedundant weights seems like not a very strong constraint especially for a small cardinality label space (like 10, in the case of this paper).","rephrased":"The concept of 'redundant weights' may not provide a significant constraint, particularly for a label space with small cardinality, such as the one with 10 labels in this paper. Could the authors elaborate on the effectiveness of this constraint in such contexts?"},{"sentence_type":"1","sentence":"--\nWhen the encoder and decoder networks are sufficiently complex, it is enough to implement each the prior and classification network as one fully-connected layer","rephrased":"The statement that 'when the encoder and decoder networks are sufficiently complex, a single fully-connected layer is adequate for the prior and classification network' could benefit from further explanation. Could the authors specify what is meant by 'sufficiently complex'?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[296,450,"Confirmed"],[1439,1639,"Missed by Model"],[1906,1956,"Not concerning"],[1959,2105,"Maybe"],[2107,2365,"Missed Maybe"],[2367,2532,"Not concerning"],[2535,2673,"Missed by Model"]],"Comments":[]}
{"id":"Bkp-xJ5xf","text":"This paper presents a so-called cross-view training for semi-supervised deep models. Experiments were conducted on various data sets and experimental results were reported.\n\nPros:\n* Studying semi-supervised learning techniques for deep models is of practical significance.\n\nCons:\n* The novelty of this paper is marginal. The use of unlabeled data is in fact a self-training process. Leveraging the sub-regions of the image to improve performance is not new and has been widely-studied in image classification and retrieval. \n* The proposed approach suffers from a technical weakness or flaw. For the self-labeled data, the prediction of each view is enforced to be same as the assigned self-labeling. However, since each view related to a sub-region of the image (especially when the model is not so deep), it is less likely for this region to contain the representation of the concepts (e.g., some local region of an image with a horse may exhibit only grass); enforcing the prediction of this view to be the same self-labeled concepts (e.g,“horse”) may drive the prediction away from what it should be ( e..g, it will make the network to predict grass as horse). Such a flaw may affect the final performance of the proposed approach.\n* The word “view” in this paper is misleading. The “view” in this paper is corresponding to actually sub-regions in the images\n* The experimental results indicate that the proposed approach fails to perform better than the compared baselines in table 2, which reduces the practical significance of the proposed approach. \n","sentences":[{"sentence_type":"2","sentence":"The novelty of this paper is marginal.","rephrased":"While the paper builds upon existing concepts, further clarification on the novel contributions of the approach would be beneficial."},{"sentence_type":"2","sentence":"The proposed approach suffers from a technical weakness or flaw.","rephrased":"The proposed approach could be strengthened by addressing potential technical limitations, such as the challenge of self-labeling with sub-regions that may not fully represent the concept."},{"sentence_type":"2","sentence":"The experimental results indicate that the proposed approach fails to perform better than the compared baselines in table 2, which reduces the practical significance of the proposed approach.","rephrased":"The experimental results suggest that there is room for improvement in the proposed approach to outperform the compared baselines, as shown in table 2, which would enhance its practical significance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[282,320,"Confirmed"],[527,591,"Not concerning"],[1237,1362,"Missed Maybe"],[1365,1556,"Maybe"]],"Comments":[]}
{"id":"LPLsZcheSlg","text":"1). The novelty and contribution are very limited. In literature, many papers have discussed the connection between different GNNs, typically, including aggregators and Updaters, such as discussed in “Deep Learning on Graphs: A Survey”. The submission only provides a kind of connection between GCN, GAT, PPPN and APPNP in the perspective of denoising. Compared with that, the survey paper actually connects many different GNNs. \n\n\n2). The writing quality is low. There are many errors, for example, in section 3, “the unnormalized version of Laplacian matrix with L−D−A”==> “the unnormalized version of Laplacian matrix with L=D−A”?\n\n\n3). In Eq. (1) to ease the discussion, the non-linear activation is not included. However, the nonlinearity is the key part for deep GNNs. In Formula (8), the GNNS AS GRAPH SIGNAL DENOISING actually oversimplified the topological smoothing over attributes, since the nonlinear transformation, especially with dropout will already conduct the signal denoting. So why use such additional effects to do that?\n\n4). The submission provides both Node classification task and ADVERSARIAL defense task to validate the performance. As for Node classification, the results however are not very promising compared with current SOTA. For example, in ICLR’20 paper “ADAPTIVE STRUCTURAL FINGERPRINTS FOR GRAPH ATTENTION NETWORKS”, the cora dataset reports “85.4±0.3%” compared with that reported by this submission only “84.59±0.8”; in cite seer “74.0±0.4%” compared with this submission’s report “72.05±0.5”. In Pubmed, this paper reports “79.70±0.4”, however, in the ICLR paper, they report “81.2±0.3%”. From that perspective, I did not see any advantage in the submission.\n\n5). As another task for validation, that is robustness to ADVERSARIAL attack. It is suggest to compare the recent SOTA “Graph Information Bottleneck” by Jure stanford in NeurIPS’20.\n","sentences":[{"sentence_type":"2","sentence":"The novelty and contribution are very limited.","rephrased":"The novelty and contribution could be more clearly articulated or expanded upon to highlight their significance."},{"sentence_type":"2","sentence":"The writing quality is low.","rephrased":"The manuscript could benefit from further proofreading to correct errors and improve clarity."},{"sentence_type":"2","sentence":"The results however are not very promising compared with current SOTA.","rephrased":"The results could be strengthened by addressing how they compare to the current state-of-the-art benchmarks."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[4,50,"Confirmed"],[436,486,"Confirmed"]],"Comments":[]}
{"id":"SJqfr3qlf","text":"This paper presents the IVE-GAN, a model that introduces en encoder to the Generative Adversarial Network (GAN) framework. The model is evaluated qualitatively through samples and reconstructions on a synthetic dataset, MNIST and CelebA.\n\nSummary: \nThe evaluation is superficial, no quantitative evaluation is presented and key aspects of the model are not explored. Overall, there just is not enough innovation or substance to warrant publication at this point.\n\nImpact:\nThe motivation given throughout the introduction -- to add an encoder (inference) network to GANs -- is a bit odd in the light of the existing literature. In addition to the BiGAN\/ALI models that were cited, there are a number of (not cited) papers with various ways of combining GANs with VAE encoders to accomplish exactly this. If your goal was to improve reconstructions in ALI, one could simply add an reconstruction (or cycle) penalty to the ALI objective as advocated in the (not cited) ALICE paper (Li et al., 2017 -- \"ALICE: Towards Understanding Adversarial Learning for Joint Distribution Matching\"). \n\nThe training architecture presented here is novel as far as I know, though I am unconvinced that it represents an optimum in model design space. The model presented in the ALICE paper would seem to be a more elegant solution to the motivation given in this paper.\n\nModel Feature:\nThe authors should discuss in detail the interaction between the regular GAN pipeline and the introduced variant (with the transformations). Why is the standard GAN objective thrown in? I assume it is to allow you to sample directly from the noise in z (as opposed to z' which is used for reconstruction), but this is not discussed in much detail. The GAN objective and the added IVE objective seem like they will interact in not all together beneficial ways, with the IVE component pushing to make the distribution in z complicated. This would result in a decrease in sample quality. Does it? Exploration of this aspect of the model should be included in the empirical evaluation.\n\nAlso the addition of the transformations added to the proposed IVE pipeline seem to cause the latent variations z' to encode these variations rather than the natural variations that exist in the dataset. They would seem to make it difficult to encode someone face and make some natural manipulates (such as adjusting the smile) that are not included in this transformations.\n\nEmpirical Evaluation:\nComparison to BiGAN\/ALI: The authors motivate their work by drawing comparisons to BiGAN\/ALI, showing CelebA reconstructions from the ALI paper in the appendix. The comparison is not fair for two reasons, (1) authors should state that their reconstructions are made at a higher resolution (seems like 128x128, which is now standard but was not so when the BiGAN\/ALI papers came out, they were sampled at 64x64), also, unlike the ALI results, they authors cut the background away from the CelebA faces. This alone could account for the difference between the two models, as ICE-GAN only has to encode the variability extant in faces and hair, ALI had to additionally encode the much greater variability in the background. The failure to control the experimental conditions makes this comparison inappropriate. \n\nThere is no quantitative evaluations at all. While many GAN papers do not place an emphasis on quantitative evaluations, at this point, I consider the complete lack of such an evaluation as a weakness of the paper. \n\nFinally, based on just the samples offered in the paper, which is admittedly a fairly weak standard, the model does not seem to be among the state-of-the-art on CelebA that have been reported in the literature. Given the rapid progress that is being made, I do not feel this should be could against this particular paper, but the quality of samples cannot be considered a compelling reason to accept the paper.\n\nMinor comment:\nThe authors appear to be abusing the ICLR style file by not leaving a blank line  between paragraphs. This is annoying and not at all necessary since ICLR does not have a strict page limit. \n\nFigure 1 is not consistent with the model equations (in Eqns. 3). In particular, Figure 1 is missing the standard GAN component of the model.\n\nI assume that the last term in Eqns 3 should have G(z) as opposed to G(z',E(x)). Is that right?","sentences":[{"sentence_type":"2","sentence":"Overall, there just is not enough innovation or substance to warrant publication at this point.","rephrased":"While the paper presents interesting concepts, further development and additional innovative elements could strengthen the case for publication."},{"sentence_type":"1","sentence":"The motivation given throughout the introduction -- to add an encoder (inference) network to GANs -- is a bit odd in the light of the existing literature.","rephrased":"The motivation to add an encoder (inference) network to GANs could be more clearly connected to the existing literature to highlight its distinctiveness."},{"sentence_type":"1","sentence":"though I am unconvinced that it represents an optimum in model design space.","rephrased":"It would be beneficial if the paper could provide more evidence or arguments to support the model's position within the design space."},{"sentence_type":"1","sentence":"The GAN objective and the added IVE objective seem like they will interact in not all together beneficial ways, with the IVE component pushing to make the distribution in z complicated.","rephrased":"It would be helpful if the paper could explore how the GAN objective and the added IVE objective interact, particularly regarding the complexity of the distribution in z."},{"sentence_type":"1","sentence":"They would seem to make it difficult to encode someone face and make some natural manipulates (such as adjusting the smile) that are not included in this transformations.","rephrased":"It would be interesting to see if the model can encode natural variations in the data, such as facial expressions, despite the transformations applied in the IVE pipeline."},{"sentence_type":"2","sentence":"The failure to control the experimental conditions makes this comparison inappropriate.","rephrased":"Ensuring that experimental conditions are consistent would make the comparison with BiGAN\/ALI more valid and informative."},{"sentence_type":"1","sentence":"I consider the complete lack of such an evaluation as a weakness of the paper.","rephrased":"Incorporating quantitative evaluations could address a current limitation of the paper and enhance its overall robustness."},{"sentence_type":"2","sentence":"Given the rapid progress that is being made, I do not feel this should be could against this particular paper, but the quality of samples cannot be considered a compelling reason to accept the paper.","rephrased":"While the field is advancing quickly, and this should be taken into account, improving the quality of samples could make a stronger case for the paper's acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[249,366,"Missed by Model"],[367,462,"Confirmed"],[472,626,"Confirmed"],[1154,1230,"Maybe"],[1552,1713,"Missed Maybe"],[1714,1899,"Not concerning"],[2253,2423,"Not concerning"],[2608,2650,"Missed by Model"],[3168,3255,"Maybe"],[3258,3302,"Missed by Model"],[3394,3472,"Confirmed"],[3686,3885,"Not concerning"],[3902,4091,"Missed by Model"]],"Comments":[]}
{"id":"hPTgQy8n-XV","text":"Overall, this paper is a contribution in the right direction and has potential to cut down the hyperparameter optimization time greatly. The paper provides an elegant way to determine the optimum hyperparameters via a differentiable scheme.\n\nHaving said that, I have several concerns about the experiments.\n1.\tAnother method which is closely related is Darts (Liu et al (2019)). Why it is not selected as a baseline in the comparisons?\n2.\tTwo datasets MNIST and SVHN are used for the experiments. Both of them are similar and contain images of digits. It would be useful if the authors could show the performance of their method on other diverse datasets like CIFAR-10 or CIFAR-100.\n3.\tSection 4.2.3: the authors report the accuracy of optimized networks, but it is not clear if that is on the validation set or on the test set.\n4.\tTable 1: I don’t see much the benefit of the proposed method DHPO. Take the version DHPO+ as example. Compared to BLANK (i.e. train the network without hyper-parameter tunning), DHPO+ is just slightly better than BLANK, there is no significant difference. For example, 98.71% vs. 98.27% for MNIST and 85.05% vs 84.95% for SVHN.\n5.\tI am not sure why the authors use the version DHPO* (running 10 times) of their method when all the other methods are run only 3 times? Is this a fair comparison? If all of the methods including DHPO+ run the same 3 times, DHPO+ is not better than the baselines on datasets SVHN, Wine, and Car.\n6.\tFinally, it would be nice if the authors could apply their methods to neural architecture search using standard benchmarks e.g. NAS-101 etc. This will truly show the effectiveness of their method.\n\nMinor Comments:\nThe paper seems to be written in a rush. The text and presentation could be significantly improved. \n- the citation of Goldberg in the introduction section is not correctly done (missing publication year).\n- space missing after BO and the following parenthesis, HB and the parenthesis, DHPO and the parenthesis.\n-random search is cited incorrectly as (ran, 2012)!\n- One page 2: incomplete sentence “While Darts can select the hyperparameters …”\n","sentences":[{"sentence_type":"2","sentence":"The paper seems to be written in a rush.","rephrased":"The paper could benefit from additional proofreading to enhance its clarity and presentation."},{"sentence_type":"2","sentence":"I don't see much the benefit of the proposed method DHPO.","rephrased":"It would be helpful if the authors could further clarify the advantages of the proposed method DHPO over existing methods."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[379,435,"Missed by Model"],[1675,1774,"Confirmed"]],"Comments":[]}
{"id":"Mh_EZwPGn_","text":"The paper presented a way to incorporate subject-specific demographic and medical information along with the brain image scan to improve the deep neural network for predicting longitudinal brain deformation. The results demonstrated a level of effectiveness of the proposed approach, although I have some specific concerns and comments that listed in the detailed review shown below.\n\n*Major comments*\n\n• The author didn't include the time difference between the training and predicted image in the \"vector of subject-specific medical attributes\". This raise my first question:\n\t• It is not clear that, for multi-timepoint longitudinal data, whether and how how did the authors accounted for registration between different length of timepoints. \n\n• Structural segmentation are used for generating evaluation metric (dice score and surface-distance). It's not clear how the segmentation is generated.\n\t• If it's generated using image registration, then that means the registration-derived deformation field are considered as ground truth. Then why not using this deformation field directly for validation?\n\t• Furthermore, if the the deformation field is the output to be optimized, should the in deformation field itself be used to calculate the lost function, and image similarity (the current term of the loss function) been used  as validation metric? This way, no additional registration-based segmentation is compulsory during the evaluation\n\t• This lead to my third point for critical question regarding the ultimate purpose of the study. In the introduction, the author claimed that \"providing an accurate prediction of the entire brain can give a richer phenotype for use in analysis or clinical practice.\" It would be better to state\/discuss more about what would be the ultimate end goal of this generative model.\n\t\t○ If segmentation is mainly used for generating clinical-relevant features such as volume or shape, would it make more sense to predict the longitudinal structural change (e.g. volume, shape, thickness, etc)? What's the comparative advantage of predicting the brain deformation, given that there are significant more parameters to train and fine-tune, which will make the generative model less robust. (E.g. Would the benefit be something like the ability to perform voxel-based morphological analysis?) \n\t\t○ Similarly, and furthermore,  if better clinical score\/diagnosis is the ultimate purpose, would this method provide better\/comparable\/worse results in predicting future clinical diagnosis, as compared to alternative generative models that predict clinical scores\/diagnosis directly, given that the latter need even less parameters to trained with?\n\t\n\t\n*Minor comments*\n• Some of the equations might need to be clarified a little bit more\n\t• In the paragraph before equation (2), $\\theta_v = Id + u_v$ : what is $I$ and $d$?\n\t• In equation (4), it is not clear what does cst mean?\n• \n• I would suggest to add a little bit more details about how the  \"subject attributes\" are concatenated to the baseline scan images, either in the text or in the Figure 1 legend. Are those attributes remapped to the size of the image and concatenated as additional channels (although the schematic diagram makes it seems like the images has been vectorized before concatenating into 1-dimensional tensor)? If so what happened if some subject doesn't have specific attributes recorded (such as the education level or clinical score)?\n\t\n• Validation:\n\t• Figure 2 and legend is a bit confusing. \n\t\t○ What does scan 0 mean?\n\t\t○ Shall *Ext* be referred to as the full set of \"subject-specific medical attributes\" rather than \"external data\" as stated in the legend?\n\t\t○ Why the upper bound (ground truth) name \"oracle\"\nThe baseline of \"integration of the average registration velocity ﬁeld (mean) in the training set\" seems a strange baseline metrix to me","sentences":[{"sentence_type":"1","sentence":"The author didn't include the time difference between the training and predicted image in the \"vector of subject-specific medical attributes\". This raise my first question:","rephrased":"It would be helpful if the authors could clarify whether the time difference between the training and predicted images was considered in the \"vector of subject-specific medical attributes\", as this could influence the results."},{"sentence_type":"2","sentence":"The baseline of \"integration of the average registration velocity \nfield (mean) in the training set\" seems a strange baseline metrix to me","rephrased":"I would recommend providing a rationale for choosing the \"integration of the average registration velocity field (mean) in the training set\" as a baseline metric, as it is not immediately clear why this was selected."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[405,577,"Not concerning"],[581,744,"Missed Maybe"],[850,899,"Missed Maybe"],[1038,1104,"Missed Maybe"],[3513,3535,"Missed Maybe"],[3730,3866,"Confirmed"]],"Comments":[]}
{"id":"H1eVuXZKnN","text":"The idea of a wrapper around any planning system is a promising novel idea.\n\nThis sentence is slightly confusing: \" In other words, the contrastive explanation should contain a valid plan that the original planner could have created using the original model.\" What does \"valid\" mean here? Does it just mean that the plan reaches the goal? Or is the main point that a contrastive explanation should be a realistic attempt by the planner, rather than say, easily outputting a plan that is clearly suboptimal? \n\nIt seems in some cases, there is no real reason one action is used before\/after another, if both are optimal plans - even though this is the trivial case, perhaps it should be mentioned in the paper.\n\nSection 3.2 is quite interesting, and clearly demonstrates some of the difficulty of answering contrastive questions informatively.\n\nOverall this is a strong paper that highlights the difficulties of providing high-quality explanations to contrastive questions. This paper is highly relevant to the workshop.\n\nminor comments:\n\t* \"diffcost\" in the tuple format in the second paragraph of 3.4 seems to be formatted as $diffcost$, I suggest using italics may be better\n\n\n","sentences":[{"sentence_type":"1","sentence":"It seems in some cases, there is no real reason one action is used before\/after another, if both are optimal plans - even though this is the trivial case, perhaps it should be mentioned in the paper.","rephrased":"While the paper addresses optimal plans, it could be beneficial to discuss scenarios where multiple actions can be considered optimal and the rationale for choosing one over the other, even in cases that may seem trivial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[509,708,"Not concerning"]],"Comments":[]}
{"id":"Hkg5Zu9Q5S","text":"This paper investigates the use of variational auto-encoders (VAEs) and disentanglement to create high quality data representations that hide sensitive attributes. The authors consider two settings: (1) a supervised setting where both the sensitive labels and the downstream machine learning task labels are available to the data holder, and (2) a weakly supervised setting where only sensitive attributes are available. For both settings, the authors propose creating data representations that have 2 components: component 1 captures any information in the data bout the sensitive attributes, and component 2 captures everything else (especially the information useful for a downstream machine learning task). The goal is to ensure that these two components are disentangled.  This is done by training classifiers on each component: 2 classifiers that try to reconstruct the sensitive attributes from each component separately (and in the supervised setting, 2 other classifiers that guess the downstream ML task from each component separately). The overall loss captures all components and ensures that one cannot reconstruct the sensitive attributes from component 2. \n\nOverall, the paper addresses an interesting and timely problem that is of great relevance to this community. However, despite being generally clear, the paper has many grammatical errors and typos. In its current shape, the paper cannot be published. \n\nMore importantly, the paper has a number of issues that need to be improved:\n\n1. The introduction makes a number of claims that are incorrect. For instance, the introduction claims that under differential privacy (and refers to Abadi et al.), machine learning models are learned from anonymized data and that complex training procedures run the risk of exhausting the budget before convergence. This is not true because under the classical setting of differential privacy, the models are trained on clean data BUT the process of learning is anonymized (see DP-SGD from Abadi et al.). More importantly, recent research and results in this space indicate that one can train high quality machine learning models with strong differential privacy guarantees (check McMahan et al. ICLR18: Learning Differentially Private Recurrent Language Models). Further, the authors claim that Federated Learning does not allow for the use of the trained model in a central setting. This is also not true because federated learning is an approach to train models on massively decentralized data -- in a way that is orchestrated by a service provider. The learned model can be used in a centralized or decentralized service. Moreover, the communication cost of training models under federated learning may be lower than communicating the data (several hundreds if not thousands of high resolution images) to a central service provider, so the claims about communication are not always correct. Finally, the authors claim that federated learning and differential privacy are useful when the private attributes are known a priori and these approaches fail to provide privacy protections when the private information contained in the dataset isn't identified. This is wrong. Both approaches do not require the knowledge of private information. They, however, require the knowledge of the downstream machine learning task -- something that may not always defined a priori.\n\n2. The privacy guarantees provided by the authors' approach are rather weak and unclear. (1) They assume that a trusted data holder already access to the dataset and wants to release private representations. In the supervised setting, why not just revealing the learned model? In the weakly supervised setting, where will the downstream machine labels come from? Are these representations released only for unsupervised learning tasks? This should be clarified -- and the experiments at the end should reflect this. (2) The privacy guarantees are with respect to (a) a computationally and statistically bounded adversary (i.e. there may very well be stronger adversaries with access to side information that can perfectly reconstruct the sensitive attributes),  and (b) pre-defined sensitive attributes (i.e. there may be other sensitive attributes that one can learn from the published representations that are not captured by this framework). \n\n3. The paper makes no attempt to properly survey the literature on learning representations under censorship and fairness constraints. For example, they do not reference and compare against: (a) Censoring Representations with an Adversary (https:\/\/arxiv.org\/abs\/1511.05897), (b) Learning Adversarially Fair and Transferable Representations (https:\/\/arxiv.org\/abs\/1802.06309), (c) Context-Aware Generative Adversarial Privacy (https:\/\/arxiv.org\/abs\/1710.09549), (d) Learning Generative Adversarial RePresentations (GAP) under Fairness and Censoring Constraints (https:\/\/arxiv.org\/abs\/1910.00411), and many others. Without a clear (empirical) comparison to these works, the benefits of the proposed approach are unclear.\n\n4. The proposed method for disentanglement does not scale to non-binary sensitive attributes (because of the blowup in the number of classifier pairs that would need to be trained to ensure disentanglement). Thus, this approach may be limited to cases with a few sensitive attributes. \n\n5. The authors are encouraged to show the learned representations (so that one could verify with the naked eye that the representations are indeed disentangling the sensitive attributes).\n","sentences":[{"sentence_type":"2","sentence":"In its current shape, the paper cannot be published.","rephrased":"To reach a publishable standard, the paper would benefit from thorough proofreading to correct grammatical errors and typos."},{"sentence_type":"2","sentence":"The privacy guarantees provided by the authors' approach are rather weak and unclear.","rephrased":"The privacy guarantees of the authors' approach could be strengthened and clarified to enhance the paper's contribution."},{"sentence_type":"2","sentence":"The paper makes no attempt to properly survey the literature on learning representations under censorship and fairness constraints.","rephrased":"The paper would benefit from a more comprehensive survey of the literature on learning representations under censorship and fairness constraints."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1371,1423,"Confirmed"],[1426,1501,"Missed Maybe"],[1507,1568,"Missed by Model"],[3163,3177,"Missed by Model"],[3379,3464,"Confirmed"],[4326,4457,"Confirmed"]],"Comments":[]}
{"id":"HJl9PL1zM","text":"This paper proposes a variation to the familiar AdaGrad\/Adam\/etc family of optimization algorithms based a gradient magnitude normalization. More precisely, the components of the gradient are split into blocks (one block per layer), and each block is normalized by its L2 norm. The concatenation of these normalized gradients are used in place of the standard gradient in AdaGrad\/Adam\/SGD. The authors find the resulting optimizer performs slightly better than its competitors on four tasks.\n\nI feel this paper would be much stronger focusing extensively on one or two small problems and models, providing insight into how normalization affects optimization, rather than chasing state-of-the-art numbers on a variety of datasets and models. I believe the significance and originality of this work to be lacking.\n\n## Pros ##\n\nThe paper is easy to follow. The algorithm and experiment setups are clearly explained, and the plots are easy to understand. I appreciate the variety in experimental setups. The authors provide a proof of convergence for the AdaGrad variant on convex functions.\n\n## Cons ##\n\nThe paper fails to provide new insights to the reader. It succeeds in asking a question (how do normalized gradients impact training of neural networks?), but fails to add theoretical or empirical knowledge that furthers the field. While effectively changing the geometry of the problem, no motivation (theoretical or intuitive) is given as to why this normalization scheme should be effective.\n\nFrom the empirical side, the authors compare the proposed optimizers on many datasets and models, but concerningly only using the baselines' default hyperparameters. Even ADAM, a supposedly \"hands-free\" optimizer, has been shown to vary greatly in performance when its hyperparameters are well chosen (https:\/\/arxiv.org\/abs\/1705.08292). This is simply unfair to the baselines, and conclusions cannot meaningfully be drawn from this alone. In addition, different tasks use different optimizers, which strikes me as odd, and no error bars are added to any plots.\n\nFrom the theoretical side, the authors show a convergence bound that is minimized when the number of blocks is one. This, however, is not what the authors use in experiments, and no reasoning about the choice of blocks == network layers is given.\n\n## Specific comments ##\n\np1: \"Gradient computation is expensive\" is not a good justification. All empirical risk minimization, convex or not, requires a full pass over the dataset. Many convex problems outside of ERM involve very expensive gradient computations.\n\np1: \"These two challenges indicate that for each iteration, stochastic gradient might be the best practical first order information we can get\". See loads of work in approximate second-order methods that show otherwise! Hessian-free Optimization, K-FAC, Learning to Learn Gradient Descent, ACKTR's use of Kronecker-factored Trust Region.\n\np2: You may want to reference Layer-Specific Adaptive Learning Rates for Deep Networks (https:\/\/arxiv.org\/pdf\/1510.04609.pdf), as it appears relevant to the layer-wise nature of your paper.\n\np2: \"Recently, provably correct algorithms...\" I'm fairly confident that Adam and RMSProp lack provable correctness. You may want to soften this statement.\n\np3: The expression being minimized is the sample risk, rather than the expected risk.\n\np5: The relationship between NG and NG_{UNIT} is confusing. I suggest keeping only the vanilla method analyzed in this paper, or that the second method be better motivated.","sentences":[{"sentence_type":"2","sentence":"I believe the significance and originality of this work to be lacking.","rephrased":"I think the paper could further emphasize its significance and originality by..."},{"sentence_type":"2","sentence":"The paper fails to provide new insights to the reader.","rephrased":"The paper could be improved by providing more novel insights that contribute to the field."},{"sentence_type":"2","sentence":"This is simply unfair to the baselines, and conclusions cannot meaningfully be drawn from this alone.","rephrased":"It would be beneficial to adjust the baseline hyperparameters to ensure a fair comparison, which would allow for more meaningful conclusions."},{"sentence_type":"2","sentence":"p1: \"Gradient computation is expensive\" is not a good justification.","rephrased":"p1: The statement that 'gradient computation is expensive' could be supported with more context or comparison to other computational challenges in the field."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[741,811,"Confirmed"],[1101,1155,"Confirmed"],[1156,1332,"Missed by Model"],[1333,1495,"Missed by Model"],[1497,1662,"Missed by Model"],[1834,1935,"Confirmed"],[1936,2057,"Missed by Model"],[2175,2305,"Missed by Model"],[2332,2400,"Confirmed"]],"Comments":[]}
{"id":"BJejdUk3qr","text":"This paper describes a self-supervised sentence embedding approach that incorporates a different view from plain text where some extent of linguistic knowledge is incorporated through the application of tree LSTM. The training procedure is standard contrastive framework where the model is encouraged to distinguish between context sentence (sentences appearing close to the target sentence) and negative samples. Evaluations are conducted on 1) downstream tasks, but with a simple logistic regression model on top of sentence embeddings; 2) probing tasks that more focus on surface information prediction, syntactic and semantic tasks; and 3) qualitative analysis with nearest 5 sentences.\n\nAlthough the experiments are thorough, I am in favor of rejecting this paper with the following reasons:\n\nFirst, the proposed model is trained with 4.6M sentences among 78M available for 33 hours. It is unclear why authors stop the training at this early stage but the results on all three evaluations seem to be inferior to the state-of-the-art by a big margin. I am happy to raise my score if authors can show the results of a well trained proposed model.\n\nSecond, the paper has some room for improvement in terms of clarity, to name a few:\n1) Authors can strengthen the motivation for multi-views learning in related work; \n2) Formula 1 for softmax is wrong;\n3) Contrastive LSTM and contrastive tree LSTM are not clearly defined in the paper, although the former should refer to quick-thoughts and the latter means the proposed method;\n4) In qualitative analysis, for the last example, there is exactly the same candidate with similarity score 0.012. According to cosine similarity, wouldn’t this be 0 and also show up in the baseline model regardless of the embeddings?","sentences":[{"sentence_type":"2","sentence":"I am in favor of rejecting this paper with the following reasons:","rephrased":"I recommend reconsideration of this paper for the following reasons:"},{"sentence_type":"2","sentence":"It is unclear why authors stop the training at this early stage but the results on all three evaluations seem to be inferior to the state-of-the-art by a big margin.","rephrased":"It would be helpful if the authors could clarify the reason for stopping the training at this stage, and explore whether extending the training period could bring the results closer to the state-of-the-art."},{"sentence_type":"1","sentence":"I am happy to raise my score if authors can show the results of a well trained proposed model.","rephrased":"I would consider revising my evaluation if the authors can provide results from a more extensively trained model."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[731,796,"Maybe"],[889,1054,"Confirmed"],[1055,1149,"Maybe"],[1322,1353,"Missed by Model"]],"Comments":[]}
{"id":"B1x6GVBxhQ","text":"The paper addresses the problem of training an object detection network that can achieve good performance on both clean and noisy images.   \nThe proposed approach is based on a gating network that decides whether\nthe image is clean or  noisy. in case of  noisy image a denoising  method is applied.  The network components form a mixture of experts architecture and are  jointly trained after a component-level pretraining.\nHow good is the gate performance? what happen if you use only one of the trained experts for all the clean\/noisy  test data? It is not clear how you combined the results of the two experts. Are you computing a weighted average of the original and the enhanced images? Did you try to use a hard decision gating at test time? \n  ","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[549,613,"Missed by Model"]],"Comments":[]}
{"id":"1AFP3GV5Odt","text":"This paper presents two variations of the standard Fitts' law study, to understand the effect of (1) a situation where targets initially appear with a given size (called the \"visual width\" in the paper) but are revealed to have a larger clickable size revealed once the cursor gets close (called the \"motor width\") or vice versa; and (2) different gaps between targets arranged side-by-side. Models are fit which account for these differences, on both new data gathered from 12 participants, and data sets gathered from several past studies.\n\nOverall, I found the design of the study to be sound, as is the data analysis and modeling methodology. I also think that the overall motivation of understanding whether interfaces with distinct visual and motor widths (to use the paper's terms) is interesting.\n\nDespite the above, I am not very enthusiastic about this paper. While I appreciate the overall motivation, I'm not sure if a Fitts' law study is the right approach for going about understanding the effects of these kinds of interfaces. Or, put in a different way, I'm not sure if the study results are all that valuable for designers (given that it's looking at 1D pointing), or whether this type of interface is common enough that it's useful to have a new Fitts' law formula to account for it. The situation in which motor width differs from visual width seems fairly niche overall, and the examples cited in the introduction where visual width is greather than motor width seems like a situation that will almost always be due to poor interface implementation, rather than a conscious design decision.\n\nIn addition to the above concerns about the contribution of the paper, the term \"motor size\" is already used in Blanch et al.'s CHI 2004 work to refer to the situation where the control-display gain is manipulated to create objects with a higher or lower size in motor space as compared to their visual space on screen, work which is not cited in this paper. It seems awkward to use such a similar term here, when C-D manipulation is not the focus.\n\nFinally, I found the study results to be difficult to interpret, as many of the results subsections are ANOVA output with little interpretation and commentary to help the reader understand what was found.\n\nBased on the above, I feel the paper is marginally below the acceptance threshold.","sentences":[{"sentence_type":"2","sentence":"Despite the above, I am not very enthusiastic about this paper.","rephrased":"While I recognize the effort and motivation behind the paper, I believe there is room for further exploration to fully capture the implications of the study."},{"sentence_type":"2","sentence":"The situation in which motor width differs from visual width seems fairly niche overall, and the examples cited in the introduction where visual width is greather than motor width seems like a situation that will almost always be due to poor interface implementation, rather than a conscious design decision.","rephrased":"The applicability of scenarios where motor width differs from visual width may be limited, and it would be beneficial to provide more examples where this occurs as a result of deliberate design choices, rather than as an unintended consequence of interface design."},{"sentence_type":"2","sentence":"Based on the above, I feel the paper is marginally below the acceptance threshold.","rephrased":"Based on the points discussed, I believe the paper is close to meeting the acceptance criteria, but would benefit from addressing the concerns highlighted."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[806,869,"Confirmed"],[1302,1610,"Maybe"],[1971,2060,"Missed Maybe"],[2062,2266,"Missed by Model"],[2268,2350,"Confirmed"]],"Comments":[]}
{"id":"nqo1xxlVXv","text":"This paper proposes a pulmonary nodule malignancy classification based on the temporal evolution of 3D CT scans analyzed by 3D CNNs. It is an interesting idea and the quality is overall rather good for an abstract paper. Some points to address are listed in the following:\n\nThe early stopping is not clear. Specify that it is on the validation set if so, and clarify these points: “number of epochs was set to 150”, “early stopping to 10 epochs”\n\nWhy is this clipping used?\n\nIt is not clear whether T1 and T2 is available for all cases (“mostly”)\n\nIn Table 1, bold results are not always the best, this is very misleading.\n\nIt is strange that the T1, T2 generalize well to the validation set but not to the test. Can you comment?\n\n“... obtained an F1-score of 0.68” -> 0.686?\n","sentences":[{"sentence_type":"1","sentence":"It is strange that the T1, T2 generalize well to the validation set but not to the test. Can you comment?","rephrased":"It would be helpful if you could provide some insight into why the T1, T2 models generalize well to the validation set but appear to have challenges with the test set."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[274,306,"Missed by Model"],[447,473,"Missed by Model"],[548,622,"Missed by Model"],[624,729,"Not concerning"]],"Comments":[]}
{"id":"PNb66LYXF5o","text":"The authors present a method that is able to learn from teacher demonstrations that may be able to act in a fully observable way and transfer this \"teaching\" to partially observable settings. They do so by introducing an additional constraint on the expected reward and optimize both for this reward and the policy in an iterative fashion. The paper has strong experiments, is well explained and concise, and should definitely be included!","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"HJx5pd_6Kr","text":"Summary:\nThis paper focuses on the area of adversarial defense -- both to improve robustness and to detect adversarially perturbed images. They approach the problem from the universal prediction \/ universal learning framework.\nModivation:\nI had a hard time understanding the motivation of this work -- specifically the connection to the universal learning framework which to be fair I am unfamiliar with. In the absence of the universal learning framework formalism the method proposed here is quite simple and in my opinion clever -- create a new prediction based on performing an adversarial attack to each target class. What value does universal learning bring to this?\nSecond, I do not follow the intuition for the chosen hypothesis class -- why work off of refined images in the first place? Is there some reason to believe this will improve robustness?\nFinally, the view that adversarial defense and attack are important topics to explore is under some debate. I am not considering this as part of my review but I would encourage the authors to look at [1].\nWriting:\nThe writing was clear and typo free.\nExperiments:\nOverall the experiments seemed inconclusive.\nSection 5 shows robustness against the unmodified \/ unrefined model (the attacks are done on the base model not the refined model). Given that these attacks are performed against the unmodified model then evaluated on the modified model the results seem a bit unfair \/ harder to interpret. The authors note this, and in Section 6 explore the \"Adaptive Adversary\" setting.\nThe results presented are performed on Mnist and Cifar10. Overall the results were not convincing to me. Table 1 shows mixed performance -- a drop in natural accuracy in all cases, decreases in FGSM. The main increase in performance is in the PGD. This was noted, but understanding in more depth why this method helps here will hopefully lead to improved performance in FGSM as well.\nFigure 2a shows very weak correlations. Figure 2b seems promising but also not necessarily a surprise given that the adversarial examples are generated against the base model and not the refined model.\nFor section 6, one risk is that the BPDA attack doesn't successfully work. Having some more proof that the attacks presented here are strong would greatly improve the work.\nLarger scale experiments would of course be nice and strengthen the paper but more importantly it would be great to see some form of toy example or demonstration of the principle improving robustness as well over just results. Something to probe the mechanism of action for example.\nFinally, having some comparisons to other defense strategies would improve this paper.\nRating:\nGiven the gap between the universal learning framework and the method proposed, as well as the inconclusive experiments at this point I would not recommend the paper for acceptance.\n\n[1] https:\/\/arxiv.org\/abs\/1807.06732","sentences":[{"sentence_type":"1","sentence":"I had a hard time understanding the motivation of this work -- specifically the connection to the universal learning framework which to be fair I am unfamiliar with.","rephrased":"The connection to the universal learning framework was not immediately clear to me, which may be due to my unfamiliarity with the concept."},{"sentence_type":"2","sentence":"Overall the experiments seemed inconclusive.","rephrased":"The experiments could benefit from additional clarity to better support the conclusions."},{"sentence_type":"2","sentence":"Given the gap between the universal learning framework and the method proposed, as well as the inconclusive experiments at this point I would not recommend the paper for acceptance.","rephrased":"Bridging the gap between the universal learning framework and the proposed method, as well as providing more conclusive experimental results, could strengthen the paper for potential acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[239,404,"Not concerning"],[623,672,"Missed Maybe"],[673,858,"Missed Maybe"],[1123,1167,"Not concerning"],[1598,1644,"Missed Maybe"],[2677,2858,"Confirmed"]],"Comments":[]}
{"id":"Hy0ZkHuxG","text":"Summary\n\nThe paper addresses the issues of fair pricing and secure transactions between model and data providers in the context of machine learning real-world application.\n\nMajor\n\nThe paper addresses an important issue regarding the real-world application of machine learning, that is, the transactions between data and model provider and the associated aspects of fairness, pricing, privacy, and security.\n\nThe originality and significance of the work reported in this paper are difficult to comprehend. This is largely due to the lack of clarity, in general, and the lack of distinction between what is known and what is proposed. I failed to find any clear description of the proposed approach and any evaluation of the main idea.\n\nMost of the discussions in the paper are difficult to follow due to that many of the statements are vague or unclear. There are some examples of this vagueness illustrated under “minor issues”. Together, the many minor issues contribute to a major communication issue, which significantly reduces readability of the paper. A majority of the references included in the reference section lack some or all of the required meta data.\n\nIn my view, the paper is out of scope for ICLR. Neither the CFP overview nor the (non-exhaustive) list of relevant topics suggest otherwise. In very general terms, the paper could of course be characterised as dealing with machine learning implementation\/platform\/application but the issues discussed are more connected to privacy, security, fair transactions, and pricing.\n\nIn summary; although there is no universal rule on how to structure research papers, a more traditional structure (introduction, aim & scope, background, related work, method, results, analysis, conclusions & future work) would most certainly have benefitted the paper through improved clarity and readability. Although some interesting works on adversarial learning, federated learning, and privace-preserving training are cited in the paper, the review and use of these references did not contribute to a better understanding of the topic or the significance of the contribution in this paper. I was unable to find any support in the paper for the strong general result stated in the abstract (“We successfully show that without running the data through the model, one can approximate the value of the data”).\n\nMinor issues (examples)\n\n- “Models trained only a small scale of data” (missing word)\n- “to prevent useful data from not being paid” (unclear meaning)\n- “while the company may decline reciprocating gifts such as academic collaboration, while using the data for some other service in the future” (unclear meaning)\n- “since any data given up is given up ” (unclear meaning)\n- “a user of a centralized service who has given up their data will have trouble telling if their data exchange was fair at all (even if their evaluation was purely psychological)” (unclear meaning)\n- “For a generally deployed model, it can take any form. Designing a transaction strategy for each one can be time-consuming and difficult to reason about” (unclear meaning)\n- “(et al., 2017)” (unknown reference)\n- “Osbert Bastani, Carolyn Kim, and Hamsa Bastani. Interpreting blackbox models via model extraction, 2017” (incomplete reference data)\n- “Song Han, Huizi Mao, and William J. Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding, 2015.\nGeoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network, 2015.\nPang Wei Koh and Percy Liang. Understanding black-box predictions via influence functions, 2017.” (Incomplete reference data)\n- “H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Agera y Arcas. Communication-efficient learning of deep networks from decentralized data. 2016.” (Incomplete reference data)\n- “et al. Richard Craid.” (Incorrect author reference style)\n- “Ryo Yonetani, Vishnu Naresh Boddeti, Kris M. Kitani, and Yoichi Sato. Privacy-preserving visual learning using doubly permuted homomorphic encryption, 2017.\nChiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning requires rethinking generalization, 2016.” (Incomplete reference data)","sentences":[{"sentence_type":"2","sentence":"The originality and significance of the work reported in this paper are difficult to comprehend.","rephrased":"The originality and significance of the work would benefit from clearer articulation to enhance comprehension."},{"sentence_type":"2","sentence":"I failed to find any clear description of the proposed approach and any evaluation of the main idea.","rephrased":"A clearer description of the proposed approach and an evaluation of the main idea would be helpful for understanding the paper's contributions."},{"sentence_type":"2","sentence":"In my view, the paper is out of scope for ICLR.","rephrased":"The paper's relevance to the ICLR's scope could be more explicitly connected to the conference themes."},{"sentence_type":"2","sentence":"I was unable to find any support in the paper for the strong general result stated in the abstract.","rephrased":"It would be beneficial if the paper provided more evidence to support the strong claims made in the abstract."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[408,504,"Confirmed"],[505,632,"Confirmed"],[633,733,"Confirmed"],[735,852,"Missed by Model"],[853,1057,"Missed by Model"],[1058,1164,"Missed by Model"],[1166,1213,"Maybe"],[1214,1306,"Missed Maybe"],[2137,2352,"Missed by Model"]],"Comments":[]}
{"id":"bC3FjZm0Xh","text":"Strengths:\n1. This paper proposes a novel method in addressing argument discourse unit detection, by incorporating constituency parser output via Graph Attention Layer. Although the reported results are better than the baseline, the scores are not comparable. Unlike previous works (Trautmann et al., 2020), the paper also does not report the complete result (see weaknesses below). \n\nWeaknesses:\n1. This paper has a poor literature review, motivation, and presentation, making it hard to read. For instance, a) In Section 1, many references are missing for argument analysis definition and examples, previous works in par3, and reference to the SPMRL dataset. Par4 is also confusing. The motivation to incorporate syntax into this task is also very weak. I suggest providing an example to show why syntax can be a good feature for ADU detection; b) In Section 2, par1-2 have a bad flow; par4 mentions “recent promising results”, but which one? It needs some references. c) It’s strange to have a Section of Experimental set-up prior to model architecture. Section 4.1 also has a bad naming (I suggest renaming it as the model name); d) The proposed method needs mathematical\/formal definition which is completely missing in this paper.\n2. Although the dataset is based on Trautmann et al., 2020, the paper does not clearly state the original train\/dev\/test split of data, as well as general statistics of stance labels. I don't think the reader needs to check the original paper for this basic information.\n3. The motivation for pruning the constituency tree is not properly presented since Section 1. For instance, a) in Figure 1, why is the depth of the tree capped to a maximal value of three? b) in Section 3.2, “Maximum depth” is not clearly explained and poorly presented. What does the author mean by “columns 2, 3,4”? Which data partition is used to determine optimal “maximum depth”? It sounds to me that this value is determined based on all the data, which potentially harms the methodology.\n4. Unclear motivation and setting of using BENEPAR constituency parser. The authors mention that BENEPAR is a multilingual parser that can parse French and English sentences, however, in the reported result, there is no experimental result for both languages. Instead, the results seem to be in 1 language.\n5. The authors discard 1300 samples of data due to tokenization requirements of BERT and BANEPAR, which I think is a very strange motivation. Moreover, the main experimental result in Table 3 uses baseline results from Trautmann et al., 2020, which can be misleading as the data is not comparable anymore.\n6. The reported result does not have a clear description of in-domain and cross-domain data, nor further explanation or analysis.\n7. This paper does not report the full result of experiments, only token-level F1-score. In Trautmann et al., 2020, there are three different metrics: token-level, segment-level, and sentence-level","sentences":[{"sentence_type":"2","sentence":"This paper has a poor literature review, motivation, and presentation, making it hard to read.","rephrased":"The literature review, motivation, and presentation could be improved for better readability and to provide a clearer understanding of the paper's contributions."},{"sentence_type":"2","sentence":"I don't think the reader needs to check the original paper for this basic information.","rephrased":"It would be beneficial for the reader if the paper included the original train\/dev\/test split of data and general statistics of stance labels to avoid referencing back to the original paper."},{"sentence_type":"2","sentence":"It sounds to me that this value is determined based on all the data, which potentially harms the methodology.","rephrased":"Clarification is needed on how the 'maximum depth' value was determined, as it is crucial to ensure the methodology is not compromised."},{"sentence_type":"2","sentence":"The authors discard 1300 samples of data due to tokenization requirements of BERT and BANEPAR, which I think is a very strange motivation.","rephrased":"The rationale for discarding 1300 samples of data due to tokenization requirements should be explained more thoroughly to understand its impact on the study."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[169,259,"Missed by Model"],[260,382,"Missed by Model"],[400,494,"Confirmed"],[661,684,"Missed by Model"],[685,755,"Missed by Model"],[974,1056,"Missed by Model"],[1057,1132,"Missed by Model"],[1137,1236,"Missed by Model"],[1297,1420,"Missed by Model"],[1421,1507,"Confirmed"],[1701,1779,"Missed by Model"],[1780,2003,"Confirmed"],[2314,2452,"Confirmed"],[2453,2616,"Missed Maybe"],[2620,2746,"Missed by Model"],[2750,2944,"Missed Maybe"]],"Comments":[]}
{"id":"SkhI_TPez","text":"The authors introduce the general concept of a differential neural computational machine, dNCM. It can apply to any fully differentiable neural programming machine, such as the Neural Turing Machine (NTM) or NRAM or the Neural GPU, but not to non-fully-differentiable architecture such as NPI. The author show how partial traces can be used to improve training of any dNCM with results on instantiations of dNCM for NTM and NRAM.\n\nOn the positive side, the paper is well-written (though too many results require looking into the Appendix) and dNCM is elegant. Also, while it's hard to call the idea of using partial traces original, it's not been studied in this extent and setting before. On the negative side, the authors have chosen weak baselines and too few and easy tasks to be sure if their results will actually hold in general. For example, for NTM the authors consider only 5 tasks, such as Copy, RepeatCopyTwice, Flip3rd and so on (Appendix E) and define  \"a model to generalize if relative to the training size limit n, it achieves perfect accuracy on all of tests of size ≤ 1.5n and perfect accuracy on 90% of the tests of size ≤ 2n\". While the use of subtraces here shows improvements, it is not convincing since other architectures, e.g., the Improved Neural GPU (https:\/\/arxiv.org\/abs\/1702.08727), would achieve 100% on this score without any need for subtraces or hints. The tasks for the NRAM are more demanding, but the results are also more mixed. For one, it is worrysome that the baseline has >90% error on each task (Appendix J, Figure 12) and that Merge even with full traces has still almost 80% errors. Neural programmers are notoriously hard to tune, so it is hard to be sure if this difference could be eliminated with more tuning effort. In conclusion, while we find this paper valuable, to be good enough for acceptance it should be improved with more experimentation, adding baselines like the (Improved) Neural GPU and more tasks and runs.","sentences":[{"sentence_type":"2","sentence":"On the negative side, the authors have chosen weak baselines and too few and easy tasks to be sure if their results will actually hold in general.","rephrased":"To strengthen the paper, it would be beneficial for the authors to consider more robust baselines and a wider variety of tasks to better assess the generalizability of their results."},{"sentence_type":"2","sentence":"While the use of subtraces here shows improvements, it is not convincing since other architectures, e.g., the Improved Neural GPU (https:\/\/arxiv.org\/abs\/1702.08727), would achieve 100% on this score without any need for subtraces or hints.","rephrased":"Although the use of subtraces indicates some improvements, it would be helpful to see a comparison with other architectures, such as the Improved Neural GPU, which might achieve similar results without the need for subtraces, to fully evaluate the effectiveness of this approach."},{"sentence_type":"2","sentence":"For one, it is worrysome that the baseline has >90% error on each task (Appendix J, Figure 12) and that Merge even with full traces has still almost 80% errors.","rephrased":"It is a point of concern that the baseline exhibits a high error rate on each task, and even with full traces, the Merge task retains a significant error percentage. Further investigation into these results could provide valuable insights."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[690,836,"Confirmed"],[1148,1387,"Maybe"],[1468,1628,"Not concerning"]],"Comments":[]}
{"id":"H0mMd5fRcZq","text":"Strengths\n1. The paper develops an effective and simple adversarial defense that requires only adding a simple regularization term during training, and additional processing of inputs during testing.\n2. The proposed defense appears to outperform baseline defenses on strong attacks. The accuracies achieved by the defense appear competitive.\n\nWeaknesses\n1. The proposed defense is novel, but some ideas are similar to ones previously proposed in the literature. In particular, the idea of feature smoothing is related to prior work as noted in section 2. Moreover, the idea of adding noise to inputs as a defense has been explored in the literature on randomized smoothing.\n2. The proposed defense is not theoretically motivated. This is not strictly necessary given the strong empirical results; however, it would be helpful to provide further intuition on why the interaction between feature smoothing during training and during active defense may enhance adversarial robustness.\n3. It is not clear to what extent the noise (step 1 of active defense) by itself enhances robustness vs. the feature smoothing step of the active defense. The authors demonstrate that standard training by itself with active defense is ineffective, indicating the importance of the feature smoothing loss during training. It would be helpful to conduct a similar ablation experiment to evaluate the importance of the noise vs. feature smoothing steps in the active defense.\n4. It is possible that the high performance of the proposed method is due to obfuscated gradients since for the attacker, optimizing inputs through the active defense may be more difficult. Adding additional experiments to demonstrate that obfuscated gradients do not occur would strengthen the paper (the authors may want to consider the experiments in Athalye et al., 2018).\n5. The authors do not state whether the proposed method is state-of-the-art. To the best of their knowledge, do the authors achieve state-of-the-art robust accuracy on CIFAR-10 at $\\epsilon=8\/255$?\n6. What is the role of the L1\/absolute value penalty in eqn 3? Would the method still be effective with an L2\/square penalty?\n\nMinor comments\n1. Some typos: \"AutoAttak\" in section 3, \" It needs to emphasize here \" -> \" It needs to be emphasized here\" in section 5\n\n","sentences":[{"sentence_type":"1","sentence":"The proposed defense is not theoretically motivated.","rephrased":"While the proposed defense shows strong empirical results, providing a theoretical motivation could further strengthen the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[677,729,"Maybe"]],"Comments":[]}
{"id":"vEAsB5Apd9R","text":"The authors propose some metrics based on thresholded uncertainty to evaluate the reliability of uncertainty estimation methods for deep learning-based segmentation, which is of interest to the community. Effect of these metrics on brain tumor segmentation has been shown. However, the proposed metrics failed to rank different uncertainty estimation methods as in the results.\n\npros:\n1, considering the ratio of filtered TPs and TNs is a reasonable idea for uncertainty assessment.\n2, the authors showed some results with a brain tumor segmentation task, which helped to understand the proposed metrics.\n\ncons:\n1, using Dice based on thresholded uncertainty to evaluate the uncertainty estimation method has been proposed before, such as the following paper: \n\n[1] Assessing Reliability and Challenges of Uncertainty Estimations for Medical Image Segmentation, MICCAI 2019.\n\nAuthors in [1] found that based on such a metric, model ensemble had a better performance than other uncertainty estimation methods. But this paper found that there was no obvious winner  among different uncertainty estimation methods according to the metrics used in this paper. Could the authors explain more about this?\n\n2, following the above problem, the results didn't show the proposed metrics have the ability to distinguish good and poor uncertainty estimation methods. How to validate the effectiveness of the proposed metrics? \n\n","sentences":[{"sentence_type":"2","sentence":"However, the proposed metrics failed to rank different uncertainty estimation methods as in the results.","rephrased":"However, it would be helpful if the authors could clarify how the proposed metrics could effectively rank different uncertainty estimation methods, as the results are not clear on this aspect."},{"sentence_type":"1","sentence":"But this paper found that there was no obvious winner among different uncertainty estimation methods according to the metrics used in this paper.","rephrased":"However, this paper suggests that there is no clear distinction among different uncertainty estimation methods based on the metrics used. Could the authors provide further insights into these findings?"},{"sentence_type":"1","sentence":"How to validate the effectiveness of the proposed metrics?","rephrased":"Could the authors elaborate on the validation process for the effectiveness of the proposed metrics?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[273,377,"Maybe"],[1355,1413,"Confirmed"]],"Comments":[]}
{"id":"Hylb4teTYE","text":"The paper analyses learnability of the IB regulariser. It is well-written and the results are interesting because the non-monotonic behavior is not something one would intuitively assume to appear. I definitely recommend acceptance of the paper, even though it may be slightly out of scope for the workshop due to its lack of experiments on limited data.","sentences":[{"sentence_type":"1","sentence":"even though it may be slightly out of scope for the workshop due to its lack of experiments on limited data.","rephrased":"However, it would be beneficial for the paper to include experiments on limited data to fully align with the workshop's scope."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[246,354,"Not concerning"]],"Comments":[]}
{"id":"y79vqGzgdOF","text":"### Quality\n* #### Weaknesses\n    * ##### Major\n        * While numerous mathematical statements are made throughout the paper, some are already well-established in the reinforcement learning literature (the chain of statements ending Section 2.2 should all hold with equality and dates back to the successor representation[1]) and others are simply stated as fact without proof, although surrounding text would suggest that the authors are claiming them as technical contributions of this work. While the introduction of variational approximations leads to lower bounds that resemble those shown in the paper, the various notations and distributions introduced make it difficult to confirm their validity right away. The authors should (at a minimum) include proofs for novel technical contributions of this work and further include proofs for supporting results that may help the reader understand the nature of their contributions.\n        * In Equations 9 and 10, (my understanding is that) the included log-likelihood ratio is between the variational approximation of the behavior policy visitation and that of the optimal policy. It seems rather likely that this ratio may suffer from numerical errors (namely, division by zero) when the exploratory behavior policy visits a region of the state-action space not covered by the optimal policy. Could the authors comment on why this is not an issue? Or are the authors making some kind of absolute continuity assumption?\n        * Ultimately, this paper is deeply concerned with addressing the challenge of exploration. Can the authors comment on why this formulation under probabilistic inference is reasonable given recent work which shows how the approximations needed for these methods to be applied in practice fail to pass even basic sanity checks? [2]\n\t* ##### Minor\n\t\t* \n\n### Clarity\n* #### Strengths\n    * The clearest element in the paper is Algorithm 1, which at least conveys the generic structure of what the authors are trying to achieve. Unfortunately, everything leading up to Section 3 is incredibly unclear stemming from a variety of sources including non-standard mathematical notation, undefined jargon\/terminology, and (to a lesser extent) grammatical errors. The authors have wasted a page describing details of widely-known Mujoco environments that could instead be allocated to adding clarity to Sections 2 and 3, which seem to articulate the bulk of the contribution. \n* #### Weaknesses\n    * ##### Major\n        * The mathematical notation used throughout the paper is terribly difficult to parse and inconsistent with the broader reinforcement-learning literature. As a concrete example, Section 2.3 contains undefined notation (\\mathcal{T}\\pi(s)), ambiguous notation (s... notation, s+ appears to denote a state and yet is later said to denote a sequence of future states but then used as a normal state in Equation 3), and nonsensical notation (the second paragraph of Section 2.5 has Q(s,a) \\sim \\frac{r(s+,a+)}{(1-\\gamma)}, which is entirely vacuous without being defined beforehand). The authors seem to jump back and forth between states indexed by time vs. not. \n        * The authors make a bad habit of introducing assumptions unnecessarily. In Section 2.4, if the first assumption on Boltzmann policies is made, then why is the second assumption on the existence of K(s) needed as well? The statement should hold under the first assumption and K(s) can be written out explicitly. Why is the first assumption of Section 2.5 needed as if it re-defines the optimal policy? Unless the policy class over which the argmax is taken is a subset of all policies, this is the definition of the optimal policy for a MDP. \n        * The authors introduce their own terminology without any formal definitions or visualizations to assist the reader in understanding what the terms are meant to convey. As a result, the first paragraph of Section 2.7 reads vacuously without knowing what is meant by \"pathways\", \"conducts\", \"adverse\", through\", or \"width.\"\n        * The paper has several grammatical errors throughout. While a small handful of these would not constitute a major weakness (and, in fact, could be easily enumerated and corrected), there are enough of them to impact readability of the paper.\n\t* ##### Minor\n\t\t* The use of the phrase \"probability matching\" in this paper is misleading since it is widely associated with Thompson sampling. Distribution matching would be a more accurate phrase for what the author is trying to convey.\n\t\t\n \n### Originality\n* #### Weaknesses\n    * ##### Major\n        * The paper lacks a section dedicated to providing readers with an overview of related prior work. Consequently, it is difficult to precisely identify how the authors' variational formulation extends or expands beyond some of the prior work mentioned in brief at the top of page 2.  \n\t* ##### Minor\n\t\t* \n\n### Significance\n* #### Weaknesses\n    * ##### Major\n        * The authors haven't included details of how many random seeds are used to generate the results in Figure 1; consequently, I'm skeptical of their significance and reproducibility. That said, just examining the average return column (which is the standard metric), it seems that the proposed approach only leads to meaningful performance improvements in simpler control problems, while results in Swimmer and Humanoid are only on par with SAC.\n        * Simpler experiments in domains where things can be concisely and cleanly visualized would go a long way towards driving home the central claim that this approach facilitates improved exploration in practice.\n\t* ##### Minor\n\t\t* \n\n# References\n1. Dayan, Peter. \"Improving generalization for temporal difference learning: The successor representation.\" Neural Computation 5, no. 4 (1993): 613-624.\n2. O'Donoghue, Brendan, Ian Osband, and Catalin Ionescu. \"Making Sense of Reinforcement Learning and Probabilistic Inference.\" In International Conference on Learning Representations. 2019.\n","sentences":[{"sentence_type":"2","sentence":"The mathematical notation used throughout the paper is terribly difficult to parse and inconsistent with the broader reinforcement-learning literature.","rephrased":"The mathematical notation used in the paper could be made clearer and more consistent with common conventions in the reinforcement-learning literature to enhance readability."},{"sentence_type":"2","sentence":"The authors make a bad habit of introducing assumptions unnecessarily.","rephrased":"The paper could benefit from a more careful consideration of the necessity of the assumptions introduced, ensuring each one contributes meaningfully to the work."},{"sentence_type":"2","sentence":"The authors introduce their own terminology without any formal definitions or visualizations to assist the reader in understanding what the terms are meant to convey. As a result, the first paragraph of Section 2.7 reads vacuously without knowing what is meant by \"pathways\", \"conducts\", \"adverse\", through\", or \"width.\"","rephrased":"The paper would be improved by providing formal definitions and, if possible, visualizations for the new terminology introduced, such as \"pathways\", \"conducts\", \"adverse\", \"through\", and \"width\", to aid reader comprehension."},{"sentence_type":"1","sentence":"The paper has several grammatical errors throughout. While a small handful of these would not constitute a major weakness (and, in fact, could be easily enumerated and corrected), there are enough of them to impact readability of the paper.","rephrased":"Addressing the grammatical errors present in the paper would improve its readability and overall presentation."},{"sentence_type":"2","sentence":"The authors haven't included details of how many random seeds are used to generate the results in Figure 1; consequently, I'm skeptical of their significance and reproducibility.","rephrased":"Providing details on the number of random seeds used for the results in Figure 1 would enhance the credibility and reproducibility of the findings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[2007,2234,"Missed by Model"],[2235,2447,"Missed by Model"],[2494,2645,"Confirmed"],[2646,3069,"Missed by Model"],[3070,3150,"Missed by Model"],[3161,3231,"Maybe"],[3712,4032,"Confirmed"],[4043,4283,"Maybe"],[4958,5136,"Maybe"]],"Comments":[]}
{"id":"qCwv8gQD6z","text":"VEry small paper. Method not novel. Miss a lot of details to evaluate results.\n\nSingle-Stage vs. Multi-Stage Machine Learning Algorithms for Prostate Segmentation in Magnetic Resonance ImagesSingle-Stage vs. Multi-Stage Machine Learning Algorithms for Prostate Segmentation in Magnetic Resonance ImagesSingle-Stage vs. Multi-Stage Machine Learning Algorithms for Prostate Segmentation in Magnetic Resonance ImagesSingle-Stage vs. Multi-Stage Machine Learning Algorithms for Prostate Segmentation in Magnetic Resonance ImagesSingle-Stage vs. Multi-Stage Machine Learning Algorithms for Prostate Segmentation in Magnetic Resonance ImagesSingle-Stage vs. Multi-Stage Machine Learning Algorithms for Prostate Segmentation in Magnetic Resonance Images","sentences":[{"sentence_type":"2","sentence":"VEry small paper.","rephrased":"The paper could benefit from a more comprehensive exploration of the topic."},{"sentence_type":"2","sentence":"Method not novel.","rephrased":"The methodology appears to overlap significantly with existing studies and could be better differentiated."},{"sentence_type":"2","sentence":"Miss a lot of details to evaluate results.","rephrased":"The paper would be strengthened by including more details to support the evaluation of the results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[0,17,"Confirmed"],[18,35,"Confirmed"],[36,78,"Confirmed"]],"Comments":[]}
{"id":"SJllyhLAYr","text":"The authors propose a variational autoencoding (VAE) framework for agent\/opponent modeling in multi-agent games. Interestingly, as the authors show, it looks like it is possible to compute accurate embeddings of the opponent policies without having access to opponent observations and actions. The paper is well written, the methods are simple yet still interesting\/informative, but there are a few questions that I find necessary to be addressed.\n\n\nMethods:\n\n1. I find the idea of learning to infer embeddings of the opponent policies from the agent's own local observations quite interesting. Intuitively, it makes sense -- since the opponent's policy effectively specifies the dynamics of the environment (from the agent's perspective), opponent's behavior must be reflected in the agent's observations. Comparing figures 1 and 2, the proposed encoder architecture also uses information about the reward (and episode termination). How critical is this information for opponent identification? Would it work without r_{t-1} and d_{t-1}?\n \n2. Sec. 4.2: \"We assume a number of K provided episode trajectories for each pretrained opponent\" -- how exactly are these trajectories obtained? Similarly, how exactly are the opponents pretrained? (Self-play, hardcoded, or something else?)\n\n3. As the authors mention, the triplet loss that discriminates between the opponents loosens the lower bound. Since the regularized objective is still a lower bound, I wonder if the triplet loss can be re-interpreted\/expresses as a specific prior on the opponent model?\n\n\nExperiments:\n\n1. Sec. 5.1: to understand the effect of opponent modeling, it would be nice to see how baselines perform in this setup against a randomly picked opponent (otherwise, the curve in Fig. 3-c is not informative). I suggest the following baselines: tit-for-tat (hardcoded), a couple of classical learning algorithms for iterated games (e.g., policy hill-climbing, WoLF), an agent that learns using policy gradients but without opponent embeddings. Without any baselines, Sec. 5.1 seems like a sanity check which just shows that the implementation works unless I am missing something.\n\n2. Sec. 5.3: (1) Why is mutual information between the approximate posterior q and the prior p makes sense as the policy embedding quality metric here? (2) Could you intuitively (or formally) justify the fact that the triplet loss degrades MI metric? Right now, this is stated as a fact but not justified. (3) It looks like Grover et al. (2018a) used deterministic trajectory encoders; how exactly is MI measured in that case?\n\n3. If I understand correctly from Fig. 4, SMA2C (which uses local information) underperforms as compared to the methods that use opponent trajectories in 6\/8 cases. To me, this somewhat confirms the point opposite to what the authors claim -- local observations, while containing some information about the opponent, are still inferior. Also, having baselines that do not use opponent embeddings on the charts of Fig.4 would help understand the contribution of opponent modeling.\n\n----\n\nI acknowledge reading the author's response, which addressed some of my questions\/concerns to some extent. However, I believe that while estimating accurate embeddings of the opponent behavior from the agent's observations only is interesting, the approach has limitations, and I feel those are not studied in-depth enough (e.g., as a reader, I would like to understand if and when I should use the proposed approach and expect it to work). My assessment of the paper stays the same.","sentences":[{"sentence_type":"2","sentence":"Without any baselines, Sec. 5.1 seems like a sanity check which just shows that the implementation works unless I am missing something.","rephrased":"Including baselines in Sec. 5.1 would provide a clearer comparison and enhance the understanding of the model's performance beyond a basic implementation check."},{"sentence_type":"2","sentence":"To me, this somewhat confirms the point opposite to what the authors claim -- local observations, while containing some information about the opponent, are still inferior.","rephrased":"The results in Fig. 4 suggest that there may be room to further explore the effectiveness of local observations for opponent modeling, as they appear to be less informative than methods using opponent trajectories."},{"sentence_type":"2","sentence":"I believe that while estimating accurate embeddings of the opponent behavior from the agent's observations only is interesting, the approach has limitations, and I feel those are not studied in-depth enough","rephrased":"It would be beneficial for the paper to provide a more in-depth analysis of the limitations of estimating opponent behavior solely from the agent's observations to guide potential users on when this approach may be most effective."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2014,2149,"Not concerning"],[2744,2915,"Not concerning"],[3182,3388,"Not concerning"]],"Comments":[]}
{"id":"SJxd2NNKhX","text":"This paper generalizes basic policy gradient methods by replacing the original Gaussian or Gaussian mixture policy with a normalizing flow policy, which is defined by a sequence of invertible transformations from a base policy.\n\nAlthough the concept of normalizing flow is simple, and it has been applied to other models such as VAE, there seems no work on applying it for policy optimization. Thus I think this method is itself interesting.\n\nHowever, I find the paper written in a way assuming readers very familiar with related concept and algorithms in reinforcement learning. Thus although one can get the general idea on how the method works, it might be difficult to get a deeper understanding on some details.\n\nFor example, normalizing flows are defined in Section 4, and then it is directly claimed that normalizing flows can be applied to policy optimization, without giving details on how it is actually applied, e.g., what is the objective function? and why one needs to compute gradients of the entropy (Section 4.1)?\n\nAlso, in the experiments, it is said that one can combing normalizing flows with TRPO without describing the details. I can't get how exactly normalizing flows + TRPO works.\n\nThe experiments also talk about 2D bandit problem, and again, without any descriptions. BTW, in the Section 4.3, what does [-1, 1]^2 mean? (I have seen {-1, 1}^2, but not [-1, 1]^2).\n\nIt seems that the authors only use the basic normalizing flow structures studied in Rezende&Mohamed (2015) and Dinh et al (2016). However, there are more powerful variants of normalizing flows such as the Multiplicative Normalizing Flows or the Glow. I wonder how good the results are if these more advanced versions are used. Maybe they can uniformly outperform Gaussian policy?\n\nUpdate:\nI feel the idea of this paper is straightforward, and the contribution is incremental. To improve the paper, stronger experiments need to be performed. ","sentences":[{"sentence_type":"2","sentence":"However, I find the paper written in a way assuming readers very familiar with related concept and algorithms in reinforcement learning.","rephrased":"The paper could be improved by providing more background information on the related concepts and algorithms in reinforcement learning to make it accessible to a broader audience."},{"sentence_type":"1","sentence":"I can't get how exactly normalizing flows + TRPO works.","rephrased":"It would be helpful if the paper could clarify how normalizing flows are integrated with TRPO."},{"sentence_type":"1","sentence":"BTW, in the Section 4.3, what does [-1, 1]^2 mean? (I have seen {-1, 1}^2, but not [-1, 1]^2).","rephrased":"Could you please clarify the notation [-1, 1]^2 in Section 4.3? It is usually represented as {-1, 1}^2."},{"sentence_type":"2","sentence":"I feel the idea of this paper is straightforward, and the contribution is incremental.","rephrased":"The paper presents a clear idea, though the contribution appears to be a modest extension of existing work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[443,579,"Not concerning"],[1149,1204,"Maybe"],[1206,1293,"Missed by Model"],[1294,1388,"Not concerning"],[1779,1865,"Maybe"]],"Comments":[]}
{"id":"0rFm6fgxSOq","text":"The paper 1) introduces a method to use three types of text embedding methods (non-contextual, contextual, LM -based) to predict  word relatedness (as a binary classification problem) for pairs of words in wordnet 2) uses these relatedness scores to build proxies of the Wordnet graph 3) carry out experiments based on the two bullet points to compare semantic understanding abilities of the aforementioned embedding methods.\n\nMajor comments:\n* The paper carries out quite a few experiments with weakly connected goals. It looks like a combination of miscellaneous results based on a common (and limited) technique, rather than delivering a coherent message with interrelated takeaways from follow-up experiments. \n* The technique to probe models is quite restricted in that it is centered around single word concepts. Given that contextualized models are utilized, it seems like a rather handicapped investigation of very powerful models.\n* In section 4.3, authors try to make a point about correlations on visuals. This is a dangerous approach, and it would be much better to rely on numerical summaries of correlations. In fact, it is extremely hard to judge correlation by looking at pictures, because correlation needs to take into account the variability in an F1 metric with the other axis kept constant (only means are shown). A curve with less slope on Figure 3 might indicate a much higher degree of co-movement with the metric on the X axis if the randomness in y axis wrt at any point in x axis is very low. Authors should revisit statistical correlation, and preferably revamp this section. That said, I'm not quite convinced that it is a publication-worthy result to say similar methods (and each of the 3 buckets is very similar within) produce similar concept relatedness scores.\n* It's hard to understand how the proposed probing classifier is different than concatenating $M(x)$ and $M(y)$ and directly applying MLP on it. One can choose an MLP with custom first hidden layer size and activation function that would be functionally equivalent to what's being proposed.\n* There is definitely truth to the title, but I'd suggest not conflating the term \"knowledge graph\", which traditionally represents actual world knowledge, and not lexical databases.\n\nMinor comment\n* Please write something under section 3 (before 3.1). Given that it's not clear on a first pass that you're introducing two different methods in 3.2 and 3.3, the empty space is a good opportunity to tell the reader about this fact.","sentences":[{"sentence_type":"2","sentence":"The paper carries out quite a few experiments with weakly connected goals.","rephrased":"The paper presents a number of experiments that could benefit from a clearer connection between their goals."},{"sentence_type":"2","sentence":"It looks like a combination of miscellaneous results based on a common (and limited) technique, rather than delivering a coherent message with interrelated takeaways from follow-up experiments.","rephrased":"The paper might be strengthened by providing a more coherent message that integrates the results from the various experiments, highlighting the interrelated takeaways."},{"sentence_type":"1","sentence":"The technique to probe models is quite restricted in that it is centered around single word concepts.","rephrased":"The probing technique could be expanded beyond single word concepts to fully leverage the capabilities of contextualized models."},{"sentence_type":"2","sentence":"This is a dangerous approach, and it would be much better to rely on numerical summaries of correlations.","rephrased":"It may be more informative to supplement the visual analysis with numerical summaries of correlations to ensure a more robust interpretation."},{"sentence_type":"3","sentence":"That said, I'm not quite convinced that it is a publication-worthy result to say similar methods (and each of the 3 buckets is very similar within) produce similar concept relatedness scores.","rephrased":"It would be helpful to further clarify how the findings contribute to the field, considering that the methods within each of the three categories are quite similar and yield comparable relatedness scores."},{"sentence_type":"1","sentence":"It's hard to understand how the proposed probing classifier is different than concatenating $M(x)$ and $M(y)$ and directly applying MLP on it.","rephrased":"Could you please elaborate on how the proposed probing classifier differs from a straightforward concatenation of $M(x)$ and $M(y)$ followed by an MLP application?"},{"sentence_type":"1","sentence":"There is definitely truth to the title, but I'd suggest not conflating the term \"knowledge graph\", which traditionally represents actual world knowledge, and not lexical databases.","rephrased":"While the title captures an element of the study, it may be beneficial to differentiate between the term \"knowledge graph\", which is traditionally associated with world knowledge, and lexical databases."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[445,519,"Confirmed"],[520,713,"Confirmed"],[717,939,"Confirmed"],[1017,1122,"Maybe"],[1604,1795,"Maybe"],[1798,1940,"Maybe"],[2089,2269,"Not concerning"]],"Comments":[]}
{"id":"POeg0b8EPs","text":"The authors proposed a method for segmentation quality assessment. The method consists of learning a reconstruction network for the masked input images and a regression network for quality assessment. The reconstruction network aims to only faithfully reconstruct input images masked correctly by the segmentation, while the regression network learns to assess the quality by looking at segmentation of different quality. The robustness of the proposed method is supported by quantitative evaluation with comparison to a baseline method.\n\nThe underlying idea interestingly links to the earlier works in unsupervised detection and couples it with quality assessment. The paper is well structured with clear contribution and provides the key results. The results show that the proposed method is more robust against adversarial attacks.\n\nAdditionally, a few concerns are:\n\n1) REG-Net is trained to assess the segmentation quality by providing it with images of different segmentations, . What is the metric to assess such segmentations, or in other words, what's the ground-truth for $P_{dice}$, and how is it obtained? \n\n2) U-net is used as the framework for REC-Net. U-net have skip connections to preserve details for segmentation, however, using skip-connections for the very first layers for reconstruction may leak much information and make the task very easy, is this the case for REC-Net in this work?\n\n3) It may be useful if the authors can give the loss function for the proposed method in the paper.","sentences":[{"sentence_type":"2","sentence":"U-net have skip connections to preserve details for segmentation, however, using skip-connections for the very first layers for reconstruction may leak much information and make the task very easy, is this the case for REC-Net in this work?","rephrased":"The use of U-net with skip connections is known to preserve details for segmentation. Could you clarify if the skip-connections in the early layers for reconstruction in REC-Net might lead to an oversimplification of the task?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1167,1407,"Not concerning"]],"Comments":[]}
{"id":"SyxqSwRvt4","text":"Pros:\n- clear and concise writing, clear motivation for the transfer learning part\n- sufficient detail presented for each experiment\n- interesting idea to relate an approach for training with noisy labels to one for transfer learning, and show improvement on previous noisy label results\n\nCons:\n- Figure 1 text is not readable (axis labels, legends, titles)\n","sentences":[{"sentence_type":"1","sentence":"Figure 1 text is not readable (axis labels, legends, titles)","rephrased":"The text in Figure 1 (axis labels, legends, titles) could be enhanced for better readability."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[297,357,"Maybe"]],"Comments":[]}
{"id":"cT3TaN8D9er","text":"Summary Of The Review:\n\nThis paper discusses the role of data in managing the COVID-19 pandemic, focusing on its collection, management, analysis, and application in decision-making. The authors present The Ohio State University's data-driven framework for monitoring the pandemic, including data sources, methods, and technologies used for case finding, contact tracing, and visualization. They discuss challenges such as privacy concerns, data quality, and the need for harmonization across different sources. The paper also explores ethical considerations in data usage during the pandemic. The authors highlight the importance of data architecture, teamwork, and ethical frameworks in addressing public health emergencies. The paper concludes with key takeaways and lessons learned for future public health emergencies.\n\nPros: \n1. The authors possess extensive knowledge and experience in managing COVID-19 at The Ohio State University, providing valuable insights and practical examples that can benefit other systems.\n\n2. The paper offers a comprehensive discussion of the university's policies.\n\nCons:\n1. Lack of references and comparisons\n\nThe paper lacks citations to substantiate and compare the findings and approaches presented, which is a notable deficiency. For instance, it is essential to clarify the definition of the \"positivity rate\" in this paper and provide a rationale for its use, which would benefit from external support. Additionally, the paper displays \"R(t) Numbers for Ohio\" in Figure 1, but fails to mention or discuss this important metric in the text, warranting a comprehensive review of the relevant literature to enhance its explanation. Similarly, the utilization of terms like \"gold table\" and \"'gold' data of people\" could be less perplexing if supported by appropriate references.\n\nFurthermore, considering the abundance of existing pandemic surveillance systems, it would be advantageous to examine their operational mechanisms. This examination would enable the identification and comparison of the strengths and weaknesses of the system presented in the paper.\n\n2. Ambiguous statements \n\nSeveral statements in the paper lack clarity and precision, leading to confusion among readers. Additionally, the paper fails to provide a comprehensive summary of the data entries presented in the tables, leaving readers unsure about the specific information contained within them. Moreover, the paper lacks explicit descriptions of tasks, analyses, or well-defined evaluations, despite drawing conclusions and using phrases such as “No improvement in the accuracy of the analysis of the effect of masking in a given setting” and “After careful consideration, it was agreed that singling out a group was often not enough of a value addition or could do more harm than good.”\n\nHere are additional instances of imprecise terminology lacking explicit definitions or thorough evaluations of their scope.\n\nSection 5.1:\n\n“Typographical errors or null values in this identifier column resulted in a non negligible shift in **the summary statistics**, given the **enormous number** of tests conducted. Once the problem had been identified, there was **joint effort to clean it up**, combining **more than four** data streams and reducing the number of unidentified tests to **a number** that would not change **the inference**. Yet, there were still **a few** individually unidentifiable entries in the datasets, albeit **not enough a number** to raise a concern. Minimizing manual entry to data sources can reduce such issues by **a considerable amount**.”\n\nSection 5.2:\n\n“The data had been migrated from the old table to the new one in theory, but in part **user generated heterogeneity**, as well as version control issues in the HelpSpot source data meant there continued to be **gaps** in the data ingested by Health Cloud (Salesforce) which do not have simple workarounds for analysis of all variables. We maintain **several tables** for the test information storage, but there are **inconsistencies** across those tables. More than one tables exist mainly because we derived simpler versions of tables with many columns that are not relevant for **day-to-day analysis**.”\n\nSection 7.2\n\n“**One group** may in fact be more often in situations involving exposure to infectious persons, or engaged in more risky behavior than others, as we **occasionally** discovered from data analysis. However, available policy level changes **may not have been feasible solutions** and were not always ultimately enacted.”\n\n3. Unaddressed privacy concerns\n\nThe authors argued that they would “examine privacy-preserving techniques” and “security and privacy remained strict requirements”. While in section 7.2, the author also said “while it is within the rights of the university to use the WiFi access point information to “follow\" an individual or to understand who is within the same room, such information has a high ’icky factor’ and should be used sparingly.” Despite this, “it was decided to use WiFi data in aggregate to assess population movements rather than individuals’ proximity to other individuals”. Furthermore, the data is “shared”; “health data were collected and subsequently shared only to the extent they would have ’meaningful use”. It would be useful to clarify who it was shared to, what was shared, what training team members had, and describe in more detail the type of data that is collected and disseminated from tracking student’s WiFi locations, seemingly without their knowledge or permission. \n\n4. Other minor problems\n\nFigure 1 in the paper was presented without any accompanying explanations, leading to confusion among readers. The lack of clarification makes it difficult to comprehend the purpose and significance of the \"Personal Protective Equipment\" and \"Enhanced Cleaning\" sections, both of which are represented by equal green circles in the figure.\n\nAlso, “Behavior over analytics“ should be section 6.1 rather than section 7.\n\nIn general, the paper offers valuable experience in data management during the COVID-19 pandemic. However, there are several areas that require improvement. First, the paper should include more references and comparisons to support its findings and approaches. Additionally, the analysis section would benefit from a more detailed explanation of the methodologies employed. The clarity and logical presentation of results and takeaways also need to be enhanced. Furthermore, the paper should address privacy concerns associated with the data management practices discussed.","sentences":[{"sentence_type":"2","sentence":"The paper lacks citations to substantiate and compare the findings and approaches presented, which is a notable deficiency.","rephrased":"The paper would benefit from additional citations to substantiate and compare the findings and approaches presented, enhancing its academic rigor."},{"sentence_type":"2","sentence":"Additionally, the paper displays \"R(t) Numbers for Ohio\" in Figure 1, but fails to mention or discuss this important metric in the text, warranting a comprehensive review of the relevant literature to enhance its explanation.","rephrased":"It would be helpful if the paper included a discussion on the \"R(t) Numbers for Ohio\" presented in Figure 1, possibly supported by a review of the relevant literature to provide a clearer explanation."},{"sentence_type":"2","sentence":"Several statements in the paper lack clarity and precision, leading to confusion among readers.","rephrased":"Clarifying certain statements in the paper could help avoid potential confusion and enhance the precision of the information presented."},{"sentence_type":"2","sentence":"Moreover, the paper lacks explicit descriptions of tasks, analyses, or well-defined evaluations, despite drawing conclusions and using phrases such as \nNo improvement in the accuracy of the analysis of the effect of masking in a given setting\n and \nAfter careful consideration, it was agreed that singling out a group was often not enough of a value addition or could do more harm than good.\n","rephrased":"The paper could be strengthened by providing more explicit descriptions of tasks, analyses, and evaluations to support the conclusions drawn, such as the analysis of the effect of masking in a given setting."},{"sentence_type":"2","sentence":"Furthermore, the data is \nshared\n; \nhealth data were collected and subsequently shared only to the extent they would have \nmeaningful use\n. It would be useful to clarify who it was shared to, what was shared, what training team members had, and describe in more detail the type of data that is collected and disseminated from tracking student's WiFi locations, seemingly without their knowledge or permission.","rephrased":"For greater transparency, the paper could clarify the extent of data sharing, the training of team members, and provide more details on the type of data collected, particularly regarding the tracking of student's WiFi locations."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1148,1271,"Confirmed"],[1447,1672,"Confirmed"],[2130,2225,"Confirmed"],[2226,2412,"Missed by Model"],[5566,5676,"Missed by Model"]],"Comments":["Literally written by ChatGPT."]}
{"id":"uCE0xjCy9eR","text":"– Summary – \n\nThe paper proposes a new GAN method that applies the quantile regression of reinforcement learning into GAN and aims to show this helps to estimate the 1-Wasserstein distance better without gradient regularization. The idea of quantile regression presented in the paper is a way to match two distributions like WGAN-GP yet at a more grained level and need no regularization like WGAN-GP. The experiments are conducted on 2D-toy examples (Ring-8, Grid-25) as qualitative results and three other image datasets (CIFAR-10, LSUN-Bedroom, Cats) with FID scores. The proposed method is compared with some GANs baselines: SNGAN, LSGAN, and WGAN-GP. \n\n\n– Strength –\n\nS1 - The paper proposes a new idea to apply quantile regression into GANs.\n\n\n– Weakness –\n\nW1 - The paper is not well-written, and the paper representation is not good.\n\nW2 - The performance of the  proposed method does not look outperforming the WGAN-GP even though the paper strongly claims the robustness of this method. As shown in Fig. 4, 5, the proposed method converges faster, but is not necessarily better than WGAN-GP at the end. It looks WGAN-GP converges much more stable than the proposed method.\n\nW3 - It does not make sense why WGAN-GP is so bad on Cats dataset as shown in Fig. 6. It could be just the problem of parameters-tuning?\n\nW4 - It's unclear why Fig. 2 misses the WGAN-GP?\n\nW5 – The paper does not convince me why the proposed method is better than WGAN-GP in either theoretical and empirical results. In addition, the paper does not provide sufficient theoretical content to show the 1-Wasserstein distance is the same as minimizing quantile values as claimed.\n\nW6 - Many mathematical notions are not explained, e.g., What is $\\rho_{\\hat{\\tau}}$ in Eq. 4? How  do the authors implement with $a = \\infty$ and $b = -\\infty$?. How is $o_{i, \\tau}$ computed?\n\nW7 - FID scores alone may be biased, the combination with IS is required in the experiments.\n\nW8 – The experimental results are not sufficient, e.g., the results are with only standard DCGAN architecture, and the paper would need more ablation studies on some selected hyper-parameters, e.g., $a, b, N, k$ ... in the method.\n\nOverall, I think the paper is far to meet the conference's standard, e.g., at paper presentation, strong empirical or theoretical evidence to justify the claims. It also would need substantial revision to improve in writing. I tend to reject the paper.","sentences":[{"sentence_type":"2","sentence":"W1 - The paper is not well-written, and the paper representation is not good.","rephrased":"W1 - The clarity of the paper could be improved to better convey the research, and the presentation of the content may benefit from a more structured format."},{"sentence_type":"3","sentence":"Overall, I think the paper is far to meet the conference's standard, e.g., at paper presentation, strong empirical or theoretical evidence to justify the claims. It also would need substantial revision to improve in writing. I tend to reject the paper.","rephrased":"Overall, the paper requires further development to reach the conference's standards, particularly in terms of paper presentation and providing robust empirical or theoretical evidence to support the claims. A substantial revision, especially in the writing, could enhance the paper's potential for acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[764,841,"Confirmed"],[848,996,"Missed by Model"],[1377,1659,"Missed Maybe"],[1666,1709,"Missed Maybe"],[1954,1997,"Missed Maybe"],[2181,2433,"Maybe"]],"Comments":[]}
{"id":"o6BLRaz_PYN","text":"Positives\n\n+ The study seems to be interesting and maybe useful for practitioners.\n\nConcerns\n\n- Very meagre contribution in terms of technical novelty and framework. \n\n- Looks like an empirical study without much conviction and direction.\n\n- Experimental evaluation and comparisons seem dated, not state of the art.\n\n- The work is very much below the expected standards of ICLR.","sentences":[{"sentence_type":"2","sentence":"Very meagre contribution in terms of technical novelty and framework.","rephrased":"The contribution in terms of technical novelty and framework could be further elaborated to highlight its significance."},{"sentence_type":"3","sentence":"Looks like an empirical study without much conviction and direction.","rephrased":"The empirical study would benefit from a clearer articulation of its objectives and intended direction."},{"sentence_type":"2","sentence":"Experimental evaluation and comparisons seem dated, not state of the art.","rephrased":"Updating the experimental evaluation and comparisons to reflect the current state of the art would strengthen the paper."},{"sentence_type":"3","sentence":"The work is very much below the expected standards of ICLR.","rephrased":"The work could be improved to meet the high standards expected at ICLR."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[96,165,"Confirmed"],[170,238,"Confirmed"],[242,315,"Confirmed"],[319,378,"Confirmed"]],"Comments":[]}
{"id":"Sye4vhvq37","text":"The authors consider anomaly detection problem.\nThey claimed that typical methods do not perform well on multi-modal distributions.\nThe authors trained GAN to generate samples in low-density regions of the original probability density. Since a discriminator is trained to classify such samples from real data, mainly belonging to high-density regions of the original probability density, then the discriminator can be used to detect anomalies.\n\nComments\n1) the authors wrote that they develop a multi-modal one-class generative adversarial network based detector to distinguish anomalies from normal data (products). Which products?\nDid the authors develop their approach specifically only for some very particular engineering problem (from Samsung)? If so, then the better place for such papers is some industrial journal\/conference. If not, then the authors should provide comparisons using other datasets than  Samsung data\n2) the paper contains enormous number of\n- misprints, e.g. “meets all standards and requirements, fraud detection citepzheng2018one where it discriminate a “ (page 1, section 1)\n- mistakes in the text, bad wording, e.g. \"Experiments demonstrate that our model outperforms the state-of-the-art one-class classification models and other anomaly detection methods on both normal data and anomalies accuracy, as well as the F1 score\" (page 1, abstract)\n- mistakes in formulas, e.g. problems with subscripts in (7), problems with expectation sign in (9), etc.\nas a result, readability of the paper is very low. From the general explanation of the idea of the proposed algorithm in section 1 it is not possible to understand how it works\n3) the general idea (train GAN to generate samples in low-density regions of the original probability density; since a disrciminator is trained to classify such samples from real data, mainly belongning to high-density regions of the original probability density, then the discriminator can be used to detect anomalies) is nice. However, partially due to very bad text, partially due to errors in formulas it is not possible to understand technical description of the algorithm, e.g.\n- why do we need H()?\n- how do we model Q(c|x)?\n- how do we model p(c|x)?\n- how constants tau and C are selected?\n- etc\n4) Experimental section is not sufficient. The authors considered only one dataset which is proprietary\n5) The authors claimed that they do not need to tune the threshold to detect anomalies from other observations. But is this actually true? In fact, for the discriminator, which is used to detect anomalies, we still need to select some threshold expressing our confidence in whether the considered observation is anomalous or not\n\nConclusion\n- the idea is interesting\n- the paper is not OK for very high standards of ICLR\n","sentences":[{"sentence_type":"2","sentence":"If so, then the better place for such papers is some industrial journal\/conference.","rephrased":"If the approach is tailored to a specific engineering problem, it would be beneficial to clarify its broader applicability or consider including comparisons with other datasets to strengthen the paper's relevance to a wider audience."},{"sentence_type":"2","sentence":"as a result, readability of the paper is very low.","rephrased":"The readability of the paper could be improved by addressing these issues, which would help in better understanding the proposed algorithm."},{"sentence_type":"3","sentence":"However, partially due to very bad text, partially due to errors in formulas it is not possible to understand technical description of the algorithm","rephrased":"The technical description of the algorithm could be made clearer by revising the text and correcting the errors in the formulas, which would facilitate a better understanding of the proposed method."},{"sentence_type":"3","sentence":"the paper is not OK for very high standards of ICLR","rephrased":"The paper would benefit from further refinement to meet the high standards expected at ICLR, particularly in terms of clarity and experimental validation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[751,834,"Not concerning"],[930,967,"Missed by Model"],[1107,1140,"Missed by Model"],[1482,1532,"Confirmed"],[1533,1658,"Missed by Model"],[1988,2136,"Confirmed"],[2266,2305,"Missed by Model"],[2736,2787,"Maybe"]],"Comments":[]}
{"id":"QfLY27FVUVM","text":"Originality:\n\nThe idea of introducing counterfactual learning into link prediction is novel. The authors introduce a new method of link prediction that combines graph neural networks and counterfactual learning.\n\nQuality: \n\n- The theoretical background is not clear enough. The formulated problem in this paper is to estimate individual treatment effects (ITE). In causal inference, assumptions are required in order to make individual causal effects identifiable, e.g., consistency, no-hidden confounders, etc. The authors should clarify and discuss these assumptions.\n\n- The authors claim that employing counterfactual learning can help train the model to capture more essential factors on the outcome. They obtain results of ATE and link prediction based on different treatments (see Table 4 and 5). However, the results are a little confusing. It is unclear how this method captures essential factors. The authors are supposed to provide more results or explanations to support their claim.\n\nClarity:\n\n+ Overall, this paper is well organized. The technical part is mostly clear. \n\n- The problem proposed in the introduction is not fully supported by the experiments. Specifically, the authors claim that answering counterfactual questions can help capture essential factors to accurately predict missing links in the test data. There is no evidence to show how this works.\n\n- The authors propose an approximation for finding counterfactual links (Eq. 3). There are no experimental results to show that the approximation method produces results similar to those in Eq. 2. Will different counterfactual link generation methods affect the model's link prediction results?\n\n- The introduction of Balancing Counterfactual Learning is not very clear. The authors should introduce the formal definitions of PˆF_f and PˆCF_f in Eq. 10. \n\n- In Figure 2, the results show that beta (balancing counterfactual learning) does not have much influence on AUC performance. Meanwhile, as the authors mentioned, AUC is an easier metric than Hits@20. The sensitivity results on Hits@20 are missing.\nEq. 8 and 9 are unclear. The training is conducted only on the training data. The loss should not be calculated based on all links, e.g., for loop N nodes.\n\n- The link prediction results need more explanation (see Significance).\n\nSignificance: \n\n- In this work, the authors first generate counterfactual samples and then train the proposed method based on the new data and original data. The contribution of this work seems limited except involving the concept of counterfactual learning. In short, the authors seem to add more samples to train a model for improving the link prediction performance. \n\n- The link prediction results need more explanation. Why does counterfactual learning help link prediction? There is a jump from treatment effects learning to link prediction. Meanwhile, since baselines are trained on original data (without counterfactual data), is this comparison fair?\n\n- There are some related works that should be included. The following published work seems to have achieved better AUC results in link prediction than the proposed method in this paper on the Cora and Citeseer datasets.\n\n(1) Davidson, T.R., Falorsi, L., De Cao, N., Kipf, T. and Tomczak, J.M., 2018. Hyperspherical variational auto-encoders. arXiv preprint arXiv:1804.00891.\n\n(2) Yang, H., Pan, S., Zhang, P., Chen, L., Lian, D. and Zhang, C., 2018, November. Binarized attributed network embedding. In 2018 IEEE International Conference on Data Mining (ICDM) (pp. 1476-1481). IEEE.\n\nMinor issues:\n- It would be better to describe terms consistently, e.g., individualized treatment effect and individual treatment effect.    \n- It would be clearer to draw balancing counterfactual learning in Fig.1(b).\n- It would be helpful to explain the ratio of created CF samples for each dataset (i.e., how many samples satisfy Eq.3). This might help evaluate the performance of the proposed model.\n\nThanks to the authors for the response.\n\n","sentences":[{"sentence_type":"2","sentence":"The contribution of this work seems limited except involving the concept of counterfactual learning.","rephrased":"While the paper introduces the concept of counterfactual learning, the authors could further elaborate on the unique contributions of their work beyond this aspect."},{"sentence_type":"2","sentence":"In short, the authors seem to add more samples to train a model for improving the link prediction performance.","rephrased":"The authors might consider clarifying how the addition of more samples through counterfactual learning uniquely contributes to improving link prediction performance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[906,994,"Missed Maybe"],[1332,1376,"Missed by Model"],[2472,2572,"Not concerning"],[2573,2683,"Not concerning"]],"Comments":[]}
{"id":"BJlmMxzQ54","text":"The paper considers the problem of domain generalization: how to learn representations given data from a set of domains that generalize to data from a previously unseen domain.\n\nThe paper needs to better define \"domain invariant\". The rotated MNIST dataset is used for evaluation. But I do not think rotated images are from different domains. The paper needs more convincible experiments to prove the effectiveness of the proposed methods.","sentences":[{"sentence_type":"2","sentence":"But I do not think rotated images are from different domains.","rephrased":"It may be beneficial to clarify how rotated images constitute different domains, as this is not immediately apparent."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[281,342,"Maybe"]],"Comments":[]}
{"id":"HJgWFLdXYV","text":"This work presents a generative model for protein backbones (graphs). A GAN is used to generate a map of all pairwise distances among nodes. Then, an autoencoder-like network tries to place the nodes in the 3D space. Finally a refinement process is used to improve the output. A set of qualitative evaluations suggest positive results.\n\nI believe that this paper is interesting to be accepted in the workshop. \n\nOverall, many aspects of the paper are related to the application of protein folding that I feel unqualified to judge. I would have found useful a better introduction to the problems in the area to understand the application.\n\n* The evaluation seems interesting but I would have hoped for a more quantitative evaluation. Although I do not know of the domain-specific metrics, a common theme in such papers is to compare the probability distributions of some extrinistic characteristics of molecules\/proteins between sample in the dataset and generated samples. The current qualitative results are nice and reasonable for a workshop paper, but this leaves no way for future work to compare to this one.\n\n* Currently, the generation of the distance maps, the recovery network and the refine modules are trained separately. It would be nice if the authors could explain why they avoided an end-to-end training procedure. Is there an optimization issue? Is this somehow related to the application?\n\n* The generated proteins are of fixed length (64). I assume that this isn't true of all proteins. (a) How does this method scale with the size of these proteins? (b) Does the current framework allow for variable-sized graphs?","sentences":[{"sentence_type":"1","sentence":"Overall, many aspects of the paper are related to the application of protein folding that I feel unqualified to judge.","rephrased":"While the paper covers many aspects of protein folding, an area I'm less familiar with, a more comprehensive introduction to the field would have been helpful for a broader audience to understand the significance of the application."},{"sentence_type":"2","sentence":"The current qualitative results are nice and reasonable for a workshop paper, but this leaves no way for future work to compare to this one.","rephrased":"The qualitative results are a good starting point, especially for a workshop paper. However, including some quantitative metrics would enhance the ability for future research to benchmark against these findings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[412,530,"Not concerning"],[973,1113,"Not concerning"]],"Comments":[]}
{"id":"m8yWndCrHma","text":"Strengths:\n- Comprehensive set of experiments on a tabular network and corresponding datasets using a single dataset\n\nWeaknesses:\n- Lack of novelty; see below\n- Lack of clarity and experimental details.\n","sentences":[{"sentence_type":"2","sentence":"Lack of novelty; see below","rephrased":"The novelty of the study could be further highlighted or elaborated upon."},{"sentence_type":"2","sentence":"Lack of clarity and experimental details.","rephrased":"The paper would benefit from additional clarity and more detailed experimental procedures."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[132,158,"Maybe"],[161,202,"Confirmed"]],"Comments":[]}
{"id":"H1eeyvnq2Q","text":"The authors state that their goal with this paper is manifold:\nThey want to learn a prior over neural networks for multiple tasks. The posterior should go beyond mean field inference and yield good results.  The authors claim in their paper that they learn an 'expressive transferable prior over the weights of a network' for multi-task settings, which they denote with the unfortunate term 'deep prior'.\n\nIn sec. 2.1 the authors introduce the idea of a hierarchical probabilistic model of weights for a neural network p(W|a) conditioned on task latent variables p(a). They realize that one might want to generate those weights with a function which conditions on variable \"z\" and has parameters \"a\". They continue their argument in Sec 2.2 that since the weight scoring can be canceled out in the ELBO, the score of the model does not depend on weights \"w\" explicitly anymore.\nThis, of course, is wrong, since the likelihood term in the ELBO still is an expectation over the posterior of q(w|z)q(z). \nHowever, the authors also realize this and continue their argumentation as follows:\nIn this case -according to the authors- one may drop the entire idea about learning distributions over weights entirely.\nThe math says: p(y|x ; a) = int_z p(z) int_w p(w|z ; a) p(y|x, w)dw dz.\nSo the authors claim that a model p(y|x, z) which only conditions on 'z' is the same as the full Bayesian Model with marginalized weights. They then suggest to just use any neural network with parameters \"a\" to model this p(y|x, z ;a) directly with z being used as an auxiliary input variable to the network with parameters \"a\" and claim this is doing the same. This is of course utterly misleading, as the parameter \"a\" in the original model indicated a model mapping a low dimensional latent variable to weights, but now a maps to a neural network mapping a latent variable and an input vector x to an output vector y. As such, these quantities are different and the argument does not hold. Also a point estimate of said mapping will not be comparable to the marginalized p(y|x).\n\nWhat is more concerning is that the authors claim this procedure is equivalent to learning a distribution over weights and call the whole thing a deep prior, while this paper contains no work on trying to perform the hard task of successfully parametrizing a high-dimensional conditional distribution over weights p(w|z) (apart from a trivial experiment generating all of them at once  from a neural network for a single layer in a failed experiment) but claims to succeed in doing so by circumventing it entirely. \n\nIn their experiments, the authors also do not actually successfully try to really learn a full distribution over the weights of a neural network. This alone suffices to realize that the paper appears to be purposefully positioned in a highly misleading way and makes claims about weight priors that are superficially discussed in various sections but never actually executed on properly in the paper.\nThis is a disservice to the hard work many recent and older papers are doing in actually trying to derive structured hierarchical weight distributions for deep networks, which this paper claims is a problem they find to be 'high dimensional and noisy', which is exactly why it is a valid research avenue to begin with that should not be trivially subsumed by work such as this.\n\nWhen reducing this paper to the actual components it provides, it is a simple object: A deterministic neural network with an auxiliary, task-dependent latent variable which provides extra inputs to model conditional densities.\nSuch ideas have been around for a while and the authors do not do a good job of surveying the landscape of such networks with additional stochastic input variables.\nOne example is \"Learning Stochastic Feedforward Neural Networks\" by Tang and Salakhutdinov, NIPS 2013, a more recent one is \"Uncertainty Decomposition in Bayesian Neural Networks with Latent Variables\" by Depeweg et al 2017.\nAn obvious recent example of multi-task\/meta\/continual learning comparators would be \"VARIATIONAL CONTINUAL LEARNING\" by Nguyen et al. and other work from the Cambridge group that deals with multi-task and meta-learning and priors for neural networks.\n\nAnother weakness of the paper is that the main driver of success in the paper's experiment regarding classification is the prototypical network idea, rather than anything else regarding weight uncertainty which seems entirely disentangled from the core theoretical statements of the paper.\n\nAll in all, I find this paper unacceptably phrased with promises it simply does not even attempt to keep and a misleading technical section that would distort the machine learning literature without actually contributing to a solution to the technical problems it claims to tackle (in relation to modeling weight uncertainty\/priors on NN). Paired with the apparent disinterest of the authors to cite recent and older literature executing strongly related underlying ideas combining neural networks with auxiliary latent variables, I can only recommend that the authors significantly change the writing and the attribution of ideas in this paper for a potential next submission focusing on multi-task learning and clarify and align the core ideas in the theory sections and the experiment sections.\n","sentences":[{"sentence_type":"2","sentence":"This is of course utterly misleading, as the parameter \"a\" in the original model indicated a model mapping a low dimensional latent variable to weights, but now a maps to a neural network mapping a latent variable and an input vector x to an output vector y.","rephrased":"This could potentially be misleading, as the parameter \"a\" in the original model was intended to map a low dimensional latent variable to weights, whereas now it seems to map to a neural network that combines a latent variable and an input vector x to produce an output vector y."},{"sentence_type":"3","sentence":"This alone suffices to realize that the paper appears to be purposefully positioned in a highly misleading way and makes claims about weight priors that are superficially discussed in various sections but never actually executed on properly in the paper.","rephrased":"This raises concerns that the paper may inadvertently give an impression of being misleading and that the claims about weight priors, while discussed, do not seem to be fully substantiated with practical execution within the paper."},{"sentence_type":"3","sentence":"This is a disservice to the hard work many recent and older papers are doing in actually trying to derive structured hierarchical weight distributions for deep networks, which this paper claims is a problem they find to be 'high dimensional and noisy', which is exactly why it is a valid research avenue to begin with that should not be trivially subsumed by work such as this.","rephrased":"It is important to acknowledge the extensive efforts of other researchers in deriving structured hierarchical weight distributions for deep networks. The paper describes this as a 'high dimensional and noisy' problem, which underscores its significance as a research avenue and suggests that it warrants a more thorough exploration than what is presented."},{"sentence_type":"3","sentence":"All in all, I find this paper unacceptably phrased with promises it simply does not even attempt to keep and a misleading technical section that would distort the machine learning literature without actually contributing to a solution to the technical problems it claims to tackle (in relation to modeling weight uncertainty\/priors on NN).","rephrased":"Overall, the paper could benefit from clearer phrasing and more efforts to fulfill its stated objectives. The technical section could be improved to better contribute to the field, particularly in addressing the challenges of modeling weight uncertainty and priors on neural networks."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1641,1899,"Confirmed"],[2062,2576,"Missed Maybe"],[2725,2979,"Confirmed"],[2980,3357,"Confirmed"],[4520,4859,"Confirmed"],[4860,5317,"Missed by Model"]],"Comments":[]}
{"id":"SJgrEg0sKr","text":"Update: I thank the authors for their response and I think the added baselines and more in depth discussion of prior work have improved the paper. However, given the limited novelty of the technical contribution, I believe the experimental section should be further extended (i.e. add a wider variety of domains and make thorough comparisons to relevant methods) in order to draw more general and robust conclusions. \n\nSummary:\n\nThis paper proposes tackles the problem of exploration in RL, with a focus on learning an exploration policy that can be used for a variety of different tasks. They introduce a formal exploration objective that promotes efficient exploration and provides a mechanism for injecting prior knowledge about the task. They also design a practical algorithm to maximize the exploration objective. Finally, they empirically show that  their method can outperform other SOTA exploration methods on challenging exploration tasks for locomotion and manipulation,  both in simulation and in the real world.\n\nMain Comments:\n\nI’ve found the mathematical formulation to be sound and the empirical evaluation convincing. Overall, the paper is clearly written and the authors are quite transparent about the assumptions made. In addition, the problem of learning exploration strategies that are task-agnostic and force the agent to effectively explore within each episode (since the goal or task is not observed) is an important problem for RL and perhaps a more realistic setting than the single fixed-task one. However, I believe some important methodological details are missing from the paper and the empirical evaluation can be improved. In particular, the paper would be more convincing if it contained comparisons against SOTA exploration (e.g. curiosity-driven, pseudo-counts, noisy-networks etc.) and inverse reinforcement learning (e.g. GAIL) methods for all the environments. Such baselines are completely missing in the Navigation and Real-World tasks. \n\nHowever, as the authors note, most baselines used for comparison have been designed specifically to learn from sparse rewards in single task settings and do not have any direct mechanisms for including priors or learning to explore well for any task from some distribution. So I wonder if it’d make sense to include baselines that do make use of prior knowledge such as IRL (i.e. GAIL) or some other state-matching approach. Those could be more appropriate and powerful baselines. \n\nAnother potential disadvantage of this method seems to be the need for a prior, which may be difficult to design or even lead to suboptimal policies if it is not well designed. However, as the authors note, it is still a weaker requirement than having access to demonstrations for example and the  prior could potentially be learned from human preferences \/ restricted feedback. \n\nOther Comments  \/  Questions:\n\n1. SMM uses prior information about the task in the form of the target distribution. Given this, I am worried that the baselines have a clear disadvantage. Did you do anything to provide the baselines with the same type of prior knowledge about the task? It would be useful to see how they would compare if they had access to the task prior (in some way) as well. \n\n2. Can you provide more insights into how this differs from variants of MaxEntRL and InvRL? Both analytically and in practice. I believe a more extended discussion of this would be valuable for readers and would alleviate some of the concerns regarding the novelty of this contribution and how its place in the broader literature.\n\n3. In the Navigation environment, how would the  results change if the goal were visible  (i.e. part of the agent’s observation)? I believe that most baselines would consider that scenario and it would  be interesting to see whether the qualitative conclusions hold or not in that case. I would expect other exploration methods to  be faster in that case.\n\n4. I also wonder if perhaps the reward is actually not that sparse  in some of these tasks but  because it is not visible, it makes the problem much harder for the baselines, which were designed to deal with very sparse reward. Can you comment on the reward sparsity in these tasks?\n\n5. At the top of page 2, you mention that there is a training phase in which the agents learn to optimize the exploration objective and at test time, it is trained with extrinsic reward. Can you please clarify on how these stages reflect in the results and what is  the regime used for the other baselines? Are they also pretrained on a variety of tasks with only their exploration bonus \/ intrinsic reward and then fine-tuned with extrinsic reward?\n\n6. In Figure 2 (c), why is it that the gap between SMM and SAC decreases as the  number  of halls increases? This seems counterintuitive and I would’ve expected to increase since I do not see why SAC would get better and SMM would get worse. \n\n7. How do you learn the density model? You mention the use of a VAE but the details of how this is trained are not specified.\n\n8. On page 5 before section 4,  you mention that you approximate the historical average  of the density model with the most recent iterate. Can you include ablations on how good this approximation is and how the results change  if you were using the historical average instead?\n\n9. In Figure 4 (b), SMM’s variance of the positive value of the angle differs significantly from the negative one. This strikes me as counterintuitive. Do you have any  intuition on why that is?\n\n\n\n\n\n\n","sentences":[{"sentence_type":"2","sentence":"However, given the limited novelty of the technical contribution, I believe the experimental section should be further extended","rephrased":"While the technical contribution is somewhat incremental, enhancing the experimental section with additional domains and comparisons could strengthen the paper's impact."},{"sentence_type":"1","sentence":"However, I believe some important methodological details are missing from the paper and the empirical evaluation can be improved.","rephrased":"The paper would benefit from including additional methodological details and further empirical evaluation to support its findings."},{"sentence_type":"2","sentence":"Such baselines are completely missing in the Navigation and Real-World tasks.","rephrased":"Incorporating baselines for the Navigation and Real-World tasks would provide a more comprehensive evaluation of the proposed method."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[147,274,"Not concerning"],[1526,1655,"Not concerning"],[1900,1977,"Confirmed"]],"Comments":[]}
{"id":"bTMoOJMy8cp","text":"### Summary of the paper\nThis paper proposes to improve retrosynthesis models with pre-training and self-training techniques. For pre-training, the model is trained on the USPTO reaction dataset and fine-tuned on USPTO-50K dataset. For self-training, the model is trained on artificial reaction instances generated by the model (i.e., back-translation). The pre-training based approach greatly improves the seq2seq retrosynthesis model and achieves comparable performance against graph based methods.\n\n### Strength\n1) The paper conducts extensive experiments for various training paradigms: joint training, self-training and pre-training. For pre-training, authors try different options of the pre-training dataset (USPTO, USPTO-MIT). \n2) The self-training approach is an interesting application of back-translation.\n\n### Weakness\n1) Technical novelty is very weak. The pre-training approach is not novel. It is simply training on a larger training set, leveraging additional data. The self-training approach is not novel either -- it is a simple application of back-translation, which is well-studied in machine translation in NLP.\n2) The performance is weak. From Table 2, we can see that current state-of-the-art are graph-to-graph based approaches. The best result of this paper is worse than the state-of-the-art (for 1,3,5-best accuracy), even though it is trained on additional data.\n3) In principle, the pre-training method is not limited to seq2seq retrosynthesis models, but authors only apply pre-training for the seq2seq transformer architecture, which performs much worse than graph-to-graph methods.\n\n### Overall evaluation and suggestions\nI vote for rejection. Unfortunately, the weakness of the paper greatly outweighs the strength. I am afraid the technical novelty is too weak for ICLR. The results are unsatisfactory due to lower 1-best accuracy compared to prior methods. To improve the paper, authors should try to apply pre-training to graph-to-graph models, which may lead to new state-of-the-art results. Since your pre-training is just training on a larger dataset, it shouldn't be too hard to do.\n\n### Post rebuttal\nI would like to thank all the reviewers for valuable feedback. My review score stays the same.","sentences":[{"sentence_type":"2","sentence":"Technical novelty is very weak.","rephrased":"The technical novelty could be further emphasized, as it appears to be incremental based on the current presentation."},{"sentence_type":"2","sentence":"The performance is weak.","rephrased":"The performance could be improved, particularly when comparing the 1-best accuracy to current state-of-the-art methods."},{"sentence_type":"1","sentence":"I vote for rejection.","rephrased":"Based on the current submission, I would recommend rejection, but I encourage the authors to address the weaknesses highlighted."},{"sentence_type":"2","sentence":"Unfortunately, the weakness of the paper greatly outweighs the strength.","rephrased":"The strengths of the paper do not fully mitigate the concerns raised regarding its weaknesses."},{"sentence_type":"2","sentence":"I am afraid the technical novelty is too weak for ICLR.","rephrased":"The technical novelty might not meet the high standards expected for ICLR."},{"sentence_type":"2","sentence":"Since your pre-training is just training on a larger dataset, it shouldn't be too hard to do.","rephrased":"Given that the pre-training involves using a larger dataset, it may be feasible to extend this approach to other models."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[834,865,"Confirmed"],[866,981,"Missed by Model"],[982,1132,"Missed by Model"],[1136,1160,"Confirmed"],[1253,1390,"Missed Maybe"],[1654,1675,"Maybe"],[1676,1748,"Confirmed"],[1749,1804,"Not concerning"],[1805,1891,"Missed Maybe"],[2029,2122,"Maybe"]],"Comments":[]}
{"id":"Z1qrdCKURyf","text":"The paper tackles an important problem in the current literature around applications of ML to 3D computer vision, i.e. learning from 3D lidar data. The two methods that this work aims to improve are quite recent (2020) and to the best of my knowledge represent the state of the art  for sequentially processing portions of an entire lidar scan. \n\nOne limitation of this work is represented by the overall novelty of the method. Since the idea is to provide a representation of the input data that better fits the circular portions wrt. [11,13], this has an incremental nature wrt. the work in [11,13], since it can be regarded as an optimization of that idea. Also the idea of undistorting feature to let a NN process a non-cartesian input representation is not novel but shares similarities with previous work [a,b]\n\nThe results provided in Table 1 show the usefulness of the proposed approach against [11,13], and the authors also provide a nice discussion trying to explain the reasons for this superiority in Section 5.3. Nevertheless, extending Table 1 to include a comparison against the state of the art would have been useful to properly position the performance of the proposed approach with respect to the current literature. The results in Figure 5 go a bit in this direction and, from the provided charts, it seems like the current approach is still behind in terms of detection and semantic segmentation, while reports state of the art results in panoptic segmentation. \n\nThe paper is sometimes hard to read, due to the presence of typos as well as sentences that contains mistakes or are simply hard to understand. To improve the readability, especially around the methodology explanation, a careful review of the language used would be beneficial. \n\nTaking everything into account I believe the paper falls short of requirements for acceptance especially with regards to the novelty and presentation aspects. \n\nAdditional points:\n- line 118: point are accumulated from 10 successive frames: how did the author pick this specific parameter, and what is the weight of this value on the performance?  \n- line 181: the Range Stratified Normalization normalizes over individual regions within a certain range rather than on the entire spatial domain: how are these regions selected? It seems to me like the choice\/number of regions should be triggered on the distance of objects and scene components with respect to the sensor. As these regions seem to be obtained by discretizing the spatial range, what happens to an object lying in between two regions? Would it receive two different normalizations?\n\nReferences\n[a] Yu-Chuan et al, Flat2sphere: Learning spherical convolution for fast features from 360 imagery. In: Proc. Conf. on Neural Information Processing Systems (NIPS) (2017)\n[b] Coors et al, SphereNet: Learning Spherical Representations for Detection and Classification in Omnidirectional Images, ECCV 2018.\n\n\n---\nPost rebuttal comment:\n\nAfter going through the rebuttal and the comments from the other reviewers I feel my initial thoughts on the paper are confirmed. The method looks at an important problem but falls short in terms of novelty, clarity and experiments. In particular I share the concerns with reviewer X4zp around the justification of polar coordinates stemming from the results presented in the paper, as well the readability issues that are raised across all reviewers. On a more minor note, the authors acknowledged in their rebuttal the lack of a more thorough review of related work around weight undistortion relatively to the citations that I suggested. While I agree the method is substantially different from those in the literature, a proper reference to the state of the art in this particular field is important to bring the proposed contribution into context. I am thus confirming my initial rating.","sentences":[{"sentence_type":"2","sentence":"Taking everything into account I believe the paper falls short of requirements for acceptance especially with regards to the novelty and presentation aspects.","rephrased":"Taking everything into account, while the paper presents interesting ideas, I believe there is room for improvement in terms of novelty and presentation to meet the acceptance criteria."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1765,1923,"Maybe"]],"Comments":[]}
{"id":"ByluvC8iYN","text":"This paper proposes an invertible transformation, similarly to a normalizing flow, that partitions the domain of a continuous density into non-overlapping regions, and uses a piece-wise invertible mapping for each of these regions.\n\nFrom the abstract, it may seem that the authors will tackle the case where x is a discrete variable; however the transformation is for distributions continuous support; I suggest to rewrite the abstract to avoid that misunderstanding.\n\nThe idea of the paper seems promising. My main concerns are of practical nature. In particular, the method introduces many parameters (the partitioning of the regions, the piece-wise mappings, etc.) that seem hard to tune in practice. Can the authors discuss how (and give the rationale why) to set all of these components their specific choices?\n\nAlso, how does the proposed approach scale with dimensionality? It is hard to partition a high-dimensional space into meaningful regions.\n\nNotation: What is K in the paper? It must be a set, since |K| is the number of components, what K isn't defined anywhere in the paper.\n\nTypo: patternm => pattern\n","sentences":[{"sentence_type":"2","sentence":"It is hard to partition a high-dimensional space into meaningful regions.","rephrased":"Partitioning a high-dimensional space into meaningful regions can be challenging. Could the authors elaborate on how their method addresses this complexity?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[881,954,"Not concerning"]],"Comments":[]}
{"id":"SJx4acHDYN","text":"In this paper, the authors address the problem of potential dependency between classes and domains in domain generalization. Based on remarks from Xie et al. (2017), they propose a new objective function AFLAC, which (provably) enforces accuracy-constrained domain invariance at its optimum.\n\nThe positioning towards related works is clear, the technical analysis is brief but precise. The experiments are well conducted and show both an improvement over the state of the art (including recent approaches) and robustness toward the choice of the hyperparameter.\n\nA longer version of this work could include a more detailed scenario of the practical application of this method, as well as experiments on more real datasets (unlike BMNISTR) illustrating the precise advantage of AFLAC on this data.","sentences":[{"sentence_type":"1","sentence":"The technical analysis is brief but precise.","rephrased":"The technical analysis is concise and precise, which is commendable."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"Hkl1gmPvnV","text":"This paper discusses the topic of model reconciliation, attempting to extend it from use in a human supervisor-robot subordinate interact to be useful in a human teammate-robot teammate interaction. The paper has several major failings: first, it's very unclear about its motivations and intent; it completely forgoes any wrap-up that might shed light on what the authors thought they had accomplished. Second, it's very difficult to read from a technical perspective, relying heavily on notation that appears to be somewhat inconsistently used. Third, it focuses half of its length (two of four pages) on review of prior material. It satisfies neither as a summary of prior work nor discussion of an advancement. I think that this paper is trying to do too much in too little space. As a 4-page paper,  the authors would do well to focus on either a broad discussion of the bidirectional model reconciliation problem, with less detail; or, a discussion of primarily new material, forgoing the existing human supervisor case, with additional detail on the human teammate case.\n\nSpecific notes:\nDescription and asymmetry of scenarios 1 and 2 on page 1 are very confusing.\nHow is Delta R represented?\n\"Task Model\" used on page 2 with no definition.\nIt's not clear in Human Supervisor\\Robot Knows Better on page 3 why the objective is (apparently) to update MRhr rather than MH, if MR is correct, but MH is wrong.\nIn the Human Supervisor\\Robot Knows Better use case, an explanation is described as updating MRhr, but it seems as if MRh would be more appropriate.\nHuman Supervisor\\Human Knows Better: Why is human modelled as successfully updating MR, but robot only as successfully updating MRhr? This indicates that users are expected to already understand the system perfectly, whereas the opposite assumption is not made. You state this assumption relatively clearly later, but then claim that you use discussion to get around it, so why is it asymmetric?\nHuman Teammate: \"with computational power on its side\"? Are you trying to argue that the robot processor is faster than the human brain? This sounds controversial at best.\nHuman Teammate \\ Robot Knows Better: \"MHr is more accurate than MH\" seems like apples and oranges. The robot understands the human's understanding of the world better than the human understands the world? How do you even compare that? \nOne alternate interpretation, that \"MHr is a better model of MH than MH itself\" is trivially false. \nAnother alternate interpretatin says that \"MHr is a better model of the world than MH\". This only says that MHr is a bad model of MH, though. ","sentences":[{"sentence_type":"2","sentence":"I think that this paper is trying to do too much in too little space.","rephrased":"The paper could benefit from a more focused scope given its length, either by providing a broad overview of the bidirectional model reconciliation problem or by delving deeper into new material with more detail on the human teammate case."},{"sentence_type":"1","sentence":"It's not clear in Human Supervisor\\Robot Knows Better on page 3 why the objective is (apparently) to update MRhr rather than MH, if MR is correct, but MH is wrong.","rephrased":"The rationale for updating MRhr instead of MH in the Human Supervisor\\Robot Knows Better scenario on page 3 could be clarified, especially when considering that MR is correct and MH is incorrect."},{"sentence_type":"2","sentence":"Are you trying to argue that the robot processor is faster than the human brain? This sounds controversial at best.","rephrased":"The statement regarding the robot's computational power compared to the human brain is quite bold and could benefit from further explanation to support this claim."},{"sentence_type":"1","sentence":"This only says that MHr is a bad model of MH, though.","rephrased":"This could imply that MHr may not be an accurate representation of MH, which might need further discussion or evidence."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[199,402,"Missed by Model"],[403,545,"Missed Maybe"],[546,713,"Missed Maybe"],[714,783,"Not concerning"],[1094,1170,"Missed by Model"],[1247,1410,"Maybe"],[2012,2127,"Maybe"],[2333,2362,"Missed by Model"],[2364,2463,"Missed by Model"],[2553,2606,"Not concerning"]],"Comments":[]}
{"id":"S1eiR7w-67","text":"Thanks for submitting your paper. It takes a lot of effort and courage to put your ideas out into the world. Sometimes the hardest work for researchers is conveying their thoughts to others in a manner in which those ideas can be understood.\n\nWith that in mind, I had an extremely difficult time following your arguments. \n\nI noticed several things:\n - There are numerous places in the text that lack proper citation, or are cited improperly.\n\n - Why was there not a related methods section? I find it hard to believe that all of your ideas have no precursor.\n\n - When there are citations, there is usually only one text and it is quite old. For example, all of your neuroscience citations reference a work that is almost 40 years old. There have been quite a few improvements in our biological understanding as well as theoretical understanding since then. ( I make this point as a common justification used in the manuscript is that the method describes how synapses function in biology. )\n\n- There is a claim regarding how this can be used in fintech. This statement doesn't belong in this work.\n\n - There are many different equations given throughout the text. Some of these equations come from areas like physics or information theory, and others seem to be of your own design. Regarding the latter, there is no justification or explanation for the origin of the equations. Regarding the former, if you are using equations from lots of different fields, or even field you think part of your audience might not be familiar with, you should, at the very least, include a some description of the algorithm or intuition as to why it is being leveraged.\n\n - It wasn't clear from your diagrams or your descriptions what the difference between a synapse and a neuron was in your architecture. It seemed like the name was used interchangeably in some areas, but then had a strict definition in others.\n\n - I was also not able to understand how the excitatory and the inhibitory connections that were to enter each neuron were connected to the previous layer of the network. Is a link between neurons in Figure 2 actually two links? If this is the case, then it is a direct violation of Dale's law. Again, I only mention this because most arguments seem to be of the form \"this is correct because it is how it is done biologically\".\n\n - There were a few claims made in the paper that were completely unsubstantiated. A good example of this was in the conclusion section part ii) where it was stated that \"using a large number of synapses and neurons SynaNN can solve the complex problems in the real world.\"\n\n- Also, the last sentence of the conclusion was not discussed anywhere in the rest of the paper. Nor was the statement itself supported except with a single citation and no description.\n\nRegarding the empirical testing of your algorithm, I was very dissapointed to see that the only dataset it was tested against was MNIST. Furthermore there was absolutely no benchmarking against other comparative algorithms. At the very least I would have expected a comparison to the perceptron algorithm that you use as inspiration, but that would also still not have been enough.\n\nThis paper needs heavy amounts of work to make it understandable. Once it is understandable an attempt to evaluate the merit of the scientific contribution would then be possible.","sentences":[{"sentence_type":"2","sentence":"I had an extremely difficult time following your arguments.","rephrased":"I found some sections of the arguments challenging to follow and would appreciate further clarification."},{"sentence_type":"2","sentence":"Why was there not a related methods section? I find it hard to believe that all of your ideas have no precursor.","rephrased":"Could you please include a related methods section? It would be helpful to understand the context and background of your ideas."},{"sentence_type":"2","sentence":"This statement doesn't belong in this work.","rephrased":"The relevance of this statement to the work is unclear and could benefit from additional explanation or context."},{"sentence_type":"2","sentence":"I was very dissapointed to see that the only dataset it was tested against was MNIST.","rephrased":"It would strengthen the paper to test the algorithm against a wider variety of datasets beyond MNIST."},{"sentence_type":"2","sentence":"This paper needs heavy amounts of work to make it understandable.","rephrased":"The paper would benefit from substantial revisions for clarity to enhance its understandability."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[262,321,"Confirmed"],[447,559,"Confirmed"],[564,641,"Missed by Model"],[1055,1098,"Confirmed"],[2333,2412,"Missed by Model"],[2607,2790,"Missed by Model"],[2843,2928,"Maybe"],[2929,3173,"Missed by Model"],[3175,3240,"Confirmed"],[3241,3354,"Missed by Model"]],"Comments":[]}
{"id":"r1eGgJ6h5r","text":"I thank the authors for the clarifications and the modifications to the paper. However, I still lean towards rejection. While the authors provided detailed explanations on some of my points here, most of these are still not in the paper, so the reader would still probably be confused. There are new figures in the appendix, but they are not referred to from the text. The paper feels like a hastily compiled collection of weakly related, somewhat anecdotal and not necessarily clearly explained and motivated experiments. While I believe there is interesting content, with the current presentation style it is really difficult to digest. As an advice, I think it may be better to not squeeze in all the results into one paper, but rather focus on some aspects and analyze them really well, with clear explanation, motivation, and preferably with demonstrating practical gains that result from the analysis - not just hypothetical, but supported by experiments.\n\n---\n\nThe paper studies transfer of representations learned by deep networks across datasets and tasks. Namely, the paper analzes the standard setup with pre-training on one dataset and further fine-tuning on a different  dataset. Results include both experiments and theory. On the experimental side, the focus is mainly on TODO. On the theory side, an analysis of transfer in two-layer fully connected networks, based on the ICML-2019 work of Arora et al., is proposed. \n\nI lean towards rejecting the paper, since the presentation and the technical quality are somewhat substandard. This is mainly based on evaluation of the experimental results, since I am not an expert in this subfield of theory and was therefore not able to check the statements and the proofs thoroughly. On the presentation side, many details are missing, which often makes understanding difficult and will likely lead to the results not being reproducible. On the experiments side, the issue is that they are quite anecdotal and have multiple confusing or questionable details, as specified below.\n\nPros:\n1) An interesting topic of trying to understand generalization and transfer in deep learning\n2) Multiple types of experiments, including visualizations of loss landscapes at convregence and at initialization, plots of Hessian eigenvalues, measuring the deviation of the weights from their initial values, measuring the variance of the gradients of the weights, measuring the transfer between different datasets, measuring the transfer performance depending on the durarion of pre-training.\n3) Theoretical analysis. As mentioned, I cannot really judge about the quality of the results.\n\nCons:\n1) The presentation is quite confusing. \n1a) The paper includes many different experiments as well as theory, and it is not very clear how these all come together and what message do they give to the reader. The paper states at one point that it \"may stimulate further algorithmic advances\", and it would be great if there was a bit more elaboration on this. \n1b) Experimental methodology is not presented in the main paper and not referred to. Some of it is described in the appendix, but also not too detailed, for instance the duration of ResNet training is not clear, the details of loss landscape visualization are confusing (for instance, the phrase \"... i.e. 0.1× gradient and a total of 200 × 200 grids\"), \n1c) The paper is over 9 pages, which is more than the recommended length of 8 pages.\n1d) Scaling in Figure 8(b) is quite suboptimal, it is impossible to read the test accuracy results.\n1e) Minor issues:\n - No color-code in Figure 3 (unclear what values do the colors correspond to) and it does not seem to be referred to in the text. \n - Page 5: \"predictive\" -> \"predictable\"?\n - Page 6 \"While pretraining on sufficiently large datasets...\" - I do not think the experiments tell anything about the dependence of the effect on the size of the dataset, so this phrasing is not justified\n\n2) I found many of the experiments confusing or unconvincing. This is partially affected by the aforementioned issues with presentation.\n2a) In Table 1 and Figure 2, it is unclear if difference in generalization between the dataesets is due to similarity to ImageNet (by the way, ImageNet is only mentioned in the caption of Table 1, but not in the text) or due to the inherent properties of the datasets (perhaps some are naturally more difficult or prone to overfitting). I think numbers for training from scratch would be helpful for disambiguating the two cases.\n2b) It is unclear why is the norm difference normalized by the square root of the number of target examples. This choice is not justified and it seems it can very noticeably affect the results in counter-intuitive way. For instance, if I understand right, if one duplicates each example in the training set, these values will change, which seems somewhat counter-intuitive. Would it make more sense to normalize by the initial norm of the weights?\n2c) In Figure 4, it is unclear if the permutations of the weights are accounted for. The output of a deep network is invariant under a wide variety of weight permutations, and it is natural that networks trained from different random initializations may converge to weights permuted in different ways. In order to meaningfully compare the weight vectors of these networks, one would have to first \"align\" them, which is a non-trivial task. Another issue I have with the results on Figure 4 is that I don't find them all that counter-intuitive: it seems natural that the weights stay relatively close to the pre-trained network when fine-tuned for that (paritally because the aforementioned permutation symmetry is already largely broken during pre-trianing).\n2d) It is unclear which downstream task is analyzed in Figure 6. Moreover, the plot seems to mix two factors: magnitue of the gradient and the smoothness of the loss landscape. Would it not make more sense to make fixed-size steps in the direction of the gradient? Moreover, I am wondering if the difference between the loss values is simply because the overall loss magnitude is larger for the randomly initialized network?\n2e) A few parts of subsection 5.1 are confusing. It is not clear where does the interpretation of Figure 8 follow from (perhaps partially because figure 8(b) is partially difficult to read). \\psi and W are not defined. What does it move that the weight matrices \"show no improvement\"? Where are the results on Caltech-101 and Webcam? Why is Food-101 mentioned in the text, but CUB-200 shown in the plots?","sentences":[{"sentence_type":"3","sentence":"The paper feels like a hastily compiled collection of weakly related, somewhat anecdotal and not necessarily clearly explained and motivated experiments.","rephrased":"The paper could benefit from a more cohesive structure that clearly connects the experiments and provides a stronger motivation and explanation for each."},{"sentence_type":"2","sentence":"I lean towards rejecting the paper, since the presentation and the technical quality are somewhat substandard.","rephrased":"I have reservations about recommending the paper for acceptance due to concerns about the presentation and technical quality, which could be improved."},{"sentence_type":"1","sentence":"The presentation is quite confusing.","rephrased":"The presentation could be clarified to better guide the reader through the paper's content."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[369,522,"Confirmed"],[1436,1546,"Confirmed"],[2638,2674,"Confirmed"],[2999,3079,"Missed Maybe"],[3439,3534,"Missed by Model"],[3556,3683,"Missed Maybe"],[3793,3934,"Missed Maybe"],[3939,4072,"Missed by Model"]],"Comments":[]}
{"id":"KldT6RXMr6","text":"**Overall appreciation (originality, quality, clarity, and significance)**\n- Originality: Adapts the intuition from the fast multipole method to sparsify attention maps, and leverage several tricks (e.g., kernel trick for linear transformers from ​​Katharopoulos et al.) to obtain a simple and intuitive formulation.\n- Quality: Method is well motivated and there are a few promising experimental results. However the experimental design has significant gaps (see suggestions below).\n- Clarity: Easy to read overall. There are some subsections that felt unnecessary \/ not concisely written (see below).\n- Significance: Although difficult to draw conclusions given the shortcomings of current experiments, the idea appears to have potential. The duality of local attention vs long-range attention controlled by two separate components is compelling. Additional guidance\/analyses on relative performance tradeoffs between widening the banded matrix Vs adding more feature maps in low rank matrix, as well as on the way to choose these feature maps would be very valuable.\n\n**Clarifying questions**\n- Fig 4 & 5: Are these showing cross entropy loss on the training set or validation set? If on the training set then results are not surprising (you are training networks with strictly more parameters). If on validation set, then the language (line 201) is a bit misleading\n\n**Suggestions**\n- Section 2.1 - This subsection could be made more concise: several definitions and propositions are introduced but subsequently not used anywhere (could be moved to appendix)\n- Section 3 - Guidance on how to select \/ craft these feature maps would strengthen your paper \n- Fig 4 & 5 - It appears you have not yet converged on the longer sequences experiment (length=512) which makes your conclusion on line 202 not clear. Additionally, I would keep consistent the y-axis scales between the three columns: as such they are a bit hard to compare across.\n- Section 4 - This section is lacking a speed vs acc\/perplexity analysis (in particular on LRA). Currently, section 4.1 has . Would be good to have in table format for speedups to appreciate actual gains. FIg. \n- Section 4 - It would be very helpful to perform a thorough ablation analysis that shows relative trade-offs (on accuracy\/perplexity, speed, memory) from increasing the banded matrix bandwidth Vs increasing the number of feature maps considered for the low rank matrix.\n- Section 4 - There are many sparse attention transformer architectures out there (e.g., Performer, Linformer). It is important to compare FMMformer to these other methods (besides linear transformers) to understand relative performance trade-offs\nSection 4 - Would recommend keeping things more consistent in terms of choice of parameters across experiments (number of kernels and bandwidth in particular)\n\n**Minor points**\n- Line 72\/73: “and has been regarded as one of the top 10 algorithms in scientific computing in the 20th century” → unnecessary, would suggest to drop this sentence\n- Line 86-87: “For the illustration purpose” → “For illustrative purposes”\n- Line 94: Define C (e.g., positive constant)\n- Line 153: ‘using the fact that LV= …” → would drop -- you have the same identity just above\n- Line 159: Would indicate what these assumptions are here\n- Line 174\/175: “It is easy to check that [...] linearly independent for almost all x” → Add proof in appendix\n- Line 220: “capturing long-term dependency’ → “long-range dependencies”\n","sentences":[{"sentence_type":"2","sentence":"However the experimental design has significant gaps (see suggestions below).","rephrased":"While the experimental design is promising, there are some areas that could be improved for a more robust evaluation (please see the suggestions below)."},{"sentence_type":"2","sentence":"It appears you have not yet converged on the longer sequences experiment (length=512) which makes your conclusion on line 202 not clear.","rephrased":"The convergence on the longer sequences experiment (length=512) seems incomplete, which could affect the clarity of the conclusion drawn on line 202."},{"sentence_type":"1","sentence":"There are many sparse attention transformer architectures out there (e.g., Performer, Linformer). It is important to compare FMMformer to these other methods (besides linear transformers) to understand relative performance trade-offs","rephrased":"Considering the variety of sparse attention transformer architectures available, such as Performer and Linformer, a comparison with FMMformer would be beneficial to highlight the relative performance trade-offs."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[405,482,"Maybe"],[1672,1808,"Not concerning"],[2435,2668,"Not concerning"],[2962,3010,"Missed Maybe"]],"Comments":[]}
{"id":"mxKzMCG3Lq_","text":"This study focuses on the stability of multi-branch networks. It analyzes the forward and backward stability of multi-branch network, and builds the relations with some widely-adopted initialization and normalization schemes. A simple new aggregation method is proposed that enjoys better stability than the sum and average aggregations. The method is extended to the multi-head attention layer in Transformer. Experiments on image classification and machine translation tasks using ResNeXt and Transformer are conduced to show the efficacy. \n\nPros:\nThe paper is well-written. Its motivation is clear and the analyses are technically correct. The proposed method is well interpretable and easy to follow. The connections with some initialization and normalization methods are well explained. \n\nCons & questions:\n1.\tThe paper should offer the definition of “stability” first. Does it refer to the numerical stability of features or the robustness to noise? What does $\\epsilon$ in Eq (3) mean? Is it the perturbation to the input feature $h_{in}$? \n2.\tHow to quantize stability? The experiments on image classification and machine translation show that the proposed method STAM is able to improve classification accuracy and BLEU score. I think these metrics are more related to representation ability. How do we know the stability is improved? \n3.\tThe extendibility is limited. The analyses are based on the assumption that all branches have the same structure without normalization layers. Does it work for network with variant branches? How to generalize this study to network with BN layers? What about the results of experiment 5.1 when BN layers are enabled? Since BN layers have been successful in solving the training difficulties of deep networks (not only multi-branch), could the authors explain the superiority of this study over BN in practical implementation? Besides, are the analyses and proposed methods also applicable to concatenation aggregation? \n4.\tThe improvements on CIFAR-10 and CIFAR-100 over baseline are insignificant. \n","sentences":[{"sentence_type":"2","sentence":"The extendibility is limited.","rephrased":"The extendibility could be further explored."},{"sentence_type":"2","sentence":"The improvements on CIFAR-10 and CIFAR-100 over baseline are insignificant.","rephrased":"The improvements on CIFAR-10 and CIFAR-100 over baseline could be more substantial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1348,1377,"Not concerning"],[1970,2045,"Confirmed"]],"Comments":[]}
{"id":"BclATGS1f9","text":"Overall: Paper is very clear and contribution is sound. I would implore the authors to ensure it is clear to the reader how (Yang et al., 2022) served as a foundation for this result both at a high-level in the main text, and at a low-level with details in the appendix. Furthermore, the contribution stands alone, but it would be beneficial to push for a real-world analysis of the assumptions to be done in future work. \n\nSpecific points:  \n- \" This implicitly restricts p_{s}(s)\". How? It is important to be precise about how your assumptions on the estimated model restrict the ground-truth data generating process. As a rule, the data generating process is separate, the estimated model should not affect it. Do you instead mean that you must restrict the data generating process to prove identifiability for the given estimated model? Please clarify.  \n- Footnote 3 on pg. 9 should be included in the assumptions.  \n- It should be justified why setting $\\theta_{i,1}=0$ can be done w.l.o.g.  \n- Not immediately clear how $O_1$ and $O_2$ are introduced in eq. (17).  \n- Should be fully clarified how Thm. 2.1 differs from any of the theoretical results in (Yang et al., 2022). It's entirely fine that it was used as a resource is proving the statement, but it would be to the reader's credit to understand what has been proven here that wasn't proven in (Yang et al., 2022)? While the following statement does clarify things (\"Moreover, the volume-preserving assumption...completely removes the need for any auxiliary variable.\"), a more precise theoretical comparison to (Yang et al., 2022) would be welcome. Clarifying the innovations upon (Yang et al., 2022) the authors performed to be able to \"completely remove the need for any auxiliary variable\" would aid readers in using said innovations in future progress. Furthermore, it would be beneficial to clarify what \"labels\" is referring to when used in the aforementioned statement, and altogether how it is used in the paper, \"number of distinct values\" is still vague, what values?  \n- While the intuition building paragraphs were helpful, it is my opinion that they will be better served in the introduction. It should be said, in fear of stating the obvious, that if the authors would like to justify their assumptions as reasonable, is to rigorously analyze real-world data to see whether the assumptions are or aren't satisfied, and if a model satisfies the given assumption, whether the identifiability criterion is satisfied. While this is hard due to the data generating process for real-world data being unknown, works exist [1] which, at the very least, have made an attempt at justification. If this is possible, this would be significantly more convincing, in my view, than the arguments from intuition currently presented.  \n- \" As a trade-off, the additional assumptions on the mixing process might limit its usage in some scenarios.\" Not to harp on this point, but a real-world analysis on whether the additional assumptions on the mixing process does limit usage in some scenarios, particularly learning in which scenarios is and isn't it limiting, should at least be suggested for future work.  \n- Once again, what is the additional novelty\/innovation, if any, in Theorem 2.2 relative to (Yang et al., 2022), besides what it inherits from Theorem 2.1, should be clarified for the reader.  \n- Minor grammatical errors should be checked, i.e. \" columns of Jacobian of estimating function\" -> \"columns of the Jacobian of the estimating function\". ","sentences":[{"sentence_type":"2","sentence":"It should be said, in fear of stating the obvious, that if the authors would like to justify their assumptions as reasonable, is to rigorously analyze real-world data to see whether the assumptions are or aren't satisfied, and if a model satisfies the given assumption, whether the identifiability criterion is satisfied.","rephrased":"To strengthen the justification of the assumptions, it would be beneficial for the authors to consider analyzing real-world data to determine the validity of these assumptions and the satisfaction of the identifiability criterion."},{"sentence_type":"2","sentence":"Not to harp on this point, but a real-world analysis on whether the additional assumptions on the mixing process does limit usage in some scenarios, particularly learning in which scenarios is and isn't it limiting, should at least be suggested for future work.","rephrased":"It would be constructive to suggest a real-world analysis in future work to evaluate the impact of the additional assumptions on the mixing process and to understand in which scenarios these assumptions may be limiting."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1001,1070,"Missed Maybe"],[2172,2493,"Not concerning"],[2910,3171,"Not concerning"]],"Comments":[]}
{"id":"vbh2o6dRxR","text":"## summary\nThe authors propose synthER, a method that can augment data necessary for RL training. Any offline and off-policy RL algorithm can utilize for the synthER. Authors show that performance is at least comparable or superior to using original dataset in offline situations, also show good results with a lower UTD ratio in online situations. The data created is sufficiently diverse and helpful for training a policy.\n\n## clarity\nThe method and results are simple and clear.\n\n## significance\n* It is shown that the diffusion model can well augment the behavior policy data.\n* It shows that generative models can be used well in situations where the cost of collecting transition data is high.","sentences":[{"sentence_type":"1","sentence":"The method and results are simple and clear.","rephrased":"The method and results are presented in a straightforward and understandable manner."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[437,481,"Not concerning"]],"Comments":[]}
{"id":"BygceR5dFS","text":"This paper proposes a theoretical framework for post-processing methods of word embeddings. Given the framework, the authors derive their own methods and then a thorough experimental analysis follows.\n\nWhile the paper reflects thorough and substantial work - both in the theoretical framework and in the experimental part, I have serious concerns about its clarity and about the experimental results and also some concerns about comparison with previous work. All these, unfortunately, make me recommend a reject decision. Below, are more details:\n\n1. Clarity: There are multiple aspects of the paper that I needed to read a few times before I understood what the authors mean. \n\nFirst, the problem definition is not clear: Even when I reached the end of the introduction, it was not clear to me what is the problem that the authors are trying to solve and what they are trying to achieve. One example of this problem is the title of the paper, which suggests that the author performs an empirical evaluation, while in practice they also suggest their own method. But this is a much broader issue - the author suggest very little motivation to how the post-processing method should work, what improvements it should provide and why we should expect such improvements. At some points I felt that this is more of a clean mathematical exercise than a discussion of methods that should improve word representations in natural language.\n\nIn addition, the authors assume a strong background in a very specific post-processing  literature and do not provide any details about its fundamentals. Only on the beginning of section 3 I learned the fundamentals of that framework and basic concepts such as the Gram matrix. I believe a scientific paper should be self-contained, the motivations, goals and fundamental concepts form previous work should be clearly stated and explained. This is not done in this paper, unfortunately.\n\nFinally, it was hard for me to determine where the survey of previous work ends and the contribution of this work begins. Particularly, it seems that the authors propose a unified framework for the methods in previous work and it is not clear which parts of that framework were already discussed in previous work and which are original contributions of the authors. This makes it also hard to estimate how different the proposed method is form the previous ones.\n\n2. Experimental analysis:\n\nFirst, the authors describe their evaluation tasks very briefly and only in the appendix. This is just a list of tasks with no insight about natural language (please see a related comment in the clarity section of this review). Then, the results are reported as a macro-average over many tasks: Given the large number of tasks this is a very crude average, and there is no way that any real insight into the change\/improvement of the vectors can be derived from this report. Finally, the reported numbers reflect very minor improvements, if at all, compared to previous post-processing methods and to the original vectors. Again, since these are macro-averages over many tasks, the conclusions that can be derived are very limited (e.g. it might be that the proposed method does improve on some of the tasks and harm the performance on others, or that it keeps the vectors very similar to the original ones - we have no way figuring out the actual picture).\n\n\n3. Comparison to previous work:\n\nAs said above, it seems that the authors view their work in a narrow context of a very specific literature. In fact, the NLP literature contains a large number of post-processing word embedding methods (often referred to as \"fitting\" or \"specialization\" methods). While these methods sometimes build on external linguistic knowledge (e.g. from wordNet or from other manually crafted lexicons), they have also shown useful with automatically constructed constraints, that are similar to the structural considerations mentioned in the paper in the sense that they do not require expert knowledge, they only build on common-sensical requirements from a good vector space for word meaning representation. Some relevant papers are:\n\nFaruqui, M., Dodge, J., Jauhar, S. K., Dyer, C., Hovy, E., & Smith, N. A. (2014). Retrofitting word vectors to semantic lexicons. arXiv preprint arXiv:1411.4166.\n\nMrkšić, N., Séaghdha, D. O., Thomson, B., Gašić, M., Rojas-Barahona, L., Su, P. H., ... & Young, S. (2016). Counter-fitting word vectors to linguistic constraints. arXiv preprint arXiv:1603.00892.‏‏\n\nMrkšić, N., Vulić, I., Ó Séaghdha, D., Leviant, I., Reichart, R., Gašić, M., ... & Young, S. (2017). Semantic specialization of distributional word vector spaces using monolingual and cross-lingual constraints. Transactions of the association for Computational Linguistics, 5, 309-324.‏","sentences":[{"sentence_type":"2","sentence":"All these, unfortunately, make me recommend a reject decision.","rephrased":"Given these concerns, I am inclined to recommend further revisions before considering acceptance."},{"sentence_type":"2","sentence":"At some points I felt that this is more of a clean mathematical exercise than a discussion of methods that should improve word representations in natural language.","rephrased":"There are instances where the paper seems to focus more on theoretical aspects rather than practical implications for improving word representations in natural language."},{"sentence_type":"1","sentence":"This is not done in this paper, unfortunately.","rephrased":"I would suggest that the paper could benefit from a clearer presentation of motivations, goals, and fundamental concepts from previous work."},{"sentence_type":"2","sentence":"Finally, the reported numbers reflect very minor improvements, if at all, compared to previous post-processing methods and to the original vectors.","rephrased":"The results suggest that the improvements over previous post-processing methods and the original vectors are modest and could be discussed in more detail."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[323,459,"Missed Maybe"],[460,522,"Not concerning"],[561,677,"Missed Maybe"],[680,889,"Missed Maybe"],[1099,1267,"Missed by Model"],[1268,1431,"Maybe"],[1433,1586,"Missed Maybe"],[1873,1919,"Maybe"],[2412,2639,"Missed by Model"],[2887,3034,"Not concerning"]],"Comments":[]}
{"id":"SJx6RN28tN","text":"This submission addresses aspect extraction from product reviews by training a neural network (NN) under weak supervision.\nThis paper seems to me to be an extension of a previous work by Angelidis and Lapata (2018), who use a predefined set of seed words in order to extract aspect of interest from product reviews.\nHowever, where Angelidis and Lapata fix both the aspect embedding matrix and the word embeddings for training, the authors in this work adopt the knowledge distillation paradigm by combining a bag-of-word model (as a teacher, simple model in which they can encode the domain knowledge), and an embedding-based NN (as a student, more complex but which can generalize better).\n\nThe reported results sound convincing, but I would have liked having a bit more discussion with regard to the two variants (BOW and EMB) of the Student model, as well as why, in most cases, dropping the seed words (SWD) does not help and when it does, it does not seem to be significant.\nThe authors would have strengthened their work by proving the claim that dropping\/replacing seed words with the 'UNK' token actually teaches the Student network to associate aspects with non-seed words during training. My assumption is that it could simply be that the model associates aspects with another set of seed words (seed words which are not among the 30 seed words per aspect and domain from MATE, but which occur regularly, along side the UNK token).\n\n* Few comments about the paper *\n- The paper is easy to read;\n- EMB and CLF abbreviations, although simple, are referred before being defined;\n- the multi-task learning training objective of the MATE-* models is not introduced (nor why did they authors not considered it);","sentences":[{"sentence_type":"1","sentence":"The reported results sound convincing, but I would have liked having a bit more discussion with regard to the two variants (BOW and EMB) of the Student model, as well as why, in most cases, dropping the seed words (SWD) does not help and when it does, it does not seem to be significant.","rephrased":"The results are promising; however, it would be beneficial to include a more detailed discussion about the two variants (BOW and EMB) of the Student model. Additionally, exploring the reasons behind the limited impact of dropping the seed words (SWD) could further strengthen the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[692,979,"Not concerning"]],"Comments":[]}
{"id":"uTspjTkKZP7","text":"Strengths: \n1.\tThe motivation of this paper is clear. It is important for few-shot learning based on metric learning to increase the inter-class distance between sample representations of different classes and decrease the intra-class distance between sample representations of the same class as much as possible.\n2.\tFrom the experimental values and visualization results, the loss function terms introduced by the authors do what they claim to do, i.e., samples of different categories move away and samples of the same category are clustered.\nWeaknesses:\nNovelty: The degree of innovation in this paper is limited, and the two loss terms proposed by the authors can be seen as an application and combination of Triplet Loss and (ICNNS).\n\nPerformance:\nThe method proposed by the authors is not significant in terms of performance, for example, it lags behind in comparison with \"Principal Characteristic Net\" in Table 1. Also, some comparisons with newer metric-based learning models are missing, such as DeepEMDv2[1].\nWriting:\nSome typing errors also need to be corrected, such as the $K_{x_i}$ in Equation 4","sentences":[{"sentence_type":"2","sentence":"The degree of innovation in this paper is limited, and the two loss terms proposed by the authors can be seen as an application and combination of Triplet Loss and (ICNNS).","rephrased":"While the proposed loss terms build upon established methods such as Triplet Loss and (ICNNS), further elaboration on their innovative aspects could strengthen the paper's contribution to the field."},{"sentence_type":"2","sentence":"The method proposed by the authors is not significant in terms of performance, for example, it lags behind in comparison with \"Principal Characteristic Net\" in Table 1.","rephrased":"The performance of the proposed method could be further improved, as it currently shows lower results compared to the \"Principal Characteristic Net\" in Table 1. Including additional comparisons with recent metric-based learning models might also provide a more comprehensive evaluation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[566,738,"Maybe"],[753,921,"Maybe"]],"Comments":[]}
{"id":"ViuDsObsPg8","text":"Summary: The paper proposes a hiearchical RL framework augmented with linear temporal logic. Low-level policies are trained to reach a set of subgoals with penalty on violating safety constraints, allowing the high-level policy to adapt to different task by composing the low-level policies to reach a set of subgoals specified by an Linear Temporal Logic clause.\n\nMy first comment is on technical novelty. Although the paper states that LOF takes a step beyond RM to enable compositionality, there is no empirical comparison or evaluation. The only experiment on evaluating compositionality (c, d in Figure 2) does not compare LOF against RM.\n\nMy second major comment is on technical exposition. The paper's writing needs a lot of work, especially the method section. The method section started off by describing different concepts used by the framework, but it is unclear how these concepts constitute LOF. For example, how exactly is LTL used in LOF? The introduction mentioned that LOF provides \"compositional\" property, but there is not a single hint of how might each piece of LOF lead to this property. It took me a few read to understand how the low-level reward might be agnostic of the high-level task, which in turn enables fast adaptation to new task because only the high-level needs to be trained, but it is better to state that clearly.\n\nI would suggest the authors to write one or two paragraphs at the beginning of the method to provide a high-level overview of (1) What LOF is, (2) what are different components of LOF (3) how these components interact with each other, intuitively (4) what are the technical challenges each component, or all components jointly, are trying to tackle  (e.g., enabling compositionality). \n\nIn addition, there are many mentioning of using reward function in the form of an FSA. I understand that this was already introduced in Icarte et al., but it is worth reviewing it in the main paper.\n\nComments on experiments:\n- For compositionality experiment, why might RM and Flat not be applicable here (related to my first comment)?\n- I do not see RM curve in (e)\n\n\nMinor:\n- \"\\phi_{liveness} is represented as a finite state automaton\". The paper has been using FSA through except first introduced FSA. It's better to be consistent.\n","sentences":[{"sentence_type":"2","sentence":"The paper's writing needs a lot of work, especially the method section.","rephrased":"The clarity of the paper, particularly in the methods section, could be improved to better convey the framework's concepts."},{"sentence_type":"2","sentence":"It took me a few read to understand how the low-level reward might be agnostic of the high-level task, which in turn enables fast adaptation to new task because only the high-level needs to be trained, but it is better to state that clearly.","rephrased":"The explanation of how the low-level reward is agnostic of the high-level task could be made more explicit, as this is a key factor in enabling fast adaptation to new tasks by training only the high-level component."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[407,540,"Missed Maybe"],[697,768,"Maybe"],[1110,1351,"Not concerning"]],"Comments":[]}
{"id":"RnDBlVi6J5o","text":"The approach of the paper appears to be original and largely technically sound. However, their use of non-uniform perturbations is quite a small and simple amendment to established techniques. As such, the results I would say are not of huge significance to those working in the area. In fact, in some cases, including some of those considered, the approach essentially amounts to no more than a change of basis for the features.\n\nI had a few problems with the clarity of the motivation. Mention is made of basing the non-uniformity on either the importance of the features or on correlations between the features (in general, these are different). The claim is made that these approaches result in more realistic adversarial examples. However, this is not necessarily guaranteed. One can imagine that perturbation of some features could be very important to classification, but not be a realistic proposition if there are dependencies to satisfy. It feels like the approach of the paper, rather than using more realistic adversarial examples, works simply because it is focussing perturbations on the most relevant features. This is not a bad thing to do, but I think the motivation and explanation are somewhat confused. i.e. is the guiding motivation realistic adversarial examples or ones that are more effective in adversarial training?\n\nAlso, it is argued, correctly, in the Introduction that there can be certain constraints\/dependencies amongst the features. However, the subsequent approach does not really allow for such dependencies in general as it is simply using a multi-variate Gaussian for the perturbations. For example, if feature 1 is always equal to twice feature 2, or say bounded below by 3 times feature 3, these dependencies cannot be accommodated in the approach. That is, the paper conflates dependencies with correlations.\n\nMore generally too, without a human in the loop to constrain perturbations to be imperceptible, larger perturbations are allowed, e.g. in their malware examples, huge changes can be made as long as the malicious functionality of the executable is not changed. This is also not covered by the proposed scheme of small non-uniform perturbations.\n\nThough the above points are not saying the approach is incorrect – just that it is not as general as the introduction and motivation would lead one to suppose.\n\nSome minor comments and typos:\n-\tCan the non-uniformity introduced, i.e. $\\Omega$, be a function of $x$?\n-\tTheorem 2.1 is largely stating the obvious in terms of the correlation between gamma-consistency and epsilon – and the exact result does not, as far as I can see, get used subsequently. So why is this theorem needed?\n-\tTheorem 2.1 confuses the probability density function with P(X=x).\n-\tTheorem 2.1 does not state over what range of values of x $P(X=x|y)>=\\gamma$.\n-\tIn equation 5, should the argument of P on the LHS be $\\delta$ and not $\\Omega \\delta$?\n-\tIt is not clear in the examples if the different features are normalised first. Part of the non-uniformity imposed would then correspond to simply normalising the features.\n-\tIn the paragraph beneath Theorem 4.2, it is argued that the result holds if $p_a$ is replaced by a lower bound. But the theorem is already stated in terms of the lower bound.\n-\tThe statement of Theorem 4.2 in the supplementary material (erroneously referred to there as Theorem 5.2) essentially lumps the key part of the proof of the theorem into a “it can be shown that” and so is not really a proof. But reference can be made to Cohen et al for details of the proof anyway.\n\nEdit: Score revised following discussion period.\n","sentences":[{"sentence_type":"2","sentence":"As such, the results I would say are not of huge significance to those working in the area.","rephrased":"While the results contribute to the field, their significance to those working in the area may be limited."},{"sentence_type":"2","sentence":"In fact, in some cases, including some of those considered, the approach essentially amounts to no more than a change of basis for the features.","rephrased":"In certain cases, the approach might be seen as primarily a change of basis for the features, which could be further elaborated upon."},{"sentence_type":"2","sentence":"It feels like the approach of the paper, rather than using more realistic adversarial examples, works simply because it is focussing perturbations on the most relevant features.","rephrased":"It appears that the effectiveness of the approach may stem from the focus on perturbations of the most relevant features, which could be an interesting point for further discussion."},{"sentence_type":"2","sentence":"This is not a bad thing to do, but I think the motivation and explanation are somewhat confused.","rephrased":"Focusing on the most relevant features is a valid strategy, though the motivation and explanation in the paper could benefit from further clarification."},{"sentence_type":"2","sentence":"That is, the paper conflates dependencies with correlations.","rephrased":"The paper might consider more clearly distinguishing between dependencies and correlations to strengthen its argument."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[193,284,"Not concerning"],[285,429,"Maybe"],[948,1125,"Not concerning"],[1126,1222,"Maybe"],[1789,1849,"Maybe"],[2650,2680,"Missed by Model"],[2683,2749,"Maybe"]],"Comments":[]}
{"id":"rkgdSV6qY4","text":"This paper proposes a memory-augmented deep learning model for streaming-based one-shot active learning. It introduces Class Margin Sampling (CMS) which leverages known class information in the margin sampling process to improve sample efficiency in the context of active learning.   \n\n CMS is well-motivated, explained, and is shown to improve results over baselines.  The experiments presented in Table 1 and their accompanying discussion provide a nice illustration of the work performed.  \n\nThe paper demonstrates the use of active learning in three known architectures with and without CMS and provides a nice explanation of the models and why they were chosen.\n\nOverall, the authors did a great job motivating and summarizing work that seems like a good fit for this workshop.  A longer version of the paper would benefit from additional discussion of the hyper parameters used in the RL agent and additional experiments. \n\nMinor Suggestions: \n- It might be helpful to mention the dataset used in Section 4 instead of just in the appendix. \n- “learning policy that generalize over different dataset, by using a generic embedding layers that maps dataset-dependent features to embeddings.” -  plurality doesn’t seem consistent here. \n- “By this particular design, all first-instance Q-values provide little but no information about the model, as we always want the model to execute a label request to maximize the expected reward” - wording\n- “structure than the other models, that turns in a behavior characterized by:” - wording\n- “In stream-based AL, observations are continuously made available to the learner that have to decide whether to request a label or to make a prediction.” -> “In stream-based AL, observations are continuously made available to the learner that has to decide whether to request a label or to make a prediction.”\n- “The model learn, with few examples per class, to make labelling decision online” -> “The model learns, with few examples per class, to make labelling decision online”","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"HyxkfxbDn4","text":"This paper considers the problem of explaining while a schedule is not feasible.\nThe work focuses on resource-constrained project scheduling problem, and the approach is based on using SMT for identifying minimal conflicts and minimal relaxations that will form the explanations of why a schedule is not feasible.\n\nThe work is clearly relevant to the workshop.\n\nI have a few concerns, though.\nFirst, it is not clear what the form of the explanations will be. While the authors do show an example, it is not clear how this can generalise.\n\nSecond, the effectiveness of the proposed explanations still needs to be assessed and properly evaluated.\n\nThird, even from a computational point of view, it is not clear (nor clearly evaluated) how the approach can scale to larger\/different problems.\n\nFinally, the authors should comment on the similarities\/differences with \n\"Generating Explanations for Mathematical Optimisation: Solution Framework and Case Study\" \nChristina Burt, Katerina Klimova, and Bernhard Primas. Proceedings of XAIP 2018.\n","sentences":[{"sentence_type":"1","sentence":"First, it is not clear what the form of the explanations will be.","rephrased":"First, it would be helpful if the authors could clarify the form that the explanations will take."},{"sentence_type":"1","sentence":"Second, the effectiveness of the proposed explanations still needs to be assessed and properly evaluated.","rephrased":"Second, further assessment and evaluation of the proposed explanations' effectiveness would be beneficial."},{"sentence_type":"1","sentence":"Third, even from a computational point of view, it is not clear (nor clearly evaluated) how the approach can scale to larger\/different problems.","rephrased":"Third, it would be advantageous to include an evaluation of how the approach scales to larger or different problems from a computational perspective."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[393,458,"Maybe"],[539,644,"Confirmed"],[646,790,"Confirmed"]],"Comments":[]}
{"id":"SygHTGnhYr","text":"The paper proposes using more expressive priors in variational autoencoders (VAEs), such as the multivariate Student’s t-distribution. The experiments demonstrate a small improvement of SSIM metric on Omniglot.\n\nExploring various design choices of the VAE, including the prior distribution, is important, However, I feel that the paper does not have a sufficient contribution. The theoretical novelty is small; the experimental evaluation is lacking and missing crucial baselines, such as normalizing flows. The text is also not very well-written. Because of these factors, I think the paper should be rejected.\n\nIn more detail, I see the following issues with the current manuscript:\n1. The manuscript is not properly anonymized as it includes acknowledgements.\n2. The title of the paper is confusing, as it suggests that only the prior is being changed. However, Table 1 shows that the posterior is changed jointly with the prior.\n3. The novelty compared to (Abiri & Ohlsson, 2019) is very small. The difference is replacing diagonal covariance multivariate Student’s t-distribution with similar distributions, such as the full covariance Student’s t-distribution or a batch of Student’s t-distributions. The empirical improvement from these changes, based on Figure 5, is quite small.\n4. The text of the paper can be significantly improved. There are many typos, e.g. “lower bound log likelihood” instead of “lower bound on the log-likelihood”. There are also issues in the math, such as a missing negation in the KL divergence at the bottom of Page 2. Some things are not specified: how exactly the diagonal values of the Cholesky decomposition are enforced to be positive? what are the bias nodes mentioned in Figure 2? what is the multivariate Student’s t-distribution density function?\n5. One thing I didn’t understand is why the KL-divergence of a product of independent (“batch”) t-distributions cannot be computed analytically using equation (3), given that the KL(prod_i q_i || prod_i p_i) factorizes as \\sum_i KL(q_i || p_i).\n6. The experimental protocol is lacking. A key missing comparison is normalizing flows (https:\/\/arxiv.org\/abs\/1606.04934) which are typically used to make the VAE prior distributions more expressive. There are also VampPrior (https:\/\/arxiv.org\/abs\/1705.07120) and LARS (https:\/\/arxiv.org\/abs\/1810.11428) which also augment VAE’s prior in various ways. Another issue is that only the SSIM metric is reported, whereas the standard way of comparing generative models is the test log-likelihood.","sentences":[{"sentence_type":"2","sentence":"However, I feel that the paper does not have a sufficient contribution.","rephrased":"However, I believe that the paper could benefit from a more substantial contribution to the field."},{"sentence_type":"2","sentence":"The theoretical novelty is small; the experimental evaluation is lacking and missing crucial baselines, such as normalizing flows.","rephrased":"The theoretical novelty could be expanded upon, and the experimental evaluation would be strengthened by including crucial baselines such as normalizing flows."},{"sentence_type":"2","sentence":"The text is also not very well-written.","rephrased":"The clarity of the text could be improved to enhance the overall presentation of the research."},{"sentence_type":"2","sentence":"Because of these factors, I think the paper should be rejected.","rephrased":"Due to these factors, I would recommend further revisions before considering the paper for acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[305,376,"Maybe"],[377,507,"Confirmed"],[508,547,"Confirmed"],[548,611,"Confirmed"],[766,855,"Missed by Model"],[936,998,"Missed Maybe"],[1207,1287,"Missed Maybe"],[1291,1343,"Missed Maybe"],[2041,2078,"Missed by Model"]],"Comments":[]}
{"id":"Hyx9C2Vqhm","text":"This paper presents a method for reinforcement learning (RL) in settings where the relationship between action and reward is confounded by a latent variable (unobserved confounder). While I firmly believe that RL would benefit from taking causality more seriously, this paper has many fatal flaws that make it not ready for publication. \n\nFirst, and most importantly, the paper is unclear about the problem it is trying to solve. It talks about confounded RL as being settings in which a confounder affects both the action and reward. In typical RL settings this wouldn’t make sense: in RL you get to choose the policy so it doesn’t make sense to assume that the choice of action is confounded while you’re doing RL. To get around this, the authors assume that they’re working with observational data and doing RL on a generative model leant from the observational data. But by doing this, they have assumed away the key advantage that RL has over causal inference: the ability to experiment in the world. The authors justify this assumption by considering high-stakes settings where experimentation is either too risky or too costly, but they don’t explain why you would want to do RL at all when you could just do causal inference directly. If you can’t experiment, RL offers no advantages over standard causal inference methods and bring serious disadvantages (sample-efficiency, computational cost, etc.). \n\n# Method\nThe authors learn a variational approximation to a particular graphical model that they assume for their RL setting. They then treat the variational approximation as the true distribution which allows them to perform causal inference via the backdoor correction. They claim this is identified but this is false - it is only identified with respect to the variational distribution, not the true distribution and we have no a priori reason to  believe that the variational distribution well-approximated the true distribution. In principle, the authors could have tested how well this works experimentally but their experimental setup has problems which prevent this being evaluated. \n\nQuibbles:\n - Page 3: the authors claim the model is “without loss of generality” but this is false - there are many settings that would not conform to this model: e.g. the multi agent settings that economics studies; health settings with placebo effects where reward depends on observations directly; etc.\n  - Page 4 above the equations: either the equations describe the variational approximation to the generative model or the equations shouldn’t all be factorized normal distributions. Real data isn’t made up of factorized normals.\n\n# Experiments\n\nThe authors evaluate their method on three simulated datasets: Confounding MNIST, Confounding Cartpole and Confounding Pendulum. All three have the same methodological problems so I’ll only focus on the MNIST dataset. They synthesize their MNIST dataset but corrupting a subset of MNIST digits with noise and treating actions as rotations. Rewards are given by the absolute difference in angle between the rotated digit and the original unrotated digit. “Confounding” is added by having a binary latent variable affect the amount that the digit is rotated - but importantly, the reward isn’t affected directly by the latent variable. Because of this, there isn’t actually a confounding problem - the “confounder” simply changes the rotation of the digit and can be treated as additional experimentation from the perspective of causal inference. The authors evaluate their method by examining reconstructions of the MNIST digit, but this simply checks how well the variational inference is working, not whether the causal inference is working (there would be no way to evaluate the latter on this dataset because there is no confounding). Effectively all they find is a better-designed variational distribution will do a better job of reconstructing the input (without modelling the latent u, the VAE is forced to average over its two states resulting in more blurry samples). \n\nThe RL evaluations aren’t described in enough detail to conclusively explain the difference observed, but it seems to be driven by the fact that the standard RL methods are working with worse variational approximation distributions.\n\n# Summary\nThis work studies a setting in which the correct baselines would be causal inference algorithms (but they aren’t considered) and their experimental evaluation has serious flaws that prevent it supporting the claims made in the paper. \n","sentences":[{"sentence_type":"2","sentence":"this paper has many fatal flaws that make it not ready for publication.","rephrased":"this paper has several critical issues that need to be addressed before it is ready for publication."},{"sentence_type":"2","sentence":"They claim this is identified but this is false - it is only identified with respect to the variational distribution, not the true distribution and we have no a priori reason to  believe that the variational distribution well-approximated the true distribution.","rephrased":"The claim that the method is identified may be misleading, as it is only identified with respect to the variational distribution, not the true distribution. It would be beneficial to provide evidence or a stronger rationale for believing that the variational distribution closely approximates the true distribution."},{"sentence_type":"1","sentence":"Quibbles:","rephrased":"Minor Concerns:"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[265,336,"Confirmed"],[339,429,"Missed by Model"],[1135,1242,"Missed by Model"],[1684,1945,"Maybe"],[2105,2114,"Not concerning"],[4279,4512,"Missed by Model"]],"Comments":[]}
{"id":"ByxFctTrcS","text":"The paper proposes using causal learning models for alleviating privacy attacks, i.e. membership inference attacks. The paper proves that causal models trained on sufficiently large samples are robust to membership inference attacks; they confirm the theories with experiments on 4 synthetic data.\nThe paper is well written; theoretical proof seems correct as it combines proof of differential privacy guarantees  in Papernot et al. 2017, robustness to membership attacks in Yeom et al. 2018 with the generalization property of causal models from Pearl 2009 and Peters et al. 2017. Results are presented clearly. The paper is novel as the authors claimed they provide the first analysis of privacy benefits of causal models.\nThe main concern of this paper is the results are only confirmed on synthetic data, where all the 4 datasets are generated from known Bayesian networks (i.e., causal graphs). It doesn’t matter if these Bayesian nets are complex or not, because most of the experiments are done with the known true causal models except the last experiment in Figure 3c. Even with learnt causal models, they were learning a Bayesian net from too optimistic data that were indeed generated from Bayesian nets, but these are usually not true for real world data. So evaluations on real dataset, or other synthetic data that are not generated from Bayesian nets are necessary for validating the methods.\nAnother question is about the ‘causal models are known to be invariant to the training distribution and hence generalize well to shifts between samples from the same distribution and across different distributions.’  More explanations about ‘invariance’ is needed. For example, in Figure 2a and Figure 3a, causal models have similar performance (except Alarm data) with DNN models on test 2, where test samples are generated from different distributions than training samples. Also in Figure 3b, the attack accuracy are no different between causal models and DNN on test 1.\nThe last minor question is why only parents of Y are included in causal models in the experiments, but not the Markov blanket as stated earlier in Figure 1. \n\n\n\n\n","sentences":[{"sentence_type":"2","sentence":"It doesn't matter if these Bayesian nets are complex or not, because most of the experiments are done with the known true causal models except the last experiment in Figure 3c.","rephrased":"While the complexity of the Bayesian networks is acknowledged, the generalizability of the results would be strengthened by including experiments on unknown causal models, in addition to the known ones used in most experiments."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[900,1076,"Not concerning"]],"Comments":[]}
{"id":"ZTJezEskkiJ","text":"This paper proposes a minor modification to the existing FL learning framework, which can be easily implemented. The major contribution of this work comes from a few theoretical analyses. The experiments are conducted on several publically accessible data sets with intuitive explanations. \n\nPros:\n- The FL toy example is quite interesting, and we get a nice starting idea for your overall paper.\n- The theoretical analysis seems pretty solid and intuitive. I didn't fully proofread all the details, but the parts that I read look correct to me.\n- The experiments reveal certain properties of FedAve and FedBN, most results are convincing and the relative improvement looks pretty predictable based on the explanation.\n\nCons:\n- The motivation on the toy example may not work well on real-world data set, especially since these assumptions may not hold in general. \n- The experiments are oversimplified and lacks a proper explanation for this kind of preprocessing.\n- Without any large-scale publically-accessible data set being utilized, I concern a lot about its performance on real applications.\n\nDetailed concerns:\n- The necessity of preprocessing all data set into the same setting is not provided. Why only keep 7438 examples for each data set? Does it have something to do with the non-iid setting? Is it possible to keep the data set in their original size? \n- I checked the supplementary as well and didn't find how do you make sure the data set assigned to each client is non-iid.  The claimed covariate shift and concept shift didn't have corresponding experimental settings being explicitly stated, which looks quite confusing to me. Also, please add the comparison with the non-iid scenario with the one proposed in FedAvg.\n-  I highly suggest the authors add a few large-scale data set to verify the effectiveness of FedBN, e.g., cifar-10, cifar-100, and imagenet. Because these data sets are more close to the scenario where each client has non-iid data. \n- Each client has 10% data seems a bit too easy especially for some simple data set, e.g., MNIST, and its variants, I highly believe a comprehensive study like the one did in the FedAvg paper by changing K, B, E, and all their combinations, is the correct way to evaluate your proposed framework. Especially, FedBN is extremely easy to implement. Without these comparisons, I believe the experiment is not complete.\n- Code is not attached, many details of FedBN remains unclear. The results may perform differently when we implement our own version. \n\n\nMinor comments: \nInconsistent notations: sometimes FedAvg but sometimes using FedAVG.","sentences":[{"sentence_type":"2","sentence":"The experiments are oversimplified and lacks a proper explanation for this kind of preprocessing.","rephrased":"The experiments could benefit from a more detailed explanation of the preprocessing steps to enhance their complexity and relevance."},{"sentence_type":"2","sentence":"Without any large-scale publically-accessible data set being utilized, I concern a lot about its performance on real applications.","rephrased":"Incorporating large-scale publicly-accessible datasets could strengthen the paper by providing insights into the performance on real-world applications."},{"sentence_type":"2","sentence":"Code is not attached, many details of FedBN remains unclear. The results may perform differently when we implement our own version.","rephrased":"Providing the code could clarify the details of FedBN and ensure reproducibility of the results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[867,964,"Confirmed"],[967,1097,"Not concerning"],[1120,1364,"Missed Maybe"],[2388,2519,"Maybe"]],"Comments":[]}
{"id":"pUGIwN7zlN","text":"\n1. Summary:\n\nThis paper address efficient searching technique in partially observed MDP. The proposed a learned belief search (LBS) and use auto-regression model to learn the belief distribution of unobserved information. With the learned belief model, they can estimate the expected return via VDN technique. They evaluate the method on Hanabi and obtain 60\\% benefit of the exact search with $35\\times$ reduction in computation cost.\nHowever, it seems that there are many typos or technique issues, i think this paper needs proofreading before it can be accepted.\n\n2. Some Concerns\/weakness:\n\n(1) When using argmax of $Q(a^i|\\tau^i)$ in n-step rollout, how to handle the overestimation? especially, there is a large variance in rollout, do you use any variance reduction technique?\n\n(2) All the experiments are evaluated on Hanabi. Does this method can solve different imperfect information games? I am not sure whether the improvement are specially designed for this particular game. I want to see at least one experiment evaluated on another different game, such as Leduc.\n\n(3) This paper is not well written. There are many typos in the equation or some other paragraphs, which i will list in the following.\n\n3. Questions:\n\n(1) what's BP in \"when the BP was trained via RL.\", page 1. BP is not defined beffor it's used.\n\n(2) what's blueprint policies in section 2.1?\n\n(3) the belief is not well defined in section 3. “We defined beliefs $B^i(\\tau_t)=P((s_t, \\{\\tau^j_t\\})|\\tau^i_t)$, which is the probability distribution ...”.  What's $\\{\\tau^j_t\\}$?\n\n(4) In Eq.2, it's a little bit confusing. in the expectation of $R^t(\\tau')$, $t$ refers to the horizon index of $\\tau'$?\n\n(5) could you explain equation 3 and 4 , they are very important in this paper. \n\n\n4. some issues\/typos:\n\n[1] page 2, \"Simplified Action Decoder (SAD) (?)\"\n\n[2] We denote the environment trajectory as $\\tau_{t}=\\{s_0, a_0, ..., s_t, a_t\\}$\n\n[3] page 8, \"At the heart of LBS is an autoregressive model\", remove \"at\"\n\n[4] page 8, \"This could e.g. be addressed by retraining\", remove \"e.g.\"\n\n[5] page 1, \" the policies of any other agents is available at test time\", is -> are.\n\n[6] MC rollouts refers to Monte Carlo rollouts?\n","sentences":[{"sentence_type":"2","sentence":"However, it seems that there are many typos or technique issues, i think this paper needs proofreading before it can be accepted.","rephrased":"However, I suggest a thorough proofreading to address the typos and technical issues before considering acceptance."},{"sentence_type":"2","sentence":"This paper is not well written.","rephrased":"The paper could benefit from additional editing for clarity and readability."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[437,566,"Not concerning"],[1083,1114,"Confirmed"]],"Comments":[]}
{"id":"SJlei_HIt4","text":"This paper is written clearly and is well thought out in its approach and results. Their contributions are clear, although ambitious as they aim to improve image reconstruction by providing a VAE a reconstructed image based on a grid image created via program synthesis. Their work does show improvement over most state of the art based on the Frechet distance as a performance measure in both their synthetic baseline as well as the Facades baseline other than VED which outperforms the proposed model. It can also be argued though that their improvements may be contributed to the augmented input overfitting the original structure. For samples in their work in which they are compared to VED, it is clear that their work does better represent the original structure, but it is not clear if their method has created a faithful reconstruction of the image or simply  a grid of an average part of the inputs which overfit to the given input. Overall, I believe this work is interesting and may be moving in the right direction for improving image reconstruction algorithms although it is an early start.","sentences":[{"sentence_type":"2","sentence":"It can also be argued though that their improvements may be contributed to the augmented input overfitting the original structure.","rephrased":"However, it would be beneficial for the authors to consider whether the improvements might be due to the model's ability to generalize well or if they stem from the augmented input potentially fitting too closely to the original structure."},{"sentence_type":"2","sentence":"For samples in their work in which they are compared to VED, it is clear that their work does better represent the original structure, but it is not clear if their method has created a faithful reconstruction of the image or simply  a grid of an average part of the inputs which overfit to the given input.","rephrased":"In the samples where the authors' method is compared to VED, while it appears to better capture the original structure, further analysis would be helpful to ascertain if the reconstructions are truly faithful or if they represent an average grid that may be too closely fitted to the input."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[504,634,"Not concerning"],[635,941,"Confirmed"]],"Comments":[]}
{"id":"U6s0FvQOUEQ","text":"In our honest opinion, the authors provide a very well written and structured paper, showing great methodical skills in their experimental study.\n\nThey first introduce the overall problematic of autonomous web navigation, then present how prior work has tackled related tasks as well as the shortcomings of such approaches when it comes to solving the task of Web Navigation. Subsequently, they present their approach, WebGUM, leveraging (1) Instruction-Finetuned Language Models, augmented with (2) Vision Transformers for multimodal data processing, and (3) trained on a huge amount of multimodal behavioural dataset of web interactions, which they collected using Large Language Models trained on human demonstrations. While the model in this approach is optimised in order to fit\/solve the task at hand, this isn't done from scratch as it uses pretrained modules (i.e. reuses prior computation). As a result, we feel that this fits well within the scope of the present venue. \n\nAdditionally, we find that the authors expose clearly expose the research questions guiding their methodology, thus proceeding with adequately tackling each of them. By means of an ablation study, they evaluate each component of their approach and experimentally show that :\n(i) the addition of visual information, the use of historical observations (2 images) does provide an increase in performance on the task ;\n(ii) instruction-finetuned LLMs outperforms unsupervised LLMs and transfer well from standard NLP tasks to the context of multimodal sequential decision making ; \n(iii) the performance of their method has a steep increase with the dataset size, while the increase is slightly milder with the model size (i.e. number of parameters) ; \n(iv) their approach has higher robustness against some perturbations to the HTML code than those based on prior finetuned and unimodal LLMs.\n\n-----\n\nOverall, the approach seems sound and rigorously executed, with the exception of two points which we believe the authors could either clarify or improve on in order to complete this work :\n\n(1) Lines 253-256 : \"Then, we train other models with this dataset and use them for data collection again. We run those models with 10,000 episodes per task and discard failure cases.\" In this statement, it is unclear to us why the negative examples are being discarded and not used to provide the agent with a negative reward, for instance.\n\n(2) Lines 268-270 : \"Due to the huge computational requirements, we run one seed to train each model throughout\nthe paper. \" In this statement, while it is clear that the burden of limited computational resources might have hindered the ability to evaluate the approach on several seeds, we believe this to be a considerable shortcoming as it reduces the statistical significance of the results.\n\n-----\n\nWe thank the authors for the great read.","sentences":[{"sentence_type":"1","sentence":"In this statement, it is unclear to us why the negative examples are being discarded and not used to provide the agent with a negative reward, for instance.","rephrased":"Could you please clarify the rationale behind discarding negative examples? Including them could potentially offer valuable learning signals for the agent, such as negative rewards."},{"sentence_type":"2","sentence":"we believe this to be a considerable shortcoming as it reduces the statistical significance of the results.","rephrased":"It would be beneficial to discuss the potential impact of using a single seed on the statistical significance of the results and consider ways to mitigate this limitation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[2255,2411,"Not concerning"],[2701,2808,"Maybe"]],"Comments":[]}
{"id":"SJx1fc7aKr","text":"The paper proposed an unsupervised anomaly detection method for the scenarios where the training data not only includes normal data but also a lot of anomaly data. The basic idea of this paper is to iteratively refine the normal data subset, selected from the whole training data set. Specifically, the paper first train an auto-encoder (AE) and determine which are the normal data samples according to the reconstruction errors. Then, using the normal data to retrain the AE again, and re-select the normal samples. Repeat the above two steps until convergence. \n\nOverall, the novelty of this paper is in doubt. Detecting anomaly by reconstruction error of AE has been explored thoroughly, and this paper only extends it to iteratively select the normal samples. The extension seems to be very straightforward. \n\nAlso, the refining process is also problematic. It will highly depend on the initial selection, and the error will be propagated to subsequent detections. How to determine which data samples are anomalous is a key to the success of the model, but the proposed method based on the variance assumption is too intuitive and not convincing.\n\nIn addition, the experimental results on the very simple MNIST task is very poor, putting the effectiveness of the proposed model in doubt.\n","sentences":[{"sentence_type":"2","sentence":"Overall, the novelty of this paper is in doubt.","rephrased":"The novelty of this paper could be further clarified, as the approach of detecting anomalies using the reconstruction error of auto-encoders is well-established in the literature."},{"sentence_type":"2","sentence":"The extension seems to be very straightforward.","rephrased":"The extension to iteratively select normal samples could be elaborated on to better highlight its contribution beyond existing methods."},{"sentence_type":"2","sentence":"Also, the refining process is also problematic.","rephrased":"The refining process could be sensitive to the initial selection, which may influence the robustness of subsequent detections. It would be beneficial to discuss potential mitigation strategies for this dependency."},{"sentence_type":"3","sentence":"In addition, the experimental results on the very simple MNIST task is very poor, putting the effectiveness of the proposed model in doubt.","rephrased":"Furthermore, the experimental results on the MNIST dataset suggest there is room for improvement in the model's effectiveness, which could be addressed in future work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[565,763,"Confirmed"],[764,811,"Maybe"],[814,861,"Confirmed"],[969,1150,"Missed by Model"],[1152,1291,"Confirmed"]],"Comments":[]}
{"id":"xn8vr0P4wAI","text":"This paper tries to propose a kernel-based discrepancy measure called generalised probability kernel that can unify MMD and KSD which is an interesting topic of discussion. The paper applies the new discrepancy to perform two-sample tests. \nThe new kernel proposed, unlike the previous RKHS kernels that only depend on data-points, incorporate the notion of probability. e.g. kernel K_{p,q} depends on density p and q. also a symmetric version on discrete KSD is discussed.\nDespite the idea is interesting, there are several flaws which can be reviewed.\n\nFirstly, I think the paper is not clearly presented, with some confusing notation.\n--in Definition 1, you defined a kernel, on distributions p and q, that is a k x k matrix; while in definition 2, the notion of K, are on samples and is a scalar output.\nit is unclear of how \\phi is defined in general; only examples are given later for specific cases so that we got an conjuncture.\n--in Definition 5, why is it different from stein operator of KDSD? or it is supposed to say difference operator?\n\nIn addition I have several confusions:\n1. why is MMD_E^2 an unbiased estimator? what happened to k(x_i, x_i)? it is not clear from the Bernstein polynomial introduced in appendix. \n2. in abstract, it claims that the kernels are between distributions instead of samples, but in the main text it is still evaluation at p_i=p(x_i) on samples; I m confused of the difference and novelty claimed.\n3. The above concern brings up the question while applying on two sample test. \n--When the MMD is used to perform two-sample test, it is assumed that both p and q are unknown. however, to my understanding, we need to know p and q to define k_{prob}; how is this going to be applied to two-sample test? \n--for KSD setting, when the symmetric KDSD is introduced, it also seems to require p and q to known for two-sample testing. In the Liu2016 setting, where goodness-of-fit test is proposed with KSD, q is known (up to normalization) while p is unknown with samples; that is a key point why KSD is useful for goodness-of-fit test.\nIn addition, is there any argument on why the symmetric-KDSD might be better than KDSD Yang et.al 2018?\n\nAn additional point is regarding literature review, which is yet throughout  to check; e.g. as\nChwialkowski, et. al  \"A kernel test of goodness of fit.\" proposed independently as Liu et.al for KSD goodness-of-fit test, that might be useful to cite.\n\nIn my point of view, ICLR may not be a venue of fit either. More reviews and clarifications may be required, for both kernel construction and application. ","sentences":[{"sentence_type":"1","sentence":"Despite the idea is interesting, there are several flaws which can be reviewed.","rephrased":"While the idea is interesting, I have identified some areas that could be improved upon."},{"sentence_type":"2","sentence":"In my point of view, ICLR may not be a venue of fit either.","rephrased":"In my opinion, further improvements might be necessary before this work is a good fit for ICLR."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[474,553,"Not concerning"],[555,637,"Missed by Model"],[808,855,"Missed Maybe"],[1094,1161,"Missed by Model"],[2429,2488,"Not concerning"]],"Comments":[]}
{"id":"rkxMYnMaKH","text":"This paper proposes a new method for correcting training label noise, using a likelihood ratio test on the predicted probability of the classifier trained on the noisy labels, and then proposes an algorithm for iteratively cleaning training labels and retraining a model.  The paper also provides a theoretical guarantee for the probability of correctly re-labeling the training set, and provides empirical results showing that the proposed method significantly outperforms existing approaches for handling noisy training labels.\n\nOverall, I think the empirical results appear very strong, but think this paper is below the acceptance threshold due to three factors, in ranked order:\n- (1) The theoretical guarantee, which is positioned as a core contribution of the paper (and in fact claims it as \"the first to correct labels with theoretical guarantees\", which is not true), is based on assumptions that seem overly strong; these are somewhat relaxed in a \"Remark\", but this seems unproven and is a confusing presentation regardless.\n- (2) The theoretical bound itself is somewhat vacuous as it contains several constant factors that seem very material to the bound, but totally opaque to the reader.\n- (3) The experiments are very strong overall, which is a major plus for the paper; however, there are some questions about the hyperparameter tuning and some other points where more clarity could improve the strength of the empirical results\n\nRegarding (1):\nAs a reader, my first natural reaction was to worry about circularity\/degeneracy in the proposed method: basically, we are using the confidence (as a ratio of predicted cond. probabilities) of the model trained on the corrupted labels to correct those labels... if the labels are so corrupted that the model is also way off, then intuitively, this method should not work.  I was wondering about how this situation would be bounded \/ handled.\n\nIt turns out in Thm 1 that an incredibly strong assumption is made, namely that the model trained on the corrupted labels, f, is a linear function of the true model, with constants a, b known to some small degree of error epsilon (note that the theorem statement says that these constants are unknown- but it then assumes that \\Delta, which is set based on a and b, is known up to \\epsilon error).  This seems like an incredibly strong assumption- and no context \/ motivation is given about why it should be taken as reasonable.\n\nThen, immediately after the Theorem, \"Remark 2\" states that this condition is not actually needed at all- but (a) then why not just strike it from Thm 1 statement, and (b) there does not seem to be any proof of this Remark in the appendix (where the proof of the main theorem itself is closer to a sketch than a standard proof...).\n\nRegarding (2):\nThe bound produced in Thm 1 seems somewhat vacuous: letting \\tau_{01} = \\tau_{10}, then the probability of the label correction being erroneous is bounded by 8C(O(\\epsilon))^\\lambda.  This quantity is presumably in (0,1\/2], so it's a small range to start... but it seems hard to get anything from this bound without some idea of what the constant factors (C, and those hidden in O(\\epsilon)) and \\lambda are.  In particular, as presented, it seems implausible that \\epsilon- the error in specifying the \\Delta threshold- gets that small, in which case these constants become very important to know!  Another way of phrasing this remark: many theoretical bounds have lots of unknown constant factors, but are ultimately just trying to expose some scaling with respect to one parameter, e.g. number of data points, and therefore the constants don't need to be known that well for the statement to have some value.  This doesn't exactly seem to be the case here- therefore it seems hard to extract something from this statement (even ignoring the strong assumptions it is predicated on).\n\nRegarding (3):\nOverall, I think the empirical performance reported in Table 2, and overall thoroughness of the ablation in Section 4, are major strong points for the paper- the performance is very impressive!  However I have a few questions, clarification of which would be very helpful in my mind:\n- (i) A major issue that seems to be raised in the earlier sections is that there is a hyperparameter \\Delta--the threshold for the likelihood ratio test--that everything depends on, and must be chosen empirically.  Table 5 shows that the effect of choosing it is not crazy, but also clearly not insignificant.  My question is: how is it chosen?  On the validation dataset?  And is this validation dataset also corrupted in the same way as the training dataset?  If not, that seems like a major whole in the setup.\n- (ii) I also have a high level question for understanding: how is it possible for the various approaches to do so well with 0.6 and 0.8 noise level of uniform flipping?  In the p=0.8 noise model, for example, the probability of a data point getting flipped to *any individual wrong label* is *greater than that of it being the correct label*.  How is it possible to learn a model based on such a dataset?  Was there some kind of pre-training?  Was the validation set not corrupted?  I don't conceptually understand how the results shown are possible...?\n\nOverall, I think points in (1) and (3) could be helped with additional clarification and contextualization, and possibly (2) as well.","sentences":[{"sentence_type":"2","sentence":"This seems like an incredibly strong assumption- and no context \/ motivation is given about why it should be taken as reasonable.","rephrased":"The assumption made appears to be quite strong, and it would be beneficial to provide context or motivation to support its reasonableness."},{"sentence_type":"2","sentence":"The bound produced in Thm 1 seems somewhat vacuous","rephrased":"The bound produced in Theorem 1 could be made more informative by clarifying the constant factors and their implications."},{"sentence_type":"2","sentence":"If not, that seems like a major whole in the setup.","rephrased":"If not, this could be an important aspect to address in the experimental setup."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[927,1036,"Missed Maybe"],[1043,1203,"Missed by Model"],[2305,2434,"Confirmed"],[2675,2767,"Missed by Model"],[2784,2834,"Confirmed"],[4632,4683,"Not concerning"]],"Comments":[]}
{"id":"asZrvZcFVNS","text":"This paper proposes a new class of adaptive algorithms inspired by finding an optimal proximal function of adaptive algorithms. They provide a theoretical analysis of the new method showing that it would potentially improve the regret bound of current algorithms. Finally, the proposed method is empirically matched with or superior to other popular algorithms on different tasks. \n\nOverall, the method is novel and backed up by some empirical results. However, I have the following concerns mainly on the theories. \n\n- The theories require a bounded domain, yet it is not justified. \n- \"*The AMX algorithm is at least as fast as AdaGrad and AMSGrad under the same assumptions*\": The regret of AdaGrad is ($\\frac{D^2}{\\alpha} + \\alpha)\\sum_{i=1}^d ||g_{1:T,i}||$ under the same setting. While for AMX, the construction of h_t potentially decreases the first term in the regret but also brings an extra log factor to the second term.  In fact,  the second term in Theorem 4.1 is ~$\\sum_{i=1}^d(\\sqrt{1+\\log\\tau}||g_{1:\\tau,i}||)$.  Overall, since that there is no clue how large $\\tau$ is, the regret of AMX may be worse than $\\sum_{i=1}^d||g_{1:T,i}||$ when $\\tau$ is close to $T$. Indeed,  the bound in Theorem 4.2 is worse than AdaGrad by a log term. \n- \"*We emphasize that a small $\\tau$ is not an assumption on the gradient distribution, but rather a condition that on satisfied.*\": There is no citation for this statement nor evidence showing that it is actually happening in the real training process. There is only a specific example to show $\\tau$ can be 1, but I'm still not convinced.  Small $\\tau$ is the key point to show the potential superiority, it would be better to illustrate how $\\tau$ behaves in real training.    \n\n\n","sentences":[{"sentence_type":"2","sentence":"There is no citation for this statement nor evidence showing that it is actually happening in the real training process.","rephrased":"It would be beneficial to provide a citation for this statement or evidence demonstrating its occurrence in the real training process."},{"sentence_type":"2","sentence":"I'm still not convinced.","rephrased":"I would encourage further clarification or evidence to support the claim."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1387,1507,"Confirmed"],[1570,1594,"Confirmed"]],"Comments":[]}
{"id":"kSYucJUgxJX","text":"This paper discusses a phenomenon wherein the feature vectors of the learned value function in reinforcement learning (RL) lose their diversity as training progresses. The paper analyzes the rank of the final hidden layer in the model parameterizing the value function and shows experimentally that for offline-RL and online-RL setups on Atari and Gym benchmarks, this rank collapse occurs with a drop in the average return. The paper further develops two models for understanding this phenomenon, (i) where the value function is modeled using the neural tangent kernel, and (ii) where the value function is modeled using a deep linear network. The paper argues that bootstrapping results in reduction of the rank of the feature matrix as training progresses for these models. A regularization term that equalizes the singular values of the feature matrix is used to mitigate this rank collapse and experimental results on Atari benchmarks are shown with this regularizer.\n\nThe main claim of this paper is to identify the phenomenon of rank collapse of the feature matrix. I have concerns about the experimental findings of this paper and correctness of its theoretical claims, which are discussed below. I am willing to increase my score if the authors can convincingly argue otherwise. Broadly, I agree this is an interesting direction but current manuscript does not convince the reader that rank collapse is indeed the cause of degradation of performance.\n\nComments.\n\n1. Figure 1 does not completely validate the claims on page 3. In Asterix, increasing the amount of data does not lead to rank collapse but the returns degrade significantly during training, why? In Seaquest, the returns (blue) have degraded essentially to zero even when the rank (blue) is at its maximum. This suggests that there are other factors which are causing the drop in performance instead of\/in addition to the rank. The trends in Appendix A1 are similarly inconsistent, as is Figure 2 (Ant-v2). The implication “if low rank, then low returns” is reasonable to expect due to reduced capacity of the value function approximation. But how do the authors deduce from these experiments that “rank collapses in data-efficient RL” (first sentence of Section 3.1).\n2. I have a similar concern about Fig. 3b (Seaquest). The rank for n=4 gradient steps\/transition clearly collapses, yet the TD error remains small, and yet the returns are quite bad. If rank collapse entails that the TD error is not minimized well-enough, and that is the cause of the drop in returns, then how can one explain this figure? I suspect the discrepancy is because the TD error is used in Fig. 3b. Can you perhaps compute a pseudo-optimal policy using a good RL method (say Rainbow) for Seaquest and use its value function as the surrogate for Q*?\n3. The narrative will benefit from being more precise. There is an egregiously large number of sentences where the word “implicit” (the paper uses this word 37 times in the first 8 pages) is used in a vague manner (see for instance Definition 1). Further, “implicit under-parametrization” a bad monicker, should the lottery ticket hypothesis be also called implicit under-parametrization?\n4. Why is Theorem 4.1 here not a direct application of Theorem 5 of Mobahi et al., 2020? Further, the big intellectual gap in the argument is that while we are trying to find the fixed point of the Bellman equation in RL, there is no such fixed point in kernel regression. So while the argument that self-distillation during iterative TD^2-minimization may cause a loss of diversity of the feature space, it does not seem to the only reason, after all some examples in Fig 3 do not show rank collapse.\n5. Perhaps the underlying problem is really that minimizing TD^2 is not an appropriate way to find the fixed point of the Bellman iteration when using function approximation. Indeed, if the TD error is small (Fig. 3b, n=4), there is nothing the network can do to improve the returns. TD error is small in this case in spite of the feature matrix having low rank; it indeed depends on the complexity of the value function.\n6. The development in Sec 4.2 using the work of Arora et a., 2019 around eq. (5) argues that when Q_k(s,a) = Q_{k+1}(s,a) for all pairs (s,a) you get rank collapse; this is a very special situation where the value function at each (s,a) is essentially proportional to the rewards at that state-action pair. I tried to follow the proof of the argument for the botostrapped updates in Theorem 4.2 but to my understanding it hides this same issue, e.g., in eq. (D.15) it is assumed that zeta is small enough which is not true. By this argument simply rescaling all the rewards to have small magnitude should result in rank collapse.","sentences":[{"sentence_type":"1","sentence":"The narrative will benefit from being more precise. There is an egregiously large number of sentences where the word \\","rephrased":"The narrative could be improved by being more precise. The frequent use of the word \\"},{"sentence_type":"1","sentence":"Further, \\","rephrased":"Additionally, \\"},{"sentence_type":"2","sentence":"I tried to follow the proof of the argument for the botostrapped updates in Theorem 4.2 but to my understanding it hides this same issue, e.g., in eq. (D.15) it is assumed that zeta is small enough which is not true.","rephrased":"I found the proof of the argument for the bootstrapped updates in Theorem 4.2 challenging to follow, particularly in eq. (D.15) where it assumes that zeta is small. Could you please clarify this assumption?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2804,2855,"Not concerning"],[2856,3047,"Missed Maybe"],[3048,3189,"Missed Maybe"],[4421,4637,"Maybe"]],"Comments":[]}
{"id":"rJxY33bSFV","text":"This paper presents an approach to obtaining representations of entities from raw text alone. They compare their method, 'RELIC', with some presumably competitive baselines, i.e., two ways of encoding entities with BERT (Devlin et al. 2018). The authors do a good job of connecting their work to previous work, noting the similarities to entity linking, entity typing, and learning entity representations from knowledge bases.\n\nIn terms of the BERT context encoder, I'm not so clear on how these representations are projected into the d-dimensional space. (I assume that d=300, as noted in 3.2?). The authors mention a transformation matrix W, but do not seem to take up how this is learned. Depending on how this is done, this could have a substantial impact on the results reported. What accuracies does BERT get without this dimensionality reduction?\n\nThe results are not altogether convincing, as the majority of entities only occur relatively rarely -- more than half have a frequency in the interval [0, 10). I interpret this as showing that the RELIC system is not particularly successful at the few-shot task, as only relatively high frequency entities have better representations with RELIC than with the BERT comparisons. \n\nFinally, the conclusions strike me as somewhat odd. What do you mean by that RELIC \"[...] allows us to learn highly interesting representations\"? An added qualitative analysis of the representations could serve to highlight this further.\n\nMinor comments:\n* Footnotes should be after punctuation\n* Is the 'All' row in Table 2 micro or macro averaged?","sentences":[{"sentence_type":"2","sentence":"The results are not altogether convincing, as the majority of entities only occur relatively rarely -- more than half have a frequency in the interval [0, 10).","rephrased":"The results would be more compelling if the frequency of entity occurrences was higher, as more than half are currently in the interval [0, 10), which suggests that further investigation into the performance of RELIC on few-shot tasks may be beneficial."},{"sentence_type":"1","sentence":"Finally, the conclusions strike me as somewhat odd.","rephrased":"Finally, the conclusions could be clarified further to better understand what is meant by RELIC \"[...] allows us to learn highly interesting representations\"."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[855,1014,"Maybe"],[1234,1285,"Not concerning"]],"Comments":[]}
{"id":"r1lQVyIAoE","text":"This paper describes a general approach to contrastive explanation using plan-property dependencies. The key concept in this paper is plan-property depenency order, in which dependencies between properties over a set of plans are related. This provides a nice conceptual framework for asking contrastive questions over different *types* of properties, rather than just e.g. actions. The idea is instantiated as goal-dependencies, which is in turn implemented as oversubscription planning and the computational cost is evaluated on a large set of IPC benmarks. This demonstrates that the basic idea is computationally expensive, but not outrageously so!\n\nSome more detailed comments:\n\n- I like this idea of plan-space explanations, as outlined in Definition 3 and 4. It was quite a bit of work to get my head around this though because there are a few different concepts (with new syntax) leading up to this. I only really did that work because I was a reviewer and because this is so highly relevant to my own work. I think a nicely crafted example would immediately make this idea clear; even using an abstract example.\n\n- I found Definition 7 difficult to follow. First, it would improve readability if there was some intuition given about when this is about. But more importantly, I could not understand the formalism here: what does A \\subseteq G mean when A is a set of actions and G is a set of goals; what does the generalised conjunction mean to conjoin a goal given an action; and what is the set B referring to? \n\n- I found the remainder of the section then a bit challenging and didn't understand parts of it because I didn't really know what PDO-GE was. I managed to recover into the compilations section.\n\n- The illustrative example does a nice job of making the concepts in the former sections more concrete, but I did find the jump from the MUGS to the textual explanation quite large. Can you just add a brief example or language template from how to get from {2,4,5} to the text?\n","sentences":[{"sentence_type":"2","sentence":"I only really did that work because I was a reviewer and because this is so highly relevant to my own work.","rephrased":"I delved into these concepts because they are highly relevant to my field and my role as a reviewer encouraged a thorough understanding."},{"sentence_type":"2","sentence":"I found the remainder of the section then a bit challenging and didn't understand parts of it because I didn't really know what PDO-GE was.","rephrased":"The remainder of the section could be more accessible if PDO-GE was explained earlier or in more detail, as I found some parts challenging to grasp."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[908,1015,"Not concerning"],[1526,1665,"Maybe"]],"Comments":[]}
{"id":"SkxQro2BqH","text":"The paper presents a method for detecting rumours in text. Early on in the paper, the authors claim that this method:\n1) is more accurate in rumour detection than prior work, \n2) can provide explainability, and\n3) does not need labelled data because it is trained on synthetic \"non-rumour looking rumours\".\n\nAll three of these statements are problematic.\nThe experimental evaluation uses a small dataset of rumour classification (about 15000 tweet related to 14 news topics) and an even smaller dataset of gene classification. The rationale is to use the gene classification task as a proxy for rumour detection. This is not valid. The gene classification task does not contribute to the evaluation of the rumour detection method. The rumour classification dataset is relatively small, but even more importantly, the experimental results on that dataset are not thoroughly analysed, for instance through an ablation test. \n\nExplainability is not evaluated experimentally, nor formally proven. \n\nThe claim that the method does not need labelled data because it is trained on synthetic \"non-rumour looking rumours\" is shaky, because 1) one could train the method on labelled data, and 2) it is not clear how \"non-rumour looking rumours\"  are guaranteed in the synthesis phase (how are they defined? how are they evaluated to be \"non-rumour looking rumours\"? etc).\n\nNote that there is no definition of what sort of data representation corresponds to a \"rumour\" in the paper. \n","sentences":[{"sentence_type":"2","sentence":"All three of these statements are problematic.","rephrased":"There are concerns with all three of these statements that need to be addressed."},{"sentence_type":"2","sentence":"This is not valid.","rephrased":"The validity of using the gene classification task as a proxy for rumour detection is questionable and requires further justification."},{"sentence_type":"2","sentence":"The claim that the method does not need labelled data because it is trained on synthetic \"non-rumour looking rumours\" is shaky,","rephrased":"The claim that the method does not need labelled data due to training on synthetic \"non-rumour looking rumours\" needs to be substantiated with more evidence."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[308,354,"Maybe"],[613,631,"Maybe"],[632,921,"Missed by Model"],[924,992,"Missed Maybe"],[995,1122,"Maybe"],[1363,1471,"Missed Maybe"]],"Comments":[]}
{"id":"rye7oAUf5E","text":"This paper presents an adjustable real-time style-transfer approach for generating a re-styled image given a style image and a content image, with the contribution that the stylisation of generated images could be adjusted\/controlled at inference time by changing a few tuning parameters. Specifically, this is achieved by modeling as input the set of weights controlling the effect of the style and content captured by each layer of the network. The authors present various qualitative analysis to compare the proposed approach with existing works (StyleNet).\n\nMy major concern is the lack of quantitative experiments for evaluation. Specifically, how does the proposed approach contrast against existing models (e.g., StyleNet) in generating different stylizations with more diverse details (last paragraph, Section 2)? The authors only present one example in the experimental section, which seems to be insufficient.\n\nMeanwhile, this submission only studies generating images, not other modalities with highly-structured representations, which might not fit the theme of this workshop.\n\nTypos:\n* Eq (1): should $\\phi(\\bm{s})$ be $\\phi(\\bm{c})$ in the first equation?\n* Eq (5): format issue\n","sentences":[{"sentence_type":"1","sentence":"My major concern is the lack of quantitative experiments for evaluation.","rephrased":"I would suggest including more quantitative experiments for a comprehensive evaluation."},{"sentence_type":"2","sentence":"Meanwhile, this submission only studies generating images, not other modalities with highly-structured representations, which might not fit the theme of this workshop.","rephrased":"Additionally, it would be beneficial to explore how the proposed method could be applied to other modalities with highly-structured representations to align more closely with the workshop's theme."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[562,634,"Not concerning"],[822,919,"Missed Maybe"],[921,1088,"Not concerning"]],"Comments":[]}
{"id":"j4H64WdMgp7","text":"I do not believe that this paper is ready for publication. There are a few main points that I think the authors could address to improve their paper for resubmission.\n\n1. Clearly state the goal of the paper\n\nAfter reading the paper, I'm still not really sure what problem the paper is trying to solve and what the results are. There is a lot of space dedicated to the subtleties of camera angles, triangle numbers, doubling distance configurations, etc. I would encourage the authors to move this into one, self contained subsection in a results section. The point of the paper should made crystal clear in the introduction. The paper focuses on surface normal details for large ocean scene, then I would encourage the authors to make that point in the first or second paragraph of the introduction and focus on the LOD part.\n\n2. Compare the papers contributions to previous work\n\nThere doesn't seem to be a comprehensive related work section. I would expect to see comparisons to the works by Tessendorf. Since FFT-based waves and normal mapping are fairly established techniques, I would like to understand how the work presented in this paper is different. If the paper is purely a new method for using LOD, that contribution should be front and center. As it stands, I don't quite know what the contribution is.\n\n3. Results need context\n\nThere are several rendered images that all generally look the same. Please help the reader here and explicitly say what is going on. State what image is the \"ground truth\", what images are using approaches that lead to artifacts, what approaches are too slow, etc. The captions don't provide much of a guide to tease out the results. (I would also suggest naming the various triangle size, double distance, etc. examples with some sort of shorthand. It's cumbersome to read all these numbers and try to remember the context).\n\n4. Summarize the results\n\nThe results are provided without a clear narrative. What would you like the reader to take away from this paper? How does table 1 contribute to my understanding of paper's method and the value of it? Similar for the stats plots. What am I supposed to be looking for? If the point of the paper was stated clearly in the introduction, this might be easier to interpret but I would still encourage the authors to layout very clearly what these plots are showing and what they are seeing (is the mapped and unmpapped plots supposed to be close together? Is that good or bad?)\n\n5. Conclusion should be a summary\n\nWhen reading the conclusion, I was hoping to find the following -- the problem you solved, the method you used, the contributions of your paper, and the benefit of your new method (summary of the results). The conclusion as it is written is confusing. After reading it, I still don't know what the goal of this paper is.\n\n\nIn conclusion, I believe this paper requires major revisions for a resubmission. I was not able to adequately evaluate the contributions of this paper in its current form.\n","sentences":[{"sentence_type":"2","sentence":"After reading the paper, I'm still not really sure what problem the paper is trying to solve and what the results are.","rephrased":"The paper could benefit from a clearer statement of the problem it aims to solve and the results achieved, which would help the reader understand the objectives and outcomes more effectively."},{"sentence_type":"2","sentence":"As it stands, I don't quite know what the contribution is.","rephrased":"It would be helpful if the paper could more explicitly highlight its contributions in relation to established techniques, which would clarify its unique value to the field."},{"sentence_type":"1","sentence":"The captions don't provide much of a guide to tease out the results.","rephrased":"Enhancing the captions to better guide the reader through the results would be beneficial for understanding the distinctions between the images."},{"sentence_type":"2","sentence":"The conclusion as it is written is confusing. After reading it, I still don't know what the goal of this paper is.","rephrased":"Clarifying the conclusion to succinctly summarize the problem addressed, the method used, and the paper's contributions would greatly enhance the reader's comprehension of the study's objectives."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,58,"Maybe"],[208,326,"Confirmed"],[1257,1315,"Maybe"],[1342,1474,"Missed Maybe"],[1607,1675,"Confirmed"],[1895,1946,"Missed by Model"],[2124,2161,"Missed by Model"],[2709,2823,"Confirmed"],[2907,2997,"Missed by Model"]],"Comments":["So much constructiveness but also harsh statements."]}
{"id":"Ah9CHkOIgV-","text":"The paper proposes a way to perturb a binary sparse NN in order to achieve a higher accuracy.\n\nFirst they trained, binarized and sparsify a network with a couple of conv and FC layers. Then, they propose to create a swarm of networks by swapping a random non-zero weight with a zero weight.\nSome of these networks happen to perform slightly better than the original one. Based on this the author propose a multi-stage algorithm that they call \"a stochastic search and succeed algorithm\" (SSS) that essentially alternates between training and swapping steps.\n\nThe paper also tries to analyze the manifold of the network weights of different swapped networks by visualizing them using t-SNE algorithm.\n\nThe evaluation is done in MNIST and car-racing dataset. Generally, I'm not convinced that the binary networks would perform much better beyond MNIST and car examples. \n\nThe paper raises a series of questions:\n- How accurately was the network trained? Did the authors rained the best possible binary sparse MNIST network before preceding to the swapping. This is not clear from the text. It would be great to at least repeat the procedure they describe for training multiple times.\n- How is the affinity matrix of tSNE is computed? I assume that if the input is binary, simple Euclidean distance won't be a great measure. Symmetric nature of the plots at Fig4 suggest that your perplexity parameter is too high. The results on the plots are rather the artifacts of the wrong affinity matrix than the properly of the weight manifold.\n- The description of SSS lacks rigor. How many networks are selected in the first step? How do first neighbor are chosen? It is an exhaustive search? What is the complexity? What is the stopping criteria? What \"stochastic\" about this algorithm?\n\nNits:\n- Blue marker is almost impossible to see on fig.5\n\n\n","sentences":[{"sentence_type":"2","sentence":"Generally, I'm not convinced that the binary networks would perform much better beyond MNIST and car examples.","rephrased":"It would be beneficial to see the performance of the binary networks on a wider variety of datasets beyond MNIST and car examples to fully assess their generalizability."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[757,867,"Maybe"],[1055,1087,"Missed Maybe"],[1322,1411,"Missed Maybe"],[1535,1570,"Missed by Model"],[1683,1777,"Missed by Model"],[1787,1835,"Missed by Model"]],"Comments":[]}
{"id":"HyI7safM6X","text":"The paper proposes a Bayesian model comparison based approach for quantifying the semantic similarity between two groups of embeddings (e.g., two sentences). In particular, it proposes to use the difference between the probability that the two groups are from the same model and the probability that they are from different models.\n\nWhile the approach looks interesting, I have a few concerns: \n-- Using the Bayesian model comparison framework seems to be an interesting idea. However, what are the advantages compared to widely used learned models (say, a learned CNN that takes as input two sentences and outputs the similarity score)? The latter can fit the ground-truth labels given by humans, while it's unclear the model comparison leads to good correlation with human judgments. Some discussion should be provided.\n-- The von Mises-Fisher Likelihood is a very simplified model of actual text data. Have you considered using other models? In particular, more sophisticated ones may lead to better performance. \n-- Different information criteria can be plugged in. Are there comparisons? \n-- The experiments are just too simple and incomplete to make reasonable conclusions. For example, it seems compared to SIF there is not much advantage even in the online setting. \n","sentences":[{"sentence_type":"2","sentence":"The experiments are just too simple and incomplete to make reasonable conclusions.","rephrased":"The experiments could be expanded upon to support more robust conclusions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1097,1179,"Confirmed"]],"Comments":[]}
{"id":"mS5xmErMzA","text":"Summary:\n\nThe authors propose a multi-scale encoder-decoder architecture to predict breathing induced organ 2D deformation in future frames. They train and test on just 12 MR sequences of unknown origin. In the evaluation, they compare their method with two other methods and show that their method performs best. For me, a few important explanations and experiments are missing in this paper.\nOverall, I think the authors present interesting ideas to predict deformation in future images. The method is still at the beginning of its development and there are a lot of things to work on. However, I think it might be helpful to present this work at MIDL and discuss further developments. \n\n\nPros:\n\n•    The authors deal with the difficult question of motion prediction in future images. To reduce the search space of possible motions, first, they analyse the motion in the training sequence and quantized them into b bins and thereby convert the regression task into a classification task. I think this is an interesting way to handle this difficult task. \n•    The paper is well written and mostly easy to follow.\n\n\nOpen Questions:\n\n•    What is Q? \n•    Which image registration method is used to align the images? How good is this method? \n•    Are the authors *introducing* or *using* the weighted cross-entropy loss function? \n•    Where are the data from? What kind of manual annotation are available? (How many landmarks on which positions?)\n•    How good is the mean landmark location error if the identity is used as the deformation field?\n•    If I understand correctly, one training per patient is needed. So for a clinical application, you first have to acquire a sequence of a patient to train the network. Afterward, the trained network can be applied during the treatment.  How long does the training take? Are results worse when there is a longer break between training and inference?\n•    What is the runtime of the method during inference?\n\n\nCons:\n\n•    The authors don’t stick to the 3-pages limit.\n•    After reading the paper, I still have open questions that should be answered in the paper.\n•    The mentioned related work is quite old (from 2002,2012,2013). I would assume that in the last past seven years, people have worked on this topic as well. \n•    If I understand correctly, no regularisation of the deformation field is used. Does the method generate smooth deformation fields without foldings? An analysis of the volume changes and foldings is missing. \n•    Are the authors *introducing* or *using* the weighted cross-entropy loss function? \n•    In Figure 3, the time axis doesn’t have a unit.  \n","sentences":[{"sentence_type":"2","sentence":"For me, a few important explanations and experiments are missing in this paper.","rephrased":"The paper would benefit from additional explanations and experiments to support the findings."},{"sentence_type":"2","sentence":"The method is still at the beginning of its development and there are a lot of things to work on.","rephrased":"The method shows promise, and I encourage further development to address the areas that could be improved."},{"sentence_type":"2","sentence":"After reading the paper, I still have open questions that should be answered in the paper.","rephrased":"The paper could be strengthened by addressing the following open questions to provide a more comprehensive understanding of the work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[314,393,"Not concerning"],[490,587,"Not concerning"],[1972,2017,"Missed Maybe"],[2023,2113,"Not concerning"]],"Comments":[]}
{"id":"Hyeg7HIAFE","text":"This article proposes a way to learn a task when no labels are available, but supposing a reward can be computed for each proposed output by the training algorithm (without limitation on the number of such computed rewards). \n\nInstead of directly formulating this as a reinforcement learning problem, one learns an energy landscape, to fit the rewards observed, as a function of the (input, proposed output) pair; then one minimizes this energy landscape with respect to the output (by gradient descent), to find the one that will supposedly lead to the best reward for that input. This approach is known as \"SPEN\" (Structured Prodection Energy Networks).\n\nTo the opposite of traditional SPENs, this article suggests to combine the energy estimation with a random search; that is, during training, for a given input x, after having computed the optimal output y according to the learned energy landscape, one explores randomly around y to search for solutions leading to better rewards. This information is then used to adapt the energy landscape.\nThis approach is new, to my knowledge, and makes perfect sense. It also fits the workshop topic (no strongly labeled data).\n\nExperiments on a significant task show improvement other methods.\n\nThe paper is nicely written, easy to read, even for complete beginners, despite the 4 page limitation.\n","sentences":[{"sentence_type":"1","sentence":"Experiments on a significant task show improvement other methods.","rephrased":"The experiments demonstrate improvements over other methods on a significant task."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1173,1238,"Not concerning"]],"Comments":[]}
{"id":"BJlmkymy5S","text":"Summary:\nThis paper conjectures that normalizing flows are fundamentally limited due to the architecture assumption that the generative function g is continuous in x. It is argued that this constraint makes maximum likelihood estimation difficult in general. Localised generative flows are proposed as a solution and consist in modeling the generative model as a continuous mixture of bijections. Experiments suggest an improvement over MAF.\n\nDecision:\nThe observation that continuity imposes a hard constraint on the network is sound, and the proposed solution appears to show some improvement. However, in its current state, this work appears to be quite fragile both from a theoretical and experimental point of view. First, it is only conjectured that this constraint poses actual problems. Second, the experimental evaluation is weak and insufficient. It omits comparisons with more recent generative flows that have shown to be able to model discontinuous densities. For this reason, I do not recommend the paper for acceptance.\n\nFurther arguments:\n- The whole paper rests on intuition without strong theoretical backup. \n- The experiments are quite poor and results frankly oversold. It is said the method \"improves performance across a variety of common density benchmarks\". While we see improvements in Table 1 over MAF, the comparison omits all recent architectures based on Normalizing Flows, such as TAN (Olivia et al, 2018), NAF (Huang et al, 2018), B-NAF (De Cao et al, 2019) or SOS (Jaini et al, 2019). All of those methods have reported better results than those provided in Table 1. They have also been shown empirically to work for discontinuous densities. While I understand that LGF can be combined with any flow architecture, the question remains whether using a continuous mixture translates into significant improvements for those baselines as well. The experimental benchmarks also omit datasets such as BSDS300, for which the higher dimensionality is usually challenging. The same goes for Table 2 which omits recent and better results, such as Glow or FFJORD.\n- Closer to LGF, a proper experimental comparison to RAD (Dinh et al, 2019) would be appreciated.\n- The proposed architecture supposedly enables better generative models. However, this comes at the price that the density can no longer be evaluated exactly and analytically. Since normalizing flows are also typically slow for sampling, this makes the benefits of the proposed architecture quite limited. In particular, it is not clear why generative models that are good at sampling only (e.g., GANs) should not then be preferred?\n- As a result of the point above, the experimental results are reported only in terms of approximated negative log-likelihood. I do not think this is fair, since models like MAF do provide exact values. It also makes the comparison with previous methods more difficult.\n\nFurther feedback:\n- As per ICLR policy, higher standards should be applied to papers with 9 or more pages. I am confident the paper could be written within 8 pages only.\n","sentences":[{"sentence_type":"2","sentence":"The whole paper rests on intuition without strong theoretical backup.","rephrased":"The paper would benefit from a stronger theoretical foundation to support its intuitions."},{"sentence_type":"3","sentence":"The experiments are quite poor and results frankly oversold.","rephrased":"The experimental section could be strengthened, and the results should be presented in a more balanced manner."},{"sentence_type":"1","sentence":"However, this comes at the price that the density can no longer be evaluated exactly and analytically.","rephrased":"One trade-off to consider is that the density in the proposed architecture may not be evaluated exactly and analytically."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[795,972,"Missed Maybe"],[1057,1126,"Confirmed"],[1130,1190,"Confirmed"],[2257,2359,"Not concerning"]],"Comments":[]}
{"id":"Skl5UDd_tV","text":"The task and method used for this paper seem quite promising, and the general task has broad applications as discussed in the paper and background sections. However, the paper seemed to trail off quickly after the first page, and the experiments section ended suddently. With some restructuring of the focus of the text to highlight the actual experiments and results, this paper could be much improved.\n\nDetails on the experiments were fairly limited - more discussion of the feature based frontend (were there standard delta and double delta with the mel, or only base mel?) and even some of the examples of the keywords in context would improve the work.\n\nRebalancing this work to include a more detailed analysis of the experiments, and reducing or minimizing the first page or so of content would be very helpful. As it stands, the experimental section is basically just the table, having more discussion of that result, and less of the surrounding description of the models, architecture and background would have been better in this 4 page format. \n\nIf the results are the focus of the paper, there should also be some testing done on standard benchmarks rather than only demonstrations on this custom dataset. If the focus is on the new dataset, there should be more discussion of the dataset structure, keywords, and some more exploratory analysis of the overall setting in order to motivate why the dataset is special, or different from standard benchmarks.\n","sentences":[{"sentence_type":"2","sentence":"However, the paper seemed to trail off quickly after the first page, and the experiments section ended suddently.","rephrased":"However, the paper could benefit from a more consistent development of ideas throughout, and a more gradual conclusion to the experiments section."},{"sentence_type":"2","sentence":"As it stands, the experimental section is basically just the table, having more discussion of that result, and less of the surrounding description of the models, architecture and background would have been better in this 4 page format.","rephrased":"Enhancing the experimental section with more detailed discussion beyond the table and streamlining the description of the models, architecture, and background could make better use of the limited space in this 4 page format."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[157,270,"Not concerning"],[819,1054,"Maybe"]],"Comments":[]}
{"id":"iKji3-TtxuR","text":"The paper describes correctly their new loss function as well as some weaknesses from the original minibatch formulation. They provide small toy examples to see the differences between the proposed and the original losses. They also discuss the computational complexity of their method and discuss some practical aspects of their contributions. \n\nEvaluation: My feeling is that the theoretical and experimental aspects are not studied enough. \n\nFor instance on the theoretical side:\n\n(i) While discussing the connections between samples from the transport plan, the authors do not discuss the transported mass. \n\n(ii) Also a study similar to [1] about the possible bias of stochastic gradient is important. Would minimizing your proposed loss function with SGD lead to the correct minimum ? \n\n\nOn the experimental side, there are many experiments, but some of them are not extensive (generative modelling and domain adaptation) which make the performances of their method unclear. I am also skeptical that the method is really competitive in practice (numerically and memory) with state of the art method due to the fact that it needs a bigger k for the loss to be computed.\n\n(i) I would encourage the authors to compelete their work on generative modelling and domain adaptation with comparison with recent methods, including methods which are also not based on optimal transport. \n\n(ii) On domain adaptation and generative modelling, I am not convinced that the proposed method outperforms other methods in practice due to its overall complexity (k>1). Other methods rely on a k equals to 1 (including deepjdot) which might make them faster to train and as efficient or more.\n\n(iii) On domain adaptation, there are more recent methods and I would like to see the comparison [2,3]. There is also this paper [4] that you cite in your supplementary and that you should compare to as this paper also tries to minimize the impact of undesirable connections from minibatches.\n\nRelated Work and Discussion: The related work is complete and well discussed. The bibliography style seems respected.\n\nClarity: The paper is clearly written except for the experimental part. A reader which do not know about generative modelling, domain adaptation, color transfer or bayesian computation can not understand the purpose of the different experiments as the explanations are in the supplementary materials. This gives the feeling that the authors just stacked experiments without discussing them properly and entirely. I think this is mostly due to the high number of different experiments. I suggest to focus on two different experiments, to develop the original problem, their methods to solve them and, finally to produce extensive experiments of different methods on several datasets. The remaining experiments could be added to the supplementary.\n\nQuestions and remarks:\n1. Does your loss transport all samples ? I think it does, but it should be proven. An overall theoretical study of the transport plan is lacking. \n2. Is your method an upper bound of OT and a lower bound of minibatch OT ?\n3. Time comparison between your method and original minibatch OT. This could be done on domain adaptation experiments for instance. \n4. Name of tables are unclear. Please add the meaning of the scores you five (Table 1 and 2).\n\n[1] Learning with minibatch Wasserstein: asymptotic and gradient properties, Fatras et al.\n[2] Sliced Wasserstein Discrepancy for Unsupervised Domain Adaptation, Lee et al.\n[3] Reliable Weighted Optimal Transport for Unsupervised Domain Adaptation, Xu et al.\n[4] Unbalanced minibatch Optimal Transport; applications to Domain Adaptation, Fatras et al.\n\n\n------------------------------\nRebuttal\n------------------------------\n\nThank you for your detailed answers to my questions. I have read the other reviews and the different answers. I still think that the idea is appealing, but the way the paper is written and the fact that the experiments are not extensive enough prevent a publication at that time in my opinion. I keep my score unchanged and I would encourage the authors to pursue the experimental evaluations or theoretical evaluations (distance of the plan marginals to the marginals ?) of their method.","sentences":[{"sentence_type":"2","sentence":"I am also skeptical that the method is really competitive in practice (numerically and memory) with state of the art method due to the fact that it needs a bigger k for the loss to be computed.","rephrased":"I have concerns about the method's competitiveness in practice, both numerically and in terms of memory usage, compared to state-of-the-art methods, particularly because it requires a larger 'k' value for loss computation. It would be beneficial to see a more detailed comparison in this regard."},{"sentence_type":"2","sentence":"This gives the feeling that the authors just stacked experiments without discussing them properly and entirely.","rephrased":"The organization of the experiments gives the impression that they could be better integrated and discussed more thoroughly within the paper."},{"sentence_type":"2","sentence":"I still think that the idea is appealing, but the way the paper is written and the fact that the experiments are not extensive enough prevent a publication at that time in my opinion.","rephrased":"While the core idea of the paper is promising, I believe that the current presentation and the scope of the experiments might not yet meet the publication criteria. Further development in these areas could strengthen the paper's candidacy for publication."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[981,1174,"Confirmed"],[2393,2504,"Confirmed"],[3849,4032,"Maybe"]],"Comments":[]}
{"id":"rJxJYI8T37","text":"The authors proposed a variant of ensemble method in reinforcement learning for query reformulation. They train multiple specialized sub-agents on disjoint partitions of the training data, and use a meta-agent, which can see all the training data, to decide the final answer. This can speed up the training thanks to parallelization. They observed that this can improve the diversity of learnt reformulations and the overall performance in some cases. \n\n\nStrengths\n1. The paper is clear and easy to follow.\n2. Multiple evaluation metrics and baseline models are considered\n\nWeaknesses\n1. The proposed method is simple and lacks novelty.\n2. The performance improvement is marginal and some empirical results are not carefully analyzed. \n\n\nSignificance\nExploring a diverse set of strategies is beneficial in reinforcement learning. This paper focuses on two aspects of this problem. One is how to learn diverse agents and the other one is how to efficiently learn these agents efficiently, which are important concerns in practice. \n\n\nOriginality\nThe model learning approach they proposed is merely a simple variant of ensemble learning. The main difference is they train sub-agents on disjoint partitions of the training data, which seems a trivial modification although this shows to improve the overall model performance.\n\n\nTechnical Quality\nOverall, the experiments are well-thought, but the following questions need to be explained:\n1.\tIn the Introduction, the authors claim three contributions they made in this paper. My question is, if the third one is really an important contribution, why didn’t the authors demonstrate it in detail in the main text? Attaching it to the appendix could make the reader confused about its significance.\n2.\tIn Table-1, the authors claim that their proposed architectures can outperform the baseline RL-10-Ensemble with only 1\/10 time. The sub-agents are trained on a partition of the training set. My question is, are these sub-agents trained in parallel on different machine? If so, why cannot the RL-10-Ensemble be trained in parallel through some multithread or distributed computation? The implementation of the proposed model and the baseline seems not that fair.\n3.\tThe main architecture is described in section 3.3 and 3.4, including the Sub-agents and the Aggregator. However, in Appendix C.1, the authors claim that the gains the proposed method comes mostly from the pool of diverse reformulators, and not from the simple use of a re-ranking function (Aggregator). This is confusing because if it is true, the proposed method is really reduced to an ensemble of the baseline model.\n4.\tIn Table-2, some of the results are worse than the baseline methods like Re-Ranker. Although the authors claim the re-ranking is a post-processing, Re-Ranker performs significantly better than the proposed model. If the authors want to better demonstrate the advantages of the proposed model, a comparison between the proposed model with re-ranking and the Re-Ranker is required.\n5.\tIn Table 10, why the proposed method fails to produce the right answer whereas the other methods perform well?\n","sentences":[{"sentence_type":"2","sentence":"The proposed method is simple and lacks novelty.","rephrased":"While the proposed method builds on existing ensemble techniques, further elaboration on its novel aspects could strengthen the paper."},{"sentence_type":"2","sentence":"The performance improvement is marginal and some empirical results are not carefully analyzed.","rephrased":"The performance improvement, while present, appears to be modest, and a more thorough analysis of the empirical results could provide additional insights."},{"sentence_type":"2","sentence":"The model learning approach they proposed is merely a simple variant of ensemble learning.","rephrased":"The model learning approach proposed is a variant of ensemble learning, and it would be beneficial to highlight the unique contributions this variant offers."},{"sentence_type":"2","sentence":"This is confusing because if it is true, the proposed method is really reduced to an ensemble of the baseline model.","rephrased":"This point could be clarified, as it suggests that the proposed method may closely resemble an ensemble of the baseline model."},{"sentence_type":"1","sentence":"If the authors want to better demonstrate the advantages of the proposed model, a comparison between the proposed model with re-ranking and the Re-Ranker is required.","rephrased":"To more effectively demonstrate the advantages of the proposed model, including a comparison with the Re-Ranker could be beneficial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[588,636,"Maybe"],[640,734,"Confirmed"],[1045,1322,"Confirmed"],[2514,2630,"Maybe"],[2847,3013,"Not concerning"]],"Comments":[]}
{"id":"LWZp03IPkVi","text":"This paper focuses on semi-supervised learning with outliers, more accurately, the unlabeled data contains some examples that belong to classes that unseen in labeled data.  The authors propose an outlier detection-based method to detect outliers and help improve the SSL performance. I have the following concerns about this paper:\n\n1) The contribution is limited. The proposal is mainly based on an existing outlier detection method. It seems that if we can detect outliers accurately and delete these outlier examples, the problem becomes an ideal SSL setting. So the open-set semi-supervised learning problem is actually an outlier detection problem?\n2) Based on question 1, in this paper, the authors do not compare the proposal with the SOTA OOD detection method. The performance of the combination of OOD detection methods and SSL methods should be reported.\n3) What are the differences between outlier detection and open-set learning. In my view, open-set learning should make the model has the ability to classify the new class data.\n4) Self-Supervised learning, e.g., SimCLR, can help to learn a separatable representation and help OOD detection tasks. There are many OOD detection algorithms based on contrastive learning that have been proposed. Can we simply pre-train a model with SimCLR using all labeled and unlabeled data, and based on the learned representation to detect outlier unlabeled examples. Have you tried this way in your experiments?","sentences":[{"sentence_type":"2","sentence":"The contribution is limited.","rephrased":"The contribution could be more clearly highlighted or expanded upon to demonstrate its novelty and impact."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[337,365,"Confirmed"]],"Comments":[]}
{"id":"N0_udPU2wa","text":"In this paper, the authors present a deep learning model that integrates a variational auto encoder (VAE) and a generative adversarial network (GAN) to generate synthetic images conditioned by synthetic labels. The method is novel, however I do have some concerns regarding the method to ensure the consistency between the MRI used as a style image and the generated cardiac shape. \n\nThe evaluation explores different experimental setups for two different open datasets available in cardiac cine-MRI (ACDC and Sunnybrook cardiac data) which makes the paper interesting to read. It would be interesting to know additional details about the data augmentation procedure used on the experiments. The observed gain in performance in the segmentation task seem to be quite large and probably significant, however comparison with alternative methods for generating synthetic cardiac-MRI images is missing.  ","sentences":[{"sentence_type":"1","sentence":"The observed gain in performance in the segmentation task seem to be quite large and probably significant, however comparison with alternative methods for generating synthetic cardiac-MRI images is missing.","rephrased":"While the observed gain in performance in the segmentation task is impressive, it would be beneficial to include a comparison with alternative methods for generating synthetic cardiac-MRI images to contextualize these results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[692,898,"Maybe"]],"Comments":[]}
{"id":"B1xFykfE54","text":"\nThis paper studies the problem of generating textual descriptions from sequences of images (i.e., a storyboard), by introducing a new dataset and two generation models. The dataset is in the cooking domain, contains about 16k recipes from the how-to blogs, each containing about 7-13 steps on average. The generated descriptions are evaluated with both automatic metrics (Bleu, Meteor, and Rouge-L), and human judgments.\n\nThe contribution of this paper is solid, given that the authors will release the datasets. I think this is a very interesting task and will inspire the development of more structure-aware generation models. My main complaint is that the descriptions of the two proposed models (SSiD and SSIL) is relatively vague. \n\nOther questions\/ comments:\nIn Section 4.2, the sequence of phases\/states are denoted with sequences of length 4 (e.g. r = <p1, p2, p3, p4>. This is slightly confusing, since there can be many more phases\/states, as shown in Table 2.\n\nIn the first paragraph of 4.2, the authors mentioned another source of supervision with unimodal textual recipes. How many unimodal recipes are used? Would it be possible to provide more details about them?\n","sentences":[{"sentence_type":"2","sentence":"My main complaint is that the descriptions of the two proposed models (SSiD and SSIL) is relatively vague.","rephrased":"I would suggest providing more detailed descriptions of the two proposed models (SSiD and SSIL) to enhance clarity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[630,736,"Not concerning"],[879,971,"Missed Maybe"]],"Comments":[]}
{"id":"BkehxucWcH","text":"The paper proposes a method for privacy-preserving training and evaluation of DNNs. The method is based on a combination of hardware support from a trusted execution enclave (Intel SGX) and an algorithm for offloading intensive computation to unsecure GPU devices and communicating with the trusted environment without losing security guarantees during communication.  Compared to related work on a similar system (Slalom), the proposed system enables secure training in addition to inference.  The approach is based on the use of additive secret sharing to relegate chunks of computation to independent GPU servers.\n\nThe evaluation presents experiments that report timings of the proposed system against a baseline. Throughput (images\/second) improvements of 8-9x are reported, but the contrast point is unclear (it appears to be CaffeSCONE, but there are several unclear points, summarized below). In addition, a set of results reporting a speed up ratio against attained accuracy of a trained VGG11 network, and a set of results reporting speed up against arithmetic intensity of the workload are given.\n\nI lean towards rejection of this draft, as it has several weaknesses:\n- The connection between the evaluation (which mostly focuses on the speed benefits) and the claimed contributions is tenuous at best. This issue is further compounded by clarity issues in the experiments and their description\n- The empirical results are unclear due to differences between simulation of SGX capability vs hardware support of SGX capability. It is not clear what part of the results is influenced significantly by this disparity, and more importantly whether all the comparisons are done in an equal footing (for example the reported results comparing CaffeSCONE with Goten are performed in two different regimes). As a byproduct, there is a confusing \"scaling factor\" described by the authors that is applied to the timings.\n- A brief mention is made of the fact that the proposed system does not in fact provide correctness guarantees (unlike CaffeSCONE), but this is dismissed by reference to utilizing the same trick used by Slalom.  However, this trick is not described or motivated.\n- The writing in the current draft is of relatively low quality, significantly impacting the readability of the paper and making it hard to understand the contributions and whether they are backed by the presented results.\n","sentences":[{"sentence_type":"2","sentence":"I lean towards rejection of this draft, as it has several weaknesses:","rephrased":"I have reservations about recommending this draft for acceptance due to several areas that could be strengthened:"},{"sentence_type":"2","sentence":"The writing in the current draft is of relatively low quality, significantly impacting the readability of the paper and making it hard to understand the contributions and whether they are backed by the presented results.","rephrased":"The clarity of the writing in the current draft could be improved to better convey the contributions and ensure that they are supported by the presented results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[843,879,"Missed Maybe"],[1108,1177,"Confirmed"],[1180,1404,"Missed by Model"],[1809,1919,"Missed Maybe"],[2132,2181,"Missed by Model"],[2185,2405,"Confirmed"]],"Comments":[]}
{"id":"uve6mun4Wv5","text":"This reproducibility report is a clear rejection in my opinion so I will take some of the review space to offer my opinion on how the authors can improve not only this report, but their research and any future work in general.\n\nFirst off, let me start with something that should be rather easy to fix: language. The paper is not written in proper English, mostly notable by the abundance of incorrect capitalizations, missing determiners and generally unscientific language (e.g. \"huge difference\", Section 3.1.2). While the paper's quality greatly suffers from this, this is of course not the basis for my review. Thus, I am simply using this space to offer some suggestions to the authors on how to improve any future articles they may write. I suggest that the authors use tools such as Grammarly (there is a free tier available but the paid plan offers checking scientific language) in their future reports. A few spelling mistakes are not a problem and I would say even expected (I also make mistakes) but the incorrect use of language disturbs the reading flow of the paper.\n\nNow, on to issues regarding the contents of the report. \n- In Section 2, a sentence from the original paper has been copied without proper quotations (\"Two separate MLPs, ...\") while also leaving in descriptions of the figure they were copied from, and consequently being out of context. \n- Generally the description of the original paper's method and experiments is insufficient in my eyes. Take for example the sentence \"They also change the dataset and ...\", where not further information is given about the actual datasets that have been used. This sentence leaves the reader wondering which dataset the original authors used. \n- The figures and tables of the main results are put in the appendix which somehow disturbs the reading flow.\n- There is actually a great difference between the reproduced Figure 2 and the original figure in that the negative sample similarity is much lower than the negative cluster similarity. This is unfortunately not further investigated. It could be the result of a different seed - just one additional run could have given you more information on this.\n- While the reproducing authors ran the experiments for a much smaller amount of epochs (which is not a problem per se) they argue that the clustering performance can only increase with more epochs. While the original paper shows a better performance with more epochs, I wonder how they reproducing authors come to that conclusion as I do not see any reason to assume that no degenerate solutions could in principle be obtained when training for more epochs. It thus seems to be a baseless assumption.\n- The authors state in Section 3.2 that something has been proven. NEVER use the word \"proof\" if you do not offer a mathematical proof. What you do is showing results that indicate\/suggest which is very different.\n- The ablation study in Section 3.3 is not actually an ablation study but rather a reproduction of an ablation study of the original paper. Under ablation study I understand experiments that were not yet presented in the original paper. An interesting ablation study would have been, for example, to test the robustness to slightly incorrect numbers of clusters, as those have to be specified a priori and are consequently an easy source of error.\n- The authors provide an extension to the originally proposed loss function by augmenting it with either an average\/max\/min operation in Section 3.4. I do not understand the motivation behind the max and min operations as those are not differentiable. With max you could argue that you have some sort of alternation between which term is being differentiated through but when using the loss function with the min operation you only make the minimum smaller and never differentiate through the other term. Regarding using the average in the loss function: The authors do not seem to notice that this is equivalent to using the (originally proposed) sum of the individual loss terms and scaling the gradients. The same result could thus be achieved by using a smaller learning rate on the originally proposed loss function. This is not mentioned anywhere in the report which makes me suspect that it went unnoticed.\n\nI have to report that the authors' names are mentioned in the contribution statement (Section 5) which undermines the double-blind peer review process. I have only seen this in the end after reading the whole report.\n\nFinally, while a review like this can be crushing, I hope you don’t give up the hope but keep trying. Eventually you will get there (although likely not with this paper)!","sentences":[{"sentence_type":"2","sentence":"This reproducibility report is a clear rejection in my opinion so I will take some of the review space to offer my opinion on how the authors can improve not only this report, but their research and any future work in general.","rephrased":"While this reproducibility report does not meet the criteria for acceptance, I would like to use this opportunity to provide constructive feedback that may help improve this report as well as future research endeavors."},{"sentence_type":"2","sentence":"Generally the description of the original paper's method and experiments is insufficient in my eyes.","rephrased":"The description of the original paper's method and experiments could be more detailed to enhance understanding."},{"sentence_type":"1","sentence":"The figures and tables of the main results are put in the appendix which somehow disturbs the reading flow.","rephrased":"Placing the figures and tables of the main results within the main text rather than the appendix could improve the reading flow."},{"sentence_type":"1","sentence":"While the reproducing authors ran the experiments for a much smaller amount of epochs (which is not a problem per se) they argue that the clustering performance can only increase with more epochs.","rephrased":"The authors suggest that clustering performance increases with more epochs, which could benefit from further clarification or evidence."},{"sentence_type":"3","sentence":"The authors state in Section 3.2 that something has been proven. NEVER use the word \"proof\" if you do not offer a mathematical proof.","rephrased":"It is important to reserve the term \"proof\" for findings that are supported by mathematical proof; otherwise, terms like \"indicate\" or \"suggest\" may be more appropriate."},{"sentence_type":"2","sentence":"Finally, while a review like this can be crushing, I hope you don’t give up the hope but keep trying.","rephrased":"While receiving critical feedback can be challenging, I encourage you to continue refining your work and research approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,226,"Confirmed"],[1373,1473,"Maybe"],[1716,1823,"Confirmed"],[2176,2372,"Not concerning"],[2633,2675,"Missed by Model"],[2678,2811,"Maybe"],[3893,4045,"Missed by Model"],[4471,4572,"Not concerning"],[4603,4640,"Missed by Model"]],"Comments":[]}
{"id":"O_5_im6SiMw","text":"- The authors clearly know a lot about the literature about analogical reasoning and RAVEN. This paper provides an excellent review of related work in a concise manner.\n\n- Technical details are largely missing. There's even not a single equation in the entire paper. This makes it difficult to believe that the proposed method would work as the authors claimed. And if it does, it poses additional questions on how general it is to other analogical problems in general.\n\n- Results are weak. It's hard to see if the proposed method is indeed better than prior work in terms of performance. For instance, under the extrapolation setting with mixed data, the WReN is much better than the proposed one. This should be the best evidence to see if the proposed method is better.\n\n- Figures are very difficult to understand. For instance, there's no explanation of what \"filter\" means in Figure 1. Bar plots in Figure 6 should have standard diveration or some other metrics in addition to the bar.","sentences":[{"sentence_type":"2","sentence":"Technical details are largely missing. There's even not a single equation in the entire paper.","rephrased":"The paper would benefit from including more technical details and equations to support the proposed method and enhance its credibility."},{"sentence_type":"2","sentence":"Results are weak.","rephrased":"The results could be strengthened by providing clearer comparisons with prior work, particularly under the extrapolation setting with mixed data."},{"sentence_type":"1","sentence":"Figures are very difficult to understand.","rephrased":"The figures could be made more accessible by adding explanations, such as clarifying the term 'filter' in Figure 1 and including standard deviation or other metrics in the bar plots of Figure 6."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[172,266,"Confirmed"],[473,490,"Confirmed"],[776,817,"Confirmed"]],"Comments":[]}
{"id":"HyeZwJEcnQ","text":"The authors use RPO (Shulman et al, 2015) to transform non-differentiable operations in Faster R-CNN such as NNS, RoIPool, mAP to stochastic but differentiable operations. They cast Faster R-CNN as a SCG which can be trained end-to-end. They show results on VOC 2007.\n\nPros:\n(+) The idea of casting a non-differentiable pipeline into a stochastic one is very reasonable\n(+) This idea is showcased for a hard task, rather than toy examples, thus making it more realistic and exciting\nCons:\n(-) Results are rather underwhelming\n(-) Important properties of the final approach, such as complexity (time, memory, FLOPs) are not mentioned at all\n\nWhile the idea the authors present seems reasonable and is showcased for a hard problem, such as object detection and on a well-designed system such as Faster R-CNN, the results are rather underwhelming. The proposed approach does not show any significant gains on top of the original pipeline (for ResNet101 the reported gains are < 0.2%). These small gains come at the expense of a more complicated definition and training procedure. The added complexity is not mentioned by the authors, such as time, memory requirements and FLOPs. In addition, the VOC2007 benchmark is rather outdated and much smaller than others. It would be nice to see similar results on COCO, which is larger and more challenging. \n\nSimilar efforts in this direction, namely making various modules of the Faster R-CNN pipeline differentiable, have shown little gains as well. For example, Dai at al., CVPR 2016, convert RoIPool into RoIWarp (following STN, Jaderberg et al) that allows for differentiation with respect to the box coordinates. ","sentences":[{"sentence_type":"2","sentence":"Results are rather underwhelming","rephrased":"The results could be strengthened to better highlight the advancements over the existing pipeline"},{"sentence_type":"2","sentence":"The proposed approach does not show any significant gains on top of the original pipeline (for ResNet101 the reported gains are < 0.2%).","rephrased":"The proposed approach shows modest improvements over the original pipeline, and further work could explore ways to enhance these gains"},{"sentence_type":"2","sentence":"These small gains come at the expense of a more complicated definition and training procedure.","rephrased":"While the gains are modest, they are achieved through a more complex definition and training procedure, which could be streamlined in future iterations"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[493,525,"Maybe"],[530,639,"Missed by Model"],[845,981,"Not concerning"],[982,1076,"Not concerning"],[1077,1175,"Missed Maybe"]],"Comments":[]}
{"id":"ouY9OB8_tcw","text":"This paper makes an attempt at combining semi-supervised and active learning. The authors note that in restricted settings, SSL and AL can achieve exponential improvements over standard supervised learning with random sampling. Instead, this work attempts to use active learning to speed up the convergence to the asymptotic classifier (in terms of epochs) and semi-supervised learning to achieve the exponential improvement in data efficiency. This work is inspired by a neural tangent kernel analysis.\n\nStrengths:\n - Integrating active learning into SSL techniques that perform well for image datasets is a good goal, as SSL techniques have dramatically improved for image datasets in the recent past.\n - Promising empirical performance against a few other algorithms.\n\nWeaknesses:\n - The empirical results are only reported for a single dataset (CIFAR10).\n - Although the proposed algorithm, Convergence Rate Control (CRC), is supposed to speed up convergence, only final accuracy is reported. Thus, the reason for the increase in performance is not validated.\n - The theory is perhaps limited because of crude approximations, which aren't validated in terms of approximation error, but overall performance (see table 1 and 2). In particular, the algorithm uses only using the gradient from the final layer parameters, a standard batch approximation, and a \"group\" approximation.\n\nQuestions:\n - Can the authors describe more the \"ill-posed nature\" of active learning?\n\n\n\nAfter reading author response ================================\n\nThank you for the response.\n\nIt's good to know that CRC outperforms random sampling on a couple other image datasets, but would be informative to see the results with respect to other AL techniques.\n\nI wasn't quite able to follow the logic of section 3.2, but this seems on the right track.\n\nThe issue I see with using the final layer is not performance related, it's that it seems to throw out the theory you claim to be using. For instance, the fact that the performance dramatically improves is troubling and makes me wonder if the algorithm is working because of the theory or for a different reason. On the other hand, if you aren't able to make the theoretical justification more compelling, I think it would be fine to say the theory is just for inspiration.\n\nI agree there is no batch approximation when G=Q. I might be missing something, but the paper says \"All experiments hereon use G = Q\/10 considering the speed vs. performance trade-off\". \n","sentences":[{"sentence_type":"2","sentence":"The theory is perhaps limited because of crude approximations, which aren't validated in terms of approximation error, but overall performance (see table 1 and 2).","rephrased":"The theoretical framework could be strengthened by validating the approximations in terms of approximation error, in addition to overall performance as shown in table 1 and 2."},{"sentence_type":"1","sentence":"I wasn't quite able to follow the logic of section 3.2, but this seems on the right track.","rephrased":"The logic in section 3.2 was a bit challenging to follow; could you please clarify this section further? It appears to be heading in a promising direction."},{"sentence_type":"2","sentence":"The issue I see with using the final layer is not performance related, it's that it seems to throw out the theory you claim to be using.","rephrased":"My concern with using only the final layer parameters is that it may not align with the theoretical approach outlined. Could you elaborate on how this choice fits within the theoretical framework?"},{"sentence_type":"2","sentence":"For instance, the fact that the performance dramatically improves is troubling and makes me wonder if the algorithm is working because of the theory or for a different reason.","rephrased":"The significant improvement in performance raises questions about whether the algorithm's success is due to the theoretical underpinnings or another factor. Could you provide further insights on this?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1067,1230,"Not concerning"],[1738,1828,"Not concerning"],[1830,1966,"Not concerning"],[1967,2142,"Not concerning"]],"Comments":[]}
{"id":"dFJDpmzfeC","text":"This paper uses three windows of CT image to mimic a RGB image so that effective models pretrained on ImageNet can be utilized on medical images.  A CNN-LSTM architecture is used to detect intracranial hemorrhage from a series of CT slices.   The paper is clearly presented, and experiments on two datasets show that the proposed method works fairly well.  \n\nStregnth\n1. Using three windows of CT image to mimic a RGB image, which make it possible to utilize models trained for natual images on medical images.\n2. Experiments on two datasets show that the proposed idea works fairly well, especially the models trained on the bigger dataset generalize well on the smaller dataset.\n\nWeakness:\n1. Methodology contribution is minimal.\n2. Performance on the ICH Detection challenge fall at the postion about top 8% now (somewhere around 35th).","sentences":[{"sentence_type":"2","sentence":"Methodology contribution is minimal.","rephrased":"The methodology contribution could be further elaborated to highlight its novelty and potential impact."},{"sentence_type":"1","sentence":"Performance on the ICH Detection challenge fall at the postion about top 8% now (somewhere around 35th).","rephrased":"While the performance on the ICH Detection challenge is commendable, further improvements could propel it into the top tier."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[695,731,"Confirmed"],[735,839,"Not concerning"]],"Comments":[]}
{"id":"rkgmOSGvhV","text":"The paper discusses variants of multi-model planning problems, one model being the actual model and the other being the human's model, where a plan also requires explanations -- model-changing actions -- to clarify to the human any model differences required to (be able to) understand that the returned plan is optimal. A major novelty is the realization that executing actions may in itself affect the human's model, so that the overall planning process has an epistemic nature. A combined (compiled) mode is proposed to this end, and various versions of objectives and methods are discussed.\n\nThis is definitely a great paper for XAIP and should be accepted. I personally found the number of notions, notations, and objectives discussed a bit overwhelming. Also the paper is not very self-contained, and basically requires deep and broad nowledge of the author' own prior work. At times, I felt like the authors are talking to themselves rather to an outside reader (e.g.: start of Section 5.1). It would be great if the authors could try to maker theior work more accessible. For presentation in the workshop, I would highly recommend to focus on a few key points rather than trying to bring the entire breadth of this paper across.\n\nI would also note, though, one aspect that seems to be missing from the discussion: the \"explanations\" considered here are a long way away from what could be considered a complete explanation of the question \"why this plan and not any other plan?\". The problem of inferential capability is a huge one (how to summarize to a human the main reasons for a decision taken based on complex reasoning processes), and in addition to this there is the issue of why the system came up with this specific solution among many possible cost-equivalent ones. In my mind, these things are actually (among) the major issues addressed in XAI. I would prefer if these issues could be emphasized a bit more, than be mentioned almost as an afterthought at the end of the related work discussion.\n\nI think the introduction should already cite the works it refers to.\n\nWrite-up is good in general. but the authors could try to simplify their notations somewhat, and\/or take care to accompany each notation with a brief natural language description. Understanding Definition4, for example, is painful as is. I would also recommend to move Section 4 further up front, it's awkward to read in Section 3.1 about whats going to happen next and then have to read 3.2 and 4 until it actually happens.","sentences":[{"sentence_type":"2","sentence":"Also the paper is not very self-contained, and basically requires deep and broad nowledge of the author' own prior work.","rephrased":"While the paper builds on complex concepts, it would be beneficial for a broader audience if it could be made more self-contained, perhaps by including a summary of the necessary background from the authors' prior work."},{"sentence_type":"2","sentence":"At times, I felt like the authors are talking to themselves rather to an outside reader (e.g.: start of Section 5.1).","rephrased":"There are moments, such as the start of Section 5.1, where the narrative could be more inclusive of readers not familiar with the authors' previous work."},{"sentence_type":"3","sentence":"Understanding Definition4, for example, is painful as is.","rephrased":"Understanding Definition 4 could be facilitated by simplifying the notation or providing a more detailed natural language description."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[662,759,"Missed by Model"],[760,880,"Confirmed"],[881,998,"Confirmed"],[1322,1486,"Missed by Model"],[2266,2323,"Confirmed"]],"Comments":[]}
{"id":"bsfCwH9-tx8","text":"This paper has several significant issues with the primary being imprecise and unclear technical description of their method:\n\n* __Lack of Clarity:__ Many parts of this paper are technically imprecise, incorrect, or too implicit. This issue is severe enough that I do not think one could implement the method from the description in the paper. This alone is enough for a paper to receive a strong reject. I will give some examples here:\n  * __S3.1 first paragraph:__ the definition of $\\mathbf{z}_i$ is inconsistent with the rest of the paper, here it represents data points, later it represents an embedding. On p. 6 it is introduced as an embedding however it is used in situations where it doesn't make sense before that, specifically (6).\n  * __Assumption 3:__ This assumption needs to be made more concrete, in particular independence between anomalies conditioned on what information? Total independence doesn't really make sense since this work is specifically working on _time series_ anomaly detection means there is some sort of dependence between different time points. Maybe we are assuming some model where the anomalous points are chosen independently a-priori and then theres a model that generates the time series conditioned on the location of the anomalies?\n  * __p.4__ \"Unlike one-class learning, we assume that there are anomalies in the training data.\" This is incorrect. For the one class support vector machine, for example, there are slack variables that explicitly allow for points in the training dataset to fall in the anomalous region\n  * __Assumption 4:__ \"For two data points in the sequence, if and only if no anomaly occurs, they have a normal or no relationship.\" This sentence is inscrutable. No anomaly anywhere? No anomalies at the points? At one of the points? What is a \"relationship\"? Is \"normal\" and \"no relationship the same thing\"? Does \"normal\" have something to do with the normal distribution?  This kind of language is unacceptable.\n  *__Assumption 5:__ Similar issues as the last point.\n  *__Definiton 1:__ See above.\n  *__(3):__ What is the motivation for the KL term?  It seems very ad hoc.\n  *__\"Tensor product\"__ This is being used incorrectly. For two tensors $S\\in \\mathbb{R}^{d_1\\times d_2\\times \\cdots \\times d_m}$ and $T \\in \\mathbb{R}^{k_1\\times k_2\\times \\cdots \\times k_n}$ the tensor product $S\\otimes T$ will lie in $\\mathbb{R}^{d_1\\times d_2\\times \\cdots \\times d_m \\times k_1\\times k_2\\times \\cdots \\times k_n}$ and be rank one in $\\mathbb{R}^{d_1\\times d_2\\times \\cdots \\times d_m} \\times \\mathbb{R}^{k_1\\times k_2\\times \\cdots \\times k_n}$. This is not how you are utilizing it in (8) for example where you are performing tensor multiplication along the first mode of $Z$ and $W$, for example. This needs to be introduced and explained. Also note that with this sort of notation transposes are not necessary.\n  *__\"tensor weight\"__ $\\mathbf{W}_{MCC}$ (4 lines below (8)): How is this selected? Is it learned? This is the only occurrence of this in the whole paper from what I can tell and how it is selected, learned, or what it means is never explained.\n  * __\"concept\":__ This needs some introduction and some intuition.\n  * There are many more instances of this issue, but being exhaustive would take far too long\n *__Insufficient Experimental Results:__ This paper needs a very comprehensive experimental evaluation since the theoretical and conceptual contributions are small. More than 2 datasets and more competitors, including better shallow baselines especially for the 3 dimensional dataset. Would be interesting to see _data depth_ based methods as well.","sentences":[{"sentence_type":"2","sentence":"This issue is severe enough that I do not think one could implement the method from the description in the paper.","rephrased":"The description of the method could be improved to facilitate replication and implementation."},{"sentence_type":"3","sentence":"This kind of language is unacceptable.","rephrased":"The language used here could be clarified to avoid ambiguity and enhance the paper's quality."},{"sentence_type":"1","sentence":"There are many more instances of this issue, but being exhaustive would take far too long","rephrased":"There are additional instances that could be improved, but I will focus on the most critical ones for brevity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,124,"Missed by Model"],[150,343,"Confirmed"],[344,404,"Missed by Model"],[1697,1726,"Missed by Model"],[1940,1978,"Confirmed"],[2118,2139,"Missed by Model"],[2974,3119,"Missed by Model"],[3192,3281,"Confirmed"]],"Comments":[]}
{"id":"6dXNH1GXgGz","text":"The proposed algorithm is not properly put in the context of other semi-supervised learning methods that are closely related. These include label propagation, clustering auto encoders, entropy minimization \/ margin maximization, prototype networks and semi-supervised clustering. Examples of these lines of research are: \n\nZhu and Ghahramani, Learning From Labeled and Unlabeled Data With Label Propagation,2002\nXie, Girschick and Farhadi, Unsupervised Deep Embedding for Clustering Analysis, 2016\nGrandvalet and Bengio, Semi-supervised learning by entropy minimization, 2005\nSnell et al, Prototypical Networks for Few-shot Learning, 2017\n\nThe idea of the paper is to penalize maximize distances between pairs of samples from different clusters as determined by the classifier output as a proxy for unlabeled samples. The paper claims previous works do not consider the spatial information provided by unlabeled examples. This is not correct. Many methods take advantage of such information such as label propagation (uses proximity between examples to propagate labels), entropy minimization (uses density of examples), etc. The novelty of the method over these previous techniques is not clear to me\n\nThe experiments section of the paper has some shortcomings as well. The datasets used in Figure 3 are also easily solved by other semi-supervised learning methods. The discussion of these figures does not lend insight into what type of problems that are challenging for previous methods are addressed by the proposed approach. Some of the experimental results do not appear to be compared to the state-of-the-art. For instance, Sajjadi et al, Regularization With Stochastic Transformations and Perturbations for Deep Semi-Supervised Learning, 2016 reports significantly better results for the MNIST dataset with 100 labeled examples compared to the results included in Table 1. Finally, the datasets used with the exception of MNIST are not standard ones used in recent semi-supervised learning papers. CIFAR-10 and STL-10 would have been better choices. \n\nThe clarity of the paper and English use is also below average. Some sentences contain informal phrases that might not be suitable for a scientific paper such as “People try…”, \"Thanks for the tool; it helped us done differentiation automatically.\"  or vague statements such as \"in some particular space, samples in the same category should be in the same cluster\". The paper goes to lengths describing simple concepts such as cluster centroids and distance between cluster centroids (equations 1-3) yet concepts more crucial to the algorithm such as ","sentences":[{"sentence_type":"1","sentence":"The novelty of the method over these previous techniques is not clear to me","rephrased":"It would be helpful if the authors could further clarify how their method differs from or improves upon previous techniques."},{"sentence_type":"2","sentence":"The clarity of the paper and English use is also below average.","rephrased":"Improving the clarity and language of the paper would enhance its readability and professional presentation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,279,"Missed by Model"],[922,942,"Missed Maybe"],[1126,1201,"Confirmed"],[1367,1529,"Missed by Model"],[2006,2057,"Missed Maybe"],[2060,2123,"Confirmed"]],"Comments":["Review cut short?"]}
{"id":"Dy8eoSa81m8","text":"This paper is well organized with an intuitive explanation and extensive experiments, and it can be considered as a good empirical study on investigating adaptive learning rates for solving machine learning problems. However, there are a few weaknesses of the paper, and I am listing them (with questions that could improve reviewers' understanding) here. \n\n1: First of all, the DSA method is in fact minimizing the loss function given current iterate $\\theta$ and gradient $g$. Thus, if the modified loss function can be solved exactly, it would produce the optimal $\\eta$ on the direction with current iterate and gradient. However, how could the author justify that it is better than a constant (or indeed any random) learning rate? Can you justify that in theory? \n\n2. Secondly, the novelty is weak as more literature review in optimization field would give rich content related to the DSA method. The classical way of deriving adaptive learning rate (mostly for the deterministic problem, but also stochastic problem in more recent literature) is line search. Line search finds appropriate learning rate along the same direction that DSA does. In addition, implicit SGD[1] was developed with implicit schema to derive a learning rate. Also, more recent work of deriving adaptive learning rate was proposed for variance reduced method [2].\n\n3. Indeed, the modified loss function is a one-dimension optimization sub-problem. The way that DSA deals with the sub-problem is to either propose a gradient descent or use hyper-parameter to perform one-step update. Could you solve it approximately by using the newton method? In [2], a predefined sub-problem was solved approximately by newton method.\n\n4. As authors define the terms in the paper, such as \"stable\", \"sensitive\", \"grad loss\" etc, this paper tries to explain the issues that was caused by non-adaptive method. However, the proposed DSA method is not solving the challenging optimization problem in the field. Could the weakness of convergence (as authors mention) for other optimizers be analyzed more? For example, optimizer often struggles to escape the saddle point, Adam with constant step-size only converges to neighborhood of local minimum, etc. I strongly feel that more in-depth understanding of issues with classical optimizers is needed for the proposed method to address the concerns in the field.\n\n5. The empirical study is extensive. However, a few confusion that I am having are:\n\n5.1 How DSA and other algorithms were configured? It seems like DSA also adopts batch training.\n\n5.2 Does DSA incur additional cost? Could it be more fair to compare algorithms with respect to computational cost instead of epoch?\n\n5.3 The plots for oscillation are specific for some problems, and would it cover general case?\n\n5.4 Other algorithm requires fine-tuned learning rate, would it be fair to compare with fine-tuned version?\n\n\nReferences:\n[1] see https:\/\/sites.google.com\/view\/panos-toulis\/implicit-sgd\n[2] see https:\/\/arxiv.org\/abs\/2102.09700\n","sentences":[{"sentence_type":"2","sentence":"Secondly, the novelty is weak as more literature review in optimization field would give rich content related to the DSA method.","rephrased":"While the paper presents the DSA method, a more comprehensive literature review in the optimization field could further highlight its novelty and situate it within the context of existing work."},{"sentence_type":"2","sentence":"However, the proposed DSA method is not solving the challenging optimization problem in the field.","rephrased":"It would be beneficial if the paper could demonstrate how the proposed DSA method addresses some of the more challenging optimization problems in the field."},{"sentence_type":"1","sentence":"I strongly feel that more in-depth understanding of issues with classical optimizers is needed for the proposed method to address the concerns in the field.","rephrased":"A more in-depth analysis of issues with classical optimizers could enhance the relevance of the proposed method and its ability to address current concerns in the field."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[773,901,"Maybe"],[1873,1971,"Not concerning"],[2216,2372,"Maybe"]],"Comments":[]}
{"id":"rkg7LLJ6h7","text":"The appproach introduces visual abstractions that are used for reinforcement learning. The abstractions are learned using a lower bound on the mutual information and options are created to generate different measurements for each abstraction. The algorithm hence learns to \"control\" each abstraction as well as to select the options to achieve the overall task. The algorithm is tested on a 3D navigation task and a few Atari tasks which are known for difficult exploration.\n\nThe paper might contain some interesting ideas, however, I am quite confused about the paper due to lack of clarity in writing. The approach is not properly motivated, many equations are not really eplained and important information is missing, so it is really hard to evaluate the contribution of the approach. Please see below for more comments:\n- It is unclear how the intrinsic reward is defined (which is critical to understand the approach).\n- It is unclear what the M different measurements are or for what they are used for. \n- It is unclear qhy equation 1 defines a classification loss. Distribution q is not defined in Eq (1).\n- I do not understand the description of Q-meta in caption of Figure 2, \"Qmeta acts every T steps, which is the fixed temporal\ncommitment window, and outputs an action to select and execute either: (1) composition over Q\nfunction from the option bank indexed by a particular entity and an intrinsic reward function or (2)\nthe Qtask policy which outputs raw actions.\" How can an action be a composition over Q-function and a intrinisic reward function? Please clarify what Qmeta and Qtask do in the text right in the beginning. \n\nI have to say that the paper confused me too much that it is likely I missed the point of the paper. On the positive side, I think the learning of the abstractions using lower bounds of the mutual information is very interesting. The authors should work on their presentation and this could be a very nice paper.  \n\n","sentences":[{"sentence_type":"2","sentence":"I have to say that the paper confused me too much that it is likely I missed the point of the paper.","rephrased":"While the paper presents complex ideas, I found it challenging to grasp the central thesis, which may indicate that further clarification could be beneficial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[533,603,"Missed by Model"],[604,787,"Missed by Model"],[826,923,"Missed by Model"],[926,1008,"Missed by Model"],[1012,1112,"Missed by Model"],[1115,1183,"Missed by Model"],[1642,1742,"Maybe"]],"Comments":[]}
{"id":"Bk5lbEjxG","text":"Summary: The authors show that using visual modality as a pivot they can train a model to translate from L1 to L2. \n\nPlease find my detailed comments\/questions\/suggestions below:\n\n1) IMO, the paper could have been written much better. At the core, this is simply a model which uses images as a pivot for learning to translate between L1 and L2 by learning a common representation space for {L1, image} or {L2, image}. There are several works on such multimodal representation learning but the authors present their work in a way which makes it look very different from these works. IMO, this leads to unnecessary confusion and does more harm than good. For example, the abstract gives an impression that the authors have designed a game to collect data (and it took me a while to set this confusion aside).\n\n2) Continuing on the above point, this is essentially about learning a common multimodal representation and then decode from this common representation. However, the authors do not cite enough work on such multimodal representation learning (for example, look at Spandana et. al.: Image Pivoting for Learning Multilingual Multimodal Representations, EMNLP 2017 for a good set of references)\n\n3) This omission of related work also weakens the experimental section. At least for the word translation task many of these common representation learning frameworks could have been easily evaluated. For example, find the nearest german neighbour of the word \"dog\" in the common representation space. The authors instead compare with very simple baselines.\n\n4) Even when comparing with simple baselines, the proposed model does not convincingly outperform them. In particular,  the P@5 and P@20 numbers are only slightly better. \n\n5) Some of the choices made in the Experimental setup seem questionable to me:\n   - Why  use a NMT model without attention? That is not standard and does not make sense to use when a better baseline model (with attention) is available ?\n   - It is mentioned that \"While their model unit-normalizes the output of every encoder, we found this to consistently hurt performance, so do not use normalization for fair comparison with our models.\" I don't think this is a fair comparison. The authors can mention their results without normalization if that works well for them but it is not fair to drop normalization from the model of N&N if that gives better performance. Please mention the numbers with unit normalization to give a better picture. It does not make sense to weaken an existing baseline and then compare with it.\n\n6) It would be good to mention the results of the NMT model in Table 1 itself instead of mentioning them separately in a paragraph. This again leads to poor readability and it is hard to read and compare the corresponding numbers from Table 1.  I am not sure why this cannot be accommodated in the Table itself.\n\n7) In Figure 2, what exactly do you mean by \"Results are averaged over 30 translation scenarios\". Can you please elaborate ?","sentences":[{"sentence_type":"2","sentence":"IMO, the paper could have been written much better.","rephrased":"I believe there is room for improvement in the clarity and presentation of the paper."},{"sentence_type":"2","sentence":"IMO, this leads to unnecessary confusion and does more harm than good.","rephrased":"This approach may inadvertently cause confusion and could be streamlined for better understanding."},{"sentence_type":"2","sentence":"The authors instead compare with very simple baselines.","rephrased":"It would be beneficial if the authors compared their model with more advanced or relevant baselines."},{"sentence_type":"2","sentence":"Even when comparing with simple baselines, the proposed model does not convincingly outperform them.","rephrased":"The results suggest that the proposed model's performance over simple baselines could be more clearly demonstrated."},{"sentence_type":"1","sentence":"Some of the choices made in the Experimental setup seem questionable to me:","rephrased":"I have some concerns about the choices made in the experimental setup that I believe warrant further explanation."},{"sentence_type":"2","sentence":"It does not make sense to weaken an existing baseline and then compare with it.","rephrased":"For a fair comparison, it would be advisable to maintain the strength of the existing baselines."},{"sentence_type":"2","sentence":"This again leads to poor readability and it is hard to read and compare the corresponding numbers from Table 1.","rephrased":"Improving the presentation of results in Table 1 could enhance readability and facilitate easier comparison of the data."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[183,234,"Confirmed"],[582,652,"Confirmed"],[653,806,"Missed Maybe"],[961,1048,"Missed by Model"],[1203,1271,"Missed Maybe"],[1502,1557,"Confirmed"],[1562,1662,"Confirmed"],[1735,1810,"Confirmed"],[2476,2555,"Confirmed"],[2689,2800,"Confirmed"],[2802,2868,"Missed by Model"]],"Comments":[]}
{"id":"p2E2W6UGgt","text":"Quality and clarity:\n- The short paper is well-written and easy to follow.\n\nSignificance:\n- The evaluation of uncertainty estimations in segmentation is crucial. Given the amount of existing uncertainty estimation methods, such metrics are critical to compare the produced uncertainty estimates quantitatively.\n\nPros:\n- The work addresses an important problem.\n- The proposed metric not only rewards uncertainties in the FP and FN but also penalizes the uncertainties in the TP and TN regions.\n- Figure 1 and Table 1 greatly improve the understanding of the proposed metric.\n\nCons:\n- The proposed metric is rather complicated to interpret since it consists of three sub-metrics and requires different thresholds.\n- The work neither describes how to combine the three sub-metrics, nor it explains how to combine the values at each threshold. Being able to summarize the metric into one scalar value would be beneficial for broader adoption and better interpretation.\n- The compared uncertainty estimation methods are insufficiently described or cited.\n\nMinor:\n- Typo in Table 1: The TP in the definition of the FTN should probably be a TN.\n- The work mentions inter-rater variability as ground truth uncertainty. It is arguable if the desired uncertainty of a model should be similar\/identical to the inter-rater disagreement.","sentences":[{"sentence_type":"1","sentence":"The proposed metric is rather complicated to interpret since it consists of three sub-metrics and requires different thresholds.","rephrased":"The proposed metric could be made more accessible by simplifying its interpretation, which currently involves three sub-metrics and multiple thresholds."},{"sentence_type":"2","sentence":"The work neither describes how to combine the three sub-metrics, nor it explains how to combine the values at each threshold. Being able to summarize the metric into one scalar value would be beneficial for broader adoption and better interpretation.","rephrased":"It would be helpful if the work provided guidance on how to integrate the three sub-metrics and the values at each threshold into a single scalar value, which could enhance its interpretability and facilitate wider use."},{"sentence_type":"2","sentence":"The compared uncertainty estimation methods are insufficiently described or cited.","rephrased":"A more detailed description and citation of the compared uncertainty estimation methods would strengthen the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[584,712,"Maybe"],[715,965,"Maybe"],[968,1050,"Confirmed"]],"Comments":[]}
{"id":"i7lQlnCLyYO","text":"### Summary\nThis paper seeks to improve disease incidence estimation methods using information from surveys about contacts, rather than the respondents direct experience. They can obtain much more information by asking about multiple individuals the respondent knows about rather than gather information about only one individual per survey. From this information, they use a modified network scale up method to determine estimated incidence for Australia, the UK, and China and use Cronbach’s alpha to verify the reliability of their data. In addition, they thoroughly clean the data they obtain in order to get a better estimate.\n\n### Strengths\n- They compare with a range of locations for validation rather than relying on only one.\n- Their data-preprocessing and estimation methods are clear and well-explained.\n\n### Weaknesses\n- The authors do not discuss how the differences in region of respondents affects the estimates in other regions. For example, how do estimates based on the regions with many respondents perform for regions with a much lower response rate?\n- They do not discuss the impact of sample size. Can a study be performed where the sample size is discussed in the context of confidence and estimate performance? It may not be viable to study, but are there hypotheses on when the sample size is too large (i.e., the sets of 15 contacts begin to overlap resulting in over-counting)?\n\n### Suggestions\n- The sentence “…and hospitalizations among 15 of the closest contacts” could use a bit more elaboration, such as “…closest contacts to survey respondents”.\n- What are the results if the data was not pre-processed?\n\n### Minor\n- What is n on line 177?\n- The writing is imprecise in some places such as line 206, 224","sentences":[{"sentence_type":"1","sentence":"The writing is imprecise in some places such as line 206, 224","rephrased":"The clarity of the writing could be improved in certain sections, for instance, lines 206 and 224."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[834,945,"Maybe"],[1074,1120,"Maybe"],[1676,1737,"Maybe"]],"Comments":[]}
{"id":"BSd2yVUxPqQ","text":"The main message of the paper is not clear. What is essentially the mathematical definition of probability estimation? All definitions in Eqs 1 - 6 are well-established terms in the uncertainty calibration literature and the phenomenon in Fig 2 is also well known to the community. It is accounted for simply as reporting prediction accuracy and calibration scores together. I am then missing what is new thing the \"probability estimation\" notion is telling us and where we see it in the experiments, which are \ndesigned simply as standard calibration experiments.\n\nI am having hard time to make sense of the calibration loss presented as an alternative to the discrimination loss. Where does p_emp^i come from? How can one define it without giving reference to a sample-based estimation of the confidence score of f(x), which eventually boils down to the calibration we know? Having given a reference to a confidence score estimate, how is it different then from ordinary calibration?\n\nThe \"function kernel\" inside Algorithm 1 appears to be the only part where one can argue about a methodological novelty. This function only replaces the Dirac measure used by standard binning with a kernel density estimator. This is a standard trick to improve numerical stability, but it is hard to say that this much makes a scientific novelty worthwhile to be published as a main-track conference paper.\n\nThe paper lacks a clear focus in its core theme and a consistent logical flow. Is the main message how good Algorithm 1 is? Then the justification of the algorithm and explanation of why it works in the way it works is missing. Is it the allegedly new applications where uncertainty calibration is used? Then references to the closest work are missing. I also do not think these are such novel applications of uncertainty calibration. For instance see:\n\nThagaard et al., Can you trust predictive uncertainty under real dataset shifts in digital pathology?, MICCAI 2020","sentences":[{"sentence_type":"2","sentence":"I am having hard time to make sense of the calibration loss presented as an alternative to the discrimination loss.","rephrased":"I find it challenging to understand the calibration loss presented as an alternative to the discrimination loss, and would appreciate further clarification or examples."},{"sentence_type":"3","sentence":"This is a standard trick to improve numerical stability, but it is hard to say that this much makes a scientific novelty worthwhile to be published as a main-track conference paper.","rephrased":"While the use of a function kernel to improve numerical stability is known, it would be beneficial to highlight how this contributes to scientific novelty in the context of a main-track conference paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[0,43,"Missed by Model"],[375,564,"Missed by Model"],[566,681,"Not concerning"],[1212,1393,"Confirmed"],[1395,1473,"Missed by Model"],[1519,1622,"Missed by Model"],[1699,1747,"Missed by Model"],[1748,1829,"Missed Maybe"]],"Comments":[]}
{"id":"r1CkPdteG","text":"The paper describes a sequence to sequence auto-encoder model which is used to learn sequence representations. The authors show that for their application, better performance is obtained when the network is only trained to reconstruct a subset of the data measurements. The paper also presents some visualizations the similarity structure of the learned representations and proposes a window-based method for processing the data.\n\nAccording to the paper, the experiments are done using a data set which is obtained from measurements of an industrial production process. Figure 2 indicates that reconstructing fewer dimensions of this dataset leads to lower MSE scores. I don’t see how this is showing anything besides the obvious fact that reconstructing fewer dimensions is an easier task than reconstructing all of them.  The only conclusions I can draw from the visual analysis is that the context vectors are more similar to each other when they are obtained from time steps in the data stream which are close to each other. Since the paper doesn’t describe much about the privately owned data at all, there is no possibility to replicate the work. The paper doesn’t frame the work in prior research at all and the six papers it cites are only referred to in the context of describing the architecture.\n\nI found it very hard to distil what the main contribution of this work was according to the paper. There were also not many details about the precise architecture used. It is implied that GRU networks and were used but the text doesn’t actually state this explicitly. By saying so little about the data that was used, it was also not clear what the temporal correlations of the context vectors are supposed to tell us. \n\nThe paper describes how existing methods are applied to a specific data set. The benefit of only reconstructing a subset of the input dimensions seems very data specific to me and I find it hard to consider this a novel idea by itself. Presenting sequential data in a windowed format is a standard procedure and not a new idea either. All in all I don't think that the paper presents any new ideas or interesting results.\n\nPros:\n* The visualizations look nice.\n\nCons:\n* It is not clear what the main contribution is.\n* Very little information about the data. \n* No clear experiments from which conclusions can be drawn.\n* No new ideas.\n* Not well rooted in prior work.\n","sentences":[{"sentence_type":"2","sentence":"I don't see how this is showing anything besides the obvious fact that reconstructing fewer dimensions is an easier task than reconstructing all of them.","rephrased":"It would be beneficial if the paper could further clarify how the reduced dimensionality reconstruction contributes to the field, considering that reconstructing fewer dimensions might be perceived as a less complex task."},{"sentence_type":"1","sentence":"The only conclusions I can draw from the visual analysis is that the context vectors are more similar to each other when they are obtained from time steps in the data stream which are close to each other.","rephrased":"The paper could enhance its impact by providing a more detailed analysis of the visual results, particularly by exploring the significance of the similarity between context vectors from adjacent time steps."},{"sentence_type":"2","sentence":"Since the paper doesn't describe much about the privately owned data at all, there is no possibility to replicate the work.","rephrased":"To facilitate reproducibility, it would be helpful if the paper could provide more details about the data or suggest alternative ways to validate the findings with different datasets."},{"sentence_type":"3","sentence":"All in all I don't think that the paper presents any new ideas or interesting results.","rephrased":"The paper could be strengthened by highlighting the novel aspects of the approach and discussing the implications of the results in a broader context."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[669,822,"Missed by Model"],[824,1028,"Confirmed"],[1029,1152,"Missed by Model"],[1153,1306,"Missed by Model"],[1308,1476,"Missed by Model"],[2064,2150,"Confirmed"],[2200,2245,"Missed by Model"],[2291,2348,"Missed by Model"],[2351,2364,"Missed by Model"]],"Comments":[]}
{"id":"r1xYhv5J5H","text":"This paper points out that the traditional way of model selection is flawed due to that the validation\/test set is often small. The authors also attribute the existence of adversarial examples to the small validation\/test set, which I agree to some degree. Hence, the authors proposed an alternative approach to comparing different classification models by the notion of inter-model discrepancy. \n\nThe main idea is reasonable, but it requires that the models to compare all perform reasonably well. Otherwise, some poorly performed models could lead to near-random or adversarial inter-model discrepancies, failing the proposed approach. \n\nAnother potential issue is that the proposed approach cannot handle training set bias. If all models are biased in similar ways (e.g., toward a particular class or domain), they will not reveal informative discrepancies for the images over which they all make similar mistakes. \n\nAnother question which is not answered in the paper is the number $k$ of images to select for each pair of classifiers. Is this number task-dependent? Is it related to the number of classes? What is a general guideline for one to choose this number $k$ given a new application scenario? \n\nThe unlabeled set is not \"unlabeled\" in essence. If my understanding was correct, it cannot contain open-set images which do not belong to any of the classes of interest. It is also nontrivial to control that the images contain only one salient object per image.\n\nHence, while I agree with the authors that existing approaches to comparing deep neural network classifiers could be improved, I think the proposed solution is not a good alternative yet. \n\n","sentences":[{"sentence_type":"2","sentence":"Hence, while I agree with the authors that existing approaches to comparing deep neural network classifiers could be improved, I think the proposed solution is not a good alternative yet.","rephrased":"While I concur with the authors that there is room for improvement in current methods for comparing deep neural network classifiers, I believe the proposed solution has potential but may require further refinement to be considered a viable alternative."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[920,1039,"Missed by Model"],[1473,1660,"Not concerning"]],"Comments":[]}
{"id":"Sklnu2iP3X","text":"This paper focuses on multi-choice QA and proposes a coarse-to-fine scoring framework. Where the coarse-grained answer scoring model computes the scores with the attention over the whole passages, and the fine-grained one only uses local contexts for each answer option (candidate).\n\nThe proposed approach was evaluated on the only dataset of WikiHop, and achieved large improvement over the other methods on the leaderboard. However, I found the paper lack of motivation about the designs of the coarse and fine scoring models. For example, why using self-attention after GRU and co-attention in the two answer scoring models?\n\nAnother concern I have is about the novelty. Besides the complicated model designs, the coarse and fine scoring models are both following some common ideas in previous work. And each model could achieve on-par results compared to previous baselines. This makes me feel that the whole approach looks more like model combination of two not-so-novel (and not very well-motivated) models.\n\nThirdly, the only evaluation on WikiHop brings more problems to the above two points. Since the motivation of the architecture design is not very clear, I am not sure whether the architectures could generalize to other benchmarks. Similar concern for the model combination approach.\n\nMoreover, the proposed approach is a general architecture for multiple-choice datasets requiring multiple evidence. To verify its generalizability, I suggest the authors add further experiments on one dataset from the following ones: either multi-choice QA datasets like ARC and RACE\/RACE-open, or other open-domain QA datasets like TriviaQA, by treating the re-ranking of answer predictions as multi-choice QA problems (like the approach in Evidence Aggregation for Open-Domain QA from ICLR2018).\n\nA minor question: why the CFC w\/o encoder could still work so well? At least the fine-grained scoring model should heavily rely on encoders. Otherwise, according to Eq (17), the fine-grained model cannot use any contextual information.","sentences":[{"sentence_type":"2","sentence":"However, I found the paper lack of motivation about the designs of the coarse and fine scoring models.","rephrased":"However, I believe the paper could benefit from a clearer explanation of the motivation behind the designs of the coarse and fine scoring models."},{"sentence_type":"3","sentence":"This makes me feel that the whole approach looks more like model combination of two not-so-novel (and not very well-motivated) models.","rephrased":"This leads me to question whether the approach is essentially a combination of two models that may not be particularly novel or well-motivated."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[426,528,"Maybe"],[879,1013,"Maybe"]],"Comments":[]}
{"id":"d70yJweg2vl","text":"Strengths:\n\nThe main idea of the paper is intuitively reasonable and the experimental section shows promising performance on the investigated tasks. The related work section is extensive and adequately situates the conducted research in a broad context.\n\nWeaknesses:\n\nAlthough the actual idea behind the paper is very incremental, the reader is still left with questions particularly w.r.t. details of the method and Remark 1:\n- In Remark 1, the authors state that if their method finds a Nash Euqilibrium, then the student policy is following a minimax regret strategy. I understand that the authors take this result from the Robust PLR paper, to which their method is very similar. However, I have certain concerns regarding this statement:\n    - The proofs in the Robust PLR paper are relying on the assumption that the replay teacher is utilizing the true regret to guide its sampling. However, there is no guarantee that either the MaxMC or PositiveValueLoss are actually estimating the true regret in a realistic setting. If e.g. an agent is not observing any reward signal in a sparse reward task, it can have zero residuals by predicting a value of 0 in all states, although there may exist a policy solving the task. In this case, MaxMC and PositiveValueLoss would not estimate the true regret.\n     - By using the level editing scheme, the second teacher in the dual curriculum seems to employ a different utility function than the constant one assumed in Robust-PLR. Does this change the theoretical results?\n     - These disconnects between the theory in the Robust-PLR method and the presented method should be carefully addressed in order to avoid false conclusions from reader of the papers.\n- Looking at Table 5, it is unclear whether the additional environment interaction required to estimate the regret on the edited levels is taken into account in the presented results. Table 5 already shows that the number of environment steps differs by around 10% between methods. Can the authors explain the reason for this difference? Further, the plots in the main paper use \"Student PPO Updates\" as the x-axis unit. I guess that this unit only takes into account the environment steps taken in levels WITHOUT the stop gradient, i.e. does not take into account the additional required evaluations incured by the level generator? Given that multiple new levels can be generated for each level selected for student training, this could be a high hidden cost.\n- From the statements at the beginning and end of Section 4.2, it seems that ACCEL does not use the random level generation, as the authors state that \"for ACCEL we begin with empty rooms and randomly edit the block locations\" and further investigate an ablation where they edit uniformly sampled levels. If the regular ACCEL algorithm is not using the domain randomization, Algorithm 1 yields a wrong picture of the ACCEL algorithm, as the random sampling case will never take place in practice.\n\nGiven the large amount of space that the authors spend on high-level introduction and discussion w.r.t. related work, it seems unsatisfying that these technical details are not clarified in the main paper.\n\nMinor Points:\n - Question: Would it be possible to compare to some adaptive domain randomization methods that do not just randomly sample tasks? Or are they ill-suited for the investigated experiments? If so, why? It would be interesting to see how a method following a different methodology performs in these experiments.\n - Another related work that should be mentioned is the work on contextual MDPs [1], which is conceptually similar to the UPOMDPs used to model the space of possible tasks.\n\n[1] Modi, Aditya, et al. \"Markov decision processes with continuous side information.\" Algorithmic Learning Theory. PMLR, 2018.","sentences":[{"sentence_type":"2","sentence":"Although the actual idea behind the paper is very incremental,","rephrased":"While the paper builds on existing concepts,"},{"sentence_type":"2","sentence":"Given the large amount of space that the authors spend on high-level introduction and discussion w.r.t. related work, it seems unsatisfying that these technical details are not clarified in the main paper.","rephrased":"Considering the extensive introduction and discussion on related work, it would be beneficial for the authors to provide more clarity on these technical details in the main paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[268,330,"Confirmed"],[2966,3171,"Confirmed"]],"Comments":[]}
{"id":"VEmAbdVMI-","text":"The paper describes a method for GAN generation of cardiac MR images along with generated anatomical segmentations for these new images.  The authors then train a segmentation network and demonstrate improved results (in general) when the training set is enlarged with GAN-generated images and their (generated) segmentations.\n\nThe method described is interesting and should prove useful in the absence of large annotated datasets.  The results seem reasonably convincing although I have some questions.  Given the limitations of the short paper I think that this is an interesting  and reasonably well described work.  Specific comments to improve the paper are below:\n\n - The specific anatomical structures segmented are not named\n - The sizes of the datasets used should be mentioned, since these are clearly very important for the reader's understanding (and to save them searching the literature)\n -  The properties of the test sets are not described - from which set do they come and how large are they?   Validation data is also not described.\n - The term fine-tuning is used without explanation until late in the paper - the meaning of this term in the context of this work should be explained before presenting the results. \n- (outside the scope of this short paper) It would be interesting to experiment with combining the two public datasets .  It would also be useful to see a graph of how the results improve as additional training images are added - is there a saturation point beyond which additional training images are not useful?  Are the generated images more useful if there was a larger number of images (i.e. more variability) in the dataset that was used to train the generator?\n\n","sentences":[{"sentence_type":"1","sentence":"The results seem reasonably convincing although I have some questions.","rephrased":"The results are quite convincing, but I do have a few questions that could further clarify the findings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[433,503,"Not concerning"],[906,1050,"Missed Maybe"]],"Comments":[]}
{"id":"H1ejhIc0tE","text":"This paper proposes to use an autoregressive Transformer model for the purpose of protein design. The model is well justified and overall the paper is written well. However there are couple of questions I have to authors:\n\n1. Since protein is a graph that doesn't have a clear ordering, which ordering to you use in autoregressive decoder ?\n2. Could you also compare the model with non-deep neural network baselines ?\n3. How expensive would it be to evaluate the energy of generated proteins ?","sentences":[{"sentence_type":"1","sentence":"However there are couple of questions I have to authors:","rephrased":"I have a few questions for the authors to help clarify certain aspects:"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[165,221,"Not concerning"]],"Comments":[]}
{"id":"_iPY3MFWjj","text":"Quality:\nStudy well designed overall.\n\n-Clarity:\nPaper clearly written. Fig 1 can be misleading when showing layers stacked vertically.\n\n-Originality:\n-- This paper does not deal with medical imaging, but only with shape encoding.\n\n--Two recent works [1,2], not cited by this paper, have proposed a CNN-based solution for computing Signed Distance Functions, one even learning how to represent different classes of shapes [1]. \n\nRef:\n[1] Park JJ, Florence P, Straub J, Newcombe R, Lovegrove S. Deepsdf: Learning continuous signed distance functions for shape representation. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2019 (pp. 165-174).\n[2] Chen Z, Zhang H. Learning implicit fields for generative shape modeling. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2019 (pp. 5939-5948).\n\n- Significance of this work\nNo clear gain demonstrated versus existing methods to compute SDF. This is more a \"feasibility\" study. I do not fully agree that complexity of SDF computing with classic  methods (e.g. fast marching) is \"a bottleneck\" \nAlso the cochlear shapes are simple and smooth, modeled as \"generalized cylinder around a centerline having four shape parameters\". This greatly limits significance. \nFinally, SDM of size 50 × 50 × 60 can seem quite small to encode more complex shapes.\n\n-Pros and cons:\nPros\n- Clear, well written\n\ncons:\n- This paper does not deal with medical imaging, but only with shape encoding.\n- Shapes being studied is smooth and simple. \n","sentences":[{"sentence_type":"2","sentence":"No clear gain demonstrated versus existing methods to compute SDF.","rephrased":"The paper could benefit from a more explicit demonstration of its advantages over existing methods for computing SDF."},{"sentence_type":"2","sentence":"I do not fully agree that complexity of SDF computing with classic methods (e.g. fast marching) is \"a bottleneck\"","rephrased":"It would be helpful if the paper could provide more evidence to support the claim that the complexity of SDF computing with classic methods is a significant bottleneck."},{"sentence_type":"1","sentence":"This is more a \"feasibility\" study.","rephrased":"The study appears to be exploratory in nature, which could be clarified as a preliminary investigation into the feasibility of the proposed approach."},{"sentence_type":"2","sentence":"This greatly limits significance.","rephrased":"The use of simple and smooth shapes may limit the broader applicability and significance of the findings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[883,949,"Not concerning"],[950,985,"Confirmed"],[1234,1267,"Not concerning"]],"Comments":[]}
{"id":"rkgX7TrIp7","text":"\n# Unrealistic assumptions and trivial theory\n\nThis papers proposes a method to adjust the learning rate of stochastic gradient methods. The problem is of great importance but the theoretical results and presentation contain many issues that make the paper unfit for publication.\n\nThe main issue that I see is that the assumption made are unrealistic and make the theory trivial. First, for gradient descent, the authors assume that the gradient is of the form L(x_t) (x_t - x*). Under this assumption, gradient descent converges on a single step with step size 1 \/ L(x_t). In the stochastic setting, they assume that *each* stochastic gradient is of the form L_i(x_t) (x_t - x*), Eq. (11). Again, SGD in this scenario converges in a single iteration with step size 1 \/ L_i(x_t).\n\nNo wonder in this scenario the authors are able to obtain linear convergence of SGD to arbitrary precision (which is known to be impossible even for quadratics).\n\n\n# Other Issues\n\n* Motivation of Eq. (9) is not discussed in sufficient detail. It is unclear to me how to obtain (9) from (7) as the authors mention. Regarding notation, L(x_t) is a scalar, hence (9) could be written more simply as \\nabla f(x_t) = L(x_t) (x_t - x*). Why the need for the Kronecker product?\n\n* The authors should clearly state what are the assumptions in the theorem statement. For theorem 1 these are not clearly stated, and phrases like \"Theorem 1 provides a simple condition for the linear convergence of SGD\" give the wrong impression that the Theorem is widely applicable.\n\n\n# Minor\n  * Belo Eq. (10): \"where \\epsilon_1 is a parameter to prevent ||x_t - x_{t-1}|| going to zero: . I guess what the authors meant is to prevent *the denominator* going to zero, you do want ||x_t - x_{t-1}|| to go to zero as you approach a stationary point\n","sentences":[{"sentence_type":"2","sentence":"This papers proposes a method to adjust the learning rate of stochastic gradient methods. The problem is of great importance but the theoretical results and presentation contain many issues that make the paper unfit for publication.","rephrased":"This paper proposes a method to adjust the learning rate of stochastic gradient methods, which is a significant problem. However, there are several issues with the theoretical results and presentation that need to be addressed before considering the paper for publication."},{"sentence_type":"2","sentence":"The main issue that I see is that the assumption made are unrealistic and make the theory trivial.","rephrased":"The main concern is that some of the assumptions may be too idealistic, which could oversimplify the theory."},{"sentence_type":"2","sentence":"No wonder in this scenario the authors are able to obtain linear convergence of SGD to arbitrary precision (which is known to be impossible even for quadratics).","rephrased":"It is surprising that the authors claim to achieve linear convergence of SGD to arbitrary precision, a result that is generally considered unattainable even for quadratics, which suggests a need for further clarification or revision of the assumptions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[137,279,"Confirmed"],[281,379,"Confirmed"],[781,942,"Confirmed"],[963,1023,"Missed by Model"]],"Comments":[]}
{"id":"SkxCsZgccr","text":"The paper is focused on perturbation-based local explanation methods; methods that only need black-box(ish) access to the model and generally seek to find a region, pixel, etc's importance score through by removing that region, pixel, etc.. The intuition is that an important region if removed, will result in a large drop in the predicted class confidence. One main issue with such methods is that the removal itself can throw the image out of the data distribution and therefore result in a drop in confidence, not because of the region's importance, but because of the network's unpredictable behavior in such unseen parts of the input space. The work is focused on giving a solution to this problem: instead of removal through blurring, graying, etc, use inpainting; i.e. replace the removed region with using given the rest of the image. The idea has already been discussed out in the literature and the novelty of the work seems to be twofold: They introduce the same method in a way that is not curated for a specific perturbation-based method and could be concatenated with \"ANY\" given (or future) perturbation-based local explanation method (which authors notate by calling it ${existing_method}-G, they study robustness to hyper-parameter choice. \n\nThe paper is quite well written and the experiments are comprehensive. I have two major comments\/issues with the work:\n\n1- The contribution of this work given existing work (more specifically the famous Chang et al work seems not to be enough for a venue like ICLR. If I want to list the contributions, it would be as follows (I would appreciate if the authors could correct me as the score is subject to change given more clarification on the matter):\n    - This work utilizes an inpainting step in combination with several methods while previous work is focused on meaningful perturbations method. This, although useful, does not introduce a novel technical contribution. The main technical contribution has been the use of inpainting (to be more exact, using generative models to approximate P(c|x_r)) which has been done before on a few previous works.\n    - The work argues that the use of inpainting in Chang et al (focused on keeping the salient object and removing background) was invalid as the inpainter model is not trained to do such a task. It could be argued that one could train another inpainting model that \"is\" capable of such a thing and therefore the general argument would not hold. One drawback of this approach, however, would be that training such an inpainting model might be difficult.\n    - Hyperparameter robustness. Studying this question is valuable. However, given that the assumption of this work and previous works is that generative approaches are generally better (even not considering the hyperparameter robustness), I am not sure how this knowledge could be used.\n\n2- Both this work and the previous works run on the assumption mentioned at the beginning of this review which basically says that non-generative perturbation-based methods throw the image out of data distribution and this is bad for such and such reasons. Although intuitively clear, I could not find any evidence in this work suggesting any meaningful difference using objective measures. One would assume that such phenomena would manifest itself clearly using insertion-deletion explanation metrics while as the authors report there was no significant difference. (Section 4.1 results clearly show a difference but this is not related to how the downstream explanation task is affected) For all it is know, generative methods have the drawback of being computationally more expensive than a simple blurring or replacing with random noise. (And a major elephant in the room is whether using an inpainter is actually taking the data back to the true data distribution which seems to be on an unproven assumption that these generative models are capable of learning the data manifold)\n\nMinor comments:\n    -Section 4.2 is really interesting. Thanks!\n    - Fig 3 results: MP is more robust than MP-G and I couldn't find any explanation of why this method behaves specifically different than the other two in the experiments section. It might be better to move the explanation in the discussions to the experiments.\n    - The task of most generative perturbation-based methods is to find a way to approximate P(c|x_\\r) which is the conditional probability given the non-removed part of the image. Usually, they do the approximation by sampling several images from the conditional P(x_r|x_\\r) (conditional inpainting)  using the generative model and averaging the prediction probability. This work seems not to be concerned with these specifics and directly feeds one of such samples. Could you explain this choice\n    - For studying the robustness of LIME, apart from the random seed, couldn't one change the hyperparameters of the superpixel method? Tha one seems more of a practical problem.","sentences":[{"sentence_type":"2","sentence":"The contribution of this work given existing work (more specifically the famous Chang et al work seems not to be enough for a venue like ICLR.","rephrased":"While the paper builds upon existing work, such as the notable Chang et al., it would be beneficial for the authors to further clarify and distinguish their contributions to strengthen the case for inclusion in a prestigious venue like ICLR."},{"sentence_type":"1","sentence":"For all it is know, generative methods have the drawback of being computationally more expensive than a simple blurring or replacing with random noise.","rephrased":"It is acknowledged that generative methods may be more computationally intensive compared to simpler techniques such as blurring or noise replacement; this aspect could be further explored to understand its implications on practical applications."},{"sentence_type":"2","sentence":"And a major elephant in the room is whether using an inpainter is actually taking the data back to the true data distribution which seems to be on an unproven assumption that these generative models are capable of learning the data manifold","rephrased":"An important consideration for future work could be to investigate the extent to which using an inpainter aligns the data with the true data distribution, as this hinges on the generative models' ability to accurately learn the data manifold."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1382,1524,"Not concerning"],[2812,2859,"Missed Maybe"],[3146,3251,"Missed Maybe"],[3552,3703,"Not concerning"],[3705,3945,"Not concerning"]],"Comments":[]}
{"id":"SygpIWqlM","text":"\n- Paper summary\n\nThe paper proposes a label-conditional GAN generator architecture and a GAN training objective for the image modeling task. The proposed GAN generator consists of two components where one focuses on generating foreground while the other focuses on generating background. The GAN training objective function utilizing 3 conditional classifier. It is shown that through combining the generator architecture and the GAN training objective function, one can learn a foreground--background decomposed generative model in an unsupervised manner. The paper shows results on the MNIST, SVHN, and Celebrity Faces datasets.\n\n- Poor experimental validation\n\nWhile it is interesting to know that a foreground--background decomposed generative model can be learned in an unsupervised manner, it is clear how this capability can help practical applications, especially no such examples are shown in the paper. The paper also fails to provide any quantitative evaluation of the proposed method. For example, the paper will be more interesting if inception scores were shown for various challenging datasets.  In additional, there is no ablation study analyzing impacts of each design choices. As a result, the paper carries very little scientific value.","sentences":[{"sentence_type":"2","sentence":"The paper also fails to provide any quantitative evaluation of the proposed method.","rephrased":"The paper could be strengthened by including a quantitative evaluation of the proposed method."},{"sentence_type":"3","sentence":"As a result, the paper carries very little scientific value.","rephrased":"To enhance the scientific contribution, the paper could benefit from more rigorous experimental validation and demonstration of practical applications."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[635,663,"Missed by Model"],[797,913,"Missed by Model"],[914,997,"Confirmed"],[1112,1195,"Missed by Model"],[1196,1256,"Confirmed"]],"Comments":[]}
{"id":"WeMGJ_pfnS4","text":"Strengths:\n- The empirical observations on the effect of memorizing atypical samples are interesting.\n- The writing is clear, with detailed descriptions of the proposed method.\n- It is good to have ablation studies on different modules in BAT.\n\nWeaknesses:\n- Since there are several extra modules in the objective of BAT (Eq. (10)), there should be evaluations under adaptive attacks, whose objective involves the terms like $\\mathcal{L}\\_{DL}$.\n- As described in the paper, it seems that the authors do not apply early-stopping during the adversarial training process. This largely weakens the performance of baselines [b]. Besides, more advanced methods listed in [c] should be considered on CIFAR-100.\n- CIFAR-100 and Tiny ImageNet are not quite widely used in the adversarial community. It would be more informative to have the results like Table 1 on CIFAR-10, where many benchmarks exist to better estimate the effectiveness of BAT.\n\nMinors:\n- As suggested by [a], weak attacks like FGSM should not be treated as an evaluation, at least not in the main text.\n- There should be more details on the settings (e.g., iteration steps) of PGD and CW attacks.\n- The $1\/\\lambda$ is 6 in TRADES paper, while it is set as 5 in, e.g., Table 1.\n\nReferences:\n[a] On Evaluating Adversarial Robustness.\n[b] Overfitting in adversarially robust deep learning.\n[c] RobustBench: a standardized adversarial robustness benchmark.","sentences":[{"sentence_type":"2","sentence":"This largely weakens the performance of baselines [b].","rephrased":"The lack of early-stopping during the adversarial training process may impact the performance of baselines [b], and it would be beneficial to consider this aspect in future iterations."},{"sentence_type":"1","sentence":"CIFAR-100 and Tiny ImageNet are not quite widely used in the adversarial community.","rephrased":"Including benchmarks on datasets like CIFAR-10, which are more commonly used in the adversarial community, could enhance the generalizability of the results."},{"sentence_type":"2","sentence":"As suggested by [a], weak attacks like FGSM should not be treated as an evaluation, at least not in the main text.","rephrased":"Considering the suggestions from [a], it may be more appropriate to include evaluations using stronger attacks than FGSM, or to discuss FGSM results separately from the main evaluation metrics."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[570,624,"Maybe"],[707,790,"Not concerning"],[950,1064,"Not concerning"]],"Comments":[]}
{"id":"VDtIz9Nj8w","text":"The idea of the paper is good. Results support the idea and gives an increase in the performance compared to baseline methods. Considering the page limit, the paper is well written. It would be nice if authors can provide a reference for lesion-wise false positive rate (LFPR) and Lesion-wise true positive rate (LTPR). ","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"hHF_80xPU","text":"The authors present a deep learning method for predicting embryo implantation probability, based on time-lapse videos acquired during IVF. The authors claim a substantial improvement relative to an expert panel of embryologists, as measured by AUC and predictive values. The method is assessed using 10-fold cross validation on 272 videos with known implantation outcome, and 4,087 videos with panel grading.\n\nThere is some pre-existing similar work in the literature - most similarly Tran et al 2019. This is appropriately cited by the authors, who describe subtle differences compared with their work. Despite this similarity, replication of a solution to the general problem on different data (using the authors' method rather than that of Tran et al) counts as sufficient originality. Significance of the work seems high: the problem is clearly important, and the potential for improvement over current clinical methods seems substantial. Quality of the work seems high, particularly given the short format: the authors present a convincing method and then validate it quite thoroughly. Clarity is good, although it would be beneficial to introduce the work of Tran et al earlier, and better explain the differences in the authors' work. The authors also do not explain their method in great detail, although I feel this is understandable given the short format.\n\nOn balance I am impressed by this paper, and strongly believe it should be accepted.\n\nPros:\n* Well-motivated.\n* Well-described.\n* High quality validation.\n\nCons:\n* Fairly similar to pre-existing work, although I think this is perfectly fair and the work still has significant originality.\n* Slight lack of clarity in differences vs previous work.\n* Lack of detail concerning the authors' method.\n* Confusing description of the dataset: how were the non-labelled videos used?","sentences":[{"sentence_type":"1","sentence":"Fairly similar to pre-existing work, although I think this is perfectly fair and the work still has significant originality.","rephrased":"While there are similarities to pre-existing work, the current study adds significant originality and builds constructively on the foundation laid by previous research."},{"sentence_type":"1","sentence":"Slight lack of clarity in differences vs previous work.","rephrased":"It would be helpful to more clearly delineate the differences between this work and previous studies to further highlight the novel contributions."},{"sentence_type":"1","sentence":"Lack of detail concerning the authors' method.","rephrased":"Providing more detail about the authors' method could enhance the reproducibility and understanding of the study."},{"sentence_type":"1","sentence":"Confusing description of the dataset: how were the non-labelled videos used?","rephrased":"Clarification on how the non-labelled videos were utilized would be beneficial for a complete understanding of the dataset and methodology."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1242,1366,"Missed Maybe"],[1532,1656,"Not concerning"],[1659,1714,"Not concerning"],[1717,1763,"Maybe"],[1766,1842,"Maybe"]],"Comments":[]}
{"id":"rkxtaO2mcr","text":"After rebuttal:\n\nThank you to the authors for responding to my review.\n\n1) The title of the conference is \"... on Learning Representations\". As I stated in the review (\"no, e.g., neural networks are employed\"), neural networks are an *example* of, but do not subsume, all representation learning methods. Therefore, I agree that papers that do not cover neural networks are welcome at the conference. However, as I stated in the review, my evaluation of the method proposed in the submission is that it does not concern representation learning (\"The employed features in Table 3 are handcrafted\"). I believe this evaluation is defensible, but of course the final evaluation is up to the chairs. However, I note that the authors did not respond directly to my evaluation that the method is not engaging in representation learning.\n\n2-7) As the other reviewer notes, the paper lacks clarity in many places, and does not sufficiently discuss prior work, including in postural control (there is one citation in the references that is not mentioned in the main text), hierarchical Bayesian optimization within or without a Gaussian processes framework (https:\/\/scholar.google.com\/scholar?hl=fr&as_sdt=0%2C5&q=hierarchical+bayesian+optimization&btnG=), or experience replay (https:\/\/scholar.google.com\/scholar?hl=fr&as_sdt=0%2C5&q=replay+machine+learning&btnG=). Therefore, it is difficult to ascertain the research contribution.\n\nAs such, I stand by my evaluation that this submission is not ready for publication at ICLR.\n\n===========================\n\nBefore rebuttal:\n\nThe submission presents a hierarchical Bayesian optimization (HiBO) approach to solving a postural control task expressed as a proportional-derivative (PD) controller.\n\nStrengths:\n- The HiBO approach outperforms the non-hierarchical BO approach on the task of postural control.\n\nWeaknesses:\n- The paper does not make use of representation learning (no, e.g., neural networks are employed) and is therefore out-of-place at ICLR. The employed features in Table 3 are handcrafted.\n- The task (simulating human postural control) is not well-situated in the context of prior work using HiBO for robotics, so the contribution remains unclear.\n- It is not clear why this problem should be formulated as contextual policy search (i.e., to what the context variable refers).\n- Only one baseline (Bayesian optimization (BO)) is reported. This baseline corresponds to the ablation of the HiBO method (i.e., the omission of the context variable), and so does not represent, more broadly, an alternative approach.\n- The concept of \"mental replay\" is briefly introduced, but no reference is made to prior work in imagined rollouts, and no ablation study on the impact of this component is performed.\n\nMinor points:\n- It is unclear why the problem setting should be labeled as \"psychological\" postural control.\n- There are several missing references (\"?\") in the text.","sentences":[{"sentence_type":"2","sentence":"The paper does not make use of representation learning (no, e.g., neural networks are employed) and is therefore out-of-place at ICLR.","rephrased":"While the paper does not focus on representation learning through neural networks, it would be beneficial to clarify how the approach aligns with the broader themes of representation learning that are central to ICLR."},{"sentence_type":"2","sentence":"The task (simulating human postural control) is not well-situated in the context of prior work using HiBO for robotics, so the contribution remains unclear.","rephrased":"It would be helpful if the authors could better situate the task of simulating human postural control within the context of prior work using HiBO for robotics to clarify the contribution of the paper."},{"sentence_type":"1","sentence":"It is not clear why this problem should be formulated as contextual policy search (i.e., to what the context variable refers).","rephrased":"The authors might consider providing a clearer explanation of the rationale behind formulating the problem as a contextual policy search, particularly in relation to the context variable."},{"sentence_type":"2","sentence":"Only one baseline (Bayesian optimization (BO)) is reported. This baseline corresponds to the ablation of the HiBO method (i.e., the omission of the context variable), and so does not represent, more broadly, an alternative approach.","rephrased":"Including additional baselines beyond Bayesian optimization (BO) could strengthen the paper by providing a broader comparison to alternative approaches."},{"sentence_type":"2","sentence":"The concept of \"mental replay\" is briefly introduced, but no reference is made to prior work in imagined rollouts, and no ablation study on the impact of this component is performed.","rephrased":"Expanding on the concept of \"mental replay\" by referencing prior work in imagined rollouts and possibly conducting an ablation study on this component could enhance the paper's depth."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[695,829,"Missed Maybe"],[865,903,"Missed by Model"],[909,949,"Missed by Model"],[1859,1993,"Maybe"],[2046,2202,"Maybe"],[2205,2331,"Confirmed"],[2334,2566,"Confirmed"],[2569,2751,"Confirmed"],[2769,2861,"Missed by Model"]],"Comments":[]}
{"id":"wzts32BTJl","text":"The authors proposed to utilize longitudinal scans for nodule malignancy classification. The proposed method is essentially applying the same backbone on two longitudinal CT scans and merge the feature vector for classification. The method was applied on an in-house dataset, and claimed not comparable with other dataset. \n\nIt’s meaningful to bring attention to longitudinal scans. The dataset is well-constructed.\nHowever, the two-stream concept is not very solid in my opinion. For example, for the two-stream action recognition paper referenced, the two streams are spatial and temporal streams. Here it’s merely the same feature extractor and classification on the concatenated feature vector. The experimental comparison is not very meaningful. The main reading from the result is that longitudinal data is better than cross-sectional which is self-evident.\n\nDetailed comments:\n1) Can the authors comment on the gap between the training\/validation F1 and the test F1. It seems the better performance of TS-3DCNN comes from better generalization capability.\n2) Which blocks from CNN are finally used, or are all the blocks used as the figure suggests? ","sentences":[{"sentence_type":"2","sentence":"The two-stream concept is not very solid in my opinion.","rephrased":"I believe the two-stream concept could be further strengthened and clarified."},{"sentence_type":"2","sentence":"The experimental comparison is not very meaningful.","rephrased":"The experimental comparison could be made more robust to enhance the significance of the results."},{"sentence_type":"2","sentence":"The main reading from the result is that longitudinal data is better than cross-sectional which is self-evident.","rephrased":"The results seem to confirm the expected advantage of longitudinal data over cross-sectional data, which could be further discussed to highlight its implications."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[699,750,"Maybe"],[751,863,"Confirmed"]],"Comments":[]}
{"id":"VJA6B4S1MJX","text":"Strengths:\n - Proposed an interesting method with nice experimental results.\n\nWeaknesses:\n - The connection to related works is not well discussed.\n - The benefit of the proposed method over other similar methods is not well justified.\n\nDetailed comments:\n 1. The main idea of this paper is based on VRNN (Chung et al., 2015). Such connection, as well as the connection to other methods based on VRNN (e.g. Aksan et al., 2018), is not clearly discussed in this paper. Other major approaches on style transferring are not well discussed either, such as VAE-based approaches (Akuzawa et al., 2018, Henter et al, 2018, Sun et al., 2020).\n 2. This paper claims \"state-of-the-art\". However, the experiments are not compared to the state-of-the-art approaches in the field.\n    - The TTS experiments focus on speaker similarity, but is compared to the Global Style Tokens (GST) model, which is not good at voice modeling due to its limited dictionary. VAE-based approach, such as Hsu et al., 2019, are better baselines. For the Tacotron baseline, it's also worth to include the result conditioned on speaker ID.\n    - On handwriting synthesis, the baseline used in the paper, Graves, 2013, is not a strong baseline either. More recent works, such as Aksan et al., 2018, Kotani et al., 2020, are better baselines.\n 3. The main novelty of this paper is Eq (2). The idea is: to generate sample $x$, the model is conditioned on both a content $c$ and a style $z$, where $z$ is from a function $M(x, x')$. Here $x'$ is a sample unrelated to $x$. A natural question is: is $x'$ really used by the model, or is it actually ignored? This is neither theoretically nor empirically answered in the paper.\n 4. To address the above question empirically, I'd suggest running two ablation studies:\n    - replace $M(x, x’)$ with $M(x)$\n    - replace $x’$ (more precisely $f'$) with a learned prior\n    - (interesting but not required) replace $x’$ (more precisely $f'$) with a random noise\n 5. There are quite some redundancy in the statement of the mismatch problem. The key idea of this paper is not presented until paper 5. It would be nice to save some space from them, and use it for the connection to related works.\n\nReferences:\n - Chung et al., A Recurrent Latent Variable Model for Sequential Data, NeurIPS 2015.\n - Aksan et al., DeepWriting: Making Digital Ink Editable via Deep Generative Modeling, 2018.\n - Akuzawa et al., Expressive Speech Synthesis via Modeling Expressions with Variational Autoencoder, Interspeech 2018.\n - Henter et al., Deep Encoder-Decoder Models for Unsupervised Learning of Controllable Speech Synthesis, 2018.\n - Sun et al., Fully-hierarchical fine-grained prosody modeling for interpretable speech synthesis, ICASSP 2020.\n - Hsu et al., Hierarchical Generative Modeling for Controllable Speech Synthesis, ICLR 2019.\n - Kotani et al., Generating Handwriting via Decoupled Style Descriptors, ECCV 2020.","sentences":[{"sentence_type":"2","sentence":"The TTS experiments focus on speaker similarity, but is compared to the Global Style Tokens (GST) model, which is not good at voice modeling due to its limited dictionary.","rephrased":"For the TTS experiments focusing on speaker similarity, a comparison with models known for stronger voice modeling capabilities, such as the VAE-based approaches, might provide a more robust evaluation."},{"sentence_type":"2","sentence":"On handwriting synthesis, the baseline used in the paper, Graves, 2013, is not a strong baseline either.","rephrased":"In the handwriting synthesis section, considering more recent and competitive baselines, such as Aksan et al., 2018 or Kotani et al., 2020, could strengthen the evaluation of the proposed method."},{"sentence_type":"1","sentence":"There are quite some redundancy in the statement of the mismatch problem.","rephrased":"The paper could benefit from reducing redundancy in the discussion of the mismatch problem to enhance clarity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[93,147,"Missed by Model"],[151,235,"Missed by Model"],[428,467,"Missed by Model"],[468,542,"Missed by Model"],[774,1013,"Confirmed"],[1112,1216,"Confirmed"],[1619,1687,"Missed by Model"],[1972,2045,"Confirmed"],[2046,2104,"Missed Maybe"]],"Comments":[]}
{"id":"S4XDagbDQfE","text":"The paper presents a subgraph approximation method to reduce communication in distributed GCN training. The authors observe that up until a certain point it is possible to delete vertices in a graph without a large accuracy loss for GCN training.  Based on the observation, the authors propose the subgraph approximation idea. They claim that if the subgraph on each machine has additional information of 1 or 2 hop neighbors, the accuracy of GCN training can be maintained. \n\nThe results are surprising since many information is lost for the border nodes. I am curious how many border nodes are labeled. I suspect that if most of the border nodes are labeled and are used for computing the loss, the model cannot be trained very well.  \n\nI don't understand the reason for random sampling in algorithm 1. Since this step is done before the actual training, it is not a stochastic procedure. I suspect the performance will vary in different runs. The authors need to add some explanation and experimental evidence for this design. In my opinion, because different nodes carry different amounts of information, we should select the set of nodes that carry the most information, for example, a node should be added to a partition if it has the most number of connections with the nodes in that partition. I don't see how random selection can perform better than this. \n\nAlso, I notice that the authors only tested with GNN with 2 layers in the experiment. Many GNN models have more than 2 layers. I am curious whether the proposed method will still work for GNN with more layers. \n\nMy main concern about this paper is its lack of justification. For a heuristic method, I would like to see more experimental results. The authors only experiment with two models on two graphs. It is not convincing that the method is generally applicable to GCN training.  ","sentences":[{"sentence_type":"1","sentence":"The results are surprising since many information is lost for the border nodes.","rephrased":"The results are intriguing, especially considering the potential information loss for the border nodes."},{"sentence_type":"1","sentence":"I don't understand the reason for random sampling in algorithm 1.","rephrased":"The rationale for random sampling in algorithm 1 is unclear to me."},{"sentence_type":"2","sentence":"I don't see how random selection can perform better than this.","rephrased":"It would be helpful if the authors could clarify how random selection might outperform more targeted node selection strategies."},{"sentence_type":"2","sentence":"My main concern about this paper is its lack of justification.","rephrased":"My primary concern is that the paper could benefit from additional justification for the proposed method."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[477,556,"Not concerning"],[739,804,"Maybe"],[1302,1364,"Confirmed"],[1579,1641,"Maybe"],[1713,1849,"Missed Maybe"]],"Comments":[]}
{"id":"6bsEQIMLR-c","text":"#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe paper proposes a novel CNN architecture for semantic segmentation based on U-Net and MobileNetV3 blocks. The proposed architecture is applied on the MiniCity dataset and performance improvements are shown.\n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n* Clarity: the paper is clear and easy to read.\n* Effectiveness: the method seems effective on small-size datasets.\n\n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n* Scope: The proposed architecture change is motivated by computational efficiency and parameter reduction rather than incorporating prior knowledge. Prior knowledge is only considered to motivate the techniques used for data augmentation, which are generic and widely used techniques.\n\n#### 4. [Overall rating] Paper rating\n* 5. Marginally below acceptance threshold\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\nDespite being effective, the proposed architecture is not motivated by incorporating prior knowledge but rather by computational efficiency and therefore the paper falls outside of the intended scope of this workshop.\n\n#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n(line 173) \"We divide the learning rate by 10 at . \"\nMissing word.\n(line 177) \"poll\" --> pole","sentences":[{"sentence_type":"2","sentence":"Despite being effective, the proposed architecture is not motivated by incorporating prior knowledge but rather by computational efficiency and therefore the paper falls outside of the intended scope of this workshop.","rephrased":"While the proposed architecture demonstrates effectiveness, it would be beneficial to see a stronger emphasis on incorporating prior knowledge to align more closely with the workshop's focus on innovative research."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1157,1374,"Not concerning"]],"Comments":[]}
{"id":"Hygw-kVKtE","text":"This paper proposed a tool for visualizing the latent spaces for generative models. The authors demonstrated this tool by applying this tool to show some visualizations of some auto-encoders (VAE, WAE and AAE).\n\nPros:\n\n1. The paper is easy to follow and the visualization results are clear. It is easy to understand the metrics from the figures of the visualization tool.\n\n2. The visualized metrics are useful and can show the differences between the WAE and the AAE compared with the VAE, which means that the visualizations are successful.\n\n3. The visualization tool can also analyze the attributes in the latent space, which is useful.\n\nCons:\n \n1. It is better if more generative models (e.g. GAN) can be studied using this tool.","sentences":[{"sentence_type":"1","sentence":"It is better if more generative models (e.g. GAN) can be studied using this tool.","rephrased":"The paper could be further strengthened by including additional generative models such as GANs in the study."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[651,732,"Not concerning"]],"Comments":[]}
{"id":"HkxXugn-cV","text":"This paper presents an objective for learning latent variable MRFs based on Bethe free energy and amortized inference. It is different from optimizing the standard ELBO in that it does not require sampling (which has large variance) nor it is a lower\/upper bound of the log-likelihood for general structured data. On some benchmark with neural HMMs, it is shown that the proposed approach achieves better held-out likelihood than other variational inference based approaches. \n\nThis paper presents an interesting idea which blends both the deep generative models research as well as the traditional Bethe free energy formulation. The prelmimarny results seems promising. I wonder how much difficult the saddle-point optimization will become on more complex models comparing with ELBO optimization. \n\nMinor comment:\n\nThe last equation in Section 2.2: the second summation should be over z_3'. ","sentences":[{"sentence_type":"1","sentence":"The prelmimarny results seems promising.","rephrased":"The preliminary results appear promising."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[630,670,"Not concerning"]],"Comments":[]}
{"id":"Skx9kUBXcH","text":"The basic idea of integrating templates for dialog generation is interesting. However, the implementation is confusing, yet another architecture, with clear motivations, intuitions, or even clarity. Worst of all, the experimental results are missing in table 2, the only placeholder for results in the paper. Further, I would appreciate human evaluation, rather than using BLEU as the metric. The latter is known to be inappropriate for dialog modeling evaluation.\n\nSection 2.1 needs more explanation.\n\n(Strong Reject)","sentences":[{"sentence_type":"2","sentence":"However, the implementation is confusing, yet another architecture, with clear motivations, intuitions, or even clarity.","rephrased":"However, the implementation could be clarified, as the motivations and intuitions behind the architecture are not clearly articulated."},{"sentence_type":"2","sentence":"Worst of all, the experimental results are missing in table 2, the only placeholder for results in the paper.","rephrased":"Most importantly, it appears that the experimental results are missing in table 2, which is a critical section for presenting the results in the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[78,198,"Confirmed"],[199,308,"Confirmed"]],"Comments":[]}
{"id":"H1JLMpYlM","text":"Summary: This paper tackles the issue of combining TD learning methods with function approximation. The proposed algorithm constrains the gradient update to deal with the fact that canonical TD with function approximation ignores the impact of changing the weights on the target of the TD learning rule. Results with linear and non-linear function approximation highlight the attributes of the method.\n\nQuality: The quality of the writing, notation, motivation, and results analysis is low. I will give a few examples to highlight the point. The paper motivates that TD is divergent with function approximation, and then goes on to discuss MSPBE methods that have strong convergence results, without addressing why a new approach is needed. There are many missing references: ETD, HTD, mirror-prox methods, retrace, ABQ. Q-sigma. This is a very active area of research and the paper needs to justify their approach. The paper has straightforward technical errors and naive statements: e.g. the equation for the loss of TD takes the norm of a scalar. The paper claims that it is not well-known that TD with function approximation ignores part of the gradient of the MSVE. There are many others.\n\nThe experiments have serious issues. Exp1 seems to indicate that the new method does not converge to the correct solution. The grid world experiment is not conclusive as important details like the number of episodes and how parameters were chosen was not discussed. Again exp3 provides little information about the experimental setup.\n\nClarity: The clarity of the text is fine, though errors make things difficult sometimes. For example The Bhatnagar 2009 reference should be Maei.\n \nOriginality: As mentioned above this is a very active research area, and the paper makes little effort to explain why the multitude of existing algorithms are not suitable. \n\nSignificance: Because of all the things outlined above, the significance is below the bar for this round. ","sentences":[{"sentence_type":"2","sentence":"The quality of the writing, notation, motivation, and results analysis is low.","rephrased":"The writing, notation, motivation, and results analysis could be improved to enhance the overall quality of the paper."},{"sentence_type":"2","sentence":"The paper has straightforward technical errors and naive statements: e.g. the equation for the loss of TD takes the norm of a scalar.","rephrased":"The paper appears to contain some technical inaccuracies that need to be addressed, such as the equation for the loss of TD which seems to incorrectly take the norm of a scalar."},{"sentence_type":"2","sentence":"Because of all the things outlined above, the significance is below the bar for this round.","rephrased":"Given the issues outlined, further work is needed to establish the significance of the contributions for this round."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[412,490,"Confirmed"],[916,1049,"Confirmed"],[1050,1170,"Missed by Model"],[1171,1193,"Missed by Model"],[1195,1231,"Missed by Model"],[1540,1619,"Missed by Model"],[1692,1851,"Missed by Model"],[1868,1959,"Confirmed"]],"Comments":[]}
{"id":"rkeDzTZ6KS","text":"This is a interesting paper on an important topic, but it was a main weakness: it assumes that the reader is deeply familiar with the CCA. In order to make the paper more accessible to a general audience, the authors should:\n1) have at least one sentence in the abstract that explains in layman terms why is CCA important and how it works (\"multi-view learning\" does not suffice); given that you have the term \"multi-view learning\" in the title, you should explain what it is and how it can benefit from CCA\n2)  re-organize the current intro, which reads more like related work, into a more traditional format\n     - one intuitive paragraph on what is multi-view learning (MVL), what is CCA, how does CCA help MVL \n     - one intuitive paragraph on an illustrative example on how MVL & CCA help solving a problem\n     - one intuitive paragraph on how the proposed approach works\n     - one paragraph summarizing the main findings\/results \n3) ideally, add a section with an illustrative running example, which would have a huge impact on the paper's readability (far more than, say, than the current Appendix) ","sentences":[{"sentence_type":"1","sentence":"it was a main weakness: it assumes that the reader is deeply familiar with the CCA.","rephrased":"The paper could be improved by ensuring it is accessible to readers who may not be deeply familiar with the CCA."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[55,138,"Not concerning"]],"Comments":[]}
{"id":"B1_TQ-clG","text":"This paper studies learning to play two-player general-sum games with state (Markov games). The idea is to learn to cooperate (think prisoner's dilemma) but in more complex domains. Generally, in repeated prisoner's dilemma, one can punish one's opponent for noncooperation. In this paper, they design an apporach to learn to cooperate in a more complex game, like a hybrid pong meets prisoner's dilemma game. This is fun but I did not find it particularly surprising from a game-theoretic or from a deep learning point of view. \n\nFrom a game-theoretic point of view, the paper begins with somewhat sloppy definitions followed by a theorem that is not very surprising. It is basically a straightforward generalization of the idea of punishing, which is common in \"folk theorems\" from game theory, to give a particular equilibrium for cooperating in Markov games. Many Markov games do not have a cooperative equilibrium, so this paper restricts attention to those that do. Even in games where there is a cooperative solution that maximizes the total welfare, it is not clear why players would choose to do so. When the game is symmetric, this might be \"the natural\" solution but in general it is far from clear why all players would want to maximize the total payoff. \n\nThe paper follows with some fun experiments implementing these new game theory notions. Unfortunately, since the game theory was not particularly well-motivated, I did not find the overall story compelling. It is perhaps interesting that one can make deep learning learn to cooperate, but one could have illustrated the game theory equally well with other techniques.\n\nIn contrast, the paper \"Coco-Q: Learning in Stochastic Games with Side Payments\" by Sodomka et. al. is an example where they took a well-motivated game theoretic cooperative solution concept and explored how to implement that with reinforcement learning. I would think that generalizing such solution concepts to stochastic games and\/or deep learning might be more interesting.\n\nIt should also be noted that I was asked to review another ICLR submission entitled \"CONSEQUENTIALIST CONDITIONAL COOPERATION IN\nSOCIAL DILEMMAS WITH IMPERFECT INFORMATION\n\" which amazingly introduced the same \"Pong Player’s Dilemma\" game as in this paper. \n\nNotice the following suspiciously similar paragraphs from the two papers:\n\nFrom \"MAINTAINING COOPERATION IN COMPLEX SOCIAL DILEMMAS USING DEEP REINFORCEMENT LEARNING\":\nWe also look at an environment where strategies must be learned from raw pixels. We use the method\nof Tampuu et al. (2017) to alter the reward structure of Atari Pong so that whenever an agent scores a\npoint they receive a reward of 1 and the other player receives −2. We refer to this game as the Pong\nPlayer’s Dilemma (PPD). In the PPD the only (jointly) winning move is not to play. However, a fully\ncooperative agent can be exploited by a defector.\n\nFrom \"CONSEQUENTIALIST CONDITIONAL COOPERATION IN SOCIAL DILEMMAS WITH IMPERFECT INFORMATION\":\nTo demonstrate this we follow the method of Tampuu et al. (2017) to construct a version of Atari Pong \nwhich makes the game into a social dilemma. In what we call the Pong Player’s Dilemma (PPD) when an agent \nscores they gain a reward of 1 but the partner receives a reward of −2. Thus, in the PPD the only (jointly) winning\nmove is not to play, but selfish agents are again tempted to defect and try to score points even though\nthis decreases total social reward. We see that CCC is a successful, robust, and simple strategy in this\ngame.","sentences":[{"sentence_type":"1","sentence":"This is fun but I did not find it particularly surprising from a game-theoretic or from a deep learning point of view.","rephrased":"While the approach is engaging, it would be beneficial to see more novel contributions from both a game-theoretic and a deep learning perspective."},{"sentence_type":"2","sentence":"From a game-theoretic point of view, the paper begins with somewhat sloppy definitions followed by a theorem that is not very surprising.","rephrased":"The paper could benefit from more precise definitions in the game-theoretic section, and the theorem presented could be further developed to enhance its novelty."},{"sentence_type":"2","sentence":"Unfortunately, since the game theory was not particularly well-motivated, I did not find the overall story compelling.","rephrased":"Strengthening the motivation behind the game theory concepts could make the narrative of the paper more compelling."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[410,528,"Maybe"],[531,668,"Confirmed"],[1189,1266,"Missed by Model"],[1357,1475,"Confirmed"]],"Comments":[]}
{"id":"0yKnMouCJpJ","text":"The primary strength of the paper lies in the simplicity of the strategy used in deriving the functional form. The extensive study involving overparametrized neural networks and large-scale vision datasets to show that the functional form approximates the generalization error is quite interesting. The authors also showcase the strength of their proposed model in hyperparameter optimization.\n\n\nQuestions:\n\n1) The covariance matrix $C$ being assumed a constant for all $\\theta$ is a very strong assumption, which is very unlikely to hold true for the overparametrized neural networks in practice. Can the authors somehow loosen the assumption by using some form of average covariance matrix over the trajectory?\n \n2) PP 109-110 in Gardiner, 2004 shows the analytic solution to eq. (4) when $g(\\theta) = A \\theta$. Are the authors assuming the risk as $\\frac{1}{2} \\theta^T A \\theta$ throughout the trajectory starting from some random initialization $\\theta(0)$? That will imply, the authors are only considering a quadratic loss function, which has a single global minimum.\n\nOne way to handle the issues mentioned in (1) and (2) can be the following:\nAssume that after several iterations of SGD, the parameters finally converge close to an attractor local minimum $\\theta^{\\star}$ with hessian $A$. Then, with $\\theta(0)$ starting in a neighborhood around $\\theta^{\\star}$, assuming that the covariance matrix $C$ is nearly a constant in the neighborhood, the authors can get eq. (7) as the analytic solution of the final distribution around the local minimum.\n\n\n3) [Experiments] How were the models initialized in the 60 VGG experiments? Was the initialization the same in all the cases? For each LR \/ batch size ratio, how does the generalization change across multiple initializations? Does the fitted curve change drastically when one considers multiple initializations for different LR \/ batch size ratios?\n\n","sentences":[{"sentence_type":"2","sentence":"The covariance matrix $C$ being assumed a constant for all $\\theta$ is a very strong assumption, which is very unlikely to hold true for the overparametrized neural networks in practice.","rephrased":"The assumption that the covariance matrix $C$ is constant for all $\\theta$ is quite strong. Could the authors explore the possibility of this holding true in practice for overparametrized neural networks, or consider using an average covariance matrix over the trajectory?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[411,597,"Not concerning"]],"Comments":[]}
{"id":"kLBIm7j71z","text":"This paper aims to understand why foundation models in RL have not succeeded at the level that they have in fields outside RL. The authors claim that when fine-tuning pre-trained models on compositional RL problems, catastrophic forgetting occurs if the relevant parts of the state space are not available at the beginning of training. This claim first is supported by a toy experiment where an agent has to traverse a 1D gridworld to retrieve an apple and return to its original position, and where the model is pre-trained on only returning to the original position. Next, the authors create a less toyish environment using the tasks defined in Continual World that they call StitchedEnv. Here, new tasks start once previous ones are completed, and the model is pre-trained on the last two tasks. Finally, for the StitchedEnv environment, the authors propose incorporating methods from continual learning literature like L2 and Elastic Weight Consolidation, as well as performing behavioral cloning with buffers from pre-training. The results show the prevalence of catastrophic forgetting in fine-tuning pre-trained RL models, and the success of continual learning approaches in mitigating this problem.\n\nThe paper is well-written and clear. It communicates a potential wasteful problem in reusing prior computation and proposes clear methods to counter it. This is a good paper for the workshop.","sentences":[{"sentence_type":"1","sentence":"This claim first is supported by a toy experiment where an agent has to traverse a 1D gridworld to retrieve an apple and return to its original position, and where the model is pre-trained on only returning to the original position.","rephrased":"The initial support for this claim comes from a simplified experiment where an agent navigates a 1D gridworld to retrieve an apple and return to its starting point, with the model being pre-trained solely on the task of returning."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[336,568,"Not concerning"]],"Comments":[]}
{"id":"B1lVmlvPi4","text":"When building a planner, or any software, tradeoff between different options need to be evaluated and systematic comparison of the 4 additional options on how frequently LP model is setup and call during the forward search are valuable lesson for any users of OPTIC who plan to use it for solving domains with extensive set of temporal and numerical constraints. The fact that those options are now build into OPTIC and are available for other users is also a plus.\n\nThe analysis is only carried out on a single domain and only compared the performance of different options. I would like to see a deeper analysis to identify and correlate particular characteristics of this domain with the observed performance of different options. Then users working on other domains can see how the results in this paper can generalize to their domains. The authors mention as their future work techniques to automatically identify the best option for a given domain, I guess through automatic identification of certain domain characteristics; it would be nice to elaborate more on how the authors plan to achieve that in the final version of the paper.\n\nExtend the evaluation to a more diverse set of benchmarks with different characteristic also will be valuable. I hope that is one of the future work too.\n\nMinor comments:\n-\tI feel “UAV-based Surveilance Domain” instead of “Large Real-Life Domains” better reflects the experiments carried out in this paper.\n-\tSTN is much faster than LP is not a surprise. It’s quite simple to implement STN consistency checking routine while LP solver is very complicate and for the LP part I assume that OPTIC needs to call an external solver through its API.\n","sentences":[{"sentence_type":"1","sentence":"STN is much faster than LP is not a surprise.","rephrased":"The observation that STN is much faster than LP is consistent with expectations, given the complexity differences in implementation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1450,1495,"Confirmed"]],"Comments":[]}
{"id":"ByxlTSdttS","text":"The paper describes a new method called Atomic Compression Network for constructing neural networks. The idea is straightforward. Basically, firstly create some neurons in random fashion, then reuse a subset of those neurons in each layer. The experiments shows ACN produces better accuracy than baseline models including a FC network, a Baysesina compression method, etc. for MINIST, etc. The paper also show ACN uses much less numbers of parameters and achieves similar accuracy when comparing with a large optima FC network on a set of datasets. \n\nOverall, I don’t support accepting this paper. First, I don’t think the proposed idea is very innovative. Please elaborate why this method seems to work well when comparing baseline models. Is it just randomly constructed network also perform well?  Secondly, I’m not convinced we will use this method to build network in real world applications. The model size is small, but in what cases this small model size matters? Is this a reliable way to create useful models? \n\nOn page 7, in Figure 3, why logistic regression only has a single point in some of the plots?\n\n","sentences":[{"sentence_type":"2","sentence":"I don't think the proposed idea is very innovative.","rephrased":"The paper could benefit from a clearer explanation of the innovative aspects of the proposed method, especially in comparison to existing models."},{"sentence_type":"2","sentence":"I'm not convinced we will use this method to build network in real world applications.","rephrased":"It would be helpful to see more discussion on the potential real-world applications of this method and in what scenarios the smaller model size could be advantageous."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[605,656,"Confirmed"],[811,897,"Confirmed"]],"Comments":[]}
{"id":"wFytLGTzGrA","text":"Summary:\n\nThis paper proposes a new approach for meta-RL. The paper claims that the proposed method reduces variance and bias of the meta-gradient estimation by only a few samples. In addition, this paper claims that their method is more interpretable. \n\nMy comments:\n\nThere are lots of unknown, unwarranted claims about this paper in addition to no thorough experiments and comparison with previous works :\n \n1. Paper claimed that their proposed method not only reduces the variance of meta-gradient but also reduces bias. Reading through this method and experiments, I don't see any theoretical or empirical justification why that should be the case.\n\n2. The method claims this method has a more interpretable meta-gradient. Again, there is nothing in this paper that verifies this claim.\n3. Paper proposed to use fewer samples for the adaptation phase. I don't understand why this can help at all.\n4. Experiments are incomplete and there is no rigorous evaluation to analyze this method.\n5. The proposed context in this paper has been already proposed in previous work, not sure what is new here.\n6. There are lots of things that need to defined like trail, few-shot, etc. \n\nIn summary, this paper is not ready at all and needs lots of works. Hence, I'd recommend this paper to be rejected.","sentences":[{"sentence_type":"2","sentence":"There are lots of unknown, unwarranted claims about this paper in addition to no thorough experiments and comparison with previous works :","rephrased":"The paper could benefit from more detailed experiments and comparisons with previous works to substantiate its claims."},{"sentence_type":"2","sentence":"I don't understand why this can help at all.","rephrased":"It is unclear how using fewer samples for the adaptation phase contributes to the effectiveness of the method."},{"sentence_type":"2","sentence":"In summary, this paper is not ready at all and needs lots of works.","rephrased":"In summary, the paper appears to require further development and more comprehensive work before it can be considered ready for publication."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[269,407,"Confirmed"],[524,652,"Missed by Model"],[727,790,"Missed by Model"],[856,900,"Confirmed"],[904,990,"Missed by Model"],[994,1099,"Missed by Model"],[1178,1293,"Confirmed"]],"Comments":[]}
{"id":"BJx9irP76X","text":"This paper proposed to solve the instance-based transfer learning and feature-based transfer learning by stacking with a two-phase training strategy. The source data and target data are hybrid together first to train weak learners, and then the ensembled super learner is utilized to get the final prediction. Details for the stacking process are provided. Experimental results on MNIST-USPS, COIL, and Office-Caltech datasets show the proposed method can boost the performance, compared to TrAdaboost. \n\nPros:\nThe paper proposes to using stacking or ensembling to solve the domain adaptation problem, which shows some insight for further domain adaptation research.\n\nCons:\n1. One of the main issues of this paper is the lack of novelty. The framework is incremented from the previous domain adaptation method such as TrAdaboost or BDA. For feature-based transfer learning, Equation (7)(8)(9) directly from the previous method. \n2. Some arguments in this paper are not solid. For example, in the abstract,   the authors claim that under the two-stage training architecture, the fitting capability and generalization capability can be guaranteed at the same time. However, this is not well-justified in the following literature. Another example is \"the settings of \\lamda and N should be taken into consideration, if \\lambda is too large, the performance of each learner can't be guaranteed, if \\lambda is too small, training data can't be diversified enough\" (page 7line 9~11)\n3. This paper is weakened by the experimental part. Firstly, only TraDaboost method is used as a baseline. The paper can be largely improved by comparing with the state-of-the-art ensembling method for domain adaptation, for example:\nSelf-ensembling for visual domain adaptation, Geoff French,  ICLR 2018.\nSecondly, the datasets used in this paper is small-scale and biased. It would be exciting to see how the proposed method will perform on the state-of-the-art large-scale domain adaptation dataset, for example, Office-Home dataset, Syn2Real dataset. \n\n Others:\n1. Some terminologies used in this paper are confusing: (1) the h_t and c are not defined in Equation (2). in Algorithm 2, how to construct kernel matrix K_t using k_t?   \n2. The written of this paper can be largely improved. Some sentences are grammarly mistaken. Typos examples: \nAbstract line 1: overtting -> overfitting\nSection 2.1, we use TraAdaboost -> We use TrAdaboost\n3. The citation style used in this paper is not correct.\n\nProblems:\n1. In section 2.2, what's the difference between the kernel matrix K with the unbiased estimate of MK-MMD (proposed by Gretton, NIPS 2012, also used in Deep adaptation network, Long, et al. ICML2015)?","sentences":[{"sentence_type":"2","sentence":"One of the main issues of this paper is the lack of novelty.","rephrased":"The paper could benefit from a clearer demonstration of its novel contributions, as it appears to build closely on existing methods such as TrAdaboost or BDA."},{"sentence_type":"2","sentence":"Some arguments in this paper are not solid.","rephrased":"Some arguments in the paper could be strengthened with additional evidence or justification, such as the claims made in the abstract regarding the two-stage training architecture."},{"sentence_type":"2","sentence":"This paper is weakened by the experimental part.","rephrased":"The experimental section could be enhanced by including comparisons with state-of-the-art ensembling methods for domain adaptation and by using larger, more diverse datasets."},{"sentence_type":"2","sentence":"The written of this paper can be largely improved.","rephrased":"The clarity of the paper could be improved with additional attention to grammar and sentence structure."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[677,836,"Maybe"],[932,975,"Confirmed"],[1480,1583,"Confirmed"],[2046,2097,"Maybe"],[2218,2268,"Maybe"]],"Comments":[]}
{"id":"rddlM7aSmbc","text":"This blog post looks at several 5 works on rule and convention transfer published in the last few years. \n\nI appreciate some of the information presented in this blog post, especially the explanation of the concepts of \"convention\" and \"rule\". I also like the illustrative example, although, given the familiarity of American football being restricted mostly to North American audiences, I would suggest using a game that has a broader appeal. In addition, any real-time dynamic game is much too far-fetched to serve as a running example for existing rule and convention transfer algorithms -- these algorithms are a long way from being able to handle such games. \n\nMy main issue with this post though is that it leaves the reader highly confused as to what the takeaway or even the main intent of this post is. At first, I thought it was going to focus on the article by Shih et al, 2021. The post briefly discusses this approach and then shifts to another approach, BAD, supposedly in an attempt to provide a context for Shih et al, 2021. It describes BAD in as much detail as Shih et al, 2021 itself, but I'm still not sure how the two are related, other than using the same Hanabi benchmark. The the blog post goes on to describe SAD. Its relationship to Shih et al, 2021 is clearer, but its description seems unnecessarily long. Then the post discusses Other-Play and MPNs. What confuses me about their discussion is that Other-Play and MPNs are specific algorithms, each with a section dedicated to it, whereas SAD and BAD don't have their own sections -- instead, they are both in the section Learning Conventions. I would expect either each section to be about a high-level idea or each section to be about a concrete algorithm. The post ends with a section \"Improvements to Human-AI Collaboration. This is also bizarre, because the post started with a very specific paper -- Shih et al, 2021 -- so I don't understand why it wraps up with discussing possible improvements to HAI collaboration in general rather than improvements to Shih et al, 2021 in particular. Overall, it's unclear why the post claimed at the beginning that it was trying to provide context specifically for Shih et al, 2021; it seems to simply describe 5 works on a broad topic, without strongly emphasizing any of them.\n\nIt's difficult to pinpoint exactly what makes this blog post so confusing to me, but I believe it's verbosity and lack of structure. The blog's narrative meanders too much and constantly mixes high-level insights with low-level details. \n \nThe same issues apply at the level of individual sentences: many sentences are verbose and\/or poorly structured. A number of phrases are used incorrectly despite remaining comprehensible, e.g., \"is catered to\" instead of \"caters to\". I started compiling a list of error corrections but stopped after noting down a few, because I realized that there are too many low-level things in need of fixing. The main aspect that needs to change is the writeup's high-level structure though. The corrections I've noted down are at the end of the review.\n\nUnfortunately, these problems mean that the post falls short of the blog track's main objective -- provide clarity and\/or insights about prior works. Therefore, I can't recommend it for acceptance in its present form.\n\n\n============================\n\n\n\n\n\"the bounds they are allowed to stand within while holding the football during play when they are allowed to pass the line of scrimmage and the requirements for earning points\" \n--> \n\"the bounds they are allowed to stand within while holding the football during play, when they are allowed to pass the line of scrimmage, and the requirements for earning points\" (Note the commas.)\n\n\n\n\", and as such faster adaptation...\"\n-->\n\"; thus, faster adaptation...\"\n\n\n\n\"Intuitively, learning separation representations between tasks and partners allows them to specifically generalize to new tasks or new partners of their choice.\"\n-->\nThis sentence is broken in multiple ways, I'm not sure what it's trying to say. What are \"separation representations\"? Did you mean \"separate representations\"? Also, what does it mean to \"specifically generalize\"?\n\n\n\n\"...work, before discussing...\"\n-->\n\"...work before discussing...\"\n\n\n\n\"improvements in this approach\"\n-->\n\"improvements to this approach\"\n\n\n\n\"The mechanics of Shih’s approach are going to be important in distinguishing it\"\n-->\n\"The mechanics of Shih’s approach are important for distinguishing it\"\n","sentences":[{"sentence_type":"2","sentence":"My main issue with this post though is that it leaves the reader highly confused as to what the takeaway or even the main intent of this post is.","rephrased":"My main concern with this post is that it could be clearer in conveying the takeaway and the main intent to the reader."},{"sentence_type":"2","sentence":"It's difficult to pinpoint exactly what makes this blog post so confusing to me, but I believe it's verbosity and lack of structure.","rephrased":"I find the blog post could benefit from more concise language and a stronger structure to avoid confusion."},{"sentence_type":"2","sentence":"I started compiling a list of error corrections but stopped after noting down a few, because I realized that there are too many low-level things in need of fixing.","rephrased":"While I began compiling a list of suggested corrections, I noticed several areas for improvement, which I believe are important to address for the overall quality of the post."},{"sentence_type":"2","sentence":"Unfortunately, these problems mean that the post falls short of the blog track's main objective -- provide clarity and\/or insights about prior works. Therefore, I can't recommend it for acceptance in its present form.","rephrased":"Given these issues, the post could be further refined to meet the blog track's objective of providing clarity and insights about prior works. I believe revisions could enhance its suitability for acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[666,811,"Confirmed"],[1292,1333,"Missed by Model"],[1807,2071,"Missed by Model"],[2302,2434,"Confirmed"],[2435,2538,"Missed by Model"],[2602,2654,"Missed by Model"],[2655,2728,"Missed by Model"],[2776,2939,"Confirmed"],[3086,3303,"Maybe"],[3965,4124,"Missed by Model"]],"Comments":[]}
{"id":"Vp5BPQUNNje","text":"Paper is easy to read and very well written in general. Assumptions, theorems, derivations, and algorithms are stated in full clarity. Authors also demonstrate their algorithm on a toy example, which is very helpful for understanding the main principles of the algorithm. I think such a paper will be of interest to NeurIPS community.\n\nThe main contribution of the paper is the information theoretical conditions that are proposed to narrow down the overall search space of graphs. In the first phase of the proposed methodology, a topological ordering of the nodes, i.e. the layers of the underlying graph, is found using these conditions. Once the topological ordering is found, the rest of the graph search becomes straightforward, Namely, the edges between the layers of the graph are searched using the conditional independence properties.\n\nHowever, any topological ordering enforced on a graph would yield a search procedure with the same efficiency as the methodology in the paper. Indeed, one could change the conditional H with any functional F, say negative H, and would still come up with a unique DAG, because there is nothing specific to H in the proposed methodology. So, I believe the selection of H needs further justification, e.g. how does the selected criteria relate to the actual topological ordering of the nodes? What are the advantages of choosing H for narrowing down the search space rather than a more general functional F?\n\nAdditionally, it is not perfectly clear to me that why the size of largest markov boundary can be assumed less than logarithm of the number of nodes. This is a critical assumption for calculation of the polynomial time complexity stated in the paper, and I think an addittional justification for this would be helpful, too.","sentences":[{"sentence_type":"2","sentence":"Indeed, one could change the conditional H with any functional F, say negative H, and would still come up with a unique DAG, because there is nothing specific to H in the proposed methodology.","rephrased":"I would suggest providing more specific justification for the choice of the conditional H in the methodology. Could you elaborate on how H is distinct from other functionals, such as negative H, in producing a unique DAG?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[989,1181,"Maybe"]],"Comments":[]}
{"id":"BtWeWPv-_Z5","text":"The paper discusses Fourier transformations of signals on partial orders and uses these to define convolutions on such signals. For partial orders, a signal $c$ causes a signal $s$ when one sums the value of the predecessors. This is a bijection, whose inverse is the Möbius transform. For any node $q$, it defines a linear \"shift\" transformation on signals whose value at node $x$ is the sum of values at nodes that are predecessors to both $x$ and $q$. These shift operators commute for all nodes $q,q'$ and can thus be simultaneously diagonalized, giving the Fourier basis.  It turns out the the previously mentioned signal and its cause are exactly related by a Fourier transform.\n\nThe authors propose to predict missing signal values by fitting a sparse Fourier spectrum on a partially observed signal. Hereby the proposed basis outperforms a Laplacian or adjacency basis.\n\nI like this paper as it proposes a Fourier transform on a novel data type and elegantly shows how this outperforms other bases. Also, it is very clearly written and a joy to read.\nI have two suggestions for points for improvement:\n1) why is the proposed method formulated as if acting on signals on DAGs, while it seems like the method is only affected by the induced partial order. For example, the Fourier basis for a complete DAG would be the same as for the chain? Wouldn't a presentation around partial orders then make more sense?\n2) Personally, I would have liked to see additional experimental comparisons to e.g. graph neural networks.\n\nAnd a question:\nAn often desired property of convolution operators is that they commute with automorphisms of the structure. This could be implemented by letting the convolution in Fourier space have the same coefficient for each eigenspace. Could the authors maybe comment on whether this is desirable in their context? It seems like there would be only two eigenvalues and thus only two parameters? How does this contrast with the graph Laplacian?","sentences":[{"sentence_type":"1","sentence":"Personally, I would have liked to see additional experimental comparisons to e.g. graph neural networks.","rephrased":"It would be beneficial to include additional experimental comparisons, such as with graph neural networks, to further validate the proposed method."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1419,1523,"Not concerning"]],"Comments":[]}
{"id":"eDiczi7Bx4w","text":"\nThis paper proposes a new approach to RL, which is based on the idea of structural neighbours. The authors show that this approach can be used to improve the performance of a variety of RL algorithms, including TD(0), Dyna and Dueling DQN. The paper is well-written and easy to follow. The experiments are well-designed and the results are convincing. Overall, I think this is a good paper and I recommend it for publication.\n\n\nPros:\n- New framework for RL\n- Convincing numerical results\n\nCons:\n- The method relies on the concept of a \"structural transformation function\", which involves an environment-specific transformation of the state space. This is a bit of a limitation, as it requires the user to specify this transformation function.\n\n## Comments:\n\n### 1. Introduction\n\n- \"RL agents can solve just about any environment they are presented with\". In my opinion, this is a bit too strong. I would suggest rephrasing it to something like \"RL agents can solve a wide range of environments they are presented with\".\n\n- \"It despite these successes, this approach only scales so far: it is simply not feasible to solve every problem from scratch by brute force.\". This sentence is a bit confusing, as it seems to suggest that RL is a brute force approach. I would suggest rephrasing it. \n\n#### 4. Structural Reinforcement Learning\n\n- After equation (5), \"...where η ∈ [0, 1] $\\eta \\in [0,1]$ is a mixing factor such that $\\eta = 0$ corresponds to no structural updates, and $\\eta = 1$ corresponds to no temporal updates\"- Is this correct? I would have expected the other way around.","sentences":[{"sentence_type":"1","sentence":"RL agents can solve just about any environment they are presented with.","rephrased":"RL agents have the potential to address a wide variety of environments they encounter."},{"sentence_type":"1","sentence":"It despite these successes, this approach only scales so far: it is simply not feasible to solve every problem from scratch by brute force.","rephrased":"Despite these successes, the scalability of this approach has limitations, and it may not be practical to address every problem from scratch."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1025,1164,"Not concerning"]],"Comments":[]}
{"id":"r1xgsDq6KB","text":"The paper provides a method\/metric for comparing sentence embedders, based on a nearest neighbor analysis. The method is straightforward: sample a sentence, embed the sentence and lots of sentences from a corpus, find the k nearest neighbors in the corpus to the sampled sentence, do the same for another embedder, calculate the overlap of the two sets of nearest neighbors.\n\nThe paper is commendably clear and easy to read.\n\nThe main problems I have with the paper are twofold: 1) it's not clear this is enough of a contribution for a top-tier ML conference; and 2) it's not clear what I do with the results.\n\nI think the idea of analysing embedders in this way is potentially interesting, but it feels like the paper needs more. This analysis could be a great section in another paper (e.g. one which proposes another embedding method); or perhaps it could be extended in some way, so that the current content only takes up 1\/2 the space, and then there's 1\/2 the paper showing how useful this analysis is, for e.g. building better embedders for particular tasks.\n\nThe abstract starts by talking about how embedders have been evaluated using various benchmarks, and hints at the idea that this new comparative approach could be an alternative. But the new method can't really be used for evaluation: I don't come away from the paper knowing whether embedding method A is better than method B, only that A is more like B than C.\n\nI think the problem with the paper as it stands is neatly summed up in the conclusion of the paper, which isn't a conclusion at all: it's just a mini-abstract. I'd like to know what readers should take away from the results, so that they can potentially build better embedders.\n\nI've given the paper a 1. rating only because I really don't think it's ready for a full ICLR paper, not because I think the method is uninteresting or useless. On the contrary, with some more work and thought about how the analysis could be used, this could be a potentially useful tool.","sentences":[{"sentence_type":"2","sentence":"it's not clear this is enough of a contribution for a top-tier ML conference;","rephrased":"The contribution may need to be more substantial to align with the expectations of a top-tier ML conference."},{"sentence_type":"2","sentence":"I've given the paper a 1. rating only because I really don't think it's ready for a full ICLR paper,","rephrased":"I've rated the paper as it currently stands, considering that it may require further development to meet the criteria for a full ICLR paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[482,559,"Not concerning"],[1531,1590,"Missed by Model"],[1710,1810,"Not concerning"]],"Comments":[]}
{"id":"BJx3w6p_jm","text":"The paper studies fatigue monitoring of EEG driving simulator experiments using various EEG analysis algorithms, one also based on ranking. The data used was from a prior experiment. \n\nThe paper is written in a rather confusing manner, which makes the assessment of originality and significance a hard task for the reviewer. A novel algorithm Bdrank (based on raking is defined) and compared to 2 other algorithms; unclear why with these and not with others. The paper ignores a large portion of the literature, starting with Kohlmorgen et al 2007, Blankertz group, Lee group etc. \nThe results  are only somewhat interesting, no understanding of the underlying physiological processes is given. \n\nOverall, I consider the paper somewhat preliminary. ","sentences":[{"sentence_type":"2","sentence":"The paper is written in a rather confusing manner, which makes the assessment of originality and significance a hard task for the reviewer.","rephrased":"The paper could benefit from clearer organization and presentation to better convey its originality and significance."},{"sentence_type":"2","sentence":"The results  are only somewhat interesting, no understanding of the underlying physiological processes is given.","rephrased":"The results could be more impactful if the paper provided a deeper analysis of the underlying physiological processes."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[185,324,"Confirmed"],[415,458,"Missed by Model"],[459,510,"Missed by Model"],[582,694,"Confirmed"],[697,748,"Missed by Model"]],"Comments":[]}
{"id":"rJxqaMwTtS","text":"This paper performs a general analysis of sign-based methods for non-convex optimization. They define a new norm-like function depending on the success probabilities. Using this new norm-like function and under an assumption, they prove exponentially variance reduction properties in both directions and small mini-batch sizes. \n\nI am not convinced about assumption 1, which plays the key role of the proof. It assumes that success probabilities are always large or equal to 1\/2. \n\nHow can we guarantee this property hold for an algorithm? I suggest the authors provide some real learning examples, under which it will satisfy the condition.  I may revise my rating according to this. \n","sentences":[{"sentence_type":"1","sentence":"I am not convinced about assumption 1, which plays the key role of the proof.","rephrased":"Assumption 1, which is central to the proof, could benefit from further justification or examples to demonstrate its validity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[330,407,"Confirmed"]],"Comments":[]}
{"id":"SyHYDG5lf","text":"## Review summary\n\nOverall, the paper makes an interesting effort to tightly integrate\nexpectation-maximization (EM) training algorithms with evolutionary algorithms\n(EA). However, I found the technical description lacking key details and the\nexperimental comparisons inadequate. There were no comparisons to non-\nevolutionary EM algorithms, even though they exist for the models in question.\nFurthermore, the suggested approach lacks a principled way to select\nand tune key hyperparameters. I think the broad idea of using EA as a substep\nwithin a monotonically improving free energy algorithm could be interesting,\nbut needs far more experimental justification.\n\n\n## Pros \/ Stengths\n\n+ effort to study more than one model family\n\n+ maintaining monotonic improvement in free energy\n\n\n## Cons \/ Limitations\n\n- poor technical description and justification of the fitness function\n\n- lack of comparisons to other, non-EA algorithms\n\n- lack of study of hyperparameter sensitivity\n\n\n## Paper summary\n\nThe paper suggests a variant of the EM algorithm for binary hidden variable\nmodels, where the M-step proceeds as usual but the E-step is different in two\nways. First, following work by J. Lucke et al on Truncated Posteriors, the\ntrue posterior over the much larger space of all possible bit vectors is\napproximated by a more tractable small population of well-chosen bit vectors,\neach with some posterior weight. Second, this set of bit vectors is updated\nusing an evolutionary\/genetic algorithm. This EA is the core contribution,\nsince the work on Trucated Posteriors has appeared before in the literature.\nThe overall EM algorithm still maintains monotonic improvement of a free\nenergy objective.\n\nTwo well-known generative models are considered: Noisy-Or models for discrete\ndatasets and Binary Sparse Coding for continuous datasets. Each has a\npreviously known, closed-form M-step (given in supplement). The focus is on\nthe E-step: how to select the H-dimensional bit vector for each data point.\n\nExperiments on artificial bars data and natural image patch datasets compare\nseveral variants of the proposed method, while varying a few EA method\nsubsteps such as selecting parents by fitness or randomly, including crossover\nor not, or using generic or specialized mutation rates.\n\n\n## Significance\n\nCombining evolutionary algorithms (EA) within EM has been done previously, as\nin Martinez and Vitria (Pattern Recog. Letters, 2000) or Pernkopf and\nBouchaffra (IEEE TPAMI, 2005) for mixture models. However, these efforts seem\nto use EA in an \"outer loop\" to refine different runs of EM, while the present\napproach uses EA in a substep of a single run of EM. I guess this is\ntechnically different, but it is already well known that any E-step method\nwhich monotonically improves the free energy is a valid algorithm. Thus, the\npaper's significance hinges on demonstrating that the particular E step chosen\nis better than alternatives. I don't think the paper succeeded very well at\nthis: there were no comparisons to non-EA algorithms, or to approaches that\nuse EA in the \"outer loop\" as above.\n\n\n## Clarity of Technical Approach\n\nWhat is \\tilde{log P} in Eq. 7? This seems a fundamental expression. Its\nplain-text definition is: \"the logarithm of the joint probability where\nsummands that do not depend on the state s have been elided\". To me, this\ndefinition is not precise enough for me to reproduce confidently... is it just\nlog p(s_n, y_n | theta)? I suggest revisions include a clear mathematical\ndefinition. This omission inhibits understanding of this paper's core\ncontributions.\n\nWhy does the fitness expression F defined in Eq. 7 satisfy the necessary\ncondition for fitness functions in Eq. 6? This choice of fitness function does\nnot seem intuitive to me. I think revisions are needed to *prove* this fitness\nfunction obeys the comparison property in Eq. 6.\n\nHow can we compute the minimization substep in Eq. 7 (min_s \\tilde{logP})? Is\nthis just done by exhaustive search over bit vectors? I think this needs\nclarification.\n\n\n## Quality of Experiments\n\nThe experiments are missing a crucial baseline: non-EA algorithms. Currently\nonly several varieties of EA are compared, so it is impossible to tell if the\nsuggested EA strategies even improve over non-EA baselines. As a specific\nexample, previous work already cited in this paper -- Henniges et al (2000) --\nhas developed a non-EA EM algorithm for Binary Sparse Coding, which already\nuses the truncated posterior formulation. Why not compare to this?\n\nThe proposed algorithm has many hyperparameters, including number of\ngenerations, number of parents, size of the latent space H, size of the\ntruncation, etc. The current paper offers little advice about selecting these\nvalues intelligently, but presumably performance is quite sensitive to these\nvalues. I'd like to see some more discussion of this and (ideally) more\nexperiments to help practitioners know which parameters matter most,\nespecially in the EA substep.\n\nRuntime analysis is missing as well: Is runtime dominated by the EA step? How\ndoes it compare to non-EA approaches? How big of datasets can the proposed\nmethod scale to?\n\nThe reader walks away from the current toy bars experiment somewhat confused.\nThe Noisy-Or experiment did not favor crossover and and favored specialized\nmutations, while the BSC experiment reached the opposite conclusions. How does\none design an EA for a new dataset, given this knowledge? Do we need to\nexhaustively try all different EA substeps, or are there smarter lessons to\nlearn?\n\n\n\n## Detailed comments\n\nBottom of page 1: I wouldn't say that \"variational EM\" is an approximation to\nEM. Sometimes moving from EM to variational EM can mean we estimate posteriors\n(not point estimates) for both local (example-specific) and global parameters.\nInstead, the *approximation* comes simply from restricting the solution space\nto gain tractability.\n\nSec. 2: Make clear earlier that hidden var \"s\" is assumed to be discrete, not\ncontinuous.\n\nAfter Mutation section: Remind readers that \"N_g\" is number of generations\n","sentences":[{"sentence_type":"2","sentence":"However, I found the technical description lacking key details and the experimental comparisons inadequate.","rephrased":"The technical description could be enhanced by including more key details, and the experimental comparisons would benefit from further elaboration."},{"sentence_type":"2","sentence":"Furthermore, the suggested approach lacks a principled way to select and tune key hyperparameters.","rephrased":"It would be beneficial to provide a more principled methodology for selecting and tuning the key hyperparameters."},{"sentence_type":"2","sentence":"I don't think the paper succeeded very well at this: there were no comparisons to non-EA algorithms, or to approaches that use EA in the \"outer loop\" as above.","rephrased":"The paper could be strengthened by including comparisons to non-EA algorithms and to approaches that use EA in the \"outer loop\", as discussed above."},{"sentence_type":"2","sentence":"This omission inhibits understanding of this paper's core contributions.","rephrased":"Clarifying this point could greatly enhance the understanding of the paper's core contributions."},{"sentence_type":"2","sentence":"I think revisions are needed to *prove* this fitness function obeys the comparison property in Eq. 6.","rephrased":"Revisions that include a proof of how this fitness function complies with the comparison property in Eq. 6 would be helpful."},{"sentence_type":"1","sentence":"I think this needs clarification.","rephrased":"Further clarification on this aspect would be beneficial."},{"sentence_type":"1","sentence":"I'd like to see some more discussion of this and (ideally) more experiments to help practitioners know which parameters matter most, especially in the EA substep.","rephrased":"Additional discussion and experiments to guide practitioners on the most impactful parameters, particularly in the EA substep, would be valuable."},{"sentence_type":"2","sentence":"The reader walks away from the current toy bars experiment somewhat confused.","rephrased":"The current toy bars experiment could be presented in a way that is clearer for the reader."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[172,279,"Missed by Model"],[280,392,"Missed by Model"],[393,491,"Missed by Model"],[810,878,"Missed by Model"],[882,929,"Missed Maybe"],[2934,3093,"Missed Maybe"],[3703,3765,"Missed Maybe"],[4490,4514,"Missed Maybe"],[4984,5019,"Missed by Model"],[5155,5232,"Confirmed"],[5913,5994,"Missed Maybe"]],"Comments":[]}
{"id":"idt8YeINctm","text":"**Strengths**\n1. Simple architecture that give good empirical results \n2. Well-written and easy to follow\n\n**Weaknesses**\n1. Incremental work, building on known work \n2. No clear performance gain over fixed-length RW models, see Table 1 \n3. Comparision to fixed-length RW models only done on small-scale datasets, compare Table 1 and Figure 1(a)\n\n\n**Questions**\n1. You state that \"Such local patterns may fail to capture the overall large-scale shape of the graphs, while several interesting\nproperties of graphs depend on the graph’s global structure.\"\n\nCan you quantify exactly for which kind of graph structures this is the case? \nE.g., by quantifiying the graph structures captured by the infinite-length RW models but not by finite-length RW models.\n\n2. Why did you not evaluate the fixed-length RW models on the OBG datasets?\n\n3. Does your architecture offer any insights on how to design deep GNNs?\n\n**Suggestions**\nTo show a clear performance gain, especially over the fixed-length RW models, one should compare the model on more large-scale datasets, e.g., from OGB and graphlearning.io. The small-scale datasets from Table 1 exhibit large standard deviations which make comparisons in terms of accuracy often not meaningful. \n\n**Minor comments**\n1. You seem to use \\citet{} when citep{} would be more appropriate\n2. First page, second paragraph:  \"graphs, So far, ...\" -> \"graphs. So far, ...\n","sentences":[{"sentence_type":"2","sentence":"Incremental work, building on known work","rephrased":"The work builds on existing research, which is a solid foundation, but it would be beneficial to highlight more distinct advancements."},{"sentence_type":"2","sentence":"No clear performance gain over fixed-length RW models, see Table 1","rephrased":"It would be helpful to provide a clearer demonstration of the performance benefits compared to fixed-length RW models, as evidenced by Table 1."},{"sentence_type":"2","sentence":"The small-scale datasets from Table 1 exhibit large standard deviations which make comparisons in terms of accuracy often not meaningful.","rephrased":"To strengthen the comparison in terms of accuracy, consider using datasets with smaller standard deviations, as the large ones in Table 1 can obscure meaningful differences."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[125,165,"Confirmed"],[170,236,"Maybe"],[1097,1234,"Maybe"]],"Comments":[]}
{"id":"0UbiZ97MKmZ","text":"The paper presents an algorithm to train on a mixture of offline trajectories with and without action labels. An inverse dynamics model is used to provide proxy actions for the missing actions. The authors find this is effective on a variety of offline RL algorithms and D4RL datasets. Whilst the evaluation is very thorough, there are a few concerns I have with regard to the presentation that should be addressed before acceptance to the workshop.\n\nStrengths:\n- Strong results for incorporating action-free trajectories.\n- Comprehensive evaluation for various choices of data distributions for the labeled and unlabelled trajectories.\n- Thorough ablations on the model and choice of RL algorithm.\n\nWeaknesses:\n- Sentence ‘we propose a new and practically…’ is slightly misleading as most notably [1] considers a similar setup with an inverse dynamics model. The comparison to that paper in the related work is more accurate and states the precise contribution of this work which should be reflected in the introduction.\n- One of the strengths listed of SS-ORL is the ability to deal with stochastic environments. However, none of the D4RL MuJoCo environments are stochastic so this claim of the algorithm is completely untested. The paper would be strengthened if the authors only referred to the tested properties of the algorithm.\n\nMinor:\n- Caption on Figure 1 is unclear out of context.\n\n[1] Baker, B., Akkaya, I., Zhokhov, P., Huizinga, J., Tang, J., Ecoffet, A., Houghton, B., Sampedro, R., and Clune, J. Video pretraining (vpt): Learning to act by watching unlabeled online videos, 2022.\n","sentences":[{"sentence_type":"2","sentence":"The paper would be strengthened if the authors only referred to the tested properties of the algorithm.","rephrased":"The paper could be further improved by focusing on the properties of the algorithm that have been empirically tested."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1231,1334,"Not concerning"]],"Comments":[]}
{"id":"9VUhOECGKJt","text":"In this study, the authors applied spectral clustering to identify high-risk opioid tapering trajectories associated with adverse outcomes using a large-scale dataset.  The study addressed an important public health issue and discovered patterns of opioid tapering using unsupervised learning. The findings can support further studies on dose tapering patterns to inform future prescribing policies and clinical practice. A couple of areas can be improved in the current manuscript.\n1. More details should be provided on creating the similarity matrix and the Laplacian matrix. A few references were mentioned but without technical details.\n2. Variables in this study have different units and scales. How did the author deal with the different scales? Did it matter if those variables were standardized?\n3. Certain patients may use dose tapering strategies based on their health conditions. For instance, slower tapering may be used because the doctor believes the patient may have a higher risk of adverse outcomes under rapid tapering. In future studies, it would be better to control those factors to disentangle the impact of tapering patterns. A discussion on this point is warranted.\n","sentences":[{"sentence_type":"1","sentence":"A couple of areas can be improved in the current manuscript.","rephrased":"There are a few areas in the manuscript that could be enhanced to further strengthen the study."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[422,482,"Not concerning"],[578,640,"Missed Maybe"]],"Comments":[]}
{"id":"d6Rmwlq9dFz","text":"Generally, I don't (and shouldn’t) reject a paper because of writing.\nHowever, the writing of this paper is too hard to follow.\nAmong hundreds of papers I have reviewed, it is the most distracting one.\nEven if there are significant technical contributions, I still cannot accept this paper because of the writing.\nHowever, the idea of applying a tree-like structure to generalize neural networks is still interesting.\nI am sorry that I cannot complete the reading because of the writing.","sentences":[{"sentence_type":"2","sentence":"However, the writing of this paper is too hard to follow.","rephrased":"However, the writing of this paper could be clearer to enhance comprehension."},{"sentence_type":"2","sentence":"Among hundreds of papers I have reviewed, it is the most distracting one.","rephrased":"This paper's writing style is notably more challenging to engage with compared to others I have reviewed."},{"sentence_type":"3","sentence":"Even if there are significant technical contributions, I still cannot accept this paper because of the writing.","rephrased":"Despite the significant technical contributions, the writing could be improved to meet the publication standards."},{"sentence_type":"2","sentence":"I am sorry that I cannot complete the reading because of the writing.","rephrased":"I encourage the authors to improve the clarity of the writing to facilitate a complete review."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[70,127,"Maybe"],[128,201,"Confirmed"],[202,313,"Confirmed"],[418,487,"Maybe"]],"Comments":[]}
{"id":"GLDtJV8zTD","text":"This paper tries to do some explanations of random forests, and proposes majoritary reasons and minimal majoritary reasons. The problem and the idea is interesting. However, there are many limitations:\n1, This paper only considers the instance with Boolean feature vector, which is the major problem. In many machine learning problems, we usually meet the problem with real-valued feature vector, such as CV and NLP applications. The paper can not be used to address real-world machine learning applications by considering boolean feature vector.\n2, Many places are unclear, such as what is \"abductive explanations\"? this notion appears many times, but no clear definition and explanation.  what is the \"prime implicant\"? still no explantion.\n3, Why trade off? why there is a trade off between complexity and sparsity, why there is a sparsity? readers are confused by the paper.\n4, the datasets are too tivial, can the paper try imagenet and NLP data sets?","sentences":[{"sentence_type":"2","sentence":"The paper can not be used to address real-world machine learning applications by considering boolean feature vector.","rephrased":"To enhance the paper's applicability to real-world machine learning applications, it would be beneficial to extend the analysis beyond boolean feature vectors to include real-valued feature vectors, as commonly found in CV and NLP applications."},{"sentence_type":"2","sentence":"Many places are unclear, such as what is \"abductive explanations\"? this notion appears many times, but no clear definition and explanation.  what is the \"prime implicant\"? still no explantion.","rephrased":"The paper would benefit from clearer definitions and explanations, particularly for terms like \"abductive explanations\" and \"prime implicant,\" which are central to the paper's arguments but are not adequately defined."},{"sentence_type":"2","sentence":"Why trade off? why there is a trade off between complexity and sparsity, why there is a sparsity? readers are confused by the paper.","rephrased":"It would be helpful if the paper could provide a more detailed discussion on the trade-off between complexity and sparsity to avoid confusion among readers."},{"sentence_type":"2","sentence":"the datasets are too tivial, can the paper try imagenet and NLP data sets?","rephrased":"To demonstrate the method's effectiveness on a broader scale, it would be valuable to test it on more complex datasets, such as those from ImageNet and various NLP tasks."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[430,546,"Maybe"],[550,742,"Confirmed"],[746,878,"Confirmed"],[882,956,"Not concerning"]],"Comments":[]}
{"id":"B1xf9mFAtr","text":"This paper discusses the old problem of mismatch between the ultimate reward obtained after optimizing a  decision (planning or control) over a probabilistic model (of dynamics) and  the training  objective for the model (log-likelihood). Experiments highlight that the NLL and reward can be very poorly correlated, that improvements in NLL initially improve reward but can later degrade it, and that models with similar NLLs can lead to very different rewards. A  reweighting trick is proposed and summarily evaluated.\n\nI like the topic of this paper but there are several aspects which I see as making it weaker than my acceptance threshold.\n\nFirst, the paper overclaims in originality. This mismatch problem is not new, it is an instance of a more general issue that end-to-end training and meta-learning try to address, and has been already studied in the context of MBRL by many authors, who actually proposed more substantial solutions. When I read the abstract I had the impression that the paper actually had a theoretical analysis showing the correlation problem, but there is no such thing, only experiments. Section 3 does not actually provide a new insight. Still, the experiments are interesting in that they reveal that the magnitude of the mismatch is probably more serious than most RL researchers believed.\n\nSecond, the 'fix' proposed is not well justified nor well tested (e.g. no quantiative comparisons, no comparisons against existing alternative methods to address the same problem, etc). This seriously weakens conclusions like \"shows improvements in sample efficiency\".\n\nOne concern I have about the experiments of fig 3 is that NLL can be really bad, thus distorting rho, which is not a robust measure. So I would only look at NLLs of models with good NLLs, to obtain a more interesting analysis.\n\nAnother concern about experiments is that I am not convinced that they were performed with SOTA MBRL methods and hyper-parameters (as demonstrated by SOTA performance on known benchmarks). Otherwise I could easily imagine how the mismatch could be much more severe than in the actual scenarios of interest.\n\nMinor points:\n\n\nBottom of page 6 refers to visualizations but I did not see if or where they were shown.\n\nWhy the e in the numerator of eq 2e? Seems useless to put any constant there.\n\nThe section on 'Shaping the cost or reward' was not clear enough to me (please expand).\n","sentences":[{"sentence_type":"2","sentence":"First, the paper overclaims in originality.","rephrased":"First, the paper could better acknowledge the existing literature on the mismatch problem, which has been previously addressed in the context of MBRL."},{"sentence_type":"2","sentence":"Second, the 'fix' proposed is not well justified nor well tested.","rephrased":"Second, the justification and testing of the proposed solution could be strengthened with quantitative comparisons and evaluations against existing methods."},{"sentence_type":"2","sentence":"This seriously weakens conclusions like \"shows improvements in sample efficiency\".","rephrased":"This aspect makes it challenging to fully support conclusions such as \"shows improvements in sample efficiency\"."},{"sentence_type":"1","sentence":"So I would only look at NLLs of models with good NLLs, to obtain a more interesting analysis.","rephrased":"It might be beneficial to focus the analysis on models with strong NLLs to provide a more nuanced understanding of the issue."},{"sentence_type":"2","sentence":"Otherwise I could easily imagine how the mismatch could be much more severe than in the actual scenarios of interest.","rephrased":"It would be helpful to ensure that the experiments are conducted with state-of-the-art MBRL methods and hyper-parameters to accurately reflect scenarios of interest."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[556,643,"Missed Maybe"],[645,688,"Confirmed"],[689,942,"Missed by Model"],[943,1169,"Missed by Model"],[1325,1510,"Confirmed"],[1511,1593,"Confirmed"],[1728,1821,"Not concerning"],[2012,2129,"Not concerning"],[2237,2314,"Missed by Model"]],"Comments":[]}
{"id":"HJeo4wAshX","text":"This manuscript shows the statistical error of the ERM for nonparametric regression using the family of a Resnet-type of CNNs. Specifically, two results are showed. First, the authors show that any block-sparse fully connected neural network can be embedded in CNNs. Second, they show the covering number of the family of CNNs. Combining with the existing results of the approximation error of neural nets (Klusowski&Barron 2016, Yarotsky 2017, Schmidt-Hieber 2017), they show the L2 statistical risk. \n\nDetailed comments:\n\n1. The intuition of using block-sparse FNN seems unclear. It seems that when $M=1$, it reduces to the sparse NN considered in [Schmidt-Hieber 2017]. In the proof of Corollary 5, the authors directly use the error of approximating Holder smooth function by sparse FNN and show that the construction in [Schmidt-Hieber 2017] is actually block-sparse. Thus, it seems unclear why we should consider such block-sparse family. Can any sparse NN be embedded in the family of CNNs?\n\n2. In the Related Work, the authors only compare with 2 previous work on the approximation error of CNN. Actually, this work is more related to [Schmidt-Hieber 2017] due to borrowing the results. It would be better to see what the novelties are compared with that work, especially in terms of the proof techniques.\n\n3. The authors claim that the construction of approximator for Holder functions in [Schmidt-Hieber 2017] is block sparse. It would be nice to give more details of the construction since this is not claimed in [Schmidt-Hieber 2017].","sentences":[{"sentence_type":"2","sentence":"It seems unclear why we should consider such block-sparse family.","rephrased":"Could the authors elaborate on the motivation for considering the block-sparse family in this context?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[527,581,"Missed Maybe"],[873,944,"Maybe"]],"Comments":[]}
{"id":"r1xiO7ruhX","text":"The presented analysis well characterizes the behavior of the spatially transformed adversarial inputs and the proposed defense is empirically confirmed to achieve more accurate and robust classification under attacks.\n\nOne concern is that the defender cannot learn whether the adversary employs spatially transformed AEs or pixel-based AEs (or some others). What happens if the classifier trained with the proposed defense accept pixel-based AEs? I recommend the authors to associate spatially transformed AEs with pixel-based AEs to learn whether the proposed defense performs more robustly compared to existing defenses. If the proposed defense method performs well for spatially transformed AEs but is vulnerable to pixel-based AEs, it is useless.\n\nIt should be better to discuss more on computational efficiency of the proposed defense since it contains SDP solving. Is the proposed deense works with larger datasets such as CIFAR100 or ImageNet?\n\n \n","sentences":[{"sentence_type":"2","sentence":"If the proposed defense method performs well for spatially transformed AEs but is vulnerable to pixel-based AEs, it is useless.","rephrased":"If the proposed defense method performs well for spatially transformed AEs but is vulnerable to pixel-based AEs, it would be beneficial to address this limitation to enhance the overall robustness of the defense."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[624,751,"Confirmed"]],"Comments":[]}
{"id":"UEG2F-i43X","text":"This paper describes a domain adaptation-based unsupervised learning of medical image registration. Preliminary results show that coarse patch-based displacement classification can be performed well using domain adaptation-based unsupervised learning, and show improvement over traditional methods. The paper is well written and concepts are explained as well as they can be in the limited 3-page space.\n\nPros: Use of deep learning concepts are well justified in the paper. Every decision comes with an explanation, whether it the type of loss function used, they way weights are updated to prevent over-fitting, or the way predictions are scaled (explained with citation).  This is a welcome change from reading several deep learning papers that simply use some network architecture, loss functions, parameters, etc. without explanation.\n\nCons: The accuracy numbers are low for all the reported methods. It would be nice to intuitively understand how the accuracy numbers translate to actual registration errors. This may be hard to compute but authors could use something like SSD, for instance, to understand what kind of registration errors are produced when the accuracy of the network is ~40%. ","sentences":[{"sentence_type":"2","sentence":"The accuracy numbers are low for all the reported methods.","rephrased":"While the reported accuracy numbers could be improved, it would be beneficial to provide a clearer connection between these numbers and the actual registration errors."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[846,904,"Not concerning"]],"Comments":[]}
{"id":"S1xeOjwDh4","text":"The paper contains exactly what I expected based on its title. It's pretty well structured and does what I expect from a \"Towards\" paper, although it leaves me with some questions. First, I still don't really understand why argumentation. This is because I don't have any background on the topic. The formal preliminaries given aren't helpful in describing to me why it's useful, as I don't know what problem argumentation is supposed to solve. This is related to a second problem: I'm not sure what you want your explanations to look like. In the end, I know you want a causal description in natural language, but I'm more concerned with the content rather than the syntax. I suspect that the explanation found is a \"causal chunk\" as discussed in 5.1, since 5.2 delves into \"more\" forms of explanation. However, this is never explicitly stated, and more importantly, you need to argue why this is a good explanation, i.e., will satisfy a user. You can't hand-wave the issue of what makes the explanation good as \"something to be investigated later\", because this is the rationale for why you think argumentation is a good direction to explore. If you aren't aiming for a useful solution, there's no point in doing the work to get there.\n\nOverall, this seems like a good paper to discuss at a workshop.\n\nNotes:\nSection 4.3 would be much easier to follow if you stuck with the example and used actions rather than letters with no context. \nFigure 4 confuses rather than illuminates. What's X? What do the colors signify? What do a-d label, and how are they related to A1-3 (from section 4.2? or section 5.1?).\nThe purpose of section 5.2 is mysterious to me. At the moment, I interpret it as saying, \"Hey, if this whole argumentation thing doesn't work, here's a thumbnail sketch of an alternative.\" If that's so, I'd prefer you flesh out your first idea for now rather than introducing a second with little detail.\n","sentences":[{"sentence_type":"2","sentence":"You can't hand-wave the issue of what makes the explanation good as \"something to be investigated later\", because this is the rationale for why you think argumentation is a good direction to explore.","rephrased":"It is crucial to address the criteria for what constitutes a good explanation within the paper, as this underpins the rationale for exploring argumentation as a direction."},{"sentence_type":"3","sentence":"If you aren't aiming for a useful solution, there's no point in doing the work to get there.","rephrased":"Ensuring that the proposed solution is practical and applicable is essential for the significance of the work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[945,1144,"Maybe"],[1145,1237,"Confirmed"],[1311,1437,"Missed Maybe"],[1439,1481,"Missed Maybe"]],"Comments":[]}
{"id":"SyxG5xWcqB","text":"This paper attempts to study if learned word embeddings for common objects contain information about \"numerical common sense\". The hypothesis is that certain numerical information may co-occur with the words for certain objects\/measurement units within their context windows. To verify this hypotheses, the authors have created a dataset through a crowd-sourcing service which represents \"numerical common sense\". Using this dataset, the authors examine the predict abilities of regressors trained on learned word embeddings and the aforementioned crowd-sourced dataset. The hypothesis is that if the regressors demonstrate good accuracy, then the word embeddings contained information relevant to \"numerical common sense\". To the best of my knowledge, this is the first paper that attempts to analyze learned word embeddings in the context of numerical common sense.\n\nThis paper should be rejected because (1) the NCS datasets are too small to represent \"numerical common sense\" (2) the NCS datasets contain faulty data points and (3) the results from the experiments conducted are not sufficient to accept or refute the hypotheses.\n\nMain argument\n\nThe first question that we must ask is - are the NCS-50x1 and NCS-60x3 datasets reliable for experiments on \"numerical common sense\". No, because of two flaws:\n\n(1) The number of samples in the dataset is too small to represent \"numerical common sense\". Consider the histogram for object \"dog\" in Figure 2. If the largest data point in this plot was absent, the average of the distribution would be smaller by several orders of magnitude. Perhaps there are other objects in the dataset which are missing samples from the tail end of the distribution that could have large effects on the mean of the collected dataset. \n\n(2) Some data points in the dataset don't make sense to me. For example, Fig 2 represents the \"small\" dataset, yet I see samples like 400m long dogs, 40m long cats, 150m long monitors and 20m long mice?\n\nAlso, it is not clear how the confidence scores of the participants were taken into account when training the regressors or if they were used at all.\n\nIf the NCS dataset does not represent \"numerical common sense\", it invalidates all experimental results from the paper.\n\nMy second issue with the paper is that it is not possible to conclude if the experimental results support or refute the hypothesis (ignoring the issue with the dataset):\n\n1. In tables 2 and 3, the correlation coefficients were quite low and and the MAEs were pretty large. In Table 3, rows 1 and 2, even though the correlation is 0.57 and 0.48, the MAE is 100 million yen and 7.5 million yen respectively which is quite large. To me this suggests that just because the correlation is larger we cannot conclude mean that the model is performing well.\n\n2. It is unclear why the correlation coefficient was chosen to decide that ARD is the superior model in experiment 1. The MAE for random forests with concatenated feature vectors was an order of magnitude smaller than that of the ARD model.\n\n3. Why are the correlation coefficients missing for the unit-only experiment in Table 2? The LS model shows very good MAE relative to the other models and perhaps the correlation should have been measured for that as well? In fact, if the correlation coefficients for this case is comparable to the case with concatenated features, it would mean that the word embedding for the object is not helping at all! Moreover, I find it surprising that the LS model with concatenated features performs worse than the unit-only features. We cannot conclude if paper's interpretation about the results is correct unless this missing information is provided.\n\n4. It is hard to judge what a correlation coefficient of 0.57 means. Why didn't you provide a scatter plot of the predictions vs targets as well? It often happens that even noisy plots demonstrate good correlations.\n\n5. The paper should have additional ablation studies - for example, what would happen in the concatenated feature vector experiment if you trained the regressors using randomly initialized word embeddings instead of the trained word embeddings? Do you get the same performance as learned word embeddings?","sentences":[{"sentence_type":"2","sentence":"This paper should be rejected because","rephrased":"I recommend reconsidering this paper for the following reasons"},{"sentence_type":"1","sentence":"Some data points in the dataset don't make sense to me.","rephrased":"Some data points in the dataset appear to be outliers or errors, such as"},{"sentence_type":"2","sentence":"If the NCS dataset does not represent \"numerical common sense\", it invalidates all experimental results from the paper.","rephrased":"If the NCS dataset does not adequately represent \"numerical common sense\", it may call into question the validity of the experimental results."},{"sentence_type":"1","sentence":"To me this suggests that just because the correlation is larger we cannot conclude mean that the model is performing well.","rephrased":"This suggests that a larger correlation does not necessarily imply that the model is performing well."},{"sentence_type":"1","sentence":"It is hard to judge what a correlation coefficient of 0.57 means.","rephrased":"It would be helpful to provide more context or a benchmark for interpreting the significance of a correlation coefficient of 0.57."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[869,906,"Confirmed"],[1774,1829,"Maybe"],[1980,2123,"Missed by Model"],[2125,2244,"Maybe"],[2673,2795,"Not concerning"],[3690,3755,"Not concerning"],[3756,3832,"Missed by Model"]],"Comments":[]}
{"id":"2M9pRB7Vy2W","text":"This paper violates workshop submission instructions to have only 4-5 pages of content. This paper has 9-pages content.\nTo be fair to other submissions, I'd recommend desk rejecting this paper. ","sentences":[{"sentence_type":"2","sentence":"To be fair to other submissions, I'd recommend desk rejecting this paper.","rephrased":"To ensure fairness in the review process, I would suggest that the authors be asked to revise the paper to meet the 4-5 page guideline before further consideration."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[120,193,"Maybe"]],"Comments":[]}
{"id":"rklud-o3tH","text":"This paper proposes to train a GAN and an EBM jointly, and bridge them using a Stein discrepancy. The paper claims it leads to novel regularization effect on both models, and stablizes the optimization process. Experiments on MNIST and CIFAR-10 show improvement in sample quality and outlier detection.\n\nBoth the idea and the experiment results are interesting. However, the derivations contain too many typos and are in general confusing, and I cannot confirm their correctness. Therefore I cannot recommend acceptance.\n\nSpecifically the proof of Theorem 1 seems problematic:\n1. In the proof you claim (15) equals $\\frac{-1}{4\\lambda_2}\\lVert D-t\\rVert_{H^{-1}}$. But (15) could only simplify to \n$\\frac{1}{\\lambda_2} ( E[D\\cdot(\\lambda_2 h)] + E_{x,x'}[\\nabla(\\lambda_2 h(x))^T k(x,x') \\nabla(\\lambda_2h(x'))],$\nwhere h is unconstrained. Compare this with the definition of the $H^{-1}$ norm,\n$sup_h \\{E[D\\cdot h]: E_{x,x'}[\\nabla h(x)^T k(x,x') \\nabla h(x')] \\le 1\\},$\nhow did you drop the inequality constraint on h?\n2. The transformation from the original objective (14) to (15) is strange as well. In the proof you claim the minimization problem below \"invoking Lagrangian duality gives\" could only turn to (15) after \"applying the approximation log(1+a)=a+O(a^2)\" and \"a further approximation\". But you can turn it into\nE[(D-t)h]+λ E_{x,x'~P_E}[∇h(x)^T k(x,x') ∇h(x')]\nsimply by simplifying the gradient terms. Also, why did the $t$ disappear in (15)?\n\nThere are also typos and issues elsewhere. To list a few:\n3. Energy-based models are not generally referred to as \"explicit models\", since the normalization constant is intractable. I would suggest to replace the occurrences of (log) \"density\" with \"energy\" to avoid confusion.\n4. The GD update rule of (6) is incorrect; the optima should also be (0, 1), instead of (1, 0).\n5. On the second line on Page 8, the unnormalized log density cannot be x^2+\\phi x, as the normalization constant would then be infinity.\n\nFor these reasons, I believe this paper needs a thorough proofreading before it can be reviewed efficiently.","sentences":[{"sentence_type":"2","sentence":"However, the derivations contain too many typos and are in general confusing, and I cannot confirm their correctness. Therefore I cannot recommend acceptance.","rephrased":"While the derivations are intriguing, they could benefit from clarification and correction of typos to ensure their correctness. This would strengthen the paper and make a case for acceptance."},{"sentence_type":"1","sentence":"For these reasons, I believe this paper needs a thorough proofreading before it can be reviewed efficiently.","rephrased":"To facilitate an effective review process, I recommend a comprehensive proofreading to address these issues."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[362,520,"Maybe"],[1973,2081,"Maybe"]],"Comments":[]}
{"id":"V_2efhR_ja","text":"Strong Points:\n1) The paper was fairly well written and easy to follow.\n2) The results are quite promising.\n\nQuestions to the author:\n1) It is unclear how the model learns the category without any supervision. It is recommended to provide more explanations as it is the major contribution.\n2) It is unclear how \\pi_c in equation 2 is determined. Does it follow the same distribution of the dataset?\n3) For figure 2, why was the proposed CIGMO not compared to GVAE plus k-means or IIC?\n4) For figure 3A, are the numbers of examples balanced in the 3 categories?\n5) For figure 3B (swapping), based on data preparation, shape should capture identity, but it is not obvious from the figure. Any thoughts?\n6) For the experiment with MultiPIE, grouping by emotion category might reveal more about the model.\n7) The model is C(category) times larger than GVAE. Is it possible that the performance gain comes from using larger model?\n","sentences":[{"sentence_type":"1","sentence":"It is unclear how the model learns the category without any supervision.","rephrased":"Could you please elaborate on how the model learns the category without any supervision? This aspect is crucial as it represents a major contribution of your work."},{"sentence_type":"1","sentence":"The model is C(category) times larger than GVAE. Is it possible that the performance gain comes from using larger model?","rephrased":"The model appears to be C(category) times larger than GVAE. Could you discuss whether the performance gain might be attributed to the increased model size rather than the model architecture itself?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[137,209,"Not concerning"],[805,925,"Not concerning"]],"Comments":[]}
{"id":"HktiHfugG","text":"This paper addresses a method of building an interpretable model for classification, where two key ingredients are (1) supervised variational autoencoder and (2) differentiable decision tree. Recently one important line of research is to build interpretable models which have more modeling capacity while maintaining interpretability, over existing models such as linear models or decision trees. In this sense, the current work is timely research. A few contributions are claimed in this paper: (1) differentiable decision tree which allows for gradient-based optimization; (2) supervised VAE where class-specific Gaussian prior is used for the probabilistic decoder in the VAE; (3) combination of these two models. Regarding the differentiable decision tree, I am not an expert in decision tree. However, I understand that there have been various work on probabilistic decision tree, Bayesian decision tree, and Mondrian tree. More literature survey might be needed to pin-point what's new and what's common with previous work. Regarding the supervised VAE, the term \"supervised VAE\" is misleading. To me, the current model is nothing but VAE with class-specific Gaussian prior. (3)  Regarding the combination of supervised VAE and DDT, it would be much better to show us a graphical illustration of the model to improve the readability. I see the encoder is common for both the decoder and DDT. However, it is not clear how DDT is coupled with the encoder. It seems that DDT takes the output of the encoder as input but the output of DDT is not coupled with VAE.  ","sentences":[{"sentence_type":"2","sentence":"Regarding the supervised VAE, the term \"supervised VAE\" is misleading. To me, the current model is nothing but VAE with class-specific Gaussian prior.","rephrased":"Regarding the supervised VAE, the term might benefit from further clarification to avoid potential confusion. It appears that the model is a VAE with a class-specific Gaussian prior, which could be more explicitly stated."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1030,1180,"Maybe"]],"Comments":[]}
{"id":"Jrisnh1UaO","text":"The paper proposes to include recurrent layers in an encoder-decoder architecture to improve the segmentation of lesion activity. The method is clearly justified and introduced and shows clear improvements over a baseline that concatenates encodings of different time points.\n\nThe extension of including recurrent connections for a temporal problems seems rather obvious but still requires effort to get working correctly. The simplicity of the approach, the applicability to different temporal applications, and convincing results make this paper a nice and interesting read.\n\nThe paper lacks clarity in the exact experimental setup and I personally would have liked a better introduction to lesion activity segmentation. Fig. 1 seems to suggest that the paper aims to segment the differences in lesion segmentations for two different time points. The figure might be slightly misleading assuming that HS is taken before HL. HS shows some lesion in the top right corner that isn't present in BL. Is that regular behaviour for those tasks?\n\n- Furthermore, it seems that the authors did not use a validation set for developing and validating their method but might report results that are overfit to the test set.\n- It is unclear how the full-volume activity maps are generated: how is are overlapping patches aggregated? Is there and consideration for boundary effects?\n- The metrics seem not clearly defined: does FPs mean voxel-wise false positives? How are lesion-wise metrics defined?\n- Lastly, do you ensure that the baseline has a similar capacity as the model including GRUs? Is there a similar memory footprint or number of model parameters? If not, this might not be a fair comparison.\n\nIt would be interesting to explore whether this model can generalise to unknown lengths of history. Also, could it be helpful to have intermediate segmentation or activity supervisions to use the varying time points as some training signal also?","sentences":[{"sentence_type":"1","sentence":"The extension of including recurrent connections for a temporal problems seems rather obvious but still requires effort to get working correctly.","rephrased":"While the idea of including recurrent connections for temporal problems may seem intuitive, the implementation and fine-tuning of such a model is commendable and requires significant effort."},{"sentence_type":"2","sentence":"Furthermore, it seems that the authors did not use a validation set for developing and validating their method but might report results that are overfit to the test set.","rephrased":"It would be beneficial for the study if the authors could clarify whether a validation set was used during the development of their method to ensure that the results are not overfit to the test set."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[277,422,"Not concerning"],[1043,1212,"Not concerning"]],"Comments":[]}
{"id":"HkxADT9OtV","text":"This paper proposes a method for learning a policy based on a variance reduced REINFORCE loss based on sampling without replacement. Experiments suggest that learning with this approach performs slightly better when compared with a greedy rollout baseline (Kool et al 2019) but it is more sample efficient requiring fewer instances to learn.\nThe paper provides results in a toy problem using a Travelling Salesman Problem with a few nodes (20), it would be interesting to evaluate the performance on a more complex task to see whether sampling without replacement would still be beneficial over other sampling schemes.\nIt would also be interesting to evaluate the performance of the normalized and non-normalized version of the loss, to see how much variance is reduce between the two proposed approaches.\n\nThis paper provides interesting preliminary results on an important topic for deep structure prediction with RL and therefore I would like to see it presented in this workshop.","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"iZuZyJGakqH","text":"This paper is an example of trying to use some complicated theories to describe some very simple observations. \n\nThis paper does not have a significant theoretical contribution because it does not have any theorem or lemma. All of the notations and definitions are just for describing their analysis method in a very abstract way. I spent quite some time understanding what those notations mean, but realize that the complex math does not help me understand the empirical findings at all, which are the main contributions of the paper. \n\nThe paper's first two empirical findings are not very interesting to me and the authors also do not explain the impact of those findings. The third finding in Figure 3 (c) could potentially deepen our understanding of BERT, but the authors need to investigate the underlying reasons to make the finding become useful. \n\nBy the way, I think the authors should also cite this work (https:\/\/aclanthology.org\/2020.aacl-main.11.pdf) (and possibly other work that also tries to align the embedding space in different layers of Transformers to analyze what language model learns). These papers show that the analysis methods used in this paper are not very novel.\n\nMinor things:\n1. ELMO -> ELMo\n2. Your notations are not consistent or not clearly explained. For example, What is E? Why e \\in E but also C \\in E? What is G_{set} = G_{m}?\n3. (7) in Equation should be right justified.\n4. Your Figure 1 is helpful. But if you really want to define those symbols for some reason, add more symbols into the figure would make your definitions easier to understand.\n5. Your scenario A corresponds to m=n in Equation (9), right? If yes, make it more clear (if you really want to define those symbols for some reason).","sentences":[{"sentence_type":"2","sentence":"This paper is an example of trying to use some complicated theories to describe some very simple observations.","rephrased":"The paper attempts to apply complex theories to straightforward observations, which may not be necessary for the understanding of the results."},{"sentence_type":"2","sentence":"This paper does not have a significant theoretical contribution because it does not have any theorem or lemma.","rephrased":"The paper could be strengthened by including theorems or lemmas to enhance its theoretical contribution."},{"sentence_type":"2","sentence":"The paper's first two empirical findings are not very interesting to me and the authors also do not explain the impact of those findings.","rephrased":"It would be beneficial if the authors could further elaborate on the impact of the first two empirical findings to highlight their significance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,110,"Confirmed"],[113,223,"Confirmed"],[224,330,"Missed by Model"],[331,535,"Missed Maybe"],[538,675,"Confirmed"],[1229,1288,"Missed by Model"]],"Comments":[]}
{"id":"rZogOl43Zd","text":"In this paper, the authors present an exploration of learning reward signals and how various reward signals can be adaptively used to provide a single reward feedback channel for a reinforcement learning process. First, they provide a solid introduction and related work research on multi-objective reinforcement learning. I would urge the authors not to present statements about work that they will continue to work on or work towards in the future. These forward-looking statements do not serve the purpose of the current work. \n\nA great deal of real estate in this paper is committed to background information on related work reinforcement learning and reward shaping which does not serve this paper. Indeed it is not until section 4.2 Methods: Selection when the author's finally present details on new methods and experimental design.\n\nThe results and figures presented are unclear and I would urge the authors to reconsider the information that they would present in terms of mean and measure of central tendency. It is hard to compare the significance of their results against their baseline methods. \n\nThis paper feels incomplete to me, and I would like to see this research continued toward a more full submission. Finally, I do not feel as though this paper is suitable for the general audience at ICLR. Perhaps there would be audiences more interested in the specific application and innovations in reward shaping at other workshops.","sentences":[{"sentence_type":"2","sentence":"A great deal of real estate in this paper is committed to background information on related work reinforcement learning and reward shaping which does not serve this paper.","rephrased":"The paper dedicates a significant portion to background information on reinforcement learning and reward shaping. It would be beneficial to more directly tie this information to the paper's contributions to clarify its relevance."},{"sentence_type":"2","sentence":"Indeed it is not until section 4.2 Methods: Selection when the author's finally present details on new methods and experimental design.","rephrased":"The new methods and experimental design are introduced in section 4.2, Methods: Selection. It may enhance the paper's impact to present this material earlier or to highlight its novelty more prominently."},{"sentence_type":"2","sentence":"This paper feels incomplete to me, and I would like to see this research continued toward a more full submission.","rephrased":"The paper could be strengthened by further developing the ideas and experiments to provide a more comprehensive submission."},{"sentence_type":"2","sentence":"Finally, I do not feel as though this paper is suitable for the general audience at ICLR.","rephrased":"The paper might find a more suitable audience in venues that focus on the specific applications and innovations in reward shaping, rather than a general conference like ICLR."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[532,703,"Maybe"],[704,839,"Confirmed"],[1110,1223,"Not concerning"],[1224,1313,"Not concerning"]],"Comments":[]}
{"id":"W0LSTQC9OoN","text":"This manuscript introduces novel arithmetic layers, which enables divide operation. Proposed NRU and NMRU achieved higher success rates and fast learning ability compared to Real NPU in various experiments.\nThe manuscript seems to cover too broad subject. Proposing an improvement method of NPU does not seemed to be highly related to NRU and NMRU. It would be better to add comments explain relationship among them, or focusing more on NRU and NMRU. Additionally, there is a concern about novelty on the proposed improvement method of NPU, since they are briefly commented on ‘Neural Power Units’(NIPS 2020). \nIn Equation (5), they used summation of cosine function to calculate sign value of output, but I think it should be product of cosine like Equation (5) in supplementary material.","sentences":[{"sentence_type":"2","sentence":"Proposing an improvement method of NPU does not seemed to be highly related to NRU and NMRU.","rephrased":"It would be helpful if the authors could clarify the connection between the proposed improvement method of NPU and the NRU and NMRU, as the relationship is not immediately apparent."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[207,255,"Missed Maybe"],[256,348,"Not concerning"]],"Comments":[]}
{"id":"HygMWn2Dn7","text":"This paper derives a formula for finding the minimum and maximum clipping values for uniform quantization which minimize the square error resulting from quantization, for either a Laplace or Gaussian distribution over pre-quantized value. This seems like too small a contribution to warrant a paper. I wasn't convinced that appropriate baselines were used in experiments. There were a number of statements that I believed to be technically slightly incorrect. There were also some small language problems (though these didn't hinder understanding).\n\nmore specific comments:\n\nabstract:\n\"derive exact expressions\" -- these expressions aren't exact. they turn out to be based on a piecewise zeroth order Taylor approximation to the density.\n\nmain paper:\n\"allow fit bigger networks into\" -> \"allow bigger network to fit into\"\n\"that we are need\" -> \"that need\"\n\"introduces an additional\" -> \"introduces additional\"\nclippig -> clipping\n\nit's not clear a-priori that information loss is the property to minimize that maximizes performance of the quantized network.\n\n\"distributions of tensors\" -> \"distribution of tensor elements\"\nthis comment also applies in a number of other places, where the writing refers to the marginal distribution of values taken on by entries in a tensor as the distribution over the tensor. note that a distribution over tensors is a joint distribution over all entries in a tensor. e.g. it would capture things like eigenvalues, entry-entry covariance, rather than just marginal statistics.\n\n\"than they could have by working individually\" -> \"than could have been achieved by each individually\"\n\nWhy the focus on small activation bit depth? I would imagine weight bit-depth was more important than activation bit depth. Especially since you're using ?32-bit? precision in the weight\/activations multiplications, so activations are computed at a high bit depth anyways.\n\nTable 1: Give absolute accuracies too! Improvement relative to what baseline?\n\nsec 2:\nsufficeint -> sufficient\n\\citep often used when it should instead be \\citet.\n\"As contrast\" -> \"In contrast\"\n\nsection 3:\nuniformity -> uniformly\n\nI don't believe the notion of p-value is being used correctly here w.r.t. the Kolmogorov-Smirnov test.\n\nFigure 1: The mean square error should never go to 0. This suggests something is wrong. If it's just a scaling issue, consider a semilogy plot.\n\nFigure 2: I'm unclear what baseline (no clipping) refers to in terms of clipping values. For uniform quantization there needs to be some min and max value.","sentences":[{"sentence_type":"2","sentence":"This seems like too small a contribution to warrant a paper.","rephrased":"The scope of the contribution could be expanded to strengthen the case for a standalone paper."},{"sentence_type":"1","sentence":"I wasn't convinced that appropriate baselines were used in experiments.","rephrased":"It would be helpful if the paper could provide further justification for the choice of baselines used in the experiments."},{"sentence_type":"2","sentence":"There were a number of statements that I believed to be technically slightly incorrect.","rephrased":"I suggest reviewing certain statements that may require technical clarification or correction."},{"sentence_type":"1","sentence":"it's not clear a-priori that information loss is the property to minimize that maximizes performance of the quantized network.","rephrased":"The paper could benefit from a clearer explanation of why minimizing information loss is expected to maximize the performance of the quantized network."},{"sentence_type":"1","sentence":"Why the focus on small activation bit depth? I would imagine weight bit-depth was more important than activation bit depth.","rephrased":"Could you elaborate on the rationale behind focusing on small activation bit depth, as opposed to weight bit-depth which might be considered more critical?"},{"sentence_type":"2","sentence":"The mean square error should never go to 0. This suggests something is wrong.","rephrased":"The mean square error approaching 0 warrants further investigation; if it's a scaling issue, a semilogy plot might be more appropriate."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[239,299,"Maybe"],[300,371,"Confirmed"],[372,459,"Not concerning"],[931,1057,"Maybe"],[1617,1740,"Not concerning"],[2236,2313,"Not concerning"]],"Comments":[]}
{"id":"tXTvQvkvplF","text":"1. For starters, one of the main contributions of EF21 is to converge at a rate of $1\/T$ instead of $1\/T^{2\/3}$. Here the author makes a mistake in line 133, saying Koloskova et al. [2020, Theorem 4.1] assumes a bound on the full gradient on worker i. However, the actual assumption in that paper was a bound on the *stochastic* gradient on worker i. These two are notably different as the latter incorporates the sampling noise. If the sample complexity is not considered (which seems to be the case of EF21), it's not surprising that a $1\/T$ rate is achieved (this is like saying GD improves upon SGD). In fact, if we remove the sampling noise in Koloskova et al. [2020, Theorem 4.1], a $1\/T$ rate is straightforward to obtain. The paper claims in the abstract EF21 \"beats\" the previous bound of $1\/T^{2\/3}$, which is confusing. Also Koloskova et al. [2020] works in the decentralized case, which is more challenging than the setting in this paper.\n\n2. Could you provide a data-parallel setting where we need communication compression but no sampling? I cannot think of any since communication overhead is usually observed in deep learning tasks and sampling is a must rather than an option. Having said that, the application of EF21 is very limited. The authors provide empirical results on deep learning tasks in the appendix, but mini-batching is used there, which is not aligned with the theory or logistic regression task. Also the data heterogeneity issue is confusing: In data center training where we are able to shuffle the dataset, we can usually reduce the intra-worker variance. Heterogeneous data usually takes place in the federated learning, where the execution of EF21 shown in the paper clearly does not cover.\n\n3. Based on 1 and 2, the main improvement of Markov compressor upon EF is data heterogeneity where $||\\nabla f_i||$ can be large when the algorithm converges. However, the only case the Markov compressor can address this seems to be in non-stochastic case. If we use stochastic gradient in the Markov compressor, the error bound does not approach zero either. How EF21 handles this issue remains unclear. \n\n4. The authors conduct different experiments  but the results are not convincing. First, # Gbits\/n is used as X-axis for all figures. However, for compression algorithms the convergence speed with respect to iterations or time are also important since when communication is reduced, the compression can become a new overhead. If the paper claims EF21 is practically better, other X-axis should be provided. Second, some of the plots for baselines are omitted for no reason, which is serious. Specifically, in the Resnet18 on CIFAR-10 experiment, EF and EF21 seems to perform similar under 128X, however only EF21 is shown under 512X while EF at 512X is not shown. Note that validation performance is not informative here, since the design of EF21 does not consider generalization.\n\nClarification on my review after reading the author response\n===\nWhile I appreciate the author answering my questions, but it appears some of my concerns were misunderstood. Specifically:\n\n**On the problem with improved rates**\n\nI did not state anywhere in my review that $G=0$, as author claimed. Let me rephrase: this is the problem with the baseline comparison. Take Koloskova et al. [2020] as example (other baselines such as Tang et al. [2020] has similar issue), in their Theorem 4.1, the convergence bound is shown as\n$O\\left(\\frac{\\bar{\\sigma}}{\\sqrt{T}} + \\frac{G^{2\/3}}{T^{2\/3}} + \\frac{1}{T}\\right)$, where $\\bar{\\sigma}^2$ and $G$ are assumed to be the bound on the variance and magnitude of the *stochastic* gradients, respectively. Now, since EF21's rate is shown in non-stochastic case, for comparison, the authors convert the baseline bound as follows: drop the first term (which makes sense since $\\bar{\\sigma}=0$); and keep the second term. That's where my confusion comes from, as $G$ is clearly correlated with the stochastic gradient in their analysis, so how do you justify the removal of term $\\frac{1}{T^{2\/3}}$ in EF21 is due to EF21 being better algorithm\/analysis, but not because the fact that two settings are different so that the conversion of baseline results is loosen? This happens because the authors converted a result from a more general setting to a special case, which could implicitly worsen the baseline result. In fact, there is no obvious way to detach the stochastic noise from $\\frac{G^{2\/3}}{T^{2\/3}}$ term without reproving the baselines in the non-stochastic case, so I don't fully understand how is it an improved rate.\n\nTo make this even clearer, consider this example (not relevant to the paper, just for illustration): suppose we prove algorithm A having rate $O(1\/T)$ on smooth functions while algorithm B having rate $O(\\rho^T)$ on smooth and strongly convex functions. Clearly, algorithm A is analyzed in a more general setting (analogous to Koloskova et al. [2020]). Can we say B is better than A by directly converting these bound in any way? Apparently not. In fact, the only way to make conclusion on rate comparison is to reprove A or B in the other setting.\n\n(**In response to author's follow-up question on why Gower et al (2019) can do the conversion correctly**): I thank the authors for bringing up this paper as it is a perfect example for illustrating the problem. In a nutshell, you can convert a result from a general case to a special case by setting zero to variables, but not in every case. It depends on how the baseline result is shown. Gower et al (2019) does an analysis for SGD, take their Theorem 3.1 as example, they show the convergence rate by $\\mathbb{E}||x^k-x^*||^2 \\leq (1-\\gamma\\mu)^k\\mathbb{E}||x^0-x^*||^2 + 2\\gamma\\sigma^2\/\\mu$ in their Equation (10). Now this result can be converted to GD with valid conversion since the term relates to stochastic sampling is the second one, and they can easily convert by setting $\\sigma=0$. However, in this paper the conversion is problematic (I acknowledge setting $\\sigma=0$ is correct in my review, it's the $G$ term that has problem) because you cannot detach the effect of stochastic gradient from $G$. Put it another way, if the baseline result looks like $O(\\sigma\/\\sqrt{T}+{1}\/{T^{2\/3}} + 1\/T)$, then your conversion would be correct since now only the first term relates to the sampling and you can easily convert the result by setting $\\sigma=0$ but that's not the case here.\n\n**On the problem with application**\n\nIn my original review, I raised the question of naming an application setting where we need communication compression but no sampling, to which EF21 can be applicable. The author states in their response that one application of EF21 is federated learning, which seems a little off to me. As we know, federated learning usually involves a large number of nodes, so a typical algorithm (such as FedAvg, SCAFFOLD) requires client sampling. However, in the multiple node version of EF21, it requires all the nodes to participate in each iteration and need to be synchronized at the end of each iteration. So if I understand it correctly, EF21 can be used in federated learning only under the following two conditions:\n\n(1) The number of nodes cannot be too large so that global synchronization is possible and negligible.\n\n(2) The number of data samples on each node (client) cannot be too large so that full gradient computation is not an overhead. \n\nI don't really understand how this is applicable, please correct me if anything in my statement is incorrect.\n\n**On the problem of extension to stochastic case**\n\nMaybe I did not state it well in the original review. My claim is that stochastic gradient actually breaks the intuition of EF21 which makes it not easy to extend. Here's why: the intuition of EF21 is illustrated in line 271: $\\mathbb{E}||\\mathcal{M}(v^t)-v^t||^2\\rightarrow 0$, while this is true for full gradient because as the algorithm converges, the magnitude of full gradient will approach zero. However, it's not clear to me why it still holds for stochastic gradient, especially the case where all the data samples have different local minimas (not quite the heterogeneity as mentioned in the paper). Specifically, could you explain why such quantity still approaches zero if $v^t$ contains sampling noise? \n\nThe authors state in their response that error feedback is orthogonal to stochastic approximation, and the latter should be handled by other variance reduction algorithms like SVRG, I'm confused. Because the baseline algorithms like DoubleSqueeze, Q-local-Sparse clearly works with stochastic approximation without involving variance reduction parts.\n\nThe author pointed out a stochastic analysis is included in the appendix I, however, no rate is shown in that analysis and that analysis ends with \"It is straightforward...to establish complexity results for our stochastic variant of EF21 .\" If the authors believe the statement of my original review \"$O(1\/T)$ rate is straightforward to obtain in baseline\" is unjustified because \"such a rate is not included in their paper\", I politely ask the authors to apply the same standard to the paper, and avoid using such statement to justify your results. Because, the rate of EF21+ too, is not shown in the paper or appendix. As pointed out by authors in their response: \"Simply claiming this does not make it true\". Please correct me if I'm wrong.\n\n**Summary**\n\nI believe all my concerns are specific on the technical issues. The idea of Markov compressor is interesting, so I've decided to raise my score slightly to give some more credit. However, at this point, I still don't think this paper meets the acceptance bar of NeurIPS as the issues I raised are serious and closely related to the main contribution of this paper, unless the authors can prove I misunderstood them all.\n\n\n\n","sentences":[{"sentence_type":"2","sentence":"Having said that, the application of EF21 is very limited.","rephrased":"However, it would be beneficial to explore broader applications of EF21 beyond the scope presented."},{"sentence_type":"2","sentence":"the results are not convincing.","rephrased":"the results could be strengthened with additional data or analysis."},{"sentence_type":"2","sentence":"some of the plots for baselines are omitted for no reason, which is serious.","rephrased":"the omission of some baseline plots warrants further explanation to ensure a comprehensive comparison."},{"sentence_type":"1","sentence":"I don't really understand how this is applicable, please correct me if anything in my statement is incorrect.","rephrased":"Could you please clarify the applicability of this approach in the context you've described?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1194,1252,"Maybe"],[1593,1729,"Missed Maybe"],[2091,2135,"Missed Maybe"],[2188,2219,"Confirmed"],[2553,2629,"Confirmed"],[7420,7529,"Not concerning"]],"Comments":[]}
{"id":"rJl0jWWnYV","text":"The paper proposes an asymmetrically-relaxed distribution alignment approach, to do unsupervised domain adaptation. For this, they propose 3 different \"relaxed\" distances. \n\nPros: \n- The paper is well written and, although dense, quite clear.\n- The proposed models are a good alternative to the original DANN\n- The long version of the paper could be submitted to a journal.\n\nCons:\n- The paper is very dense. \n- Experiments section is very short and explanation of results is minimal. We do not know what are the different acronyms because they are not defined. They are only defined in the long version of the paper, that was attached. \n- Conclusions are lacking.\n","sentences":[{"sentence_type":"1","sentence":"The paper is very dense.","rephrased":"The paper is rich in content, which can make it challenging to digest."},{"sentence_type":"2","sentence":"Experiments section is very short and explanation of results is minimal.","rephrased":"The experiments section could be expanded to provide a more detailed explanation of the results."},{"sentence_type":"2","sentence":"We do not know what are the different acronyms because they are not defined.","rephrased":"It would be helpful if the acronyms used in the paper were defined within the text for clarity."},{"sentence_type":"2","sentence":"Conclusions are lacking.","rephrased":"The paper would benefit from a more comprehensive conclusions section to summarize the findings and implications."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[383,407,"Not concerning"],[411,483,"Confirmed"],[484,635,"Confirmed"],[639,663,"Confirmed"]],"Comments":[]}
{"id":"H1eIiBMvhV","text":"The paper follows up on one of the proposals by the Fox et al XAIP paper 2017, user questions \"Why A rather than B?\" with reference to a current plan. It thoroughly outlines and discusses the system that would need to be brought into place for answering this type of question based on the \"as a service\" idea meaning that the core of the answer generation is done by compilation into a planning proble, generating a new plan which serves as the basis for the answer.\n\nThe paper is mostly fairly high-level, discussing the various issues and possible problems and solutions in a lot of detail. I think this is perfectly adequate for presentation and discussion at the workshop. It certainly contains lots of thoughts that other workshop participants may take up upon\/adapt to various other settings they may be interested in.\n\nTwo critical comments: \n\nThe new plan generated may differ from the previous plan in arbitrary ways unrelated to the user question. This is an inherent limitation of the approach, which should be discussed here. Maybe I overlooked that discussion; if not, I'd ask the authors to add such a discussion.\n\nThe title is very non-informative, and imho much too broad. Please make your headline more specific to the particular kind of questions, and answers, you are addressing here.","sentences":[{"sentence_type":"2","sentence":"The title is very non-informative, and imho much too broad.","rephrased":"The title could be more informative and specific to better reflect the focus of your paper on particular types of questions and answers."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1129,1303,"Maybe"]],"Comments":[]}
{"id":"aPFTobiH9Qh","text":"This submission looks more like a working draft rather than a conference paper. In particular,\n\n**There are many typos**, making the reading very difficult (I am highlighting a few of them, only on page 1):\n- which *have* their own limitation (abstract)\n- that uses *functions* from Reproducing Kernel Banach Spaces (abstract)\n- and *test* it on a range on ML tasks (abstract)\n- the acronyms MLMKL, DGP, DKL are never introduced (abstract and later)\n- *W*e are still (1st paragraph)\n- *kernel from Hilbert Space* makes little sense (1st paragraph)\n- There has *been* (1st paragraph)\n- *W*e then examine (2nd paragraph)\n- *two layer RKBS kernel* makes little sense (2nd paragraph)\n- the connect*ion* with multiple (2nd paragraph)\n- *W*e also talk about *the* library (2nd paragraph)\n- the bibliography entry [Scholkopf and Smola] seems wrong\n\n**The maths are not rigorous**, to the extent they are almost incorrect:\n- the introduction of RKBSs is very confusing, as the proposed definition looks more like the RKHS definition to me, see e.g., Definition 4.18 in \"Support Vector Machines\" by Steinwart and Christmann, 2008\n- Theorems 2.1 and 2.2, that are not part of the contribution, should be explicitly linked to the paper they come from\n- undefined notation in eq. (2.9)\n- I would like to point out the paper \"Autoencoding any Data through Kernel Autoencoders\" by Laforgue et al., 2019 which considers a similar framework as the one introduced at the top of page 3. A Representer Theorem is also proved therein, as in [Bohn et al. 2019], except that it applies to potentially infinite dimensional output Hilbert spaces\n- the introduction of the $\\Theta_l$ is not understandable\n- In section 3.2 the proof is said to be given in the Appendix, but the latter is empty\n\n**The contribution is very limited**:\n- the Representer Theorem (RT) being mainly due to orthogonality properties, it is not surprising to recover it for a class of functions that share this property with RKHSs\n- I cannot see any novel idea in the proofs, so proving another RT seems not a sufficient contribution for acceptance\n- I cannot find any motivation for the presented results\n- the authors themselves acknowledge that their experimental contribution is very limited","sentences":[{"sentence_type":"2","sentence":"This submission looks more like a working draft rather than a conference paper.","rephrased":"This submission seems to be at an early stage and could benefit from further refinement before it reaches the standard of a conference paper."},{"sentence_type":"2","sentence":"The maths are not rigorous, to the extent they are almost incorrect:","rephrased":"The mathematical rigor could be improved to ensure the accuracy and clarity of the presented concepts."},{"sentence_type":"2","sentence":"The contribution is very limited:","rephrased":"The contribution could be more clearly articulated to highlight its novelty and relevance to the field."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,79,"Maybe"],[96,205,"Missed by Model"],[917,960,"Missed Maybe"],[1624,1680,"Missed by Model"],[1983,2098,"Missed by Model"],[2101,2155,"Missed by Model"]],"Comments":[]}
{"id":"AuyjVP0WBB","text":"The introduction is so long while there is less attention to their work, materials and methods. While there is a large number of patients I am wondering why the authors have not divided their dataset into training and validation sets. It is not clear for me if the images have been annotated by radiologist or by automatic algorithm. The authors have not mentioned what is the imaging technique (while I’m assuming it’s MRI). I don’t think this paper in this format is suitable for publication.","sentences":[{"sentence_type":"2","sentence":"The introduction is so long while there is less attention to their work, materials and methods.","rephrased":"The introduction could be more concise, allowing for a more detailed presentation of the work, materials, and methods."},{"sentence_type":"3","sentence":"I don't think this paper in this format is suitable for publication.","rephrased":"The paper may require significant revisions before it is ready for publication."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[0,95,"Confirmed"],[235,333,"Missed Maybe"],[334,425,"Missed Maybe"],[426,494,"Confirmed"]],"Comments":[]}
{"id":"YkxrVVHzBVF","text":"####################################\n\nStrengths:\n- The themes discussed in this paper, including the full posterior having modes corresponding to either signal or noise which should be discriminated between with active learning, are very interesting. In particular, Figures 1 and 2 were interesting and illustrative.\n- The related work section and description of Gaussian Processes is mostly satisfactory\n- The experiments compare against a diverse set of active learning acquisition functions and experimental simulators\n\n####################################\n\nWeaknesses:\n\nWhile this paper presents some interesting ideas, overall I feel that certain major elements need to be significantly improved before it is ready for publication.\n\nWhen I first read the abstract, I was intrigued by the idea of the bias-variance tradeoff being neglected in active learning, how in GP this tradeoff corresponds to the length scale and noise term, how “the optimal mode of the joint posterior of the hyperparameters is equivalent to the optimal bias-variance tradeoff”, and how B-QBC and QB-MGP directly incorporate this tradeoff in their acquisition functions to mitigate bias-variance issues. However, in my opinion, these points are not strongly reflected in the paper itself:\n\n*** Introduction ***\n\nStarting in the introduction, I had expected a cohesive theme illustrating the issues presented in the abstract: how the bias-variance tradeoff is neglected in active learning, a strong argument for bias-variance correspondence to length scale and noise term, and strong connections with the hyperparameters posterior. Instead, I found the topics in the introduction only very loosely coupled: specifically, I think the connections between the predictor vs guide, bias vs variance, and signal vs noise in GPs need to be strengthened and more direct arguments made. For instance, statements such as “The problem is directly related to the well-known bias-variance trade-off, although we reformulate it as a balance between modeling the data as signal or noise” or “However, none of\nthese approaches directly address the core problem: which mode to choose? Ideally, this should be\nanswered with prior information about the problem, although typically that is not available, making\nthese approaches less practical.” seem extremely important, but most of the time I found such critical statements vague and unsupported. While Figure 1-2 were interesting, I did not find myself convinced that the bimodal behavior in Figure 2 is a general phenomenon and found myself unsure how it connected to bias and variance. Is this multimodal behavior between signal and noise an established fact in the literature, or is this perspective a major contribution of this paper? Either way, I believe statements around this point need to be strengthened. Overall, after reading the introduction I found myself unconvinced about the strong points presented in the abstract. I also expected that I would find more details supporting these points in Section 3, which seem to be missing there (e.g., establishing connections between bias-variance and specific GP hyperparameters).\n\n*** Sections 2-3 ***\n\nOtherwise, I was mostly happy with Sections 2-3. One point in Section 3 I’d like to bring up is that the authors claim earlier in the paper that “In this paper, we follow a general approach and assume no prior knowledge about the kernel or hyperparameters.” However, the authors state in Section 3 that they use an RBF kernel. Can the authors comment about this? Is this specific choice not in fact an assumption about the kernel?\n\n*** Section 4 ***\n\nIn Section 4, B-QBC seems reasonable, but I was not convinced that it somehow addressed the key bias-variance tradeoff and\/or mode selection problem in GP active learning described earlier in the paper. The idea of discriminating between modes seems reasonable, but I believe that in order to motivate B-QBC, a much stronger argument (stronger than the illustrative example in Figures 1-2) needs to be presented about why the hyperparameter posterior is multimodal, and how B-QBC will specifically select the correct one. In terms of QB-MGP, I found myself confused by its presentation. I was not convinced that equation (11) is maximizing the predictive variance of the mixture model --- I can imagine that it comes directly from a variance decomposition, but I believe the derivation of this fact should be presented. Moreover, as with B-QBC, why should maximizing the predictive variance of this mixture model solve the mode-selection problem and tradeoff between bias and variance? Furthermore, how do the authors expect B-QBC and QB-MGP to compare qualitatively? Since QB-MGP is equivalent to B-QBC plus a variance term, how do the authors expect this variance term to impact the performance of the acquisition function? Overall, B-QBC and QB-MGP seem to me to be the two fundamental contributions of the paper, and I believe more discussion is needed here to derive and motivate their use and strongly connect them to resolving bias-variance\/signal-noise\/mode selection tradeoffs.\n\n*** Section 5 ***\n\nWhile I appreciate the multitude of simulators tested in the experiments, I am not convinced by the experimental results. The performance curves seem to have high variance, and I am not convinced by the summary statistics and takeaways presented. It is not at all clear to me from Figure 4-5 and Tables 2-3 that “B-QBC outperforms the benchmark functions, whereas QB-MGP is the most robust acquisition function and achieves the best accuracy with the fewest iterations.” \n\nSpecifically, analyzing performance at a single iteration number based on a converged reference curve only captures a small part of the overall picture. I believe it would be better to examine summary statistics that better capture the overall performance of each method, such as evaluating multiple iteration numbers or looking at summary statistics such as AUC. The authors make a comment in section 5.3 attempting to justify this single iteration point evaluation, but I did not find it convincing. I am also unsure if the likelihood ratio and error quotients in Table 2 provides an adequate summary of the data. When using the raw results in Table 3, any sort of benefits for B-QBC and QB-MGP in Figure 5 become much less clear to me when looking at raw data instead of quotients. Can the authors comment about this choice of presenting summary statistics in terms of relative performance rather than raw values? Regardless, given the not insignificant error bars, I would be more convinced by these results if they were accompanied by statistical testing against either the best performing method or random sampling (see other active learning meta-analyses such as “A benchmark and comparison of active learning for logistic regression”, Yang and Loog 2018).\n\nIn Figure 4, it seems difficult to take away anything very useful from these experiments, due to the overlapping error bars in each trial and the fact that in some experiments and methods (including QB-MGP and B-QBC) the error is in fact increasing. It seems that the performance differences can be made more clear by plotting error bars for summary statistics (e.g., standard error or confidence intervals) and increasing the number of trials beyond only 10. I do not look at Figure 4 and have confidence that I should use QB-MGP and B-QBC over the other methods. In my opinion, the takeaways stated in the text are overstated based on these curves, such as QB-MGP being the “best choice” from the Sine RMSE plot, when it seems to be that multiple methods tie QB-MGP in performance, or that B-QBC could even be considered better than the other methods, given the overlapping error bars. Furthermore, there are analytical takeaways that to me seem vague and unsupported, such as “This agrees with our expectation that QB-MGP seems to be more robust than B-QBC to different types of noise.” Why is this an expectation? Statements such as “QB-MGP is achieving the highest RMSE due to favoring to capture the small region with a non-linear signal compared to the vast linear region” or “Looking at all the active learning iterations, the GP fitted with MAP seems to give the best trade-off between the NLML and RMSE, indicating that the regular GP with ALM is the best for smooth problems” are in my opinion speculative takeaways that seem unsupported. Could QB-MGP favoring the non-linear portions be shown empirically, for instance?\n\nAlthough it’s possible that I missed these details in my reading (although I went back again to check), I have some reproducibility concerns. It is unclear how “convergence” is calculated for selecting each plot reference as well as the examined iteration number. How exactly are NLML and RMSE calculated, do they utilize the full posterior, and which data are they calculated with respect to --- the sampled data points, or a held-out set of randomly sampled data? Are the distributions in Figure 5 at the simulator level, or is all data pooled together from all simulators? In Table 2, if different trials' references converged at different times, how was a single iteration value selected? Low-level details such as these are important and seem to be missing (or should at least be included in an appendix), which prevents a full understanding of the experimental results.\n\nFurthermore, I believe additional experiments should be run to support the main claims made in the paper. A major claim is that the full posterior is multi-modal, motivating the proposed active learning experiments. I think an experiment that shows this empirically through some metric would strengthen this major claim. I also think that additional experiments are needed to characterize the performance of the proposed schemes beyond performance alone. Specifically, my reading of the paper is that the proposed methods are designed to select the correct full posterior mode as quickly as possible. It would be useful to show during trials of B-QBC and\/or QB-MGP how a single (correct) mode of the full posterior emerges during MCMC sampling, and the others are suppressed (and possibly comparing this metric against baseline methods).\n\nIn general, I did not find myself convinced by Section 5.3 and found it lacking. It discusses two important details --- why a single iteration slice is sufficient for performance analysis, and where specifically in the acquisition and model evaluation pipeline the full posterior was used rather than the hyperparameter MAP (and why this choice was made for every step) --- but I found the first discussion unconvincing and the second discussion a bit  confusing. Specifically, I found this important sentence confusing “However, since we focus on benchmarking the acquisition functions and not the models, we believe that using the mode is more accurate when comparing it to the regular GP since we only change the fitting procedure.”\n\n######################################\n\nOther points *not* factoring into decision, but serving as feedback for the authors:\n\nIt has been pointed out before (Settles, B. (2012). Active learning: Synthesis lectures on artificial intelligence and machine learning. Long Island, NY: Morgan &  Clay Pool. --- Section 3.5) that information gain maximization can be interpreted as a type of query by committee, where KL divergence on the label is used as a notion of disagreement. Specifically, if the BALD acquisition function is equivalently written as $\\mathbb{E}_{\\theta} [\\mathrm{KL}(p(Y \\mid \\theta) \\Vert p(Y))]$, then this is comparable to B-QBC, which uses a mean discrepancy instead of a KL-divergence. I think this is an interesting connection that would strengthen the work in terms of why B-QBC might perform better than BALD. What is mean discrepancy doing well that KL divergence isn't?\n\nTo me, the use of \"GMM\" seems unusual here to describe a mixture of Gaussian Processes. I checked the literature cited by the authors, and I did not see “Gaussian Mixture Model” or GMM being used as the authors do here to describe a mixture of Gaussian Processes (as opposed to the classical GMM notion of a mixture of multivariate Gaussians in a vector space). Personally, I think using the phrase \"GMM\" runs the risk of confusing the model with a classical GMM framework (as opposed to a Gaussian Process). However, this may be a matter of personal opinion.\n\nThe first paragraph of Section 5 seems out of place to me. It discusses important points, but I think Section 5 should start with a more general description of the experiments instead of just the Sine simulator. Also, I think the experiments could be strengthened by comparison against random (passive) sampling.\n\nMinor points:\n- in the abstract, Query by Mixture Gaussian Processes -> Query by Mixture *of* Gaussian Processes\n- the sentence “The literature suggests handling this problem with clever initializations...either always initializing…” seems redundant to me\n- the location of Gramacy2d and Motorcycle should probably be switched in Figure 4 since the text seems to follow a row-first description of Figure 4\n- I think the right subplot of Figure 5 should show a zoomed-in region to better visualize the methods besides BALD\n- Personally, I don’t think the future work paragraph adds much to the paper, and I don’t understand what this sentence proposes: “Eventually, our ultimate goal is to provide practitioners with an auxiliary tool to map the simulators’ output behaviors in a more efficient manner.”\n","sentences":[{"sentence_type":"2","sentence":"While this paper presents some interesting ideas, overall I feel that certain major elements need to be significantly improved before it is ready for publication.","rephrased":"This paper presents some interesting ideas, but there are major elements that could benefit from further development to fully meet publication standards."},{"sentence_type":"2","sentence":"Instead, I found the topics in the introduction only very loosely coupled: specifically, I think the connections between the predictor vs guide, bias vs variance, and signal vs noise in GPs need to be strengthened and more direct arguments made.","rephrased":"The introduction could benefit from a tighter coupling of the topics, particularly by strengthening the connections between the predictor vs guide, bias vs variance, and signal vs noise in GPs, and by providing more direct arguments."},{"sentence_type":"2","sentence":"While Figure 1-2 were interesting, I did not find myself convinced that the bimodal behavior in Figure 2 is a general phenomenon and found myself unsure how it connected to bias and variance.","rephrased":"Although Figures 1 and 2 are interesting, it would be helpful to clarify how the bimodal behavior in Figure 2 is representative of a general phenomenon and how it relates to bias and variance."},{"sentence_type":"2","sentence":"Overall, after reading the introduction I found myself unconvinced about the strong points presented in the abstract.","rephrased":"After reading the introduction, I suggest providing additional evidence or explanations to support the strong points presented in the abstract."},{"sentence_type":"2","sentence":"In Section 4, B-QBC seems reasonable, but I was not convinced that it somehow addressed the key bias-variance tradeoff and\/or mode selection problem in GP active learning described earlier in the paper.","rephrased":"In Section 4, while B-QBC appears to be a reasonable approach, it would be beneficial to more explicitly demonstrate how it addresses the key bias-variance tradeoff and mode selection problem in GP active learning as described earlier in the paper."},{"sentence_type":"2","sentence":"I do not look at Figure 4 and have confidence that I should use QB-MGP and B-QBC over the other methods.","rephrased":"Figure 4 could be improved to more clearly demonstrate the advantages of using QB-MGP and B-QBC over other methods."},{"sentence_type":"2","sentence":"In my opinion, the takeaways stated in the text are overstated based on these curves, such as QB-MGP being the \\","rephrased":"The conclusions drawn in the text may benefit from a more cautious interpretation of the data presented in the curves, particularly regarding the performance of QB-MGP."},{"sentence_type":"2","sentence":"Furthermore, there are analytical takeaways that to me seem vague and unsupported, such as \\","rephrased":"Some analytical takeaways could be further substantiated with additional evidence or clarification, for example, the statements regarding the robustness of QB-MGP compared to B-QBC."},{"sentence_type":"2","sentence":"In general, I did not find myself convinced by Section 5.3 and found it lacking.","rephrased":"Section 5.3 would benefit from additional details and clarification to strengthen the arguments presented."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[574,736,"Not concerning"],[1207,1266,"Missed Maybe"],[1610,1855,"Not concerning"],[2407,2598,"Not concerning"],[2826,2943,"Confirmed"],[2944,3147,"Missed Maybe"],[3622,3824,"Not concerning"],[6867,7116,"Missed by Model"],[7327,7431,"Not concerning"],[7755,7956,"Missed by Model"],[10216,10296,"Confirmed"]],"Comments":[]}
{"id":"Hk4ciAteG","text":"This paper proposes a variant of neural architecture search.  It uses established work on network morphisms as a basis for defining a search space.  Experiments search for effective CNN architectures for the CIFAR image classification task.\n\nPositives:\n\n(1) The approach is straightforward to implement and trains networks in a reasonable amount of time.\n\n(2) An advantage over prior work, this approach integrates architectural evolution with the training procedure.  Networks are incrementally grown; child networks are initialized with learned parameters from their parents.  This eliminates the need to restart training when making an architectural change, and drastically speeds the search.\n\nNegatives:\n\n(1) The state-of-the-art CNN architectures are not mysterious or difficult to find, despite the paper's characterization of them being so.  Indeed, ResNet and DenseNet designs are both guided by extremely simple principles: stack a series of convolutional layers, pool occasionally, and use some form of skip-connection throughout.  The need for architectural search is unclear.\n\n(2) The proposed search space is boring.  As described in Section 4, the possibly evolutionary changes are limited to deepening the network, widening the network, and adding a skip connection.  But these are precisely the design aspects that have been well-explored by human trial and error and for which good rules of thumb are already available.\n\n(3) As a consequence of (1) and (2), the result is essentially rigged.  Since only depth, width, and skip connections are considered, the end network must end up looking like a ResNet or DenseNet, but with some connections pruned.  There is no way to discover a network outside of the principled design space articulated in point (1) above.  Indeed, the discovered network diagrams (Figures 4 and 5) fall in this space.\n\n(4) Performance is worse than the best hand-designed baselines.  One would hope that, even if the search space is limited, the discovered networks might be more efficient or higher performing in comparison to the human designs which fall within that same space.  However, the results in Tables 3 and 4 show this not to be the case.  The best human designs outperform the evolved networks.  Moreover, the evolved networks are woefully inefficient in terms of parameter count.\n\nTogether, these negatives imply the proposed approach is not yet at the point of being useful in practice.  I think further work is required (perhaps expanding the search space) to resolve the current limitations of automated architecture search.\n\nMisc:\n\nTables 3 and 4 would be easier to parse if resources were simply reported in terms of total GPU hours.","sentences":[{"sentence_type":"2","sentence":"The state-of-the-art CNN architectures are not mysterious or difficult to find, despite the paper's characterization of them being so.","rephrased":"While the paper suggests that state-of-the-art CNN architectures are challenging to identify, it may be more accurate to say that their design principles, such as those in ResNet and DenseNet, are becoming increasingly well-understood."},{"sentence_type":"3","sentence":"The proposed search space is boring.","rephrased":"The proposed search space could benefit from more diversity to explore beyond the well-established design modifications like deepening and widening the network, or adding skip connections."},{"sentence_type":"3","sentence":"As a consequence of (1) and (2), the result is essentially rigged.","rephrased":"The limitations outlined in points (1) and (2) may lead to a search process that converges on familiar architectures, such as ResNet or DenseNet, which could restrict the potential for novel discoveries."},{"sentence_type":"2","sentence":"Moreover, the evolved networks are woefully inefficient in terms of parameter count.","rephrased":"Additionally, there is room for improvement in the efficiency of the evolved networks, particularly regarding the number of parameters used."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[713,847,"Confirmed"],[1093,1129,"Confirmed"],[1442,1668,"Confirmed"],[2249,2333,"Not concerning"]],"Comments":[]}
{"id":"a_OBmY9V7vb","text":"Strengths\n1) This paper addresses an important problem.  The monotonicity constraint is often overlooked by the ML community, but it does play an important role in many real-world applications. Therefore, an improved method to encourage monotonicity can have sizable impact on these applications, and help ML practitioners better impose their priors on the hypothesis space.\n2) Writing is clear.\n\nWeaknesses\n1) The contribution is rather incremental.\n2) The authors didn't provide adequate explanations for certain important details in the paper itself.  For example, the authors propose to create synthetic examples by interpolating both features and vectors, but in the experiment involving binary classification data set, it's not clear how to interpolate the labels here. Did the authors simply interpolate between 0 and 1?  Why we need to use both interpolated examples as well as random examples (not clear from the paper)?","sentences":[{"sentence_type":"2","sentence":"The contribution is rather incremental.","rephrased":"The contribution builds upon existing work and could be further elaborated to highlight its novelty."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[411,450,"Confirmed"],[454,553,"Missed by Model"]],"Comments":[]}
{"id":"ryxgDPLFF4","text":"The papers propose a model in which some of the latent variables of an unsupervised model are associated with a small number of user defined labels. This increases the discriminativity of the model and enable it to separate factors of variation associated with those labels. \nThe introduction of the new term in the objective essentially places the model withing the domain of supervised models (or at least semisupervised). However, all the numerical test appear to be against unsupervised models. Improvement by those standards seems trivial to me. I would urge the authors to include comparisons against other semisupervised methods that work on similar numbers of labeled data","sentences":[{"sentence_type":"2","sentence":"Improvement by those standards seems trivial to me.","rephrased":"I would suggest that the improvement, when compared to unsupervised models, could be more clearly contextualized or benchmarked against semisupervised models to highlight its significance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[499,550,"Confirmed"]],"Comments":[]}
{"id":"Bye3mL6v2V","text":"This paper deals with the problem of formalising contrastive explanations (i.e., why did you apply action A rather than B?) into PDDL2.1.  As a characteristics, the approach proposed is  domain and planner independent, focusing on temporal planning.  The problem is definitively interesting to the workshop and to the XAIP in general.\n\nThe authors propose a set of questions (1..7) that require contrastive explanations. Then, for each question they show how they can be encoded into PDDL2.1 to allow for a contrastive explanations.\nThe paper is well written and motivated. The contribution is clear and the approach presented is sound, though at preliminary stage, as the authors declared.\n\nI think that using a list of questions is a human-like approach towards explanations in AI Planning, as they allow users understanding the reasons behind the planner's decision through hypotheses, as a human would do. I think this approach - properly extended - is successful. The paper is still at preliminary stage and I think it would benefit from a discussion and presentation at the XAIP workshop.\n\nThe user-interaction part to ask questions to users might be beneficial from some recent NLP algorithms, such as word-embedding. It allows one to represent word meaning into a N-dimensional vector space. Words with similar meaning are mapped to a similar position in the vector space. For example, “powerful” and “strong” are close to each other, whereas “powerful” and “Paris” are farther away. The word vector differences also carry meaning. For example, the word vectors can be used to answer analogy questions using simple vector algebra: “King” - “man” + “woman” ≈ “Queen” (Mikolov, Yih, and Zweig, 2013). This knowledge also grows over time, making the system able to \"understand\" different meaning of sentences on the base of the lexicon used. Ideally, the user might write a question in a natural language, and word-embeddings might be used to \"suggest\" one of the contrastive questions to be applied.\n","sentences":[{"sentence_type":"1","sentence":"The paper is still at preliminary stage and I think it would benefit from a discussion and presentation at the XAIP workshop.","rephrased":"While the paper presents promising initial results, further development and a discussion at the XAIP workshop could enhance its maturity and impact."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[969,1094,"Not concerning"]],"Comments":[]}
{"id":"SylPx5jiYS","text":"This paper investigates the well-studied problem of solving satisfiability problems using deep learning approaches. In this setting, the authors propose a neural architecture inspired by message passing operations in deep probabilistic graphical models. Namely, the architecture takes as input a CNF formula represented as a factor graph, and returns as output a set of soft assignments for the variable nodes in the graph. The internal layers of the architecture consist of propagation, decimation and prediction steps. Notably, decimation operations take an important role in learning non-greedy search strategies. Besides PDP operations, the architecture incorporates parallelization and batch replication techniques. The learning model is trained in a non-supervised way, using a cumulative (discounted) log-likelihood loss that penalizes the non-satisfying assignments returned by the algorithm.  \n\nOverall, the paper is relatively well-written and well-positioned with respect to related work. However, it is difficult to accept the paper in its current state: as explained below, it is difficult to understand how the PDP architecture effectively solves SAT problems, and experiments are not really conclusive. \n\nAlthough the idea of using general message-passing techniques for learning to solve SAT problems is relevant, the overall architecture left me somewhat confused. In the SAT problem, we have a CNF formula, say $F$, and the goal is to predict whether $F$ is satisfiable or not. In the former case, the solver is required to additionally supply a model of $F$, that is, an assignment of variables to values satisfying $F$. However, unless I missed something, the PDP architecture returns as output a set of $T$ “soft assignments” for each input SAT instance, which leads to two major concerns: \n* There is no final decision (SAT\/UNSAT), so how can we predict the satisfiability of an instance $F$ with just a set of $T$ assignments? I guess that the PDP model will predict SAT (resp. UNSAT) if the resulting loss is small (resp. large) enough, but this is very unclear.\n* Furthermore, the output set consists of “soft” assignments, as defined by (4). But a solver should return a \"discrete\" assignment mapping variables to values in $\\{0,1\\}$. So, how can we convert soft assignments to discrete ones? Are the authors using a rounding method? \n\nThe experimental results are a bit confusing too. First of all, which generator has been used for random instances ($4$-SAT) and pseudo-industrial instances? For the sake of reproducibility, this should be mentioned in the revised version of the paper. Furthermore, it seems that at first sight, PDP is competitive with Glucose, as illustrated in the left part of Figure 1. Notably, the performance of Glucose degrades as the ratio $M\/N$ grows. But this is not surprising because its timeout is set to 3s. However, the right part of Figure 1 is telling another story: apparently, Glucose can solve all instances in less than 10s. So, for the sake of fairness, it would be legitimate to report curves (left part) using 10s per instance: this would highlight the behavior of PDP with respect to modern SAT solvers on random instances using reasonable timeouts for the UNSAT part. The idea of making experiments on pseudo-industrial instances is interesting, but the PDP algorithm trained on those instances (i.e. PDP-modular) is rapidly degrading as the ratio $M\/N$ increases. In fact, the difference between PDP-4SAT and PDP-modular is not statistically significant for UNSAT instances. Finally, Glucose is clearly dominating PDP on pseudo-industrial instances, as it can solve all instances with just a timeout of 2s per instance. ","sentences":[{"sentence_type":"2","sentence":"However, it is difficult to accept the paper in its current state: as explained below, it is difficult to understand how the PDP architecture effectively solves SAT problems, and experiments are not really conclusive.","rephrased":"While the paper presents interesting ideas, the current presentation and experimental results do not make it clear how the PDP architecture effectively solves SAT problems. Additional clarity and more conclusive experiments would strengthen the paper."},{"sentence_type":"1","sentence":"The overall architecture left me somewhat confused.","rephrased":"The overall architecture could benefit from a clearer explanation to enhance understanding."},{"sentence_type":"1","sentence":"The experimental results are a bit confusing too.","rephrased":"The presentation of the experimental results could be improved for better clarity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1000,1217,"Confirmed"],[2061,2086,"Missed by Model"],[2362,2411,"Confirmed"]],"Comments":[]}
{"id":"_RNys7yqwu","text":"This paper uses a multi-modal, publicly available dataset of 235 patients to detect intervertebral disc coordinates. The paper is well-written and addresses preprocessing and validation metrics. However, additional implementation details could have been included. \n1) How was the receptive field size (r) selected? 2) It was not made clear that the network processes sub-images of size r in order to count\/detect the discs in the entire image. 3) It is unclear how many patches are extracted within the each image.\n\nWhy do the authors think that redundant counting produced better detection?\n\nThe detection points on Fig 1. and Fig 2.A. are too small to determine the size of the predicted Gaussian functions.\n \n ","sentences":[{"sentence_type":"1","sentence":"Why do the authors think that redundant counting produced better detection?","rephrased":"Could the authors elaborate on the rationale behind the observation that redundant counting produced better detection?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[318,443,"Missed by Model"],[447,514,"Missed by Model"],[516,591,"Confirmed"],[593,708,"Missed Maybe"]],"Comments":[]}
{"id":"ByxOfQOJcr","text":"This paper proposes an architecture for generating images with objects manipulated according to user-specified or conditional instructions. I find the domain very interesting and do believe that tasks like these are critical for learning human-like cognitive capabilities.\n\nThis paper is also very clear and easy to follow and understand what the authors have done.\n\nBut I do feel like this work could use more polishing. There are four components that are used in this work, CVAE, LSTM, RN, and GANs. It seems that those components are all taken straight out of the shelf and combined. It would be interesting to see what subtle changes were important in a combined system to further increase performance.\nFor example, why is RN only before decoding, could RN possibly help the decoder as well?\n\nWhat are some of the most frequent failure cases?\nThe qualitative results look reasonable, and I’m quite surprised that only 10K images were used for training. Improvements in which areas would lead to perfect results?\n\nWould better performance be obtained if every module were to be trained separately first, rather than the proposed end-to-end approach?\n","sentences":[{"sentence_type":"1","sentence":"But I do feel like this work could use more polishing.","rephrased":"However, I believe there is potential for further refinement in this work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[367,421,"Not concerning"]],"Comments":[]}
{"id":"pLG4_cx9Ib7","text":"Summary:\n- This paper proposes to consider the importance of each parameter in the post-training quantization of weights. The authors propose to use weight magnitude as the importance indicator and to minimize the weighted distance between the full-precision weights and quantized weights. Experiments are performed on various NLP models and tasks.\n\nStrengths: \n- The paper is structured clearly and the proposed method is simple.\n\nWeaknesses: \n1. It is not clear to me why the change in the loss in (7) and (8) is necessarily related to the magnitude of the weights. From (8), the loss change \\delta L  is only related to the hessian, and each weight's perturbation, but not the weight's magnitude.\n\n2.  The second concern comes from the novelty of the proposed method. Indeed, loss-aware (or importance-aware as in this paper) quantization which considers the quantization effect of each parameter to the loss has already been proposed several years ago in [1,2]. In [1,2], they also approximate the loss using the second-order Taylor expansion like in equation (7) in this submission. Moreover, the proposed importance-aware quantization solution in equation (5)  is exactly the same as equation (8) in [1], except that their importance is derived from the diagonal hessian instead of weight magnitude (which is not quite reasonable, refer to the first point).\n\n3. One other post-training quantization method GOBO in [3], which also uses codes and codebooks to quantize language models, is also not compared. From their reported results, under the same number of bits, GOBO has higher accuracy than the proposed method. E.g., GOBO has 83.76% accuracy for the 3-bit quantization on MNLI  while the proposed method only has 82.9%.\n\n4. From Table 2, there is no winning configuration of (E,C,P) that works well on all studied models and tasks. How to determine these hyperparameters for  new tasks empirically? Tuning these parameters separately for each task can be inefficient.\n\nReference:\n\n[1] Hou et al. \"Loss-aware binarization of deep networks.\" International Conference on Learning Representations. 2017.\n\n[2] Hou et al. \"Loss-aware weight quantization of deep networks.\" International Conference on Learning Representations. 2017.\n\n[3] Zadeh, Ali Hadi, and Andreas Moshovos. \"GOBO: Quantizing Attention-Based NLP Models for Low Latency and Energy Efficient Inference.\" arXiv:2005.03842, 2020.","sentences":[{"sentence_type":"2","sentence":"which is not quite reasonable, refer to the first point","rephrased":"which raises questions when compared to the first point"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1306,1361,"Not concerning"]],"Comments":[]}
{"id":"nawgHD3xIG1","text":"The authors present build on the recurrent state space model by Haffner et al. (2019) to include a hierarchy of latent spaces. The idea is that the lower levels model short-term changes while the higher levels of the hierarchy model longer temporal dependencies.\n\nPros:\n1. The paper is largely well-written and easy to follow.\n2. The experiments do show that the proposed method is able to capture the long-term trends better than the chosen baselines for the chosen datasets. \n3. Experiments showing different amounts of information present at different levels of the latent space are interesting and show that desired hierarchical structure in the latent space is achieved.\n\nCons:\n1. In light of the paper \"Improved conditional VRNNs for video prediction\" by Castrejon et al., I do not believe there is enough novelty in this paper in terms of the latent space architecture, as this paper also applies a hierarchical latent space model for video prediction. The main contributions are in the analysis of the hierarchical architectures using information-theoretic measures for three datasets, which I believe are not sufficient for accepting this paper. The authors should clarify the main differences in the proposed method and the paper by Castrejon et al.\n\n2. Related to the above point, the datasets for the experiments should be stronger as this paper's novelty is mainly empirical. The KTH action dataset is the closest to a real-world dataset, but is still simplistic with just one moving object and a fixed background. The authors should consider experimenting with more challenging datasets. This is necessary to understand the limitations of the proposed method. \n\nUPDATE AFTER AUTHOR RESPONSE:\nI appreciate the authors' response and for clarifying the contributions. However I still feel that the experiments and datasets are too simple and not realistic. I am increasing my rating to reflect this.","sentences":[{"sentence_type":"2","sentence":"I do not believe there is enough novelty in this paper in terms of the latent space architecture, as this paper also applies a hierarchical latent space model for video prediction.","rephrased":"The paper could benefit from a clearer delineation of its novel contributions to the latent space architecture, especially in comparison to existing models such as the hierarchical latent space model for video prediction by Castrejon et al."},{"sentence_type":"2","sentence":"However I still feel that the experiments and datasets are too simple and not realistic.","rephrased":"I would encourage the authors to consider more complex experiments and datasets to further demonstrate the applicability of the proposed method in realistic scenarios."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[779,959,"Not concerning"],[1779,1867,"Not concerning"]],"Comments":[]}
{"id":"hoDS_1yTCt","text":"The paper presents a simple method for continual RL where the task information is not available to the agent. The method combines replay and recurrent mechanisms with a SAC base. The authors find the derived algorithm ‘3RL’ is a strong method across CW10 and MW20.\n\nStrengths:\n- Thorough empirical evaluation and rigorous comparison to the immediate baselines.\n- Interesting investigation in explaining the forward transfer abilities of 3RL\n\nWeaknesses:\n- It is not clear in Algorithm 1 how the buffer D_old is populated.\n- Whilst from the point of view of the RL algorithm, the task information is not included, it appears that task identifiers are implicitly still used to split the replay data. Thus, the algorithm is not truly task agnostic, and it would be useful for the authors to comment on this.\n- It would be useful to explain what the representation is over in Figure 1 (explained later in Section 3.3)\n\nMinor:\n- It is inappropriate to include an identifying repository in a double-blinded review. I would advise the authors link to an anonymous repository in the future.\n- Missing Appendix label for Appendix K on page 8 and Appendix H on page 7.\n","sentences":[{"sentence_type":"2","sentence":"It is inappropriate to include an identifying repository in a double-blinded review.","rephrased":"For future submissions, please ensure that any repository links are anonymized to adhere to the double-blind review process."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[924,1082,"Confirmed"]],"Comments":[]}
{"id":"Sygio3cbcE","text":"This paper presents Molecule Chef, a model that maps between continuous latent codes and bags of readily available reactants. When combined with existing models that predict what products will result from a reaction with the given reactants, this model can be used to propose methods to synthesize new compounds. The continuous latent space is also useful for enabling continuous search for reactions that lead to products with desired properties.\n\nOverall, this is a strong paper, both in terms of motivation and results:\n- The pipeline of first sampling multisets of reactants from Molecule Chef, then using an existing model to predict products, generates 99% valid molecules (molecules known to exist) with a high degree of novelty (molecules not in the training data). This compares favorably with comparable baselines from previous work.\n- It's possible to learn a predictor from latent code directly to some desirable property of the end product, such as QED score. Using this, it is possible to search in the latent space for reactions that lead to products with high QED score. It is shown that gradient-based search (which can only be done in this latent space, and not in the reactants space) is better than a naive random walk. This justifies the use of a continuous latent code, instead of directly generating bags of reactants.\n\nSome questions I had:\n- It would be nice to know how well a model that doesn't have the latent code, and instead directly generates bags of reactants, does in terms of the generation quality metrics in Section 4.1, and the retrosynthesis experiments in 4.3.\n- Section 4.4 was unclear--what are the \"undesirable features\", and why would we expect Molecule Chef to avoid such features?","sentences":[{"sentence_type":"1","sentence":"Section 4.4 was unclear--what are the \"undesirable features\", and why would we expect Molecule Chef to avoid such features?","rephrased":"Could you please clarify what is meant by \"undesirable features\" in Section 4.4, and could you elaborate on how Molecule Chef is designed to avoid such features?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1603,1726,"Not concerning"]],"Comments":[]}
{"id":"Byl9rif-KN","text":"This paper presents a new data set for few shot learning with multiple classes being introduced simultaneously in each example. It also introduces a slight variant on existing few shot architectures first simultaneously learning multiple new classes.\n\nI am unconvinced that the problem of multi-class few shot learning poses a substantially different challenge from single class few shot learning. The cited source, Carey & Bartlett, is a paper entirely about one class few shot learning, so I don't see any evidence that humans, at least, have a distinct method of learning multiple classes simultaneously. The claim, \"It is yet an active area of study to know how human are capable of doing this,\" clearly requires at least one example of active research. While the community would no doubt welcome a new data set for few shot learning, the burden is on the authors to explain why this particular variation on the problem poses a distinct challenge or could be useful to treat separately. \n\nI don't see the significant innovation present in multi-prototype networks. Please contrast them with existing methods for identifying what object in a scene might be referred to with a new label, without trying to simultaneously label multiple objects.\n\n Minor issues:\n\nPlease don't cite an entire textbook (Goodfellow) as a source for a specific claim about human cognition. \n\nThis work could benefit greatly from a confident proofreader. Pervasive English grammar and spelling errors make the paper a lot less readable.","sentences":[{"sentence_type":"2","sentence":"This work could benefit greatly from a confident proofreader. Pervasive English grammar and spelling errors make the paper a lot less readable.","rephrased":"The manuscript would benefit from thorough proofreading to correct numerous grammar and spelling issues, which would enhance its readability."},{"sentence_type":"1","sentence":"Please don't cite an entire textbook (Goodfellow) as a source for a specific claim about human cognition.","rephrased":"It would be helpful to provide a more specific reference from the textbook (Goodfellow) to support the claim about human cognition."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[993,1068,"Missed by Model"],[1264,1369,"Confirmed"],[1372,1515,"Maybe"]],"Comments":[]}
{"id":"BylO8mDPKN","text":"This short paper presents a framework to train a neural Name Entity Recognition (NNER) model, from partially labelled data.\nThe idea is to first train a NNER model on a small but fully labelled dataset (Ds), and use this model to labelled another, unlabelled, dataset (Dc). A reference set is then used to find mentions of entities in Dc. Finally, both Ds and Dc are combined to retrain the NNER model, which is then used to refine the labeling of Dc.While the second step is about data augmentation, the third and last step is about training the NNER model iteratively. Both steps are repeated K times.\nHowever, it is not explicitly mentioned whether the NNER model is retrained from scratch, or if it is fine-tuned.\nThe authors should give information regarding the setup of their model since they obviously change it from (Genthial, 2017).\nWhile this part is of the paper  was easy to follow, I found the section about the experiments and the discussion of the results much more confusing. The authors report results from 9 experiments in a single table, with a confusing naming, e.g.:\n- what does \"+CRF\" mean? Does it refer to the architecture from (Genthial, 2017) with the CRF layer replaced with a softmax layer?\n- the NNER-3%, why 3% and how did you select this subset of the Bio-ID dataset?\n- Experiments 7 to 9, C1 and C2 are not explained, just mentioned in the caption.\nOverall, Section 4 is really dense and hard to follow. Instead, the authors should consider splitting the explanation for each of their experiments in individual paragraphs.","sentences":[{"sentence_type":"1","sentence":"While this part is of the paper  was easy to follow, I found the section about the experiments and the discussion of the results much more confusing.","rephrased":"While I found this part of the paper clear, the section on the experiments and discussion of results could benefit from additional clarity."},{"sentence_type":"2","sentence":"Overall, Section 4 is really dense and hard to follow.","rephrased":"Overall, Section 4 could be made more accessible by breaking down the information into individual paragraphs for each experiment."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[843,992,"Maybe"],[1058,1081,"Missed by Model"],[1302,1381,"Missed by Model"],[1382,1555,"Confirmed"]],"Comments":[]}
{"id":"SJg5feZqnQ","text":"The paper aims at a better understanding of the positive impacts of Batch Normalisation (BN) on network generalisation (mainly) and  convergence of learning. First, the authors propose a novel interpretation of the BN re-parametrisation. They show that an affine transform of the variables with their local variance (scale) and mean (shift) can be interpreted as a decomposition of the gradient of the objective function into a regressor assuming that the gradient is parallel to the variables (up to a shift) and the residual part which is the gradient w.r.t. to the new variables. In the second part of the paper, authors review various normalisation proposals (differing mainly in the subset of variables over which the normalisation statistics is computed) as well as the known empirical findings about the dependence of BN on the batch size. The paper presents an experiment that combines two normalisation variants. A further experiment strives at regularising BN for small batch sizes.\n\nUnfortunately, it remains unclear what questions precisely the authors answer in the second part of the paper and, what is more important, how they are related to the novel interpretation of BN presented in the first part. This interpretation holds for any function and can be possibly seen as a gradient pre-conditioning. However, the authors do not \"extend\" it towards the gradients w.r.t. the network parameters and do not consider the specifics of the learning objectives (a sum of functions, each one depending on one training example only). The main presented experiment combines layer normalisation with standard batch normalisation for a convolutional network. The first one normalises using the statistics over channel and spatial dimensions, whereas the second one uses the statics over the batch and spatial dimensions. The improvements are rather marginal, but, what is more important, the authors do not explain how and why this proposal follows from their new interpretation of BN.\n\nOverall, in my view, this paper is premature and not appropriate for publishing at ICLR in its present form.\n","sentences":[{"sentence_type":"2","sentence":"Unfortunately, it remains unclear what questions precisely the authors answer in the second part of the paper and, what is more important, how they are related to the novel interpretation of BN presented in the first part.","rephrased":"It would be helpful if the authors could clarify the specific questions addressed in the second part of the paper and how these relate to the novel interpretation of BN presented in the first part."},{"sentence_type":"3","sentence":"Overall, in my view, this paper is premature and not appropriate for publishing at ICLR in its present form.","rephrased":"Overall, I believe that further development and clarification might be needed before this paper is ready for publication at ICLR."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[994,1216,"Confirmed"],[1317,1540,"Missed Maybe"],[1825,1989,"Missed by Model"],[1991,2099,"Confirmed"]],"Comments":[]}
{"id":"rkZd9y9xz","text":"The paper proposes a novel way of compressing gradient updates for distributed SGD, in order to speed up overall execution. While the technique is novel as far as I know (eq. (1) in particular), many details in the paper are poorly explained (I am unable to understand) and experimental results do not demonstrate that the problem targeted is actually alleviated.\n\nMore detailed remarks:\n1: Motivating with ImageNet taking over a week to train seems misplaced when we have papers claiming to train ImageNet in 1 hour, 24 mins, 15 mins...\n4.1: Lemma 4.1 seems like you want B > 1, or clarify definition of V_B.\n4.2: This section is not fully comprehensible to me.\n- It seems you are confusingly overloading the term gradient and words derived (also in other parts or the paper). What is \"maximum value of gradients in a matrix\"? Make sure to use something else, when talking about individual elements of a vector (which is constructed as an average of gradients), etc.\n- Rounding: do you use deterministic or random rounding? Do you then again store the inaccuracy?\n- I don't understand definition of d. It seems you subtract logarithm of a gradient from a scalar.\n- In total, I really don't know what is the object that actually gets communicated, and consequently when you remark that this can be combined with QSGD and the more below it, I don't understand it. This section has to be thoroughly explained, perhaps with some illustrative examples.\n4.3: allgatherv remark: does that mean that this approach would not scale well to higher number of workers?\n4.4: Remarks about quantization and mantissa manipulation are not clear to me again, or what is the point in doing so. Possible because the problems above.\n5: I think this section is not too useful unless you can accompany it with actual efficient implementation and contrast the practical performance. \n6: Given that I don't understand how you compress the information being communicated, it is hard to believe the utility of the method. The objective was to speed up training time because communication is bottleneck. If you provide 12,000x compression, is it any more practically useful than providing 120x compression? What would be the difference in runtime? Such questions are never discussed. Further, if in the implementation you discuss masking mantissa, I have serious concern about whether the compression protocol is feasible to implement efficiently, without writing some extremely low-level code. I think the soundness of work addressing this particular problem is damaged if not implemented properly (compared to other kinds of works in current ML related research). Therefore I highly recommend including proper time comparison with a baseline in the future.\nFurther, I don't understand 2 things about the Tables. a) how do you combine the proposed method with Momentum in SGD? This is not discussed as far as I can see. b) What is \"QSGD, 2bit\" If I remember QSGD protocol correctly, there's no natural mapping of 2bit to its parameters.","sentences":[{"sentence_type":"2","sentence":"many details in the paper are poorly explained (I am unable to understand)","rephrased":"Some details in the paper could benefit from further clarification to enhance understanding."},{"sentence_type":"2","sentence":"I really don't know what is the object that actually gets communicated","rephrased":"It would be helpful if the paper could more clearly define the object that is being communicated."},{"sentence_type":"3","sentence":"it is hard to believe the utility of the method","rephrased":"The paper would benefit from more evidence to support the utility of the method."},{"sentence_type":"2","sentence":"I have serious concern about whether the compression protocol is feasible to implement efficiently, without writing some extremely low-level code.","rephrased":"It would be valuable to discuss the feasibility of implementing the compression protocol efficiently, possibly avoiding the need for extremely low-level code."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[195,269,"Maybe"],[610,662,"Missed Maybe"],[665,777,"Missed by Model"],[1067,1102,"Missed Maybe"],[1166,1448,"Confirmed"],[1947,1994,"Not concerning"],[2221,2256,"Missed by Model"],[2321,2467,"Not concerning"]],"Comments":[]}
{"id":"E0a6xLrNSgb","text":"summary:\nThis paper proposes Divide-and-Conquer Monte Carlo Tree Search (DC-MCTS), a planning algorithm for goal-directed decision-making problems, which makes a plan of the trajectory via recursive hierarchical partitioning. DC-MCTS assumes a (suboptimal) goal-directed low-level policy and its oracle value function. Then, it formulates the given planning problem as finding a sequence of sub-goal states and applies the divide-and-conquer strategy, i.e. split the original task into two sub-tasks (defined as initial state and goal state) and recursively solve them. Unlike the standard MCTS, the decision making of DC-MCTS operates not on the action space but on the state space of the problem, and the decision is made non-sequential way. Experimental results show that DC-MCTS outperforms the MCTS baseline that expands only the right sub-problem.\n\n\n\npros:\n- It is interesting to perform planning for sequential-decision making problems in a non-sequential manner via a divide-and-conquer approach.\n\n\ncons:\n- The assumption that goal-conditioned policy and its value is required seems to be too strong, which may limit the generality of the proposed method.\n\n- In the experiments, the baseline algorithm seems to be weak. For example, it would have been nice if it could be compared with other recent methods that combine goal-conditioned RL and planning (e.g. [1], [2]) if applicable. Also, PUCT-like planning algorithms that operate in usual action space could also be a good baseline, where the policy prior can also be trained with HER.\n\n\n\ncomments and questions:\n- It seems to be unfair that the training strategy for the heuristics is different for DC-MCTS and the MCTS baseline. It would be great to see the performance of MCTS that uses the same heuristics training strategy as DC-MCTS.\n\n- The DC-MCTS can be seen as treating 'state space' as 'action space', which implies that it has a much larger branching factor than the traditional action-selecting MCTS since the number of states is typically much larger than the number of actions. Then, why should DC-MCTS be preferred over planning algorithms that operate in usual action spaces? It would be great to see a comparison with the PUCT baseline that works in the original action spaces, where the prior policy and value function is trained using HER.\n\n- (page 7) Did the model-free baseline in the initial experiments use HER? or was it trained only with the actually experienced samples?\n\n- In Figure 2, why the solved ratio did not converge to 1? What kind of behavior can we observe qualitatively when the algorithm fails to solve?\n\n- It seems DC-MCTS is relevant to path planning algorithms. Then, for example, could DC-MCTS be compared with the RRT family?\n\n- Above section 3.2: (line 17-18 in TRAVERSE) -> (line 15-16 in TRAVERSE) ?\n\n\n[1] Eysenbach et al., Search on the Replay Buffer: Bridging Planning and Reinforcement Learning, NeurIPS 2019\n[2] Nasiriany et al., Planning with Goal-Conditioned Policies, NeurIPS 2019\n","sentences":[{"sentence_type":"2","sentence":"In the experiments, the baseline algorithm seems to be weak.","rephrased":"In the experiments, it would be beneficial to compare the proposed method with a stronger baseline algorithm to better highlight its strengths."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1167,1227,"Maybe"]],"Comments":[]}
{"id":"Tkxbdf6xkZ","text":"The quality and clarity of the work are good.\nPros:\nMultiple channels of the input images are aggregated in classification.\nThe paper is well organized and well written.\nMulti-view solution achieves better performance on testing data.\nCons:\nThe native channel aggregation is used in this work.\nThe process of \"decon\" is not clearly described.","sentences":[{"sentence_type":"1","sentence":"The native channel aggregation is used in this work.","rephrased":"The use of native channel aggregation could be further developed to enhance the methodology."},{"sentence_type":"1","sentence":"The process of \"decon\" is not clearly described.","rephrased":"The manuscript would benefit from a more detailed description of the \"decon\" process."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[241,293,"Not concerning"],[294,342,"Not concerning"]],"Comments":[]}
{"id":"r1xK9aFAY4","text":"This paper proposes to use Hierarchical VQ-VAE for the purposes of large image generation. The paper is written clearly and well justified. \n\nThe authors extend the originally proposed VQ-VAE model to learn two (top & bottom) level hierarchies of images. The only con of the model is that, post-hoc PixelCNN (or PixelSnail in this paper) needs to be used to learn the prior over discrete codes in order to sample images at generation time.\n\nAlthough authors claim that the model generates diverse & high quality looking it would be great to put some quantitative number on it. Doing with side-by-side samples from BigGAN and Hierarchical VQ-VAE and asking people to rate which models generated samples they prefer. As well as it would be great to see the nearest neighboring training images from the dataset according to closest distance in the embedding space.","sentences":[{"sentence_type":"1","sentence":"The only con of the model is that, post-hoc PixelCNN (or PixelSnail in this paper) needs to be used to learn the prior over discrete codes in order to sample images at generation time.","rephrased":"One area for improvement is the model's reliance on post-hoc PixelCNN (or PixelSnail as used in this paper) to learn the prior over discrete codes for image sampling at generation time."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[255,439,"Not concerning"]],"Comments":[]}
{"id":"ryeT97XIKH","text":"Efficient Inference and Exploration for Reinforcement Learning\n================================================================\n\nThis paper presents a pure-exploration algorithm for reinforcement learning.\nThe approach is based on an assymptotic analysis of the Q-values, and their convergence to central limit distribution.\nUsing this analysis, and under specific assumptions, the algorithm outperforms existing algorithms for exploration.\n\n\nThere are several things to like about this paper:\n- Many existing analyses for efficient exploration are all based around more-of-the-same concentration bounds, which end up being quite messy and un-elegant. This approach based on central limit theorem appears to be more insightful and cleaner and I think there is something nice about that!\n- The proposed algorithm is reasonable, for the setting in question, and the experimental results show that it outperforms benchmark exploration algorithms in this setting.\n- The general structure of the paper, quality of writing and technical rigour appears to be of good standard... although I did not check all technical details carefully. [The paper is 24 pages long and we have many reviews]\n\n\nHowever, there are also some significant places where this paper falls short:\n- The problem setting that the authors consider is really not typical of the \"exploration\" problem in RL... I'm not talking about the fact that this is a \"pure exploration\" algorithm (that's fine), but instead that Assumption 3 is really not a good model for the types of problems that are \"hard\" for exploration in RL! For example, in the RiverSwim problem choosing an exploration policy = 0.8 right is essentially saying that you've already solved the hard part of the problem. Note - I am a little bit confused about the experiments in Tables 3 and 4, here it seems that you start with a pi(1|s)=0.6 which again feels like a cheat...\n- Would it be possible to compare this algorithm in a more like-for-like standard RL setting, perhaps using the standardised bsuite https:\/\/github.com\/deepmind\/bsuite (the \"deep sea\" problems might be of particular interest here.)\n- Alternatively, I can imagine a future version of the paper being more upfront about this deviation from the \"standard\" setting and highlighting that this is a special-type of result quite different from typical exploration in RL.\n- I'm not sure that this sort of paper is well-served by a conference like ICLR... certainly there seems very little of \"learning representation\" in this discussion of Tabular RL. That would sort of be OK if the paper made nods to how these *insights* could carry over the deep learning or at least RL with (linear) function approximation... I don't see much of that.\n\n\nOverall I do think this is an interesting paper, with a novel approach to pure exploration in tabular MDPs under specific assumptions.\nHowever, I'm not sure that this paper is well-suited to ICLR and I have some concerns about whether it really does address the sort of \"exploration\" problem in RL that one might expect.","sentences":[{"sentence_type":"2","sentence":"The problem setting that the authors consider is really not typical of the \"exploration\" problem in RL...","rephrased":"The problem setting considered in the paper seems somewhat atypical for the exploration challenges commonly faced in RL..."},{"sentence_type":"2","sentence":"Note - I am a little bit confused about the experiments in Tables 3 and 4, here it seems that you start with a pi(1|s)=0.6 which again feels like a cheat...","rephrased":"I would appreciate some clarification on the experiments in Tables 3 and 4, particularly regarding the initial policy pi(1|s)=0.6, to better understand how it aligns with the exploration challenges."},{"sentence_type":"2","sentence":"I'm not sure that this sort of paper is well-served by a conference like ICLR...","rephrased":"I would recommend considering whether the focus of this paper aligns with the typical themes and topics of interest at a conference like ICLR."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1266,1371,"Not concerning"],[1744,1900,"Maybe"],[2366,2446,"Not concerning"]],"Comments":[]}
{"id":"2oUn545DV9i","text":"##### Impact:\n\nThe submission claims that other works that investigation compositionality in representation learning do not actually test compositional generalization (\"because all combinations have positive joint probabilities in training\"). However, I disagree that this is the case in prior work; here are some examples of prior works that correctly hold out novel combinations (of underlying components) for test time:\n- https:\/\/openreview.net\/forum?id=HJz05o0qK7\n- http:\/\/papers.nips.cc\/paper\/8825-learning-by-abstraction-the-neural-state-machine\n- https:\/\/arxiv.org\/abs\/1910.09113\n- https:\/\/arxiv.org\/abs\/1912.09713\n- https:\/\/arxiv.org\/abs\/1912.12179\n\nThere are many such examples; they are too numerous to list here.\n\n##### Quality: \n\nThe algorithmic components in Section 4 are not adequately motivated, and the relationship of the algorithm to prior work in compositional representation learning is not discussed.\n\n  The evaluation tasks are extremely simple (overlayed MNIST digits and conjoined word token) and are, as such, far from the complexity of existing work on compositionality (which can deal with, for example, naturalistic image data; see the references above for examples of such works).\n\n##### Clarity:\nThere are many points of ill clarity \/ inconsistencies; for example:\n- \"The main approach for compositional generalization is to learn compositional representations\" Is this really the \"main approach\"? Compositional generalization has been studied in many contexts outside of representation learning (e.g., see https:\/\/semanticsarchive.net\/Archive\/jcyZDc1Y\/Goldberg.Compositionality.RoutledgeHandbook.pdf)\n\n- \"We find that the extraction ability does not transfer naturally, because the extraction network suffers from the divergence of distributions\" Why is it assumed here that there is an extraction network? The \"extraction network\" is referred to several times in the introduction and methods section prior to its introduction\/explanation.\n\n- \"compositional generalization is a type of out-of-distribution (o.o.d.) transferring or generalization, which is also called domain adaptation\" This is inconsistent with the previously discussed definition of compositional generalization i.e., that it is not just domain adaptation. I think the submission could do with a better job of dealing with the distinctions between OOD generalization \/ domain adaptation \/ concept drift.\n\n- \"We propose to obtain compositional representations not from the extractor but reversely from an auxiliary network.\" At this point, neither the \"extractor\" nor the \"auxiliary network\" are defined.\n\n- \"These networks can be some existing networks for compositionality learning\" If so, what are examples of \"existing networks for compositionality learning\"?","sentences":[{"sentence_type":"2","sentence":"The algorithmic components in Section 4 are not adequately motivated, and the relationship of the algorithm to prior work in compositional representation learning is not discussed.","rephrased":"The motivation for the algorithmic components in Section 4 could be strengthened, and a more thorough discussion of the relationship of the algorithm to prior work in compositional representation learning would be beneficial."},{"sentence_type":"2","sentence":"The evaluation tasks are extremely simple (overlayed MNIST digits and conjoined word token) and are, as such, far from the complexity of existing work on compositionality (which can deal with, for example, naturalistic image data; see the references above for examples of such works).","rephrased":"The evaluation tasks, such as overlayed MNIST digits and conjoined word tokens, could be expanded to better match the complexity of existing work on compositionality that deals with more complex data, like naturalistic images (refer to the examples in the references)."},{"sentence_type":"1","sentence":"There are many points of ill clarity \/ inconsistencies; for example:","rephrased":"There are several points that could benefit from improved clarity and consistency; for example:"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[742,922,"Not concerning"],[926,1210,"Not concerning"],[1227,1295,"Not concerning"]],"Comments":[]}
{"id":"EJnWIx-xMA3","text":"The idea of understanding the distributional robustness of distributional RL seems novel and has not been done before. Other than that, the technical contributions and insights are marginal, unclear, and disconnected: \n- Theorem 1 is a marginal extension of (Zhang et al., 2020): they impose a distribution $N$ on a disturbance function $v(s)$\n- Function approximation: It was actually a simple linear model with KL loss as the distributional loss for distributional RL, thus the Lipschipts smoothness there is very straightforward and is not really helpful for the real setting of distributional RL. Moreover, In RL, we often consider bounded reward, so if we consider the expected RL with squared loss function, it still enjoys all the properties of KL loss arising from distributional RL \n- Disconnected results: How were the analysis in Sections 4.2 and 4.3 related to distributional RL? After the sensitivity analysis, the paper did not give any actionable insights from their analysis except that \"the degree of sensitivity is heavily determined by the task\" . This conclusion is not helpful and does not need any such sensitivity analysis. \n- The paper says that QRDQN is more robust than DQN in MountainCar but Figure 3 tells the opposite. Plus, three experiments are of the same nature; thus I think it is not necessary to split it into three subsections to make them sound comprehensive. \n- Section 5.3: \"QRDQN eventually achieves similar performance as DQN, although QRDQN significantly reduces the sample efficiency [in Breakout]\". From my own experience with this experiment, I don't think so. \n\n\n**Minor comments**:\n- Eq (4) can be simplified \n- Section 3.1: \"the state space go to infinity\": unclear \n\n- ","sentences":[{"sentence_type":"2","sentence":"Other than that, the technical contributions and insights are marginal, unclear, and disconnected:","rephrased":"However, I find that the technical contributions and insights could be better connected and more clearly articulated:"},{"sentence_type":"2","sentence":"It was actually a simple linear model with KL loss as the distributional loss for distributional RL, thus the Lipschipts smoothness there is very straightforward and is not really helpful for the real setting of distributional RL.","rephrased":"The use of a simple linear model with KL loss for distributional RL makes the Lipschitz smoothness quite straightforward, which may limit its applicability in more complex settings of distributional RL."},{"sentence_type":"3","sentence":"This conclusion is not helpful and does not need any such sensitivity analysis.","rephrased":"This conclusion could be strengthened with further analysis or by providing more actionable insights."},{"sentence_type":"2","sentence":"From my own experience with this experiment, I don't think so.","rephrased":"Based on my experience, the results might differ, and it would be beneficial to consider additional experimental validation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[119,217,"Maybe"],[370,600,"Not concerning"],[1067,1146,"Not concerning"],[1544,1606,"Not concerning"]],"Comments":[]}
{"id":"BJej8Z_1aX","text":"This paper proposes permutation invariant loss functions which depends on the distance of sets. They motivate this by problems where one wants to detect objects (say stones in an image) where there is no explicit ordering of objects. \n\nPros: The idea sounds interesting and seems like this approach could work well in practice. The authors provide an interesting algorithm which minimizes this loss function in O(N^2) instead of O(N^3). Moreover, the authors also show interesting properties of the Holographic loss, along with some interesting properties of the minima etc.\n\nCons: My major criticism of this work is that, while this seems like an interesting idea, the authors do not really provide extensive results on real world datasets. They consider a simple proof of concept which is based on MNIST images. I do not think this is sufficient. I would have been much more convinced with this paper if I had seen results on Pascal VOC and COCO, since this is the main motivation of their work.","sentences":[{"sentence_type":"2","sentence":"I do not think this is sufficient.","rephrased":"I believe that including results from more complex datasets such as Pascal VOC and COCO could strengthen the paper's findings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[814,848,"Not concerning"]],"Comments":[]}
{"id":"XEHe8JIxjXu","text":"# Strengths\n\n1. I think the motivation behind the paper is strong and is a good fit for ICLR. The idea of being able to take a noisy object detector and learn how to denoise its outputs using a set of sensible priors, without retraining or needing to know the inner workings of the object detector itself, is a simple and attractive one to me. The paper does a good job of explaining this motivation and framing the work.\n2. The METAGEN model proposed in Section 3 is clearly explained and seems like a reasonable approach to impose the various desirable metacognitive priors.\n3. The experiment uses a range of object detectors to show that the proposed METAGEN model can provide benefit to any generic noisy black-box detector.\n4. The work appears to be fully reproducible via code at https:\/\/anonymous.4open.science\/r\/MetaGen-0391\/ \n\n# Weaknesses\n\n1. What motivated the choice of dataset? Given the simplicity of generating data, why not make more complex scenes, and more complex trajectories? For example, are there any object-to-object occlusions in the dataset? Based on the videos and trajectories provided, it seems possibly not? These are interesting because they can easily confuse detectors and are a good motivation for trying to introduce notions of object permanence into models. Does the model hold up in more cluttered environments where real occlusions occur? The approach would be, I think, considerably more compelling if it was shown to work on more than one dataset, particularly without significant tuning of METAGEN hyperparameters between the two. \n\n2. How were the initial three models trained? I wonder if the main difference in improvement by applying METAGEN is more to do with how strong those models were to begin with. It might be interesting to show e.g. what is the relative improvement if all three models are pre-trained to the same level of test performance? It might also be interesting to see what happens as the detection models are given different amounts of pre-training. How does the performance vs training data size curve look for the models with and without METAGAN?\n\n3. The robotics community has been using methods like particle filtering for quite a long time to deal with issues of unreliable sensing \/ perception. Although they do not frame their work in the same metacognitive light, the end effect is somewhat similar - the perception model provides noisy frame-by-frame inputs while a dynamics\/state space model is used to smooth the estimates enforcing notions like object permanence. I'm blanking on a good reference that's closest to this work, but it would be nice to see some effort to make a connection here. \n\n4. There are certain experimental details which I think could be added to improve understanding.  For example, the order of training scene samples clearly has an effect, but how critical is it? What are the effects of change non-maximum suppression \/ not filtering to top five highest-confidence detections per frame? How sensitive are the results to the various hyperparameters involved in the SMC optimization?\nWere there any observed or hypothetical failure modes of this metacognitive approach, where it might actually worsen the outcome? One can imagine it could be vulnerable to certain kinds of cascading error, for example.\n\n5. Sec 5 - for the second comparison model, is this thresholding the softmax classification output of the detector? If so, is the 0.00 fitted threshold value for Faster R-CNN rather surprising? Is it close to being perfect in detection performance?\n\n6. I'm unclear why object label-level Jaccard similarity was chosen as the metric. I understand that it would indirectly capture some notion of spatial accuracy, but could this be done more explicitly? e.g. by also measuring whether projected objects or predicted bounding box centroids lie within the ground truth bounding box?\n\n# Minor points\n\n1. Fig 2 caption chould ideally be self-explanatory without referring to text. Why is plant in blue in top panel? \n\n2. The two different colors in Fig 3C is hard to see - maybe use dashed outlines to make it more obvious?\n\n3. Table 2 Faster R-CNN row has a numerical typo\n\n4. It would be good to see Fig 3 for the other two models for comparison, perhaps in the Appendix if they are not particularly interesting?\n\n5. \"the assumption of spatio-temporal continuity implies that any moving object must exhibit a continuous trajectory... we do not implement this constraint, although doing so is a solved problem\" -- I think calling this \"solved\" may be a bit reductive; could this statement be qualified a little more?\n\n6. Misc typos; \"removing and existing\" -> an; \"were originally inferring\" -> inferred\n\n7. The bounds in Tables 1 and 2 could be simplified to a single +\/- number; also probably could be shown to 2 decimal places to improve readability.","sentences":[{"sentence_type":"1","sentence":"I'm blanking on a good reference that's closest to this work, but it would be nice to see some effort to make a connection here.","rephrased":"While I cannot provide a specific reference at the moment, it would be beneficial for the paper to draw connections to similar methods used in the robotics community, such as particle filtering, to strengthen the context of your work."},{"sentence_type":"1","sentence":"I think calling this \"solved\" may be a bit reductive; could this statement be qualified a little more?","rephrased":"The statement regarding the 'solved' status of spatio-temporal continuity could be expanded upon to acknowledge the complexity of the issue and the ongoing research in this area."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[2539,2667,"Not concerning"],[4512,4614,"Not concerning"]],"Comments":[]}
{"id":"rJefg9sVF4","text":"This paper relies on autoencoders in order to to distribution matching in high dimensional spaces, with the following recipe:\n   1) build an autoencoder of the data g(f(x)) - eq 1.\n   2)  build an autoencoder in latent space - ensure that f(g(z)) can reconstruct both z samples from N(0, 1) - eq 2 and f(g(f(x))) - eq 3.\n   3) Show (under assumptions) that if  eq 2 is minimized, for  z samples from N(0, 1), if f(g(z)) = f(g(f(x)) for some x in the original data space, then g(z) belongs to the reconstruction distribution. This entails that if the conditions of the theorem are satisfied (namely if f(g(z)) = f(g(f(x)) for some x in the original data space). sample quality will match reconstruction quality. \n  4) Use 3) to justify that  f(g(z)) should have high likelihood in the distribution induced by f(g(x)). Achieve that either by maximum likelihood (approximate - since there is no guarantee that h is invertible) or by variational inference. \n\nEquation 5: equation 5 follows from a change of variable and then using that f(x) for x in the data will be normally distributed. What ensures this? Minimizing equation (2) ensures that f(g(z)) will be normally distribution, with z sampled from N(0, 1). \n\nCons:\n  * The paper is very convoluted to read. Notation is missing and the discussion is missing important aspects which is making following the correctness of the paper difficult. I urge the authors to add further discussions and figures.\n  * Parts of the loss function used are rather ad hoc.\n * The method seems dependent on 3 important hyperparameters. The sensitivity to hyperparameters is not discussed.\n\nPros:\n  * good empirical results\n  * code is open sourced\n\nCitations: I would add a citation to VEEGAN[1] which also uses distribution matching in latent space.\n\n[1] Srivastava, Akash, et al. \"Veegan: Reducing mode collapse in gans using implicit variational learning.\" Advances in Neural Information Processing Systems. 2017.\n","sentences":[{"sentence_type":"2","sentence":"The paper is very convoluted to read. Notation is missing and the discussion is missing important aspects which is making following the correctness of the paper difficult.","rephrased":"The paper could benefit from clearer organization and more comprehensive notation. Including additional discussion on key aspects would enhance the readability and help in verifying the correctness of the paper."},{"sentence_type":"2","sentence":"Parts of the loss function used are rather ad hoc.","rephrased":"The rationale behind certain parts of the loss function could be better explained to understand their contribution to the overall methodology."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1221,1392,"Maybe"],[1456,1506,"Not concerning"]],"Comments":[]}
{"id":"v0mvvt7yWlc","text":"This paper presents a 2-stage procedure to a) learn representations from offline data b) fine-tuning on downstream tasks. The method builds on DINO, a self-supervised algorithm relying on distillation.\nThe paper demonstrates the benefit of the approach on on 3 different 3D datasets and 2 policy learning algorithms (RL, IL). The paper is clearly written and contains many ablations (benefit of data augmentation \/ effect of dataset size \/ long fine-tuning schedules). \nOverall, this paper would be a nice contribution to the workshop.","sentences":[{"sentence_type":"1","sentence":"Overall, this paper would be a nice contribution to the workshop.","rephrased":"Overall, this paper is a valuable contribution to the workshop."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[470,535,"Not concerning"]],"Comments":[]}
{"id":"HJxvuxujtr","text":"This paper presents an approach for learning density estimates of a data distribution convolved with noise through “denoising density estimators” and shows how to leverage these density estimates to train generative samplers. The methods are evaluated on toy low-d datasets, MNIST, and fashion MNIST where they show reasonable density estimates and OK sample quality. \n\nMy major concern with this paper is that the “denoising density estimator” proposed here is identical to denoising score matching (which is not cited or discussed). The second contribution of learning a sampler given a density estimate is interesting but likely suffers from all the instabilities of GAN training, and does not compare to related work on distilling energy-based models. Unless both these concerns are addressed, I cannot recommend this paper for acceptance.\n\nMajor comments:\n* The idea of learning a generative model whose energy gradient (score) matches the gradient of the data distribution has been explored extensively under the name “score matching”. The proposed approach of “Deep Denoising Density Estimation” is *identical* to denoising score matching (Vincent et al., 2011, http:\/\/www.iro.umontreal.ca\/~vincentp\/Publications\/smdae_techreport.pdf). There’s no discussion of any prior work on score matching in this paper, or comparison with recent approaches in this space (e.g. sliced score matching https:\/\/arxiv.org\/abs\/1905.07088, and https:\/\/arxiv.org\/abs\/1907.05600 that uses denoising score matching).\n* The algorithm presented for learning a generator given an energy function is not compared to other implicit sampling approaches like MCMC. Additionally, the algorithm requires alternating density estimation with updating the generative model, which is quite similar to GAN-training alternating density ratio estimation with updating the generative model. Thus the proposed algorithm likely experiences similar instabilities and challenges in how to partially solve the density estimation step. There are no comparisons to any GAN-based approaches anywhere in the paper. That said, mixing DSMs and explicit generators is a neat area of research.\n* The experiments are too limited, and do not compute any quantitative metrics on the image datasets.\n\nMinor comments:\n* “Defining property of PGMs is that they provide functionality to sample” ->  what about density estimates? Likelihood ratios? etc.\n* Boltzmann machines don’t allow for efficient inference\n* Intro could should spend more time discussing relation to energy-based models, score matching, noise-contrastive estimation\n* Eqn 2 only holds for sigma^2 -> 0, please add and discuss this limitation\n* Divergenc -> divergence, above eqn 12\n* I found the math in section 4 very confusing. What’s the <> notation in this context? Do you need to introduce \\Delta? Alternating density (ratio) estimation and generative model updates is super common in GAN literature and is not discussed here.\n* Table 1: are the estimates of log-likelihood upper or lower bounds? Unlike other approaches, you don’t have exact likelihoods so I’m not sure your #s are comparable.\n* 2048 samples per iteration -> batch size?\n* “For faster convergence, we take 10 DDE gradient steps…”  -> please add an experiment showing how results are impacted by # of gradient descent steps. Is larger # steps always better?\n* MNIST\/Fashion MNIST samples aren’t that good to my eye and there are no quantitative metrics (e.g. KID, FID, IS)","sentences":[{"sentence_type":"2","sentence":"The experiments are too limited, and do not compute any quantitative metrics on the image datasets.","rephrased":"The experiments could be strengthened by including quantitative metrics on the image datasets to provide a more comprehensive evaluation."},{"sentence_type":"2","sentence":"MNIST\/Fashion MNIST samples aren't that good to my eye and there are no quantitative metrics (e.g. KID, FID, IS)","rephrased":"The visual quality of the MNIST\/Fashion MNIST samples could be improved, and it would be beneficial to include quantitative metrics such as KID, FID, and IS for a more objective assessment."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2152,2251,"Not concerning"]],"Comments":[]}
{"id":"T-BAPXW4A","text":"The authors proposed a 4D encoder-decoder CNN with convolutional recurrent gate units to learn multiple sclerosis (MS) lesion activity maps using 3D volumes from 2 time points. The proposed architecture connects the encoder and decoder with GRU to incorporate temporal information. It's compared to an earlier method which uses a 3D network and time-point concatenation and reports improvement in Dice scores, false positive rates and true positive rate. \n\nThe improvement gained by the proposed method validates the effectiveness of recurrent units, and the most significant gain is from the false positive rates. \n\nMeanwhile, a few clarifications may be necessary:\n\n1) in term of runtime, does the addition of GRUs take much more training time and memory comparing to the concatenation of 3D volumes? \n2) what is the dimension of input, is it $H\\times W \\times D$ or $T\\times H \\times W \\times D$ ?  If it's the latter one, is the convolution done with a 4D filter? \n3) more details about the convGRU may be useful, for example its architecture.\n\nOverall, the problem the paper tackles is critical, and the proposed network component is effective to some extent. The conclusion is more like a validation for the usefulness of the temporal information, while technical novelty may not be very sufficient in this case.","sentences":[{"sentence_type":"2","sentence":"The conclusion is more like a validation for the usefulness of the temporal information, while technical novelty may not be very sufficient in this case.","rephrased":"The conclusion strongly supports the usefulness of incorporating temporal information. However, it would be beneficial to see further exploration of technical novelty in future work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1165,1318,"Not concerning"]],"Comments":[]}
{"id":"rygGRaKpFB","text":"In this paper, the authors propose a strategy for neural architecture search. The basic idea is effectively to model the accuracy of architectures in the search space, and use this model to select subsequent architectures with a MCTS-like procedure.\n\nOverall, my primary concern with the paper is a lack of context in the larger field of model based optimization. To be clear, the authors' method is clearly an instantiation of model based optimization. However, much of the paper is arguably written as though this needs to be invented from first principles. For example, much of section 3 is arguably a specific instantiation of the basic model based optimization loop, and much of the discussion on global versus sequential search exists in this literature as well.\n\nI believe the paper would be greatly improved by (1) providing this context, and (2) explaining the authors' approach within this context. Much of the discussion contrasting arbitrary action spaces with handcrafted ones are somewhat lost in the actual experimental setup: For example, the ConvNet-60K and LSTM-10K datasets have well specified parameter spaces. Beyond this, I'd like the authors to contrast the surrogate tree model used with simple CART trees: the fitting procedure in section 3.1 is quite similar to standard methods used to fit regression trees. \n\nAdditionally in the same context, a significant amount of related work is missing. The use of tree models for model based optimization have been considered before (e.g., SMAC), although the MCTS acquisition with a single tree surrogate is novel as far as I am aware. Other recent methods in model based optimization exist, including those with specific application to architecture search that explicitly outperform the basic Bayesian optimization algorithm (e.g. NASBot), and I'm therefore not sure if the comparison to the most basic instantiation of BayesOpt is appropriate. \n\nBeyond this, the experimental performance of the authors' method seems quite good on the tasks considered, and at least a substantial subset of the baselines considered are recent. I would therefore not be upset to see the paper published and would be willing to increase my score; however, I believe the framing of the paper needs substantial imrpovement.","sentences":[{"sentence_type":"2","sentence":"However, much of the paper is arguably written as though this needs to be invented from first principles.","rephrased":"However, the paper could benefit from acknowledging established principles in model based optimization and building upon them more explicitly."},{"sentence_type":"2","sentence":"I would therefore not be upset to see the paper published and would be willing to increase my score; however, I believe the framing of the paper needs substantial imrpovement.","rephrased":"I would support the publication of the paper, provided that the framing is significantly improved, which would also lead me to increase my score."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[454,559,"Not concerning"],[2097,2272,"Not concerning"]],"Comments":[]}
{"id":"yGxaTNQkd7b","text":"\n# Quality & Clarity: 5\n\nThis work investigate several inductive biases in the context of communication games involving visual interpretability. \n\nIn the introduction and background section, the authors describe previous computational approaches clearly, establishing the lineage of the current work under Mihai & Hare 2021. \n\nHowever, on line `24` the introduction fails to clearly state the primary contribution of this work, instead opting for deflationary rhetoric of\n> In this paper we explore Mihai & Hare (2021b)’s model in more detail.\nWithout a clear statement of purpose (i.e. \"Here, we explore the interaction of more \"human-like\" perceptual representations in communication with...\") the remainder of this paragraph appears to be arbitrary compositions of other works in the field of communications and computer vision. \n\nIn the background, starting on line 40, the authors establish a link between human vision's ability to represent scenes at different levels of representation. However, this link was disorganized. Instead of enumerating cited works at the end of the paragraph, the manuscript's clarity would have been dramatically improved if this sections began with human vision as an inspiration and then referenced the relevant communication research. \n\nIn the model section, lines 57-60 mention that the communication via drawing task that the model is trained to perform \"seems impossible for humans\" without any citation or further explanation. Humans already enjoy several board games that rely on drawing real-world objects. Without a stronger qualification than intuition this comment is distracting at best or wrong at worst. It is unclear how framing the relevant task as super-human benefits the work. \n\n# Originality NA\n\nThis reviewer is not familiar with the literature on communication and does not have a comment for originality. \n\n# Significance 5\n\nUnderstanding and implementing the computational principles that allow humans to effectively communicate under both processing and pragmatic constraints is a central aspect to human intelligence. \n\nThis work aims at establishing a set of working components: 1) a visual system that can effectively represent the world in a way that 2) summarizes key features that 3) can be queried meaningfully. \n\nFrom this manuscript, 1 & 3 are given partial service but the degree to which these goals are accomplished are obfuscated by the format of Table 1. \n\nIt is unclear that this work achieves goal 2. In Fig 2, the authors illustrate the qualitative interpretability of model sketches from a variety of images. It is  clear that adding additional inductive biases in the form of perceptual losses leads to differences across models where those that include such losses have recognizable drawings (especially row 3: ViT-B\/32 + clipdraw). However, as the authors mention in future directions, it is unclear whether the model is drawing the scene or collapsing to the scene category. The authors only show two scenes that are close in category (horse, horse + jockey) and their resulting sketches do not appear to reflect any interpetable difference; both, sketches appear to be a horse. The additional sketches on page 9 do no alleviate this concern, with objects in several sketches oriented in the reverse direction than those in the input image. Given that this work relies on qualitative comparisons to support the conclusion of the title, it would be prudent to organize such figures by category such that this could be easily illustrated to readers. \n\n\n# Pro \/ Cons\n\n## Pros\n\n- important premise: Human vision can represent key aspects of a scene succinctly \n- exploration of novel model by composing CLIP and prompt engineering\n \n## Cons\n- paper itself suffers from lack of clarity and structure\n- it is unclear that the authors meet their objective of qualitative interpretability based on the Fig 2\n- it is unclear why the different approaches in the work lead to differences in performance in terms of interpretability. ","sentences":[{"sentence_type":"2","sentence":"However, this link was disorganized.","rephrased":"However, the organization of this link could be improved for better clarity."},{"sentence_type":"3","sentence":"Without a stronger qualification than intuition this comment is distracting at best or wrong at worst.","rephrased":"This statement would benefit from additional evidence or citations to support the claim and enhance the paper's credibility."},{"sentence_type":"1","sentence":"it is unclear why the different approaches in the work lead to differences in performance in terms of interpretability.","rephrased":"It would be helpful if the authors could provide more insight into how the different approaches contribute to variations in interpretability performance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[327,471,"Missed Maybe"],[993,1029,"Not concerning"],[1551,1653,"Maybe"],[3885,4004,"Not concerning"]],"Comments":[]}
{"id":"zwjdf-RHib3","text":"This paper provides enough details of their method, and shows performance improvement over some existing methods. However, I have major concerns about the problem formulation, the motivation of the method, and the experiments. \n\nThis paper aims to address four problems at the same time: (1) few-shot learning, (2) multimodal FS learning, (3) semi-supervised FS learning, and (4) FS learning under data noise. It is not clear what are the unique challenges posed by each problem, and why this paper combines all the problems together to create a new and complex problem. There need to be more intuitive justifications on the importance of the problem studied. \n\nThe method is also quite complex and not well-motivated. It is unclear what challenge doe each component address. It is also difficult for me to understand what value does the proposed mixture model offer that is specific to the problem studied.\n\nThe experiment setting is confusing to me. Could the author explain in more details about the (1) multimodal data, (2) semi-supervised setting, and (3) dataset noise. It seems to me that all the baseline results are reproduced on the new setting (please correct me if I'm wrong), because previous methods are not targeted to this problem. In such cases, the improvements over baselines are expected. The authors either need to adapt the baseline, or provide more justifications on why the baselines are strong enough. ","sentences":[{"sentence_type":"2","sentence":"The method is also quite complex and not well-motivated.","rephrased":"The method appears complex, and it would be helpful if the authors could provide further motivation and clarification for its design."},{"sentence_type":"2","sentence":"It is also difficult for me to understand what value does the proposed mixture model offer that is specific to the problem studied.","rephrased":"I would appreciate it if the authors could clarify the specific value that the proposed mixture model brings to the problem being studied."},{"sentence_type":"1","sentence":"It seems to me that all the baseline results are reproduced on the new setting (please correct me if I'm wrong), because previous methods are not targeted to this problem.","rephrased":"It appears that the baseline results may have been reproduced in the new setting, which could be due to previous methods not being specifically designed for this problem. Could the authors provide clarification on this?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[662,718,"Maybe"],[776,907,"Not concerning"],[1076,1247,"Not concerning"]],"Comments":[]}
{"id":"Exs5efxx_","text":"The paper proposed self-learning to pre-train a U-Net model using benign cases, that would not be otherwise used because not containing annotations, to perform a reconstruction task. This U-Net is later used to segment lesions using manual annotations. A public dataset is used for evaluation. The use of self-supervision is interesting here, and shows some improvement whe compared to using full supervision. In the evaluation, masses and calcifications are merged, which may have an impact in the clinical applicability of this system. No comparison with existing models on the same public dataset are reported.","sentences":[{"sentence_type":"2","sentence":"No comparison with existing models on the same public dataset are reported.","rephrased":"The paper would be strengthened by including a comparison with existing models on the same public dataset."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[538,613,"Not concerning"]],"Comments":[]}
{"id":"BJeLBiDdF4","text":"The authors propose a semi-supervised strategy for sequential decision-making. They initially use supervised imitation learning to approximate the expert policy; then they extract features through weak constraints (temporal and global) from this policy. In addition, they use an autoencoder to complement the aforementioned features. \n\n+ well-written paper\n+ well-motivated with clear ideas\n- could elaborate more on the differences with the literature\n- stronger ablation study about each constraint's contribution should be performed\n\n\nSome additional question that were not clear while studying the paper:\n1) Why do the authors use 8 clusters? What's the intuition behind this number?\n2) What are the exact training\/implementation details? For instance, how many episodes did their method require? \n3) The authors mention that there might be an imbalance among the different types of constraints. Could they elaborate on that? \n4) Why are the data with high uncertainty identified as useful sub-goals?\n\n","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"Skgx6y4AYH","text":"This paper shows a trade-off relationship between computational cost (memory usage, train\/test time) and performance on several NLP machine learning algorithms that use n-gram statistics. The authors claim that a simple n-gram representation vector with a conventional classifier (MLP, SVC, Naive Bayes...) is computationally efficient.\n\nThe large set of experiments on various conventional NLP models and n-gram statistics provide detail information about the trade-off relation between performance and computational cost. My concern is that the computational efficiency of the conventional NLP model is well known to NLP researchers. It would be nice if the authors provide a more persuasive explanation for the importance of this research question.","sentences":[{"sentence_type":"2","sentence":"My concern is that the computational efficiency of the conventional NLP model is well known to NLP researchers.","rephrased":"While the computational efficiency of conventional NLP models may be familiar to many in the field, it would be beneficial for the paper to more clearly articulate the novel contributions of this research."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[524,635,"Not concerning"]],"Comments":[]}
{"id":"BygKOjQKYE","text":"This work proposes the use of a noise correction loss in the context of graph neural networks to deal with noisy labels. The GNN is implemented following the message passing approach proposed by Xu (2019). The authors compare 3 different noise estimators (namely the conservative, anchors and exact approaches) in the task of graph classification using 9 datasets.\n\nThe paper tackles an interesting and relevant problem to the community. The contribution of the proposed loss in real settings is not clear since only experiments with synthetic noise were performed. More importantly, in its current form the paper is not easy to follow and there are missing details and omissions that should be corrected:\n\n- Until we read the “Empirical results” section, it is not clear what are the differences between the conservative, anchor and exact methods. The description given in the “Empirical results” section should be part of the “Method” section.\n\n- For the conservative approach, it is not clear what is the loss function used to train the first model which estimates C.\n\n- In Sec 2.1, what is \"m\" in 2^m ? Is this the number of possible labels?\n\n- What is C^a in Table 2?\n\n- Table 3 indicates “We calculate the mean and std of accuracy score on test data for 10 runs each configuration”. However, there is only one value reported in the table which I assume corresponds to the mean value.\n\n- Figure 2 indicates “X-axis presents the test accuracies”. As far as I understand, test accuracies are indicated in the Y-axis.\n","sentences":[{"sentence_type":"2","sentence":"More importantly, in its current form the paper is not easy to follow and there are missing details and omissions that should be corrected:","rephrased":"To enhance the paper's clarity and completeness, I suggest adding more details in certain sections and addressing the following omissions:"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[566,705,"Not concerning"]],"Comments":[]}
{"id":"ryexDZ32KB","text":"This paper presents a new method to obtain cross-lingual contextual embeddings by aligning monolingual ones through 3 steps: transform each token individually, merge them as needed to obtain a uniform granularity across languages, and reorder them.\n\nWhile I think that the proposed method has some interest, and the extensive ablation experiments are useful to better understand its behavior, I do not think that the it makes enough merits to be accepted in the conference. I feel that the paper tends to overly complicate things, and it is often difficult to extract any clear idea from it. The proposed method is also much more complicated than previous approaches, yet it does not perform better than them (XLM has better absolute results and exactly the same cross-lingual transfer gap, while being substantially simpler). More concretely:\n\n- The paper tends to overly complicate things. For instance, Section 2.1 and 2.2 try to mathematically formalize very basic intuitions. Unless the formalization is important for clarity (which is not, as these are obvious ideas) or necessary later in the paper (which is not either), there is no point in doing that. This only makes the paper more difficult to follow than what it should.\n\n- The only extrinsic evaluation is in XNLI, where the authors evaluate the zero-shot cross-lingual transfer performance from English into Chinese. However, the proposed method does not bring any improvement over the current state-of-the-art in this setup. The proposed method gets 80.2% and 71.7% accuracy in English and Chinese, respectively, leaving an absolute transfer gap of 8.5%, while the XLM model from Lample and Conneau (2019) obtains substantially better results (85.0% and 76.5%) with the exact same transfer gap of 8.5%. This could still be good enough if the proposed method had some other advantage over the previous SOTA, but I cannot find any and, in contrast, I do find some disadvantages (see below).\n\n- In addition to being more complicated than previous approaches, the proposed method also introduces new hyperparameters and seems more difficult to train. For instance, the authors need to incorporate annealing to train the transformation module, and the model seems quite sensitive to the corresponding hyperparameter (Table 1).\n\n- While both multilingual BERT and XLM simply fine-tune a pre-trained BERT model to perform some downstream task, the proposed method is used as a feature extractor, and the authors train an ESIM (LSTM) model on top. The reported experiments do not control this factor (i.e. what would happen if one learns an ESIM model on top of XLM)?\n\n- The authors highlight that their system can be trained in \"less than 5 hours, on a single GPU\", while \"XLM uses much more data and training time\", but this is quite deceptive. Your approach also requires training a monolingual BERT model for each language, which is even more expensive than training a single joint model as XLM does. It is true that one could potentially use publicly available monolingual models, but most pre-trained models in languages other than English are already multilingual, anyway, so I do not see a strong practical justification for this.\n\n- The proposed model and the ones it is compared to do not use the same training data. This can have some justification (it might be computationally prohibitive for the authors to pre-train their own models, which might be the reason why they use public models trained on different data) but they should be more upfront about this. In relation to this, it is unfair to remark that the proposed method uses less parallel data than XLM, while not even mentioning that it uses more monolingual data (if I am not wrong, XLM was only trained in Wikipedia, while BERT also used a book corpus at least for English). To make things worse, the authors claim that \"XLM uses much more data and training time than our approach\", which seems wrong.\n\n- The authors criticize XLM because it \"does not produce the same representation for different languages, so there is no guarantee of the performance in transfer learning\". This might be true, but is it anyhow different for your proposed method? Your method is not better empirically, and it does not have any theoretical guarantee either.\n\n- As the authors themselves acknowledge, the proposed method is similar in spirit to Schuster et al. (NAACL'2019) -which is also much simpler- but they do not compare to it in their experiments.\n\nAll in all, I think that the paper tends to overly complicate things, and ultimately fails to answer a simple central question: why should one prefer your approach over previous methods like XLM, or what is it that it makes it otherwise interesting or relevant?","sentences":[{"sentence_type":"2","sentence":"I do not think that the it makes enough merits to be accepted in the conference.","rephrased":"I believe the paper could be strengthened before it meets the acceptance criteria for the conference."},{"sentence_type":"2","sentence":"I feel that the paper tends to overly complicate things, and it is often difficult to extract any clear idea from it.","rephrased":"The paper could benefit from simplifying the concepts for clarity and ease of understanding."},{"sentence_type":"1","sentence":"The proposed method is also much more complicated than previous approaches, yet it does not perform better than them.","rephrased":"The proposed method appears to be more complex than previous approaches, and a comparative analysis of performance would be helpful."},{"sentence_type":"2","sentence":"This only makes the paper more difficult to follow than what it should.","rephrased":"Simplifying these sections could make the paper more accessible to readers."},{"sentence_type":"2","sentence":"I cannot find any and, in contrast, I do find some disadvantages (see below).","rephrased":"It would be beneficial to highlight any potential advantages of the proposed method alongside the discussed disadvantages."},{"sentence_type":"1","sentence":"It is true that one could potentially use publicly available monolingual models, but most pre-trained models in languages other than English are already multilingual, anyway, so I do not see a strong practical justification for this.","rephrased":"While one could use publicly available monolingual models, the practicality of this approach may be limited given the prevalence of multilingual models."},{"sentence_type":"2","sentence":"To make things worse, the authors claim that \"XLM uses much more data and training time than our approach\", which seems wrong.","rephrased":"The claim that \"XLM uses much more data and training time than our approach\" could be re-evaluated for accuracy."},{"sentence_type":"2","sentence":"All in all, I think that the paper tends to overly complicate things, and ultimately fails to answer a simple central question: why should one prefer your approach over previous methods like XLM, or what is it that it makes it otherwise interesting or relevant?","rephrased":"In conclusion, it would be helpful if the paper more directly addressed the central question of why one should prefer this approach over previous methods like XLM, or what distinguishes it as interesting or relevant."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[393,473,"Not concerning"],[474,591,"Not concerning"],[1162,1233,"Not concerning"],[1877,1954,"Not concerning"],[2963,3196,"Not concerning"],[3807,3933,"Maybe"],[4472,4733,"Maybe"]],"Comments":[]}
{"id":"BylbaEivn7","text":"The paper theoretically analyzes the sparsity property of the stationary point of layerwise l1-regularized network trimming. Experiments are conducted to show that reaching a stationary point of the optimization can help to deliver good performance. Specific comments follow.\n\n1. While the paper analyzes the properties of the stationary point of the layerwise objective (5), the experiments seem to be conducted based on the different joint objective (8). Experimental results of optimizing (5) seem missing. While the reviewer understands that (5) and (8)  are closely related, and the theoretical insights for (5) can potentially translate to the scenario in (8), the reviewer is not sure whether the theory for (5)  is rigorously justified by the experiments.\n\n2. It is also unclear how tight the bound provided by Theorem 1 is.  Is the bound vacuous? Relevant statistics in the experiments might need to be reported to elucidate this point.\n\n3. It is also unclear how the trade-off in point (b) of the abstract is justified in the experiments.\n\nMinor Points:\npage 2, the definition of $X^{(j)}$, the index of $l$ and $j$ seem to be typos.\npage 2, definition 1, the definition of the bracket need to be specified. \npage 4, the concept of stationary point and general position can be introduced before presenting Theorem 1 to improve readability.\npage 4, Corollary 1, should it be $nnz(\\hat{W})\\le JN k_{\\mathcal{S}}$?\npage 7, Table 2, FLOPS should be FLOP? \npage 8, is FLOP related to the time\/speed needed for compression? If so, it should be specified. If not, compression runtime should also be reported.\n\n\n\n\n","sentences":[{"sentence_type":"1","sentence":"While the reviewer understands that (5) and (8) are closely related, and the theoretical insights for (5) can potentially translate to the scenario in (8), the reviewer is not sure whether the theory for (5) is rigorously justified by the experiments.","rephrased":"The reviewer recognizes the close relationship between objectives (5) and (8), and the potential applicability of the theoretical insights from (5) to (8). However, it would be beneficial to see more experimental evidence that rigorously justifies the theory for (5)."},{"sentence_type":"2","sentence":"Is the bound vacuous?","rephrased":"It would be helpful to include additional statistics in the experiments to clarify how tight the bound provided by Theorem 1 is."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[834,855,"Not concerning"]],"Comments":[]}
{"id":"EdxJ5_cc1gq","text":"\n## Strengths\n1. The studied problem is interesting. Estimating the induced preferences are quite important for recommender systems, especially for real-world applications, where users indeed interact with recommendation algorithms.\n2. The proposed method makes sense. It is well motivated.\n\n## Weaknesses\n\n- Why don't the authors deploy some wide-used simulators, such as Virtual-Taobao [1]. The literature survey about the simulator in recommender systems should be considered.\n- It is always noisy if the experiments are based on the simulation. \n- The experimental setup is overall too ideal. For example, in real-world applications, the recommendation engine\/system may do not allow preference manipulation.\n- There are a lot of choices that are selected biasedly. For example, the authors use a BERT model (Sun et al., 2019) as the human model, which leaves me a question: how about the other choices? Is this model the best choice? \n- The authors should re-think the value of this work. If there is no solid evaluation manner, a proper solution is to plug this method into some commonly-accepted recommendation pipelines. For example, you can first use the estimated preferences shifts to improve the backbone recommendation models and then evaluate based on traditional evaluation manners of recommender systems. In the current version of this work, it is still unclear whether the method work or not.\n- There is no competitive baseline method in the results (Table 1 and Table 2). I suggest the authors at least add some heuristic methods as baselines.\n- The complexity of the proposed approach is unclear. Will it be a burden for the recommendation model?\n\n[1] Shi, Jing-Cheng, et al. \"Virtual-taobao: Virtualizing real-world online retail environment for reinforcement learning.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 33. No. 01. 2019.\n\n## After Rebuttal\nThe authors have carefully summarized my concerns into five aspects. I agree with the reply to the 1st, 2nd, and 4th, while I partly agree or disagree with the 3rd and 5th. Thus I have raised my score.","sentences":[{"sentence_type":"2","sentence":"It is always noisy if the experiments are based on the simulation.","rephrased":"Experiments based on simulation can introduce noise, which may affect the results. It would be beneficial to discuss how this aspect was addressed or mitigated."},{"sentence_type":"3","sentence":"The authors should re-think the value of this work.","rephrased":"The authors may want to further articulate the value of this work, particularly in the context of solid evaluation methods or integration into existing recommendation pipelines."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[482,548,"Not concerning"],[942,993,"Not concerning"]],"Comments":[]}
{"id":"S4ge54uJpZ5","text":"**Summary**: The authors present a method for training slot-attention based models using implicit differentiation by leveraging the interpretation of the slot-attention mechanism as a fixed-point operation. They demonstrate that the training algorithm is effective at stabilizing training, thereby improving state of the art model performance on multiple standard benchmarks while simultaneously making training of such models easier.\n\n**Strong points**: \n- The contribution of the paper is theoretically grounded and experiments tracking the jacobian of the transformation align well with theory. \n- The method is simple and may have the potential to significantly improve the stability of slot-attention based models. \n\n**Suggestions for minor improvements**:\n- A greater number of seeds, specifically 2 seeds for visualization of vanilla slot attention and 3 seeds for the new method are not entirely convincing for the significant claims being made, especially when one of the three seeds does not agree. Furthermore the performance of the vanilla SLATE model on the presented two seeds is somewhat concerning given the extremely poor performance in comparison to prior published work.\n- Remove some excessive claims without justification or further details. For example in the conclusion stating it may \"potentially [improve] any iterative inference algorithm\".\n\nOverall the paper appears to be a solid contribution to slot-attention based algorithms and I believe it would be a valuable addition to the workshop. \n","sentences":[{"sentence_type":"2","sentence":"A greater number of seeds, specifically 2 seeds for visualization of vanilla slot attention and 3 seeds for the new method are not entirely convincing for the significant claims being made, especially when one of the three seeds does not agree.","rephrased":"To strengthen the evidence for the significant claims being made, it would be beneficial to include a larger number of seeds for both the visualization of vanilla slot attention and the new method. This would help to ensure the robustness of the results, particularly when there is a discrepancy among the seeds."},{"sentence_type":"2","sentence":"Furthermore the performance of the vanilla SLATE model on the presented two seeds is somewhat concerning given the extremely poor performance in comparison to prior published work.","rephrased":"Additionally, it would be helpful to provide an explanation for the performance of the vanilla SLATE model on the two seeds presented, as it appears to differ significantly from the results reported in prior published work."},{"sentence_type":"1","sentence":"Remove some excessive claims without justification or further details. For example in the conclusion stating it may \"potentially [improve] any iterative inference algorithm\".","rephrased":"It would be advisable to temper some of the broader claims, such as the potential improvement of any iterative inference algorithm, by providing additional justification or details to support these assertions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[764,1008,"Not concerning"],[1009,1189,"Maybe"],[1192,1366,"Not concerning"]],"Comments":[]}
{"id":"adVW86smVv","text":"The authors show that a CNN deblurring approach gives promising results for real-time spiral readout MRI. The work is reasonably convincing, as a first step, and achieves impressive-seeming results. Clarity is good, with the authors explaining both their problem and proposed solution. Originality lies mainly in the application: there does not seem to be a lot of pre-existing work in the literature. Significance seems sufficient for a short format paper – there may be practical issues with the authors' approach compared to reference approaches, but this is a promising first step. On balance, I recommend this paper for acceptance.\n\nPros:\n* Original work on an interesting application.\n* Convincing evaluation of performance.\n* Well-written and clear.\n\nCons:\n* Unclear to what extent Figure 3 is truly representative – it might be beneficial to include several example images.\n* Limited discussion of the quantitative results in Figure 2.\n* No quantitative results for experimental data (due to lack of ground truth). Understandable in a short paper format, however.","sentences":[{"sentence_type":"1","sentence":"Unclear to what extent Figure 3 is truly representative \n","rephrased":"It would be helpful to clarify how representative Figure 3 is by including additional example images."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"B1ggQEC6tS","text":"This paper addresses a very good question - can we do better in terms of model learning, so that we can find the much sought after middle ground between model free and model based RL. In particular, the authors ask, can we find a way to learn a model that is reward\/task independent, so that a new task can be equally well handled. This is timely and the general thrust of the thinking, in terms of learning from perturbation around trajectories, is good but I am not sure the proposed methods are sufficiently well developed to merit publication. I am also concerned that the authors do not consider numerous issues with the setup that are fairly well understood as issues for system identification.\n\nThe main idea, as laid out in §1.1, is to observe that the parameter update depends mainly on the way a small perturbation in parameters is reflected as a variation in the optimal trajectory (by asking for the probability of a trajectory, this variation becomes the probability of a nearby trajectory). The authors then approach the approximation of this in terms of a discrete finite differences estimate. There are some extensions, such as using a local GP model instead of a local linear model and consideration of ways in which the system might not be exactly repeatable given initial states. These are all proper questions but there are many more important unanswered ones:\n\n1. Starting with where the model setup begins, it is not clear why a complex nonlinear dynamical system, i.e., the typical multi-jointed robot taken as a dynamical system (so, not just kinematics and quasi-static movements), can be sufficiently well approximated using a discretised finite point set that is used at the start of §2 - how does one find the correct T, the correct step size, how does one change these for the local nature of the dynamics (some places might be smoother than others, in phase space), etc.? Even more importantly, are we assuming we know the proper state space ahead of time so that there is no history dependence due to unobserved variables?\n\n2. As such, the authors are proposing to perform closed-loop system identification in a completely data-driven manner. It is well known that this is hard because in the absence of suitable excitation, not all necessary modes in the dynamics will be observed. The only controlled example considered, in §4.3, and subsequent discussion about 'zero-shot' generalisation is getting at this. However, neither at the conceptual level nor in terms of the detailed experiment do I see a good account of what allows this approach to learn all aspects of the dynamics of the system from just small perturbations around a closed loop trajectory.\n\n3. In light of all this, I find the evaluation really weak. Some experiments I would have liked to have seen include - (i) a control experiment based on a standard multi-link arm to show how bad the issue of model mis-match is for the task being considered (I suspect, not much), (ii) experiments with local linearizations, and perhaps piecewise local linearizations, to show how much innovation is needed or is being achieved by the proposed advances, (iii) for us to be talking about 'zero shot' generalisation and the like, more sophisticated tasks beyond merely changing the reaching point (as I say before, it is not even clear that a good PID controller with a roughly plausible linearization is not sufficient to achieve similar effects, and certainly there is a plethora of more sophisticated baselines one could have drawn upon).\n\n4. Some of the discussion comes across as a bit naive, e.g., we have a lemma 3 whose proof is simply a geometric argument about cubes without sufficient consideration of properties of dynamics. I don't doubt the result but in the way it is presented here, it seems shoddy.\n\nAlso, some smaller questions not properly explained:\na. How do you know which kernels for good for the GP in equations 9-10?\nb.  Why should we expect the correlation procedure in §3.0.1 to always work without aliasing and what is the way to get at the suitable domain?\n\n\n","sentences":[{"sentence_type":"2","sentence":"I am not sure the proposed methods are sufficiently well developed to merit publication.","rephrased":"I believe the proposed methods could benefit from further development to strengthen the case for publication."},{"sentence_type":"2","sentence":"The authors do not consider numerous issues with the setup that are fairly well understood as issues for system identification.","rephrased":"It would be beneficial if the authors could address several well-known issues related to system identification that seem to be overlooked in the current setup."},{"sentence_type":"2","sentence":"I find the evaluation really weak.","rephrased":"The evaluation could be strengthened by including additional experiments such as..."},{"sentence_type":"2","sentence":"Some of the discussion comes across as a bit naive.","rephrased":"Some aspects of the discussion may benefit from a deeper analysis, such as..."},{"sentence_type":"3","sentence":"it seems shoddy.","rephrased":"it appears to lack rigor in its current form."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[459,547,"Not concerning"],[2716,2750,"Maybe"],[3787,3803,"Maybe"]],"Comments":[]}
{"id":"C3ss9WbttO","text":"The focus of this paper is to compare different navigation control schemes in the context of room-scale VR games.  The first control scheme was gaze directed and the second was hand directed.  These schemes were compared in two different interaction tasks and both quantitative data and qualitative data was collected. Statistical tests were performed on the quantitative data and no significant differences were found.  The qualitative data showed that some participants found the hand directed control scheme to be problematic in that it was difficult to maintain awareness of the avatar's facing direction.  The paper also highlights the importance of gathering qualitative data in addition to quantitative user metrics.  \n\nI commend the authors for the work they put into this paper and the work is certainly asking an interesting question.  The paper is clear and easy to read and understand and the references seem appropriate although the paper should probably cite\n\nLaViola, J., Kruijff, E., McMahan, R., Bowman, D., and Poupyrev, I. 3D User Interfaces: Theory and Practice, Second Edition, Addison Wesley, ISBN 0134034325, April 2017\n\nas a lot of what the paper states is in this text.  Unfortunately, the results from this paper are not significant and it does not make a contribution to the field.  The importance of gathering qualitative data in addition to quantitative data is already known. It would be good for the authors to explore other navigation methods, perhaps more modern ones, to see how they affect user experience. As it stands this paper is not ready for GI.","sentences":[{"sentence_type":"2","sentence":"Unfortunately, the results from this paper are not significant and it does not make a contribution to the field.","rephrased":"While the results from this paper may not show statistical significance, they provide a foundation for further research and contribute to the ongoing discussion in the field."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1196,1308,"Maybe"]],"Comments":[]}
{"id":"ChS4Nb39tCZ","text":"**Limited novelty:** The technical novelty of this paper is relatively limited. Using a replay buffer to approximate historical objectives is a well-known approach in continual learning. Extending it to FL seems to be straightforward as long as the replay buffer remains local to each client. The theoretical analysis is somewhat interesting but it relies on strong assumptions such as convexity (more details below), which does not hold for deep neural networks. Furthermore, the result is a bit cumbersome and difficult to interpret, and the analysis technique and result appear to be quite similar to Yin et al. (2020b).\n\n**Unrealistic assumptions:** It is evident that objectives related to deep learning models are not convex, so it would be good to analyze the convergence of non-convex objectives as well. Moreover, I feel that the assumption that the time drift is independent across both $t$ and $i$ (Remark 3.2) is a fairly strong assumption. Usually, the data varies gradually over time, so the time drift should also change gradually over time $t$, instead of being independent for each $t$. I further do not understand why $\\delta_i$ needs to be zero-mean. Usually an upper bound of the gradient drift across clients is sufficient for the analysis. In general, considering gradient drifts as random variables is problematic, since you are talking about the full (i.e., non-stochastic) gradients in the definition of drifts. These gradients only depend on the model parameter $\\omega$ and there should be no other random source (unless you consider the time evolution of data to be random, but even then it should be at least Markovian instead of fully independent).\n\n**Interpretation of results:** The results are generally cumbersome. It would be worthwhile to see whether some of the terms can be simplified in the $\\\\mathcal{O}(\\\\cdot)$ notation. I do not understand how Section 4.2 is related to time-varying scenarios. In particular, it is not clear why setting $p_{t,i}=1$ would eliminate $R$. Intuitively it does not seem to make sense, since the information loss (upper bounded by $R$) should affect the convergence even if $p_{t,i}=1$. I also do not understand what \"CFL methods accelerates the convergence by reducing the variance term\" means in Remark 4.5. While I see that the result in Theorem 4.4 has less terms compared to the result in Theorem 4.2, it is unclear how those terms are related to the variance.\n\n**Experiments:** When talking about generative methods, the paper mentions \"Maintaining a core set for each client may become impractical when\nlearning scales to millions of clients\". I'm not sure why the core set needs to be maintained collectively across different clients, and if this is the case in the core set method evaluated in the experiments, it may cause privacy issues. It seems sufficient for each client to separately select and manage its own core set. In other words, assuming that each client has a fixed amount of storage, whenever new data arrives, it has to delete some old data. The client can choose to delete the data samples that are less representative, and increase the weights of the remaining representative data samples. In this way, a core set would be constructed on each client alone, without involvement of other clients, so there will not be a scalability issue. In general, the use of replay buffer (e.g., in the core set method) for continual learning is quite standard.\n\nMinor: The paper should have a conclusion section highlighting the main results and findings.","sentences":[{"sentence_type":"2","sentence":"The technical novelty of this paper is relatively limited.","rephrased":"While the application of a replay buffer in federated learning builds upon existing approaches, further elaboration on the unique contributions of this work could enhance the perception of its novelty."},{"sentence_type":"2","sentence":"Furthermore, the result is a bit cumbersome and difficult to interpret, and the analysis technique and result appear to be quite similar to Yin et al. (2020b).","rephrased":"The presentation of the results could be more streamlined for easier interpretation, and it would be beneficial to clearly distinguish your analysis technique and findings from those in Yin et al. (2020b)."},{"sentence_type":"1","sentence":"In general, considering gradient drifts as random variables is problematic, since you are talking about the full (i.e., non-stochastic) gradients in the definition of drifts.","rephrased":"It may be helpful to reconsider the treatment of gradient drifts as random variables, given that the paper discusses full gradients, and to clarify the rationale behind this approach."},{"sentence_type":"2","sentence":"The results are generally cumbersome.","rephrased":"Clarifying and simplifying the presentation of the results could make them more accessible to readers."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[21,79,"Not concerning"],[464,623,"Not concerning"],[1262,1436,"Not concerning"],[1711,1748,"Maybe"]],"Comments":[]}
{"id":"7Tq83-QjVz-","text":"This paper proposes a model for job application screening. Since there is no job-related dataset available, the authors manually assigned labels to a large job application dataset. A skill set (e.g., Apache Hadoop, Apache Pig, HTML, Javascript) is firstly extracted from the job dataset.  Then a competency group is constructed (e.g., big data, front-end) as the labels. The problem is then formulated as a multi-label classification problem. That is, given a skill (which may belong to multiple competency groups), the model has to predict its competency groups. The authors proposed to use BERT as the main model. Moreover, the authors use additional features like similarity-based and cluster-based features. The experimental results are good. We think it can help recruiters find a suitable applicant.\n\nHowever, this paper is straightforward. Using BERT as a main model for text classification is a well-known technique, and many papers already applied BERTs in other domains like biomedicine and law. So we think the technical contribution of this paper is limited. Furthermore, some parts of this paper are not clearly explained. For example, the authors mentioned that they also use some features like frequency-based and group-based features, but did not find detailed descriptions of these two features.\n\nOne positive side of this paper is that the authors release a publicly available job application dataset.\nEstablishing a dataset is time-consuming, and requires a lot of human efforts. The dataset consists of 700,000 job requisitions, which is large enough. It is good that the authors are willing to share this dataset.\n\nTo sum up, this paper proposes a skill classification model for job screening, which is useful, but we think that the methodology and its technical contribution are not strong enough. It might not be qualified as a regular paper for ICLR.\n\nSkillBERT: \"Skilling\" the BERT to Classify Skills","sentences":[{"sentence_type":"2","sentence":"However, this paper is straightforward.","rephrased":"However, the approach taken in this paper is well-established in the field."},{"sentence_type":"2","sentence":"So we think the technical contribution of this paper is limited.","rephrased":"Therefore, we believe the technical contribution of this paper could be further elaborated upon."},{"sentence_type":"3","sentence":"It might not be qualified as a regular paper for ICLR.","rephrased":"It may benefit from additional work to meet the criteria for a regular paper at ICLR."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[807,846,"Not concerning"],[1006,1070,"Not concerning"],[1071,1135,"Missed Maybe"],[1820,1874,"Not concerning"]],"Comments":[]}
{"id":"YVog82YZQ4K","text":"This paper presents a new adversarial attack targeting the votes derived from the primary capsules of a capsule network. It demonstrates that this is a stronger attack against capsules networks than an attack directly optimizing the output logits of a capsule model. This paper has some novel contributions to the literature but can be improved in a few areas.  \n\nThe paper spends a fair bit of time discussing the efficiency of their attack but does not meaningfully motivate this focus. They claim that the time it takes to compute adversarial attacks against capsule networks may have contributed to the claimed robustness, but all the papers they cite which discuss the adversarial robustness of capsule networks measures the success rate with respects to the number of attack optimization steps as opposed to optimization time. Furthermore as shown in table 3, their new attack does not significantly decrease the attack creation time for most optimization strategies. I believe the focus on attack optimization time should be removed from the paper entirely, and the space can be dedicated to some of the results relegated to the appendix such as black box attacks, or the class conditional reconstruction detection. \n\nBy creating an attack that specifically targets the votes of the primary capsules this paper is able to increase the success rate of adversarial attacks against capsule networks. It does this however, by effectively not attacking the capsule part of a capsule network. Rather they have created an attack which optimizes the features extracted by the CNN feature extractor used to derive primary capsules. This is an interesting finding, and illustrates that capsules networks are more vulnerable to adversarial attack than perhaps previously believed due to their reliance on CNN feature extraction, but it is important to note that it does so by optimizing for activations of non-capsule components of a capsule network. This is not a major flaw of the paper, but i believe it warrants some discussion, space providing.\n\nThis paper also presents the success rate and undetected rate of their new attack against the class conditional reconstruction attack presented by Yao et al. This section improves the paper, but there are some omissions. Namely they do not in the main text nor in the appendix visualize the resultant attacks. This is an issue as both Yao et al (2020) (Detecting and diagnosing adversarial images with class-conditional capsule reconstructions) and  Yao et al (2020) (Deflecting Adversarial Attacks) show that the undetected attacks often resemble the target class, even under small epsilon bounds. This paper also does not address the additional defense mechanisms presented in Deflecting Adversarial Attacks, which were shown to drastically increase the attack detection rate, specifically in colour datasets such as cifar10.  \n\nThis paper would be improved by addressing those 3 main issues.  \n\n------------------- \nsmaller issues, \n\nthe text describing figure 2 is confusing, and i am not entirely sure what the point of the figure it. perhaps more space could be dedicated the distinguishing the b and c plots and discussing why this motivates the work. \n\nthere is a missing equation link in section 4 \n\nthere is a missing table link in appendix E  \n\n\n\n----POST AUTHOR RESPONSE --------\n\n1.) Efficiency of our Vote-Attack: \n\nIt is clear that the vote attack is more time efficient than other attacks, but there is no clear motivation for this improvement. To my knowledge the attack creation time has never been a barrier to adversarial research, nor has it prevented real world adversarial attacks. As a result this focus of the paper simply confuses the reader, be spending time addressing an issue that is not important in research or practical settings.  \n\n2.) Optimizing for activations of non-capsule components of a capsule network: \n\nIn the authors response they discuss the semantic meaning of the votes of capsules. This too is a bit of a red herring. Although when discussing the motivation behind capsules, the potential for semantically meaningful capsule votes is invoked, there is nothing in the training procedure that ensures that the activations of the capsules correspond directly to features that humans would find semantically meaningful. In my original review i mentioned that by not attacking the output of the capsules after the routing procedure, this attack was simply optimizing for representations extracted from a standard neural network. In this way this work is similar to the representation attacks first presented by [1] which showed the success of representation attacks on standard neural networks.  \n\n3.) The undetected attacks often resemble the target class, under the class-conditional capsule reconstructions detection:\n\nTh addition of the attack visualizations is an improvement but the authors do not specify which attacks are successful and undetected and a few of the visualized attacks do indeed resemble the target class.   \n\n4.) The additional defense mechanisms presented in Deflecting Adversarial Attacks:\n\nThe authors are right to point out the scope of the paper, and it is perhaps unreasonable to expect this paper to address these defence mechanisms, but their inclusion would greatly strengthen the paper. \n\n[1] Sara Sabour, Yanshuai Cao, Fartash Faghri, and David J Fleet. Adversarial manipulation of deep\nrepresentations. In ICLR, 2016.","sentences":[{"sentence_type":"2","sentence":"I believe the focus on attack optimization time should be removed from the paper entirely, and the space can be dedicated to some of the results relegated to the appendix such as black box attacks, or the class conditional reconstruction detection.","rephrased":"I suggest reconsidering the emphasis on attack optimization time and potentially using the space to further elaborate on results currently in the appendix, such as black box attacks or the class conditional reconstruction detection."},{"sentence_type":"1","sentence":"This is not a major flaw of the paper, but i believe it warrants some discussion, space providing.","rephrased":"While this is not a major flaw, it would be beneficial to include some discussion on this aspect if space permits."},{"sentence_type":"1","sentence":"This is an issue as both Yao et al (2020) (Detecting and diagnosing adversarial images with class-conditional capsule reconstructions) and  Yao et al (2020) (Deflecting Adversarial Attacks) show that the undetected attacks often resemble the target class, even under small epsilon bounds.","rephrased":"It would be informative to include visualizations of the resultant attacks, as demonstrated by Yao et al. (2020), to better understand how undetected attacks often resemble the target class, even under small epsilon bounds."},{"sentence_type":"2","sentence":"As a result this focus of the paper simply confuses the reader, be spending time addressing an issue that is not important in research or practical settings.","rephrased":"Therefore, the focus on attack optimization time might be more impactful if it were connected to its relevance in research or practical settings."},{"sentence_type":"1","sentence":"In my original review i mentioned that by not attacking the output of the capsules after the routing procedure, this attack was simply optimizing for representations extracted from a standard neural network.","rephrased":"In my original review, I noted that focusing on the output of the capsules after the routing procedure could provide a more direct assessment of the capsule network's robustness to adversarial attacks."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[974,1222,"Not concerning"],[1947,2045,"Not concerning"],[2357,2645,"Not concerning"],[3652,3809,"Maybe"],[4312,4519,"Not concerning"]],"Comments":[]}
{"id":"ZzIh-oWF-S","text":"This paper presents a unet-like architecture that is enriched with skip connections from lower levels of the downsampling\/upsampling paths towards upper levels. The task the authors attempt to solve is multi-organ segmentation from CT scans, and results are comparable or better than the state-of-the-art, according to a nice evaluation (the test set of a grand-challenge). I believe this is a solid short paper and I support acceptance. I would like however to see more technical details about what is the exact way in which connections are built in this network. Figure 1 could benefit from a better written caption, in this sense. \n\nMinor comments:\n1) In the first page, you probably wanted to write \"generative\" instead of \"generational\"?\n2) Could you please clarify if the input\/output of your architecture is volumetric or bidimensional? You first mention that you implemented a volumetric OAR segmentation method, but later in the text you say you had 21,000 256x256 images, which sounds like you dealt with 2d images. ","sentences":[{"sentence_type":"1","sentence":"Figure 1 could benefit from a better written caption, in this sense.","rephrased":"It would be helpful to provide a more detailed caption for Figure 1 to enhance understanding of the connections within the network."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[565,633,"Not concerning"]],"Comments":[]}
{"id":"Byes1a-St4","text":"This paper presents an approach to classifying online reviews to aspect classes, when no gold labels for aspect labels are available. Their weakly supervised approach involves using a small set of seed words which describe these aspects. Their approach involves first showing that current weakly supervised approaches with neural networks are not suitable for learning the task under the setting used in the paper. To help with this issue, they turn to a variant of the paradigm of knowledge distillation, with the difference that they use a 'teacher' based on a bag-of-words classifier with seed words, and a student which is an embedding-based neural network.\n\nIn terms of the methodology used, the motivation for the simplicity of the student is somewhat lacking. While it is, of course, legitimate to leave more complicated formulations to future work, I am not certain of what exactly the authors mean when they find that that representations from the unweighted average of word embeddings is effective. Is the idea here simply that they tried a simple approach, and found the results to be sufficiently good to verify their approach?\nIt would have been interesting to see some more approaches here, in order to see whether improving the representations could yield better results, or whether perhaps the representations of the student do not matter so much. A relatively fast and simple thing to do, would be to embed the segments using a pre-trained BERT model.\n\nNonetheless, the results seem convincing, as their relatively simple distillation approach yields results which seem substantially above previous work.\n\n\nMinor comments:\n* The footnotes at ends of sentences should be written after punctuation\n","sentences":[{"sentence_type":"2","sentence":"In terms of the methodology used, the motivation for the simplicity of the student is somewhat lacking.","rephrased":"Regarding the methodology, it would be helpful if the authors could provide further motivation for choosing a simpler student model."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[663,766,"Not concerning"]],"Comments":[]}
{"id":"S1xuhkHFqS","text":"In this paper, the authors present two contributions:\n1)\tThe primary contribution is to show that CycleGAN can be formulated as a probabilistic version of a particular penalized-least squares problem (theory)\n2)\tAs proof of concept, they apply their version of CycleGAN to accelerated MRI and deconvolution microscopy (application)\n\nWhile I find the idea to be potentially interesting, the presentation of the theory is unclear and not well-motivated; after reading, I’m not convinced that the connection to CycleGAN is as significant as the authors claim. The experimental results are preliminary. My decision is to reject. Below are separate critiques on the sections.\n\nSection 2-3: Hope the authors could clarify \/ strengthen these points in revision:\n-\tSince the discussion in Section 3 is based on the optimization problem in Equation (7), this problem should be well-motivated. Currently it is presented as a problem that has been explored previously by Zhang et al and Aggarwal et al. However, after taking a look at those papers, I don’t understand where this regularization term comes from. In these papers, the regularization term (i.e. equation 2 or 3 of Zhang et al) appears independent of y. Since this term is key to the paper, it should be well explained here. E.g. at the end of section 2.2: G_\\theta(y) is a CNN pretrained on what task?\n\n-\tIn the inverse problem, the objective is to estimate x from y. Therefore we care about \\argmin x in Equation (7). In the probabilistic setting presented in Equation (8), analogously the objective is to estimate \\pi^*, which is the solution to the primal problem. The theory shows that the primal formulation in Equation (8) is equivalent to the dual formulation in Equation (16), but does not show how the dual solution yields the primal solution, which is lacking as obtaining the primal solution seems to be the point of solving the PLS problem. (Interestingly, in Section 4, the authors are using the dual solution x = G_\\theta(y) as if it is the mapping given by pi(x|y)… this needs to be explained.)\n\n-\tThe authors claim that Proposition 1 shows that the cyclic loss term in their dual formulation is a more general version of the cycle-consistency loss in CycleGAN. But looking closely at Proposition 1 and its proof, it seems that the equivalence holds only for specific weights, not for arbitrary weights. Additionally, the specific weights are unknown (they depend on the solution \\pi^* to the primal problem…). I do not understand the claim that this is a generalization of cycle-consistency loss, nor do I see how the authors implement their version of the cyclic loss as it depends on unknown weights.\n\n-\tThe connection to CycleGAN seems to hold only when p=q=1?\n\n-\tEnd of section 3: The authors conclude “our cost formulation using (17) with (18) and (19) is more general compared to the standard CycleGAN, since a general form of measurement data generator Hx can be used”. I don’t see the connection between the theory and this claim. Even with CycleGAN, both generators can be arbitrary or fixed if one of them is known. \n\n-\tThe proofs are easy to follow, though perhaps they could be moved to the Appendix in favor of providing more motivation and explanation in the main text. \n\nSection 4:\n-\tThe authors motivate the problem with the PLS setup but then they use the learned regularization term x = G_\\theta(y) as if it is the mapping given by pi(x|y).  I am confused by this.\n-\tPutting aside the connection to the PLS problem, my interpretation of the experimental setup is that the authors use CycleGAN with Wasserstein GAN loss instead of the classic discriminator loss, where one of the generators is known (and hence only one generator\/discriminator pair is needed). I might be missing something, but I’m not sure that this approach is different enough from CycleGAN.\n-\tConsidering that the authors have the ground truth, they could provide quantitative evaluation of their method against other methods, rather than showing a few qualitative results where it is working.\n","sentences":[{"sentence_type":"2","sentence":"The experimental results are preliminary. My decision is to reject.","rephrased":"While the experimental results appear to be in the early stages, I would recommend a revision to provide more comprehensive data before considering acceptance."},{"sentence_type":"1","sentence":"I don't see the connection between the theory and this claim.","rephrased":"The connection between the theory and this claim could be made clearer."},{"sentence_type":"1","sentence":"I might be missing something, but I'm not sure that this approach is different enough from CycleGAN.","rephrased":"It would be helpful if the authors could further clarify how this approach significantly differs from CycleGAN."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[557,624,"Not concerning"]],"Comments":[]}
{"id":"r1xS3EkZn4","text":"This paper treats the problem of providing explanations for a multilayer perceptron which is used as an inverse controller for rover movement in an environment with obstacles. Authors employ several machine learning techniques to provide insights and explanations for this specific problem. \n\nAuthors provide several good ideas on how to explain a black-box model. However, there are several flaws in the paper, which can be improved with better analysis of results and defining the hypothesis of the paper. The paper structure and writing style also could be significantly enhanced to convey the right messages. Also, a reader is missing punchlines and clear conclusions and contributions of the paper. Authors treat each ML technique separately, and there is no systematic comparison of the outcome of the methods. Also, the paper is not addressing and discussing the proposed approach concerning state-of-the-art works. (Authors could, e.g. take a look at DARPA survey on XAI).\n\nSome more detailed comments:\n- The title does not match the paper content. Authors should be more precise and careful when using some standard terminology such as planning, control, controllers, machine learning algorithms. \n- The introduction is too high level and authors address ML techniques too general. This story could be shortened and some discussion and comparison to the related work on explainability of NN and black box models, in general, could be added. \n- It seems that there are many authors assumptions encoded in the design of explanation algorithms. Also in some cases, the explanation algorithm simplifies the learned function of NN controller. How could these approaches be generalized to other structures of NNs or for a different control problem?\n- Another concern, also highlighted by authors, is that most of these explanation algorithms are still hard to interpret especially by non-technical user. A systematic comparison based on some interpretability measure, accuracy as well as informativeness between provided explanations would be useful for a reader. \n \n\n\n\n\n\n","sentences":[{"sentence_type":"2","sentence":"However, there are several flaws in the paper, which can be improved with better analysis of results and defining the hypothesis of the paper.","rephrased":"However, the paper could be strengthened by a more thorough analysis of results and a clearer definition of the hypothesis."},{"sentence_type":"2","sentence":"The paper structure and writing style also could be significantly enhanced to convey the right messages.","rephrased":"Improving the paper's structure and writing style could help in conveying the core messages more effectively."},{"sentence_type":"2","sentence":"Also, a reader is missing punchlines and clear conclusions and contributions of the paper.","rephrased":"It would be beneficial to include more impactful statements and clearly articulate the conclusions and contributions of the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[365,507,"Not concerning"],[508,612,"Not concerning"],[613,703,"Not concerning"]],"Comments":[]}
{"id":"S1lp0zP-9r","text":"Motivated by the sub-optimality of using orthogonal recurrent  matrix in RNNs with nonlinearity and noise, the authors look into non-normal alternatives, in particular matrices with chain-like structure in preserving memory in RNNs. The authors compare normal and non-normal RNNs on several sequential benchmark datasets, and show that non-normal RNNs perform better than their normal counterpart. \n\nThe paper is easy to follow. The novelty of the work is limited though. The chain structure was introduced in Ganguli et al. (2008). The work studies the benefit of initializing recurrent weights in nonlinear RNNs with these chain-like structures.\n\nChen et. al. (2018) already pointed out the limitation of orthogonal initialization alone for nonlinear RNNs, and proposed closed-form initialization for RNNs with different activation functions. It would be worthwhile to include a comparison to that method.\n\nIn experiment section 2.3.1, it would be helpful to include comparison of performance of chain with feedback using different beta values to confirm the intuition that stronger feedback strength would negatively impact the memory. \n\nResults in section 2.3.2 Table 1 are not exactly align with the story. Do the authors have any intuition on why the chain with feedback perform better than the chain variant. \n","sentences":[{"sentence_type":"2","sentence":"The novelty of the work is limited though.","rephrased":"While the paper builds on existing concepts, further elaboration on the novel contributions of this work would enhance its impact."},{"sentence_type":"2","sentence":"Results in section 2.3.2 Table 1 are not exactly align with the story.","rephrased":"The results in section 2.3.2 Table 1 seem to diverge from the narrative; could the authors provide further insights or clarification?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[429,471,"Not concerning"],[1141,1211,"Not concerning"]],"Comments":[]}
{"id":"r1ieZZcxf","text":"SUMMARY \n========\nThis paper proposes to measure the \"influence\" of single neurons w.r.t. to a quantity of interest represented by another neuron, typically w.r.t. to an output neuron for a class of interest, by simply taking the gradient of the corresponding output neuron w.r.t to the considered neuron. This gradient is used as is, given a single input instance, or else, gradients are averaged over several input instances. \nIn the latter case the averaging is described by an ad-hoc distribution of interest P which is introduced in the definition of the influence measure, however in the present work only two types of averages are practically used: either the average is performed over all instances belonging to one class, or over all input instances.\n\nIn other words, standard gradient backpropagation values (or average of them) are used as a proxy to quantify the importance of neurons (these neurons being within hidden layers or at the input layer), and are intended to better explain the classification, or sometimes even misclassification, performed by the network.\n\nThe proposed importance measure is theoretically justified by stating a few properties (called axioms) an importance measure should generally verify, and then showing the proposed measure fullfills these requirements.\n\nEmpirically the proposed measure is used to inspect the classification of a few input instances, to extract \"class-expert\" neurons, and to find a preprocessing bug in one model. The only comparison to a related work method is done qualitatively on one image visualization, where the proposed method is compared to Integrated Gradients [Sundararajan et al. 2017].\n\nWEAKNESSES\n==========\nThe similarity and differences between the proposed method and related work is not made clear. For example, in the case of a single input instance, and when the quantity of interest is one output neuron corresponding to one class, the proposed measure is identical to the image-specific class saliency of [Simonyan et al. 2014].\nThe difference to Integrated Gradients [Sundararajan et al. 2017] at the end of Section 1.1 is also not clearly formulated: why is the constraint on distribution marginality weaker here ?\nAn important class of explanation methods, namely decomposition-based methods (e.g. LRP, Excitation Backprop, Deep Taylor Decomposition), are not mentioned. Recent work (Montavon et al., Digital Signal Processing, 2017), discusses the advantages of decomposition-based methods over gradient-based approaches. Thus, the authors should clearly state the advantages\/disadvantes of the proposed gradient-based method over decomposition-based techniques.\n\nConcerning the theoretical justification:\nIt is not clear how Axiom 2 ensures that the proposed measure only depends on points within the input data manifold. This is indeed an important issue, since otherwise the gradients in equation (1) might be averaged completely outside the data manifold and thus the influence measure be unrelated to the data and problem the neural network was trained on. Also the notation used in Axiom 5 is very confusing. Moreover it seems this axiom is even not used in the proof of Theorem 2.\n\nConcerning the experiments:\nThe experimental setup, especially in Section 3.3.1, is not well defined: on which layer of the network is the mask applied? What is the \"quantity of interest\": shouldn't it be an output neuron value rather than h|i (as stated at the begin of the fourth paragraph of Section 3.3.1)?\nThe proposed method should to be quantitatively compared with other explanation techniques (e.g. by iteratively perturbing most relevant pixels and tracking the performance drop, see Samek et al., IEEE TNNLS, 2017).\nThe last example of explaining the bug is not very convincing, since the observation that class 2 distinctive features are very small in the image space, and thus might have been erased through gaussian blur, is not directly related to the influence measure and could have been made aso independently from it.\n\nCONCLUSION\n==========\nOverall this work does not introduce any new importance measure for neurons, it merely formalizes the use of standard backpropagation gradients as influence measure.\nUsing gradients as importance measure was already done in previous work (e.g. [Simonyan et al. 2014]). Though taking the average of gradients over several input instances is new, this information might not be of great help for practical applications.\nRecent work also showed that raw gradients are less informative than decomposition-based quantities to explain the classification decisions made by a neural network.","sentences":[{"sentence_type":"2","sentence":"Overall this work does not introduce any new importance measure for neurons, it merely formalizes the use of standard backpropagation gradients as influence measure.","rephrased":"While the work builds upon existing concepts, such as the use of standard backpropagation gradients, it would benefit from a clearer demonstration of how this formalization provides novel insights or advantages in measuring neuron importance."},{"sentence_type":"2","sentence":"The last example of explaining the bug is not very convincing, since the observation that class 2 distinctive features are very small in the image space, and thus might have been erased through gaussian blur, is not directly related to the influence measure and could have been made aso independently from it.","rephrased":"The connection between the influence measure and the final example explaining the bug could be made clearer, as it seems that the observation regarding class 2 features could potentially be made without the use of the influence measure."},{"sentence_type":"2","sentence":"Using gradients as importance measure was already done in previous work (e.g. [Simonyan et al. 2014]). Though taking the average of gradients over several input instances is new, this information might not be of great help for practical applications.","rephrased":"The paper acknowledges the use of gradients as an importance measure in previous work and introduces the concept of averaging gradients over multiple instances. It would be beneficial to provide more evidence or case studies to illustrate the practical applications and utility of this new approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[3707,4016,"Not concerning"],[4040,4205,"Not concerning"],[4206,4456,"Not concerning"]],"Comments":[]}
{"id":"uezBS89xMhk","text":"First of all, I believe the paper is looking into a very important question that attracts lots of attention recently. The set of techniques proposed in the work are also reasonable and practical, where the proposed progressive space pruning seems to work very well. Empirically, the obtained models do perform better compared to standard Transformer baselines. As for the comparison with previous methods, since there are too many implementation details that can affect the fairness of the comparison (e.g. length of pretraining, batch size, teacher performances, etc), it's hard to judge the actual scale of the gain.\n\nThere are also a few concerns. \n- Firstly, when the block-wise search is used, it feels like the NAS-BERT is trained in a way that is more similar to a variant of distillation that additionally utilizes intermediate hidden states. As this signal is not used in the standard BERT baseline, some improvement could actually come from this factor besides a better model (architecture+param). A better baseline could be a Transformer trained in a similar way.\n- Secondly, in terms of novelty, this work is more like the combination of existing ideas, namely \"once-for-all\" and \"block-wise search\". One general issue with \"once-for-all\" is after the search, although you obtain multiple models of different sizes, the excellence these models are tied to the (1) specific set of shared parameters obtained and (2) the pre-training task. So, whether this is really a good way to obtain the desired task-agnostic compressed models is still questionable.\n","sentences":[{"sentence_type":"2","sentence":"Secondly, in terms of novelty, this work is more like the combination of existing ideas, namely \"once-for-all\" and \"block-wise search\".","rephrased":"Secondly, while the work integrates established concepts such as \"once-for-all\" and \"block-wise search\", further discussion on how these ideas contribute to the novelty of the approach would be beneficial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1077,1212,"Not concerning"]],"Comments":[]}
{"id":"SJebvU4Mt4","text":"The authors of this work propose and evaluate a scheme for data augmentation (DA) that is based on rigid and non-rigid transformations of the training samples. The proposed approach is based on a generative adversarial training paradigm that is constrained by two discriminators that regularize the generated(-transformed) images to conform with the class of the input sample and at the same time ensure dissimilarity with input sample. Since the proposed scheme is differentiable it can be trained jointly ans in an end-to-end fashion with a classifier.\n\n# Pros\n- The text is well written in terms of the language and structure, while the authors adequately describe the proposed scheme. \n- The contributions have been clearly stated\n- The results along with the examples in Appendix C look promising\n\n# Cons\n- One of the claimed contributions (i.e. well suited for low-data regime) is not fully supported by the experimental results (Figure 2, CIFAR10 results)\n- Some details are missing in the description of the experimental setup. Are the results presented in 3.1, with or without joint training with the classifier?\n- In Figre 3 (section 3.2), there are no results with the classic baseline-light\/strong DA. It would be insightful on how the joint training could affect the performance of the classifier. \n- [minor] there some grammatical mistakes in the second paragraph of the Introduction\n\nOverall, the text is easy to follow and well written. The combination of the spatial transformer block with a generative model is an interesting approach yet the performance seems to be slightly lower the state of the art. Considering also the fact that such generative schemes are difficult to define and train I wonder if it worth the effort. I would greatly appreciate such a discussion in the text.","sentences":[{"sentence_type":"2","sentence":"Considering also the fact that such generative schemes are difficult to define and train I wonder if it worth the effort.","rephrased":"Considering the complexity of defining and training such generative schemes, it would be beneficial for the authors to discuss the trade-offs and potential benefits to justify the effort involved."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1622,1743,"Not concerning"]],"Comments":[]}
{"id":"HyeSRogOYV","text":"Interesting article on evaluating camera's egoview based embedding of images into a 3D latent space that can reconstruct the 3D viewpoint of surfaces in the scene. Article quite short and dense and difficult to understand all the details.\n\n- How does the 3D-Unet evaluate the Ego-motion of the camera viewpoint ? Given the article is short, explanation on the architecture are quite fundamental.\n- Does the 3D latent space resemble any shape or surface ? Or is the latent space representation abstract ?\n- How are the intrinsic and extrinsic parameters of the camera evaluated in this setup ? We require these parameters to be estimated when evaluating a homography between two views. \n- Though the number of labels during training required are small, we still require a rich set of 3D object datsets and different viewpoints generated from them. Can you provide an idea of how this architecture generalizes to new classes and shapes of objects in images.\n- An idea of memory consumption for such architectures would be quite useful. ","sentences":[{"sentence_type":"2","sentence":"Article quite short and dense and difficult to understand all the details.","rephrased":"The article is concise, which is good, but some sections could benefit from additional detail to enhance clarity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[164,238,"Not concerning"]],"Comments":[]}
{"id":"QDqF_Wouup","text":"Studying the convergence behavior of belief propagation and generalized belief propagation is an ongoing research topic, with many aspects still being not well understood. The paper tackles this important problem and provides a favorable initialization strategy for a special types of models. That being said, the novelty of the current paper is limited and the findings only apply to a restricted setting (more precisely, Theorem 1 is analogous to Lemma 3.3 in [Koehler]. The proofs are also analogous. While the authors claim that the results generalize to a more general case, this seems not to be the case); moreover, the notation and terminology is often imprecise (to the point of being misleading); finally, the paper fails to reference important related work -- both classical papers on belief propagation as well as recent advances. More details are presented below.\n\n## Limitations\nI completely understand that one has to make certain model assumptions to prove something formally. But this paper makes model assumptions for which it has already been established (at least for plain BP) that the most accurate fixed point is the one aligned with the local potentials ([Koehler] and [4]). Since the energy landscape is also well understood in this scenario (see for example [4] and [8]) it comes as no surprise that the convergence results of [Koehler] can be generalized. The result would be stronger if it would hold for any choice of regions (motifs). From the derivations presented, this does not seem to hold. Alternatively, making certain statements about the energy landscape of generalized BP for models with frustrations or arbitrary local potentials and how considering certain motifs might render the originally non-convex free energy convex would be of great interest.\n\n## Notation\/Terminology\nThe Bethe free energy is only defined over pairs of random variables. The generalization to larger groups of variables is named Kikuchi free energy.\nIt is repeatedly stated that Ising models with an external field are considered but the equations always consider local fields. The major difference is that local fields are potentially different for every variable, i.e., we have $h_i$, whereas an external field is equivalent over all variables, i.e., we have $h_i=h$\nThe summation indices $(i,j), (i,j,k),...$  are used imprecise. One must ensure that every pair, triplet,... contributes only once to the energy (or normalize the energy accordingly).\nThe ferromagnetic model is not used consistently throughout the literature. Whereas [1] refers to ferromagnetic models whenever $J_{ij}>0$, [6] has the same definition as in this paper.\nEquation 5 uses $\\lambda(\\ldot)$ that has never been introduced.\nI cannot make sense of the double product in Equation 7. I would expect that the first product should go over all neighbors of $i$ (except for $M3(j)$) but not over all variables as stated here.\n\n## Related Work\nThe generalization of the Bethe free energy to higher models in Section 3 is not novel. This is precisely the Kikuchi free energy.\nThe derivations in Section 3 are a straightforward generalization of the classical derivations for the Bethe free energy in [2].\nThe claim that there are not guarantees on how close the beliefs at the \"best\" fixed point is to the exact one are not entirely correct (see [5] and [7]).\nThe accumulation of the effect from multiple variables into one message seems similar to the concept of the effective field in [5].\nMinor Remarks\nThe terms \"variable\" and \"spin\" are used interchangeably. Sticking to one form would improve the clarity.\nIn line 72 $X$ denotes the random variable. In the remaining paper it is always $X_i$\n.\nline 86: Ising models, which is defined -> which are defined\nPlease fix the references. [Koehler] for example has been published at this very conference (NeurIPS) and is not just an arXiv preprint.\n[1] Mooij, Joris, and Hilbert Kappen. \"Sufficient conditions for convergence of loopy belief propagation.\" (2012).\n\n[2] Heskes, Tom. \"On the uniqueness of loopy belief propagation fixed points.\" (2004).\n\n[3] Meltzer, Talya, Amir Globerson, and Yair Weiss. \"Convergent message passing algorithms-a unifying view.\" (2009).\n\n[4] Knoll, Christian, Adrian Weller, and Franz Pernkopf. \"Self-Guided Belief Propagation--A Homotopy Continuation Method.\" (2018).\n\n[5] Knoll, Christian, and Franz Pernkopf. \"Belief Propagation: Accurate Marginals or Accurate Partition Function–Where is the Difference?.\" (2020).\n\n[6] Saade, Alaa, Florent Krzakala, and Lenka Zdeborová. \"Spectral clustering of graphs with the bethe hessian.\" (2014).\n\n[7] Ihler, Alexander, John Fisher, and Alan Willsky. \"Loopy Belief Propagation: Convergence and Effects of Message Errors\"\n\n[8] Zachary Pitkow, Yashar Ahmadian, Ken Miller. \"Learning unbelievable probabilities\"","sentences":[{"sentence_type":"2","sentence":"That being said, the novelty of the current paper is limited and the findings only apply to a restricted setting","rephrased":"However, the scope of the paper's novelty appears to be somewhat narrow, with the findings being applicable primarily to a specific setting"},{"sentence_type":"2","sentence":"moreover, the notation and terminology is often imprecise (to the point of being misleading)","rephrased":"Additionally, there are instances where the notation and terminology could be more precise to avoid potential confusion"},{"sentence_type":"2","sentence":"finally, the paper fails to reference important related work","rephrased":"Lastly, the paper would benefit from acknowledging more of the important related work in this field"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[293,405,"Not concerning"],[612,704,"Maybe"],[706,766,"Maybe"]],"Comments":[]}
{"id":"6ztLO2NuAx","text":"##########################################################################\n\nSummary: \n\nThis paper proposes BBRefinement, which is a post-processing for object detection to refine the predicted bounding boxes. BBRefinement takes cropped images from predicted bounding boxes as input and refine the bounding box with a separate network that is only targeted in predicting box offsets.\n\n##########################################################################\n\nPros:\n\nThe proposed method is simple and experiment shows the effectiveness of proposed method.\n\n##########################################################################\n\nCons:\n\n1. Missing literature review. This paper is not the first one to study how to refine bounding boxes. There are a lot of works on refining bounding boxes [A, B, and many more], but this paper fails to discuss related works and explain the connection as well as the differences with them.\n\n2. Missing ablation studies. Section 2.2 discusses principals of BBRefinement, including the importance of using mixture data. However, there is no experiment supporting this claim. Also the expanding ratio of bounding boxes is an important parameter, but there is also no experiment on this parameter.\n\n3. This paper only applies the proposed method to very simple baselines like Faster R-CNN and RetinaNet. These methods (Faster R-CNN, RetinaNet) are known to predict not tight bounding boxes. I wonder if BBRefinement is still necessary when a method already predicts tight bounding boxes like Cascade R-CNN [C].\n\n4. It is not clear to me how the model is trained, especially how boxes are sampled during training. Is it an image-centric sampling or an instance-centric sampling? Does sampling strategy matter? There could also be false positives in the prediction, does these boxes harm the training (e.g. existence of background box)?\n\n5. Table 1 needs more explanation, do you need to train separate BBRefinement for each model? If not, what boxes do you use to train the BBRefinement.\n\n6. The timing of BBRefinement, is \"23ms for B1 and 44ms for B3\" a single box? What is the average end-to-end runtime on the whole dataset? The timing is also much faster than EfficientNet speed in [D], [D] reports 52 ms for B1 and 114 ms for B3. Can you explain why your timing is 2x faster?\n\n7. The dataset split on COCO also has problem, COCO train 2014 and part of val 2014 is exactly the same as train 2017. And the 5000 minival 2014 is exactly the same as val 2017.\n\n##########################################################################\n\nReasons for score:\n\nAlthough this paper presents a simple and effective solution, the overall quality of the paper is poor. First, this paper does not have discussion on related works **AT ALL**. Second, it misses important implementation details and important ablation studies. Third, this paper only applies the method to weak detectors and fails to apply it to methods that give tight bounding boxes like Cascade R-CNN. Finally, the authors put a [link to the code](https:\/\/gitlab.com\/irafm-ai\/bb-refinement) which leaks the authorship (one author's name and institute); this is a violation of the double-blind review policy. Considering all this facts, this paper is a clear reject to me.\n\n##########################################################################\n\nReferences:\n\n[A] Object detection via a multi-region & semantic segmentation-aware CNN model, ICCV 2015  \n[B] A MultiPath Network for Object Detection, 2016  \n[C] Cascade R-CNN: Delving into High Quality Object Detection, CVPR 2018  \n[D] Designing Network Design Spaces, CVPR 2020  \n","sentences":[{"sentence_type":"2","sentence":"Although this paper presents a simple and effective solution, the overall quality of the paper is poor.","rephrased":"While the paper presents a straightforward and potentially effective solution, there are several areas where the quality of the paper could be improved."},{"sentence_type":"3","sentence":"Considering all this facts, this paper is a clear reject to me.","rephrased":"Considering these factors, I would recommend a revision of the paper before it can be accepted."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2589,2692,"Maybe"],[3198,3261,"Maybe"]],"Comments":[]}
{"id":"HklZG5TYFB","text":"This paper introduces a new adversarial training approach, where a generator is used to generate the most challenging adversarial examples and the classifier is trained to correctly classify the generated adversarial examples. In this way, the robustness of the classifier is expected to be improved. For the generator, the input includes the original data sample, the gradient of the classifier, and the true label of the data sample. The paper is clearly presented and easy to follow. The experimental results relatively support the main claims of the paper.\n\nThe reasons that I go towards mild rejection for this paper are as follows:\n\n1. The general idea of improving the robustness of a classifier to by feeding adversarial examples to it is not a new idea. As shown in the paper, the idea has been adopted in Goodfellow et al. (2015) and Madry et al. (2018). In addition, [1] comprehensively studied how to ensemble different adversarial attacks as \"training data\" of a classifier to improve its robustness. The paper generates adversarial examples with a generator that takes various things as inputs, which can be viewed as an extension to the method in [2]. [2] introduced a generator that only takes the data sample as inputs and the difference to the paper is that the one in this paper additionally takes gradients and label as inputs. With Goodfellow et al. (2015), Madry et al. (2018), and [1], it may not be too hard to apply the method in [2] to improve classifier robustness. Therefore, it is questionable whether the additional information used in the generator of this paper helps and how it helps. I did not see any comparison in the experiments.\n\n2. Although the experiments look to be well conducted, it is not comprehensive enough. For the defence methods in comparison, only two approaches that fall into the exact same line of the proposed method are included. In this line, I think it is necessary to compare with [1], which combines various attacks. Moreover, I would also expect a comparison with other closely related methods such as [3] and [4], to further demonstrate the effectiveness of the proposed one.\n\n3. It is also suggested to do ablation tests on the inputs of the generator to see how each part of the inputs helps. If gradients and true label are removed from the generator, it reduces to [2]. Therefore, those ablation tests also help the comparison with [2].\n\nMinor comments:\n\n1. It could be interesting to visualise the perturbations that are generated from the generator.\n\n2. Some of the figures and captions are too small to see in a printout.\n\n\n[1] Tramèr, Florian, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh, and Patrick McDaniel. \"Ensemble Adversarial Training: Attacks and Defenses.\" (2018).\n\n[2] Xiao, Chaowei, Bo Li, Jun-Yan Zhu, Warren He, Mingyan Liu, and Dawn Song. \"Generating adversarial examples with adversarial networks.\" arXiv preprint arXiv:1801.02610 (2018).\n\n[3] Samangouei, Pouya, Maya Kabkab, and Rama Chellappa. \"Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models.\" (2018).\n\n[4] Matyasko, Alexander, and Lap-Pui Chau. \"Improved network robustness with adversary critic.\" In Advances in Neural Information Processing Systems, pp. 10578-10587. 2018.","sentences":[{"sentence_type":"2","sentence":"Therefore, it is questionable whether the additional information used in the generator of this paper helps and how it helps.","rephrased":"Therefore, it would be beneficial for the paper to provide a clearer explanation or evidence of how the additional information used in the generator contributes to the overall approach."},{"sentence_type":"1","sentence":"I did not see any comparison in the experiments.","rephrased":"Including comparisons in the experiments with relevant works could strengthen the paper's claims and provide a more comprehensive evaluation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1493,1617,"Not concerning"],[1618,1666,"Not concerning"]],"Comments":[]}
{"id":"7YggefBKGf","text":"Summary:  This paper proposes a domain-shift problem using fewer training examples. It suggests representation fusion as the concept of unifying and merging information from different layers of abstraction. \nCross-domain Hebbian Ensemble Few-shot learning (CHEF) is introduced for extracting features using representation fusion.  More importantly, CHEF does not need to backpropagate information through the backbone network.   CHEF  is applied to various cross-domain few-shot tasks and cross-domain real-world applications from drug discovery.\n\nStrong Points: 1-  The paper is well organized and easy to understand.\n2-  The model is evaluated in four benchmark datasets CropDisease, EuroSAT,  ISIC2018, and ChestX.  It also conducted experiments on two large scale datasets (prepared from ImageNet dataset), miniImagenet and tieredImagenet.  The proposed model shows consistent and promising performance in all datasets.  \n\n3- It introduced Hebbian learners for feature fusion that does not require backpropagation of error signals through the entire backbone network.  Only the parameters of the Hebbian learners need adjustment. Therefore it is speedy and versatile.\n\nWeaknesses: 1- The crucial contribution of this work is Hebbian Learner. Therefore it should devote more space for Hebbian Learner. The explanation about Hebbian Learner provided in this paper is not sufficient understanding to propose an approach clearly. I recommend the authors that include more description of Hebbian Learner.  I understand the space limit, but the model's crucial and essential contribution should be included in the main paper.\n2- This paper claims that using \"Hebbian Learner makes CHEF extremely fast,\" but I did not find any supporting experiments in the main paper to prove this statement. It should include results on time comparison.\n3- This paper performed the experiments on a few-shot learning setup for that chosen 5, 20, and 50 examples per class to train the model and observed continuous improvement on model performance. To show the limit of model performance, the experiments should also be performed using all available examples in the datasets.\n4-  authors have selected ResNet-12 as the backbone model; any specific reason for this? I wonder to see the model performance for more deep networks like ResNet-101 as the backbone model.\n5- It would be better to show the individual contribution of the Hebbian Learner. Therefore result should also be included in the ablation analysis section without using Hebbian Learner in the same setting.\n6-   On page#4, the authors have mentioned that \"We combine the NK feature vectors into a matrix Z ∈ R^ NK×D and initialize a weight matrix W ∈ R ^K×D.\"  But it is not mentioned about the initialization technique. Random initialization, Xavier initialization, etc. ?\n7- Some essential baseline approaches are missing for comparison, such as  \"Few-Shot Adversarial Domain Adaptation\" by Saeid Motiian et al. NIPS 2017.\n\n\nOverall: The paper needs to include many things for better clarity. I feel it provides some insufficient information or does not clearly explain the proposed model's crucial contribution. It needs to include experimental results for different settings, as I mentioned in the weaknesses section, to prove the model's efficacy. \n\n\n\n\n \n\n\n \n\n\n\n","sentences":[{"sentence_type":"2","sentence":"The explanation about Hebbian Learner provided in this paper is not sufficient understanding to propose an approach clearly.","rephrased":"The paper could benefit from a more detailed explanation of the Hebbian Learner to enhance the clarity of the proposed approach."},{"sentence_type":"2","sentence":"I feel it provides some insufficient information or does not clearly explain the proposed model's crucial contribution.","rephrased":"The paper would be improved by providing more comprehensive information and a clearer explanation of the proposed model's key contributions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1305,1429,"Not concerning"],[3042,3161,"Not concerning"]],"Comments":[]}
{"id":"SDX_gEuuOya","text":" ##########################################################################\n\nSummary:\n \nThis paper investigates several potential sources of sample-inefficiency and proposes an integrated algorithm to improve the sample-efficiency of model-based reinforcement learning. This paper builds upon Dreamer and incorporates sparse, self-supervised, contrastive model representations and efficient use of past experience. The experiments on DeepMind control suit show that the proposed method outperforms dreamer and the ablation study further verifies the contribution of each component of the proposed algorithm.\n\n##########################################################################\n\nPros: \n \n1. This paper tackles a valuable problem of improving the sample efficiency of model-based RL. \n\n2. The idea of incorporating sparse, perturbation-invariant, contrastive model representations and Prioritized experience replay is interesting and promising.\n \n3. The paper is well written and the results section is well structured. They outperform baseline methods on a popular benchmark and conduct an ablation study.\n \n##########################################################################\n\nCons: \n \n1. Novelty is limited. They use a series of techniques that have already been respectively proved to be useful. \n\n2. This paper has a much more complex architecture than Dreamer but the performance improvement is not very significant as shown in Figure 3 but\n3. The authors claim the contrastive and sparse representations are useful for sample-efficiency but they do not visualize and check the learned representations. They should first show their proposed loss functions can truly lead to more sparse and contrastive representations and then show such representations can contribute to improve the sample efficiency.\n\n##########################################################################\n\nQuestions and suggestions:\n1. In Section 2.2, why do the authors choose the model error for the sampling probability. Can you use the policy error or value error？\n\n2. As shown in Table 1, contrastive learning and L1 regularization can individually improve the performance, but why contrastive + L1 has a negative result? Can you give some insights?\n\n3. For Table 2, plots of learning rate will be more intuitive.\n\n4. How to determine the weighting factor in Equation 5?\n\n\n ##########################################################################\n\nMinor comments: \n1. There are too much white space on page 3.\n2. In Figure 2, it is better to compare ReaPER with Dreamer on the same state.\n3. In Table 1, what does “PER” mean?\n","sentences":[{"sentence_type":"2","sentence":"Novelty is limited. They use a series of techniques that have already been respectively proved to be useful.","rephrased":"While the paper builds on existing techniques, it would be beneficial to highlight the novel aspects of how these techniques are integrated and applied to the problem of sample efficiency."},{"sentence_type":"2","sentence":"This paper has a much more complex architecture than Dreamer but the performance improvement is not very significant as shown in Figure 3","rephrased":"The paper presents a more complex architecture compared to Dreamer, and it would be helpful to discuss the trade-offs between complexity and the observed performance improvements, as indicated in Figure 3."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1202,1310,"Not concerning"],[1316,1453,"Not concerning"]],"Comments":[]}
{"id":"t_SqOfi5Ik","text":"Authors present a machine learning, computer vision pipeline for FISH based HER oncogene detection and quantification in histopath images. \n\nThe paper is well written and easy to follow. \nEven if the technical contribution is limited, the main pitch of the paper is application novelty. The authors clearly present this in the paper and do not overclaim technical novelty. \n\nThe authors only provided performance for individual steps of the pipeline. End-to-end performance analysis should have been included. \n\nThe authors could have included a few more detail about the algorithm, such as the input size to individual networks, training parameters, etc..","sentences":[{"sentence_type":"1","sentence":"Even if the technical contribution is limited, the main pitch of the paper is application novelty.","rephrased":"While the technical contribution may be seen as incremental, the paper effectively emphasizes its novelty in application."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[188,286,"Not concerning"]],"Comments":[]}
{"id":"BkxyP8SZ9E","text":"The authors investigate the use of a structured generative model \nto perform demixing of data in an unsupervised way.\nThe paper is well written (clearly highlights the lack of supervision prevents training a conditional generative model, and how structure is here key for both learning the model and performing demixing at inference time), and has thorough experiments on simple datasets. \nThe main limitation - but one which the author recognize and start to investigate  - is that there are no guarantee the current structure is an inductive bias strong enough  to guarantee that the recovered separated signals correspond to the desired ones. \nI worry that for complex datasets the approach would not yield the desired results.\nAlso - one could argue the archetypal problem for source separation is the cocktail party problem - it would have been interesting to try some audio data.","sentences":[{"sentence_type":"2","sentence":"I worry that for complex datasets the approach would not yield the desired results.","rephrased":"It would be beneficial to see how the approach performs on more complex datasets to fully assess its robustness and effectiveness."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[647,730,"Not concerning"]],"Comments":[]}
{"id":"rJxkVRfTFB","text":"The paper models the neural architecture search (NAS) as a network pruning problem, and propose a method to sparsify the super-net during the search of architectures.\n\nOverall, the novelty in this paper is not strong and their experimental performance is weak compared with recently published papers. I do not see a need to have such a new algorithm in the NAS literature. Please see the question below:\n\nQ1. \"Bayesnas: a bayesian approach for neural architecture search\". ICML 2019\n- This paper also takes a pruning's perspective for NAS, but it is much more efficient than the proposed one. Would the authors have some discussion and experimental comparison with this paper? Specifically, Bayesnas considers more complex sparse patterns then the submission.\n\nQ2. \"adaptive stochastic natural gradient method for one-shot neural architecture search\". ICML 2019\n- Could the authors have some discussion with this paper? This paper has comparable performance, but it is also much faster.\n\nQ3. What are the benefits of the proposed method? \n- From Tables 2 & 3, the proposed method is not better than STOA on the accuracy or number of parameters. \n- CNAS + autoaugmented can offer better accuracy, but the comparison is not fair as different pre-processing method is used.","sentences":[{"sentence_type":"2","sentence":"Overall, the novelty in this paper is not strong and their experimental performance is weak compared with recently published papers.","rephrased":"While the paper presents an interesting approach, the novelty could be further highlighted, and the experimental performance may benefit from additional comparison with recent literature to underscore its strengths."},{"sentence_type":"3","sentence":"I do not see a need to have such a new algorithm in the NAS literature.","rephrased":"It would be helpful if the authors could further clarify the unique contributions and potential applications of their algorithm within the NAS literature."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[168,300,"Not concerning"],[301,372,"Not concerning"]],"Comments":[]}
{"id":"B1BFRS7ZM","text":"There may be some interesting ideas here, but I think in many places the mathematical\ndescription is very confusing and\/or flawed. To give some examples:\n\n* Just before section 2.1.1, P(T) = \\prod_{p \\in Path(T)} ... : it's not clear \nat all clear that this defines a valid distribution over trees. There is an\nimplicit order over the paths in Path(T) that is simply not defined (otherwise\nhow for x^p could we decide which symbols x^1 ... x^{p-1} to condition\nupon?)\n\n* \"We can write S -> O | v | \\epsilon...\" with S, O and v defined as sets.\nThis is certainly non-standard notation, more explanation is needed.\n\n* \"The observation is generated by the sequence of left most \nproduction rules\". This appears to be related to the idea of left-most\nderivations in context-free grammars. But no discussion is given, and\nthe writing is again vague\/imprecise.\n\n* \"Although the above grammar is not, in general, context free\" - I'm not\nsure what is being referred to here. Are the authors referring to the underlying grammar,\nor the lack of independence assumptions in the model? The grammar\nis clearly context-free; the lack of independence assumptions is a separate\nissue.\n\n* \"In a probabilistic context-free grammar (PCFG), all production rules are\nindependent\": this is not an accurate statement, it's not clear what is meant\nby production rules being independent. More accurate would be to say that\nthe choice of rule is conditionally independent of all other information \nearlier in the derivation, once the non-terminal being expanded is\nconditioned upon.\n\n","sentences":[{"sentence_type":"2","sentence":"There may be some interesting ideas here, but I think in many places the mathematical description is very confusing and\/or flawed.","rephrased":"While there are interesting ideas presented, the mathematical description could be clarified and strengthened in several sections."},{"sentence_type":"1","sentence":"This is certainly non-standard notation, more explanation is needed.","rephrased":"The notation used here appears to be non-standard and would benefit from additional explanation."},{"sentence_type":"2","sentence":"But no discussion is given, and the writing is again vague\/imprecise.","rephrased":"It would be helpful to include a discussion on this topic to provide clarity and precision in the writing."},{"sentence_type":"2","sentence":"this is not an accurate statement, it's not clear what is meant by production rules being independent.","rephrased":"The statement regarding the independence of production rules could be clarified to accurately reflect the intended meaning."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[544,612,"Not concerning"]],"Comments":[]}
{"id":"rJxofaHa_r","text":"This paper identifies an important weakness of batch normalization: it increases adversarial vulnerability. It is very well written and the claims are theoretically sound. In the experiments, the authors demonstrated a significant difference in robustness between networks with or without batch normalization layers, in varies settings against both random input noise and adversarial noise. This weakness of batch norm was explained due to the \"decision boundary tilting\" effect caused by the normalization. Overall, this paper has done solid work to reveal an interesting phenomenon. If it is true, this finding will impact almost all DNN models. \n\nMy concern is that this phenomenon is just another effect of \"gradient masking \" (as pointed out by Athalye, et al.). Batch norm is a well-known technique to avoid overfitting, without batch norm the network can be easily trained to be saturated with almost zero gradients, demonstrating a false signal of \"robustness\" to noise. The random noise and real-world corruption experiments are definitely helpful to clear this doubt, but only partially. My concern remains because of two obvious signs of  gradient masking: \n1. The accuracy on PGD-li (epsilon=0.031) attacks are suspiciously too high (20% - 40% Table 3\/4). For this level of attack, the acc should be nearly zero. This is likely caused by the gradient masking effect, considering the cifar-10 networks were trained for longer time with larger learning rate (150 epochs, fixed lr 0.01). Training on MNIST is much easier to get zero gradients.  \n2. The weight decay discussion is not helpful at all, on the contrary, it confirms my concern on the gradient masking effect. In Table 8, the robustness was increased ~40% by just using large weight decay. This is not the \"real robustness\", and can be easily evaded by adaptive attack (see Athalye's paper).\nWith the above two concerns in mind, I doubt the phenomenon revealed in this paper is just \"one can easily train a saturated model without batch norm\" or equivalently \"it's hard to train a saturated model with batch norm\". It is hard to say if this is a bad thing for batch norm.\n\nI am quite surprised that the authors ignore this completely. Here are a few things that can be done to rule out the possibility of gradient masking. The masked gradient can be identified by: 1) One-step attacks perform better than iterative attacks; 2) Unbounded attacks do not reach 100% success., etc (see Section 3.1 of Athalye's paper).\n1. Including FGSM in the experiments and show the same trends as PGD-li. \n2. Show two networks have similar gradient norms.\n3. Apply cw-l2 attack, and show batch norm has forced large perturbation.\n\nTwo other suggestions:\n1. Summarize the different angles\/steps taken to verify the phenomenon, somewhere before the experiments.\n2. Cannot see why the input dimension discussion contribute to explanations of the batch norm weakness.\n\n============\nMy rating stays the same after rebuttal. \n\nMy original concerns are like the other reviewers: why BN, not other techniques such as structure of DNNs MLP vs CNN vs ResNet, activation functions, weight decay, learning rates, softmax etc. My initial suspect was that it is caused by gradient masking likely caused by the l2 weight regularization, so asked the authors to look at the gradient norms and run some testes to rule this out. Yes, the weight norm is directly related to the Lipschitz continuity of the function represented by the network, but it often becomes more complicated on complex nonlinear neural networks. \n\nAccording to the new experiment results, the vulnerability is indeed not an effect of gradient masking, thanks for the clarification. However, the new results also indicate that the finding is susceptible to both weight decay and learning rate: in Figure 16 (a): \"Un PGD\" < \"BN PGD\" before learning rate decay, andFigure 17 (a) vs (b), doubling the weight decay penalty to 1e-3 also increases the vulnerability of BN. Overall, I believe the phenomenon exists, but the reasons behind requires more explanations, at least not just the batch norm.","sentences":[{"sentence_type":"2","sentence":"The weight decay discussion is not helpful at all, on the contrary, it confirms my concern on the gradient masking effect.","rephrased":"The discussion on weight decay could be expanded to better address potential concerns regarding the gradient masking effect."},{"sentence_type":"2","sentence":"I am quite surprised that the authors ignore this completely.","rephrased":"It would be beneficial if the authors could address this aspect in their discussion to provide a more comprehensive analysis."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1558,1680,"Not concerning"],[2144,2205,"Maybe"]],"Comments":[]}
{"id":"0S1-PSG2-e","text":"The paper tackles an important issue, namely how to tune the step sizes in SGD during the training, trying to approximate step sizes which would be used in GD (even though the search direction is still noisy). Relevant prior work is cited. The method is simple and easy to understand. Step sizes are kept piecewise constant over updates. New batches are sampled, and the loss values along the search line are fitted with a low-order polynomial. There is some heuristic to choose the interval around 0 for the step. Importantly, these batches are sampled from the validation set. While this sounds very elaborate to find the minimum of the approximation, they later say they are just trying for sufficient descent along the line. Compared to previous work, the method is simple and seems quite robust. As drawbacks, the method seems pretty expensive, and it has a large number of free parameters that need to be chosen.\n\nA major weakness of the paper is the empirical evaluation. The comparison to related work in 3.1 is a bit meaningless, because they look at validation error. Now, their method uses the validation set extensively (to sample batches), while the others do not, so the comparison is flawed. One would have to evaluate on an independent test set. What is also really missing here are figures about the extra amount of time required. My suspicion is that PLS is quite a bit cheaper than what they do here, even though admittedly it needs specific implementations (which, for TensorFlow, are provided by the authors).\nThen, in 3.2, they do not compare against this related work anymore. Why not? Again, I am missing a proper quantification of extra cost. It is also unclear how the many free parameters of their heuristic are chosen. For Figure 6 left, it is hard to understand why there is this difference. The reason is buried in the text somewhere: \"To determine whether to measure a new step size...\". This describes a rule for how often to update step size, and it again has unspecified free parameters. For Figure 6 right: This comparison is meaningless unless the stopping criteria for all methods are clearly stated. If ELF is using *extra* batch evaluations to adjust learning rate, it must be slower than ADAM or SGD if the same number of epochs are done. What takes the extra time for ADAM and SGD? Do they run more epochs? If so, what is the stopping rule? If that rule depends on validation error, the comparison is flawed (see above), because ELF accesses the validation set a lot, while ADAM and SGD do not (except for initial HPO). Or do they all run the same number of epochs? If so, what takes the extra time for ADAM and SGD? If this is some initial HPO, it has to be clearly specified, as it could range from cheap to very expensive depending on what is done.\n\nGiven these issues, I feel the work cannot be properly evaluated. My recommendation is to (a) clearly quantify the extra cost for all methods compared, (b) to compare against PLS and GOLS1 everywhere, (c) to be very specific about how training is stopped when comparing training runtime, and (d) to evaluate metrics on a dataset that ELF has no access to.\n\nSince ELF seems quite expensive, it would be useful to try and see what can be done with batch losses evaluated along the training trajectory, instead of having to sample independent ones. They should also test how few batch losses are needed to still get good behaviour. In general, some ablation studies are needed that would drive down extra compute and check how fast this can be made.\n","sentences":[{"sentence_type":"2","sentence":"The comparison to related work in 3.1 is a bit meaningless, because they look at validation error.","rephrased":"The comparison to related work in section 3.1 could be more meaningful if it included an analysis based on an independent test set, rather than solely on validation error."},{"sentence_type":"1","sentence":"My suspicion is that PLS is quite a bit cheaper than what they do here, even though admittedly it needs specific implementations (which, for TensorFlow, are provided by the authors).","rephrased":"It would be beneficial for the paper to include a cost analysis comparing PLS and the proposed method, especially since specific implementations for TensorFlow are provided by the authors."},{"sentence_type":"2","sentence":"This comparison is meaningless unless the stopping criteria for all methods are clearly stated.","rephrased":"To enhance the validity of the comparison, it would be helpful to clearly state the stopping criteria for all methods."},{"sentence_type":"3","sentence":"Given these issues, I feel the work cannot be properly evaluated.","rephrased":"Addressing these issues would enable a more thorough evaluation of the work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[979,1077,"Maybe"],[1348,1530,"Not concerning"],[2042,2137,"Maybe"],[2794,2859,"Not concerning"]],"Comments":[]}
{"id":"Hke1_V2qnm","text":"In this paper, the authors proposed a unified framework which computes spectral decompositions by stochastic gradient descent. This allows learning eigenfunctions over high-dimensional spaces and generating to new data without Nystrom approximation. From technical perspective, the paper is good. Nevertheless, I feel the paper is quite weak from the perspective of presentation. There are a couple of aspects the presentation can be improved from. \n\n(1) I feel the authors should formally define what a Spectral inference network is, especially what the network is composed of, what are the nodes, what are the edges, and the semantics of the network and what's motivation of this type of network.\n\n(2) In Section 3, the paper derives a sequence of formulas, and many of the relevant results were given without being proven or a reference. Although I know the results are most likely to be correct, it does not hurt to make them rigorous. There are also places in the paper, the claim or statement is inclusive. For example, in the end of Section 2.3, \"if the distribution p(x) is unknown, then constructing an explicitly orthonormal function basis may not be possible\". I feel the authors should avoid this type of handwaving claims.  \n\n(3) The authors may consider summarize all the technical contribution in the paper. \n\nOne specific question:\n\nWhat's Omega above formula (6)? Is it the support of x? Is it continuous or discrete? Above formula (8), the authors said \"If omega is a graph\". It is a little bit confusing there. ","sentences":[{"sentence_type":"2","sentence":"Nevertheless, I feel the paper is quite weak from the perspective of presentation.","rephrased":"However, I believe there is room for improvement in the clarity and structure of the presentation."},{"sentence_type":"1","sentence":"There are also places in the paper, the claim or statement is inclusive.","rephrased":"There are sections in the paper where the claims or statements could be more explicitly defined."},{"sentence_type":"2","sentence":"I feel the authors should avoid this type of handwaving claims.","rephrased":"It would be beneficial for the authors to provide more substantial evidence or reasoning for such claims."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[297,379,"Not concerning"],[940,1012,"Not concerning"],[1172,1235,"Not concerning"]],"Comments":[]}
{"id":"HkxkY2T8KE","text":"The authors try to unify different algorithms for sequence generation and present a generalized entropy regularized policy optimization formulation. They show that divergent algorithms can be reformulated as special instances of the framework,\nwith the only difference being the configurations of reward function and a couple of hyperparameters.\n\nThe analysis and proposed framework are interesting. \n\nI have several technical questions. \n\n1. One cercen about the work is that the formulation in Eq. (1) is not natrual and it is not reasonable intuitively. Which one is the final model, q or \\theta?  According to previous description, \\theta is the model (or model parameters). However, for MLE, when \\alpha->0, \\theta will not make any impact to the reward defiend in Eq. (1), and only q determines the reward. That is, optimizing L(q,\\theta) will only update q but not \\theta. \n\n2. \"Generally, a larger exploration space would lead to a harder training problem.\" I don't get this point.  \"common rewards (e.g., BLEU) used in policy optimization are more smooth than the \u000e-reward, and permit exploration in a broader space.\"  If BLEU is more smooth, why leads to a harder training problem? ","sentences":[{"sentence_type":"2","sentence":"One cercen about the work is that the formulation in Eq. (1) is not natrual and it is not reasonable intuitively.","rephrased":"I have a concern regarding the formulation in Eq. (1); it seems somewhat counterintuitive. Could you clarify whether q or \theta is the final model?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[443,556,"Not concerning"]],"Comments":[]}
{"id":"xb6stKM-O3T","text":"The paper is of good quality, clear, and well-written. The authors clearly explained their motivation, addressed the shortcomings of previous methods, and touch upon all the necessary architectures. I would like to bring up a few important points that require attention.\n\n1. I'm a bit confused about the design of the constant variables $\\alpha$ and $\\epsilon$. In order to obtain a positive value, $\\alpha$ is set to a positive multiplication of a hyperbolic tangent function. However, some further clarification would be greatly appreciated.\n\n2. I highly appreciate the way all the methodologies are being explained with proper figures and equations.\n\n3. Based on the data presented in Figure 4, the figures depicting the data fitting during training are in perfect alignment with the observed data points. I am curious if dropouts were utilized in the model and, if not, whether overfitting occurred. It would be greatly appreciated if the authors could provide their insight on this matter.\n\n4. Based on Figure 5, the forecasting accuracy of $I, R, D$ for three different months appears to be relatively consistent when compared to actual observations.\n\n5. One of the pros of this paper is that the authors discussed the main limitation of PINNs and how requirement of prior knowledge could be a constraint while solving problems and potentially may impact accuracy if underlying epidemiological laws are poorly understood or data inconsistencies exist. \n\nThis paper on PINNs for infectious diseases is commendable, delivering accurate weekly forecasting results. While other studies have explored physics-informed neural networks in various compartmental models, such as SIR, SIRS, and SEIRM, this research stands out by successfully delivering on its initial claims.","sentences":[{"sentence_type":"1","sentence":"I'm a bit confused about the design of the constant variables $\\alpha$ and $\\epsilon$.","rephrased":"Could you please provide additional clarification on the design of the constant variables $\\alpha$ and $\\epsilon$?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[275,361,"Not concerning"]],"Comments":[]}
{"id":"XYY9b6aXaey","text":"This paper is clearly not ready for publication. It has a number of extremely large issues. The only strength of the paper is that the task of learning human guides from visual inputs is potentially interesting. However, otherwise the execution of this paper is very flawed.\n- Why just Angry Birds? The evaluation should be much more thorough than a single game.\n- While they have a dataset of human guides for each level, it's extremely small, with only a few hundred levels total. \n- The evaluation is generally sparse and uncompelling. They have no quantitative metrics at all, their qualitative evaluation is not impressive, and their evaluation is based on an extremely small number of examples anyway.\n- The paper also doesn't even seem complete. There are only 3 sections, a bit over 5 pages, etc.\n\nI have a number of other concerns, but these are enough to make this paper seem like a clear reject.","sentences":[{"sentence_type":"2","sentence":"This paper is clearly not ready for publication.","rephrased":"This paper appears to require significant revisions before it is ready for publication."},{"sentence_type":"2","sentence":"The evaluation is generally sparse and uncompelling.","rephrased":"The evaluation could be more comprehensive and persuasive."},{"sentence_type":"2","sentence":"The paper also doesn't even seem complete.","rephrased":"The paper seems to be incomplete and could benefit from additional sections and content."},{"sentence_type":"3","sentence":"I have a number of other concerns, but these are enough to make this paper seem like a clear reject.","rephrased":"While I have additional concerns, addressing the major issues outlined could improve the paper's viability for publication."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[0,48,"Confirmed"],[49,274,"Missed by Model"],[486,538,"Maybe"],[539,707,"Missed by Model"],[710,752,"Confirmed"],[806,906,"Maybe"]],"Comments":[]}
{"id":"S1eEnWqJqV","text":"This paper proposes two methods to extend recent work in filtering SMC-based variational objectives to the smoothing case. The first approach is a Monte Carlo objective (MCO) based on Forward Filtering Backward Smoothing (FFBS), and the second technique gives the SMC proposal distribution access to all observations. The authors evaluate both techniques experimentally and find that the FFBS-based technique does not perform well, while giving the proposal access to all observations improves performance on several tasks. \n\nWhile the paper is generally written well and easy to follow, the main technique (giving the proposal access to all observations) has been presented previously in the literature and is misrepresented as a smoothing algorithm when it is not.\n\nTo expand on these points:\n\n1. Filtering Variational Objectives (Maddison et al. 2017) section 6.4 presents experiments that run FIVO with a proposal that conditions on the state of a bidirectional RNN run over the observations. They find that it does not reliably help on their tasks.\n2. Changing the information that the proposal distribution has access to does not change SMC’s sequence of target distributions. If only the proposal is changed and the form of the weights is not changed, then the algorithm is still based on filtering SMC and is not smoothing. Unfortunately, it is not entirely clear what SMC scheme the authors use with the new proposal. It seems that they use the future-conditioned proposal with the weights defined in equation (12), but if this is not the case it should be clarified. \n\nFurther feedback:\n\n1. As discussed in Maddison et al. 2017, an MCO based on filtering SMC cannot become tight, even when q is set to the true smoothing distribution. Because of this, it is useful to compare the performance of the proposed algorithm to the IWAE bound (with the same proposal) which can become tight and allow the proposal to make full use of the information available to it. The authors should consider incorporating this comparison in their experiments.\n2. On page 4 the authors state “As with the IWAE, increasing K yields a tighter bound L_SMC defined below”. I am not aware of a proof that L_SMC is provably tighter as K increases. The authors should provide a proof or citation or remove the statement.\n3. There is prior work on developing variational objectives based on smoothing SMC, including  \n\nGraphical model inference: Sequential Monte Carlo meets deterministic approximations, Lindsten et al 2018 \nTwisted Variational Sequential Monte Carlo, Lawson et al. 2018  \n\nThe authors should consider incorporating this in their related works.\n\nOverall, it is still interesting to consider why an MCO based on filtering SMC would perform better when the proposal is given access to all observations. If the authors change their paper to address the points above, I will consider changing my score.\n","sentences":[{"sentence_type":"2","sentence":"Unfortunately, it is not entirely clear what SMC scheme the authors use with the new proposal.","rephrased":"It would be helpful if the authors could clarify which SMC scheme is used with the new proposal."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1332,1426,"Not concerning"]],"Comments":[]}
{"id":"SC2yW2Mfgwt","text":"The paper contains two curriculum learning algorithms of which one assume knowledge of the parameters found by the baseline, uniform-sampling, model to push updates in that direction, and the second orders images according to an increasing stddev\/entropy of pixels. While the first approach is impractical because of the strong assumption, the second approach demonstrates small gains that lie within random variance (Fig. 5, Fig. 6) and would be not straight-forward to apply to non-image data e.g. text. These reasons make the paper hard to accept.\n\nThe main problem is knowing the parameters of the baseline, SGD, optimization. It's not clear why would one even need optimization again, if (a good enough) result is already known and gains from this re-optimization do not significantly improve over this baseline. The speedups mentioned in the abstract (45% and 43%) could not be located in the results in main body of the paper. How were they measured? Even if aligning updates with the SGD-trained parameters does speed up convergence, re-training from scratch will cost 143% of baseline time instead of 43%, as the standard training needs to be counted too.\n\nIssues include:\n- How to sample using \\rho_{t,i}? It's not a distribution and can be negative.\n- Figure 1: Judging from the plot, the vanilla curve converges faster than the curriculum. How can one see the >40% curriculum speed up?\n- Abstract's claim of removing noise is only supported in Section 4 through citing related works. Also, more evidence would be needed to call k a regularizer.\n- lines 9-10 in Algorithm 1 would interfere with bucketing in seq2seq applications and adversely affect performance.\n\nRegarding related work in Sec. 3: I couldn't confirm in (Graves et al, 2017) that they also sort examples by difficulty.\n\nThe last approach to define curriculum through statistical quantities makes sense, in principle, although the difference between curves in Fig. 5 is very small and could be caused by random variance as the error bars on Fig. 5 and Fig. 6 show. Another problem is that it's straight-forwardly applicable only to images and not categorical data, like text. \n\nOne suggestion of possible paper improvement: consider swapping and reworking sections 5 and 3, so that the content of sec. 5 becomes the main proposal and a reworked sec. 3 - its analysis. There one could analyze if the example ordering according to stddev does bias updates towards some \"good\" point of convergence, with one possible definition of \"good\" according to (now, unknown during optimization) SGD results.\n\nOther minor remarks:\n- \"greedy approach\" is mentioned multiple times before being explained on page 4. Consider deferring the use of term to that place.\n- Contributions: useful is a vacuous word, consider dropping it.\n- notation: square brackets used to denote several objects - sequences [B1, B2, ..] , ranges [T] and vectors [x1, x2, .. ]. Using different brackets could be better.\n- well-known concepts:\n  * no need to define stddev and mean in (2)\n  * (Arora, 1981): if entropy requires a citation at all then citing Shannon directly would be more appropriate.\n- Sec. 2: curriculum is defined by two functions -> we define curriculum by two functions\n- conclusion: display -> show\n- while CL indicate that -> while CL indicates that\n- judicial ordering -> judicious ordering\n\n=== After rebuttal ===\n\nThank you for your answers. I'm keeping the rating at 3.\n\n1)+2). I'm still not convinced that it's fair to claim an improvement of X% for a curriculum that, relying on final weights of a \"vanilla\" SGD-trainedmodel, converges in _additional_ X% to the 100% of \"vanilla\" time.\n\n3). Fair enough, but the revised draft still reads like examples are sampled from it.\n\nI double checked the context of citing (Graves et al, 2017) and believe it's still imprecise as in the original draft.","sentences":[{"sentence_type":"2","sentence":"The main problem is knowing the parameters of the baseline, SGD, optimization. It's not clear why would one even need optimization again, if (a good enough) result is already known and gains from this re-optimization do not significantly improve over this baseline.","rephrased":"A key concern is the necessity of knowing the parameters of the baseline, SGD, optimization. It would be beneficial for the paper to clarify the rationale for re-optimization when the results from the baseline are already established, especially if the improvements are not substantial."},{"sentence_type":"1","sentence":"The speedups mentioned in the abstract (45% and 43%) could not be located in the results in main body of the paper. How were they measured?","rephrased":"I was unable to find the speedups of 45% and 43% mentioned in the abstract within the main body of the paper. Could you please clarify how these figures were measured?"},{"sentence_type":"2","sentence":"Even if aligning updates with the SGD-trained parameters does speed up convergence, re-training from scratch will cost 143% of baseline time instead of 43%, as the standard training needs to be counted too.","rephrased":"It would be helpful to consider that even if aligning updates with the SGD-trained parameters accelerates convergence, the total computation time, including re-training from scratch, may exceed the baseline by a significant margin, which could be a point of further discussion."},{"sentence_type":"1","sentence":"Figure 1: Judging from the plot, the vanilla curve converges faster than the curriculum. How can one see the >40% curriculum speed up?","rephrased":"In Figure 1, it appears that the vanilla curve converges more quickly than the curriculum. Could you provide further explanation on how the curriculum achieves a speed up of over 40%?"},{"sentence_type":"1","sentence":"Abstract's claim of removing noise is only supported in Section 4 through citing related works. Also, more evidence would be needed to call k a regularizer.","rephrased":"The abstract's claim regarding noise removal seems to be primarily supported by references to related works in Section 4. It may strengthen the paper to provide additional evidence to substantiate the role of k as a regularizer."},{"sentence_type":"2","sentence":"lines 9-10 in Algorithm 1 would interfere with bucketing in seq2seq applications and adversely affect performance.","rephrased":"It would be worth discussing how lines 9-10 in Algorithm 1 might interact with bucketing in seq2seq applications, as there could be implications for performance that merit further exploration."},{"sentence_type":"1","sentence":"Regarding related work in Sec. 3: I couldn't confirm in (Graves et al, 2017) that they also sort examples by difficulty.","rephrased":"In Section 3's discussion of related work, I was unable to verify the claim that (Graves et al, 2017) also sorted examples by difficulty. Could you please clarify this point?"},{"sentence_type":"1","sentence":"The last approach to define curriculum through statistical quantities makes sense, in principle, although the difference between curves in Fig. 5 is very small and could be caused by random variance as the error bars on Fig. 5 and Fig. 6 show.","rephrased":"The approach of defining curriculum through statistical quantities is conceptually sound. However, the small differences observed in Fig. 5 might benefit from further analysis to determine if they are significant or could be attributed to random variance, as suggested by the error bars in Fig. 5 and Fig. 6."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[552,817,"Not concerning"],[818,957,"Not concerning"],[958,1164,"Not concerning"],[1263,1397,"Not concerning"],[1400,1556,"Not concerning"],[1559,1673,"Not concerning"],[1675,1795,"Not concerning"],[1797,2040,"Not concerning"]],"Comments":[]}
{"id":"wSwnm2j-31w","text":"**Summary**\nMany modern classifiers are trained with class labels - it's natural because you train the model with precisely the target label you want the model to produce! But let's think out of the box and introduce stronger forms of supervision - e.g. bounding boxes for the object of interest. What benefits will they bring? The paper is arguing that the added strong supervision (boxes on top of ImageNet dataset) helps image classifiers reduce their over-confidence. This is done by training the classifier with the **adaptive label smoothing**, where each CNN input is assessed according to the actual proportion of the foreground object and the target vector is label smoothed to reflect the proportion.\n\n**Pros**\nThe paper is one of those papers which dig into the overlooked bits in the widespread practice. Given that the point is valid and solidly tested under extensive experiments, the paper is likely to leave a strong mark in the research community, providing researchers and practitioners chances to re-think about their habits and hidden assumptions. This paper has great potential to guide the researcher in such a direction. I believe we can also learn from this paper potentials to use strong supervision for improving not only the main task performance (e.g. classification) but also guide \"how\" the models should achieve the recognition - e.g. by improving the input attribution (explainability), robustness (adversarial and natural), bias (e.g. texture or bg bias), and uncertainty (as done in this paper).\n\n**Cons**\nIt is a little unfortunate that the paper falls short in terms of presentation and experimental depth. It is not fully convincing yet that the proposed solution is working, given the width and depth of experiments. I would highly suggest the authors re-structure the paper and add substantially more experimental validations for the next paper. Below are more specific comments on the weaknesses.\n\n1. **The proposed adaptive label smoothing actually worsens many of the key performance metrics.**\nIn Table 1, we observe that compared to \"hard label\" (0.669 top-1 accuracy), \"A. L. S.\" (or adaptive label smoothing) has only 0.655 top-1 accuracy on ImageNet validation set. It is a bit difficult to swallow the result, given that ALS is **requiring more annotation budgets** (bounding boxes) to prepare the training set. It is not only the main task where ALS is falling short. Also on calibration metrics (ECE and MCE), ALS is doing **worse** than the baseline, with higher ECE and MCE measures (lower is better). The authors argue that ALS successfully decreases the overconfidence, which is true indeed, but this is only half of the story! By decreasing the overall confidence, ALS turns out to further decrease confidence in correct prediction (underconfidence scores). Table 1 seems to suggest that ALS is actually not working.\n\n2. **Given the breadth and ramifications of the claim (see pros above), the set of experiments seems limited (only ImageNet + ResNet50 + COCO transfer learning).**\nGiven that the issue 1 above is resolved, I would still suggest doing more experiments on more datasets (e.g. OpenImages?) and more architectures (e.g. Other ResNet or EfficientNet families) to ensure that ALS is actually working, independent of the specific dataset-architecture pair.\n\n3. **Structure the paper better.**\nThe paper spends multiple paragraphs repeating points that are already made (sections 1,2) and spends so little on important implementation details and evaluation setups (section 4). There are seven paragraphs in section 1 - please aim to make it four paragraphs. This will include moving the experimental analysis on the confidence scores to section 4 (introduction is not a good place to already talk about numbers!). Try to shorten the six paragraphs in section 2 into three paragraphs. \nThe paper will now be only 6.5-7 pages long. With the remaining pages, describe the following in greater details:\n- The different splits of ImageNet-1K training set: please give them names & use the designated names in Tables 1&2.\n- Write down the precise implementation details and the definitions of evaluation metrics in 4.2 (e.g. ECE, MCE, under\/overconfidence) instead of referring readers to the previous papers. Please indicate whether higher or lower values are better (also in the tables).\n- When discussing the results, please talk about **all** the results for all evaluation metrics, instead of just overconfidence, as done in section 4.2. Please also talk with numbers, instead of just saying e.g. \"these results have a low overconfidence score\".\n\n4. **Nits**\n* When I checked last time, ImageNet training set had **42%** images annotated with bounding boxes. Is **38%** (section 4.1) correct?\n* (Lin et al., 2014) --> MS COCO (Lin et al., 2014) \n* described in -2 --> described in table 2\n* allows the CNNs to cheat: I find it difficult to agree with that statement. There are many papers saying the use of context has helped a lot in their application scenarios. Please tone it down.\n\n5. **Final idea to throw**\nDid you consider using unsupervised objectness methods - like Edgebox, Selective search, MCG object proposals? Or saliency detection methods (https:\/\/paperswithcode.com\/task\/salient-object-detection)? Being able to use them will replace your need for bounding box supervision.\n\n**Key reasons for the rating**\n\nWhile the paper has and triggers many great ideas for researchers in this field, the experimental results are not supporting the main idea and claims. The presentation is quite a bit of an issue too. My suggestion is to substantially improve and scale-up the experiments for the next conference.\n\n**Response to the last comments made by the authors**\nThe referenced paper (https:\/\/arxiv.org\/pdf\/1906.04933.pdf ) is not answering the question I have. Nor does section 4.2.\n\nMy question is: does ALS really improve the quality of uncertainty?\n\nThe paper's answer seems to be no.\n\nLook at Tables 1, 2, 3, and 4 in the revised paper. It is great that ALS achieves a lower O.conf (overconfidence), meaning that for wrong predictions, ALS helps to produce lower confidence values. However, this comes at the cost of higher U.conf (underconfidence), meaning that even for correct predictions, ALS makes the model produce low confidence values. A confidence measure that always produces a low value, regardless of whether the prediction was correct or not, is not useful.\n\nThe authors may say \"look at Table 1 - our uncertainty measure produces lower scores for images with objects removed\". While this is true and it is a good signal, object removal is only a particular case for introducing uncertainty in an image. Eventually, I believe a good uncertainty measure should first of all produce a good ranking of test images such that the correctly predicted images are ranked first (this paper does not quantify this). Then comes the question of calibration (like ECE and MCE). Then comes the evaluations with specific uncertainty scenarios (like OOD images, object removal, or other controls on image uncertainty).","sentences":[{"sentence_type":"2","sentence":"It is a little unfortunate that the paper falls short in terms of presentation and experimental depth.","rephrased":"The paper could benefit from improvements in presentation and further experimental depth."},{"sentence_type":"2","sentence":"It is not fully convincing yet that the proposed solution is working, given the width and depth of experiments.","rephrased":"The proposed solution would be more convincing with a broader and deeper set of experiments."},{"sentence_type":"2","sentence":"I would highly suggest the authors re-structure the paper and add substantially more experimental validations for the next paper.","rephrased":"I recommend that the authors consider restructuring the paper and including more experimental validations in future work."},{"sentence_type":"2","sentence":"It is a bit difficult to swallow the result, given that ALS is **requiring more annotation budgets** (bounding boxes) to prepare the training set.","rephrased":"The results may raise questions, especially since ALS requires additional annotation resources for the training set."},{"sentence_type":"2","sentence":"Table 1 seems to suggest that ALS is actually not working.","rephrased":"Table 1 raises concerns about the effectiveness of ALS in its current form."},{"sentence_type":"1","sentence":"allows the CNNs to cheat: I find it difficult to agree with that statement.","rephrased":"The assertion that CNNs are 'cheating' may not fully capture the complexity of the issue, and I would suggest a more nuanced discussion."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1540,1642,"Maybe"],[1643,1754,"Maybe"],[1755,1884,"Confirmed"],[2213,2359,"Not concerning"],[2813,2871,"Not concerning"],[3359,3541,"Missed by Model"],[4855,4930,"Not concerning"],[5538,5586,"Missed by Model"]],"Comments":[]}
{"id":"YqPiQ6AOu0x","text":"Strength:\n- The paper is written in clear manner.\n- The proposed method is easy-to-implement in NP schemes.\n- The code is also provided together for the reproducibility.\n\nWeakness:\n- The novelty is somewhat limited, that this is a direct utilization of Neural Bootstrapper.\n- I'm confused on the message of the paper. In Fig 1, the authors argue that the baselines (1) overfits the data from the linear regression samples, and (2) are incapable of capturing uncertainty. However, in Fig 3, the proposed NeuBANP seems overfitted and the baselines seems that they can capture the uncertainty (at least) in interpolation. If I missed something, please let me know.\n\n\n","sentences":[{"sentence_type":"2","sentence":"The novelty is somewhat limited, that this is a direct utilization of Neural Bootstrapper.","rephrased":"While the paper builds on existing work, such as the Neural Bootstrapper, it would be beneficial to clarify and emphasize the novel contributions of your approach."},{"sentence_type":"1","sentence":"I'm confused on the message of the paper.","rephrased":"The message of the paper could be made clearer, particularly in how the figures support the main arguments."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[183,273,"Not concerning"],[276,317,"Not concerning"]],"Comments":[]}
{"id":"S1e-YHZ2tE","text":"Summary:\n\nThe authors argue that distribution shift can be detrimental when doing semi-supervised learning. As a simple fix, they propose to not share batchnorm statistics between labeled and unlabeled data. They show consistent improvement for the case where little unlabeled data contains examples for the classes of which labels are present.\n\nNovelty:\n\nThe idea to have separate batchnorm parameters seems natural and also seems to work for the problem described here. However, conditional batchnorm is a well-known technique in general so the overall novelty is limited.\n\nRating:\n\nThe overall empirical results are consistent and testing on common perturbations is very insightful. I think the paper is not outstanding, but a simple and valuable contribution to the workshop.","sentences":[{"sentence_type":"2","sentence":"The idea to have separate batchnorm parameters seems natural and also seems to work for the problem described here. However, conditional batchnorm is a well-known technique in general so the overall novelty is limited.","rephrased":"While the application of separate batchnorm parameters is a logical step for the problem at hand and shows effectiveness, it should be noted that conditional batchnorm is a recognized technique in the field. This context may affect the perception of novelty, but it does not diminish the practical contribution of this work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[356,574,"Not concerning"]],"Comments":[]}
{"id":"5fZ8FOFhs","text":"The quality and clarity are high in this work. \nPros: \nThe method is designed for unsupervised lesion or outlier detection.\nOnly normal data is utilized in the training of the reconstruction network.\nThe method achieves better mean absolute errors of dice prediction under different levels of adversarial attack.\n\nCons:\nThe performance is evaluated on the adversarial attacks. The performance on lesion and outlier is not evaluated.","sentences":[{"sentence_type":"1","sentence":"The performance is evaluated on the adversarial attacks. The performance on lesion and outlier is not evaluated.","rephrased":"While the performance under adversarial attacks is well evaluated, it would be beneficial to also include an evaluation of the performance on lesion and outlier detection."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[320,432,"Not concerning"]],"Comments":[]}
{"id":"HJeAzEJQqS","text":"This works presents a method for inferring the optimal bit allocation for quantization of weights and activations in CNNs. The formulation is sound and the experiments are complete. My main concern is regarding the related work and experimental validation being incomplete, as they don't mention a very recent and similar work published in ICIP19 https:\/\/ieeexplore.ieee.org\/document\/8803498: \"Optimizing the bit allocation for compression of weights and activations of deep neural networks\". A reference in related work as well as a comparison in experimental validation would be necessary  and the novelty of this work is rather weak given the above mentioned 2019 publication.","sentences":[{"sentence_type":"2","sentence":"My main concern is regarding the related work and experimental validation being incomplete, as they don't mention a very recent and similar work published in ICIP19 https:\/\/ieeexplore.ieee.org\/document\/8803498: \"Optimizing the bit allocation for compression of weights and activations of deep neural networks\".","rephrased":"I would recommend including a discussion of the related work, particularly a recent publication in ICIP19, which seems closely related to your study. This could strengthen your literature review and provide a more comprehensive experimental validation."},{"sentence_type":"2","sentence":"the novelty of this work is rather weak given the above mentioned 2019 publication.","rephrased":"It would be beneficial to more clearly articulate the novel contributions of your work, especially in light of the similar study published in 2019."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[182,492,"Not concerning"],[596,679,"Not concerning"]],"Comments":[]}
{"id":"SyRcMDPeG","text":"SUMMARY \n\nThe model is an ANN whose units have the absolute value function abs as their activation function (in place of ReLU, sigmoid, etc.). The network has bi-directional connections (with equal weights) between consecutive layers, but it operates only in one direction at a time. In the forward direction, it is a feed-forward net from image to classification (say); in the reverse direction, it is a feed-forward net from classification to image. In both directions it operates in supervised fashion, trained with backpropagation (subject to the constraint that the weight matrix is symmetric). In the forward direction, the activation vector y over the classification layer is L2-normalized so the activation of a class c is the cosine of the angle between y and the 1-hot vector for c.\nAlthough there is a reverse pass through the net, the training loss function is not adversarial; the loss is just the classification error in the forward pass plus the reconstruction error in the backward pass.\nThe generalization accuracy in classification on 42k-image MNIST is 97.4%.\n\nSTRENGTHS\n\n* Comparisons are made of the reconstruction performance with the proposed abs activation function and with ReLU on one or both passes, and a linear activation function.\n* The model has the virtue of simplicity, as the authors point out.\n\nWEAKNESSES\n\n* The discussion of evaluation of the model is weak. \n  - No baselines are given. (A kaggle leaderboard shows the 50th-ranked model at 97.8% and the top 8 models at 100%.)\n  - The paper talks of a training set and a \"dev\" set, but no test set, and generalization performance is given for the dev set rather than a test set.\n  - No quantitative evaluation of the reconstruction (backward pass) performance is given, just by-eye comparison of the reconstruction error through figures.\n  - Some explanation is needed of why the ReLU cases were fatally plagued with NaN errors.\n* Claims of interpretability advantage seem unwarranted since the claimed interpretability applies to any classification ANN, as far as I can see.\n* The work seems to be at too preliminary a stage to warrant acceptance at ICLR.","sentences":[{"sentence_type":"2","sentence":"The discussion of evaluation of the model is weak.","rephrased":"The discussion of the model's evaluation could be more comprehensive and detailed."},{"sentence_type":"2","sentence":"The work seems to be at too preliminary a stage to warrant acceptance at ICLR.","rephrased":"The work may benefit from further development and additional results to strengthen the submission for acceptance at ICLR."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1344,1394,"Maybe"],[2065,2143,"Not concerning"]],"Comments":[]}
{"id":"rJxpiIYr5r","text":"The paper presents a model that, given parallel bilingual data, separates the common semantics from the language-specific semantics on a sentence level. \n\nOverall the presentation is clear and the experiments show gains over the baselines. One major point of confusion however is that, while early on in the paper (introduction), it is stated repeatedly that one of the strengths of the proposed model is that it is sensitive to word order on a sentence level, this particular aspect of the model is neither evaluated nor analysed. Instead the empirical analysis focuses on sentence length, punctuation and semantics. The analysis of all these three aspects is superficial: for sentence length, it consists of  computing the sentence mean and median; for punctuation,  it consists of masking punctuation; and the last part just computes vectors of nouns only (and states that this is \"semantics\"). But there is no analysis per se.\n\nOverall, the paper presents a model and shows gains over baselines. The extent to which these gains are due to tuning as opposed to the inherent design of the model is not clear. The analysis is superficial.\n","sentences":[{"sentence_type":"2","sentence":"The analysis of all these three aspects is superficial: for sentence length, it consists of computing the sentence mean and median; for punctuation, it consists of masking punctuation; and the last part just computes vectors of nouns only (and states that this is \"semantics\"). But there is no analysis per se.","rephrased":"The analysis could be deepened to provide more insights. For instance, beyond computing sentence mean and median for sentence length, a more detailed statistical analysis could be beneficial. Similarly, for punctuation, exploring the impact of punctuation beyond masking could be informative, and a more comprehensive approach to semantics, beyond just computing vectors of nouns, would strengthen the analysis."},{"sentence_type":"2","sentence":"The analysis is superficial.","rephrased":"The analysis would benefit from a more detailed examination to fully showcase the model's capabilities."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1111,1139,"Maybe"]],"Comments":[]}
{"id":"Jrd2km6-jP_","text":"This paper provide a method for high-order structure prediction problem. Specifically, the paper first defines a high-order structure on graphs named graph simplicial complex (GSC). Then the paper introduces a feature generation method used for the high-order structures. The features are also used in the proposed method for high-order structure prediction. The proposed method is based on a nonparametric kernel which carries the feature similarities of high-order structures. With this kernel the method uses a Bernoulli distribution for the prediction of the existence of the high-order structure in unseen times. \n\nIn my opinion, the paper has the following strengths and weaknesses. \n\nFor strengths, first, the kernel estimator based method does not require learning process and shows good efficiency in the prediction tasks. The kernel estimator also plays an important role in capturing the high-order interactions in the evolving graphs. Second, the paper provides with theoretical analysis on the consistency and asymptotic normality of the proposed kernel estimator. The theories show possibility of inferring the estimation error and the confidence intervals for predictions. \n\nFor weaknesses, first, the paper ought to make further clarification on the essential differences (and maybe even better, the advantages) between the defined GSC with the traditional high-order structures, such as simplex, hyperedges, or just small graphs. Also experimentally the paper should show more of the advantages of using GSCs. For example, the experiment only use d=1 and 2. Perhaps the experiment should show its advantage when dealing with much higher-order structure predictions rather than these simple cases. Second, the presentation of the paper needs further polish. The paper defines notations on-the-fly, and it makes the readers not easy to follow. For example, if we only look at the notations related to G, there are G_t, G_{-}^{(d)}, G_{t,p}, G'_t(), G_t(d), G_{t-}^{(d)}, and they are defined here and there in Section 3. The readers will need to make their own notation table just to follow the paper. I personally failed at looking for the definition of G_{t-}^{(d)}. In Definition 3, it looks like it is a vertex set, but in the time complexity analysis it becomes a number.  Also, in the time complexity analysis, does the complexity of counting number of simplices of each d need to be considered? Third, for the experiments, the paper should consider using more dynamic methods of link prediction especially when you are only comparing the results of prediction lower-order structures. In Table 1, what is the runtime for baselines, training or making predictions? Overall the experiments need to be more concrete. Last but not least, this paper might not be a good fit for ICLR community since it does not focus on the representation learning methods. ","sentences":[{"sentence_type":"2","sentence":"The paper defines notations on-the-fly, and it makes the readers not easy to follow.","rephrased":"The paper could benefit from a more systematic approach to defining notations, which would enhance readability and comprehension for the readers."},{"sentence_type":"2","sentence":"I personally failed at looking for the definition of G_{t-}^{(d)}.","rephrased":"I had difficulty locating the definition of G_{t-}^{(d)}, which suggests that the notation could be clarified or indexed more effectively."},{"sentence_type":"3","sentence":"Last but not least, this paper might not be a good fit for ICLR community since it does not focus on the representation learning methods.","rephrased":"While the paper presents valuable insights, it may benefit from aligning more closely with the representation learning methods that are the focus of the ICLR community."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1774,1858,"Maybe"],[2117,2183,"Not concerning"],[2735,2872,"Not concerning"]],"Comments":[]}
{"id":"VGjNO-JQmFu","text":"$\\textbf{Strengths}$\nStrengths can be summarized as below:\n* **Clarity** This paper is well organized and easy to follow.\n* **Rationality** The assumptions adopted in this paper are either commonly used in the literature of non-convex\noptimization or has theoretical\/empirical validations. I didn't observe major flaws in the theories as well as proofs.\n\n* **Quality** Overall, this is a novel work that provides insights on understanding the convergence behavior of label smoothing regularization. When optimizing with SGD, it is theoretically depicted that an appropriate LSR which reduces the variance can speed up convergence and require less sample complexity.\n\n$\\textbf{Weaknesses}$\n* **The threshold of $\\delta$ in Theorem 3** In Theorem 3, the threshold of $\\delta$ is shown to be $\\frac{\\epsilon^2}{4\\sigma^2}$ in order to reach an $\\epsilon-$stationary point. Note that this threshold is dependent on $\\epsilon$, it seems that the condition $\\delta\\leq\\frac{\\epsilon^2}{4\\sigma^2}$ might be hard to achieve. It would be better if the authors could provide me with more explanations or empirical validations regarding this threshold.\n* **Estimation of $T_1$**  One potential weakness of this work is the estimation of $T_1$. Clearly, if we adopt a smaller value of $T_1$, the performance of TSLA is very likely to perform worse than learning without LSR. And if estimate $T_1$ is larger than its theoretical form, the convergence (training time) of TSLA will be longer. Besides, I feel like the estimation of $T_1$ is a tough task. Thus, I think this might be a potential weakness. \n* **Ablation study of $\\theta$** In Table 3, as mentioned by authors, large $\\theta$ (i.e., $\\theta>0.4$) frequently results in the worse performance of TSLA than LSR for different value of $T_1$. It seems that a good performance of TSLA relies on the quality of $\\theta$ and $T_1$.   ","sentences":[{"sentence_type":"1","sentence":"It would be better if the authors could provide me with more explanations or empirical validations regarding this threshold.","rephrased":"It would be helpful if the authors could provide additional explanations or empirical validations to clarify the threshold of \\\\$\\delta\\\\$ in Theorem 3."},{"sentence_type":"1","sentence":"Besides, I feel like the estimation of $T_1$ is a tough task.","rephrased":"Additionally, the estimation of \\\\$T_1\\\\$ appears to be a challenging aspect that could be further elaborated."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1018,1142,"Not concerning"],[1479,1540,"Not concerning"]],"Comments":[]}
{"id":"SJe6g59diN","text":"This paper considers real-life planning problems characterized by temporal\/numeric constraints and analyses its resolution process via a forward-search planning strategy based on a step-by-step application of a Linear-Programming (LP) procedure for consistency checking.   On one hand, the LP checking performed during the search process allows the pruning of many infeasible branches; on the other, it does carry high computational costs. In this paper authors investigate the possibility for the planners to call the LP solver less often and using, at each search step, a cheaper consistency check based only on the STP (Simple Temporal Problem) constraints.\n\nThe paper is well written and well organized and proposes a relevant topic to the workshop. Despite the proposed results seems relevant for the specific area of application considered in the work, given the use of an STP solver as a basic mechanism for  consistency checking is common in several timeline-based planners, it could generate a limited interest in the workshop participants.","sentences":[{"sentence_type":"2","sentence":"Despite the proposed results seems relevant for the specific area of application considered in the work, it could generate a limited interest in the workshop participants.","rephrased":"While the proposed results are relevant for the specific area of application considered in the work, it would be beneficial to highlight how these findings could engage a broader audience at the workshop."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"GI_orRBYT","text":"When there is no ground truth, it is difficult to directly train a CNN to do deblurring.\nThis paper use delurring result from another method, and simulate blurred input using a physical model. \nIn this way, the paired image follows the physical model of blurring.\n\nPros:\nThe method respects the physics in MRI. And the result is very promising. \n\nCons: \n(Minor) The first experiment did not compare with Lim et al., 2019a.","sentences":[{"sentence_type":"1","sentence":"This paper use delurring result from another method, and simulate blurred input using a physical model.","rephrased":"The paper innovatively uses deblurring results from another method and simulates blurred input using a physical model."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[89,192,"Not concerning"]],"Comments":[]}
{"id":"H1gUBpm8KV","text":"This paper provides an adaptation of the minimum description length (MDL) principle in computational neuroscience to propose a new attention mechanism for deep neural networks (DNN), whether in a supervised, unsupervised, or reinforcement learning setting. The authors name this attention mechanism \"regularity normalization\". \n\nAs of now, the manuscript suffers from many imprecisions and inaccuracies, thus hindering its eloquence.\n\nFirst of all, the authors equate MDL with negative log-likelihood (NLL), but nowhere in the text do they make this connection explicit. Yet, there is a considerable body of literature in minimizing negative log-likelihood for unsupervised learning applications. Maybe i am missing an important distinction between MDL and NLL, but even then, the authors should clarify that distinction.\n\nThe definition of the universal code \\bar{P}(x) is unclear, and there is no justification of the existence of such universal code.\n\nThe following sentence is quite mysterious: \"the compressibility of the model will be unattainable for multiple inputs, as the probability distributions are different\". It is impossible to know what these \"multiple inputs\" and \"different probability distributions\" are.\n\nMany of the claims in the paper lack a proper definition of their terms. An example is: \"The normalized maximum likelihood minimizes the worst case regret with the minimax optimal solution\". This sentence is very opaque given that the authors haven't explained how they compute regret, what \"worst-case\" means, and thus what \"minimax\" corresponds to in their specific setting. The authors should not leave to reader's guesswork the understanding of these technical terms.\n\nThe introduction of the paper is well written. The discussion of prior literature, especially in the field of neuroscience, is solid. However, the presentation of the new contribution is too vague to redeem the lack of convincing experimental evidence for its success.\n\nFor example, Algorithm 1 (Regularity Normalization) relies heavily on the computation of complexity (COMP in Equation 2), but this equation is not self-contained. On the left-hand side, there is a model class \\Theta. On the right-hand side, there are samples x. How does x relate to \\Theta? Is the equation integrated over the probability distribution X of the data? None of these questions are properly answered in the text. Therefore, the algorithm is not reproducible. This problem is not limited to Equation (2). Equation (3) is also very difficult to understand, with a dummy variable x_j in the denominator summing up to \"0 ... i\".\n\nAlthough this paper exhibits a relatively original and interesting idea for training deep neural networks, i do not recommend it for publication, because it is still in an immature stage. I would recommend the authors to carry out further research, both theoretical and experimental, on regularity normalization, and submit an updated version of this paper in the near future.","sentences":[{"sentence_type":"2","sentence":"As of now, the manuscript suffers from many imprecisions and inaccuracies, thus hindering its eloquence.","rephrased":"The manuscript could benefit from addressing certain imprecisions and inaccuracies to enhance its clarity."},{"sentence_type":"2","sentence":"The following sentence is quite mysterious: \"the compressibility of the model will be unattainable for multiple inputs, as the probability distributions are different\". It is impossible to know what these \"multiple inputs\" and \"different probability distributions\" are.","rephrased":"The statement regarding model compressibility and multiple inputs could be clarified further, particularly how it relates to varying probability distributions."},{"sentence_type":"1","sentence":"Many of the claims in the paper lack a proper definition of their terms.","rephrased":"It would be helpful if the paper provided more precise definitions for the terms used in its claims."},{"sentence_type":"2","sentence":"The authors should not leave to reader's guesswork the understanding of these technical terms.","rephrased":"The authors could enhance the paper by explicitly defining the technical terms to facilitate the reader's understanding."},{"sentence_type":"2","sentence":"However, the presentation of the new contribution is too vague to redeem the lack of convincing experimental evidence for its success.","rephrased":"Strengthening the presentation of the new contribution and providing more experimental evidence could substantiate its success."},{"sentence_type":"2","sentence":"Therefore, the algorithm is not reproducible.","rephrased":"Clarifying these aspects could greatly improve the reproducibility of the algorithm."},{"sentence_type":"2","sentence":"i do not recommend it for publication, because it is still in an immature stage.","rephrased":"I believe that the manuscript would benefit from further development before it is ready for publication."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[329,433,"Not concerning"],[955,1224,"Not concerning"],[1226,1298,"Not concerning"],[1603,1697,"Not concerning"],[1833,1967,"Not concerning"],[2395,2440,"Not concerning"],[2715,2795,"Not concerning"]],"Comments":[]}
{"id":"SJyMoI5gG","text":"This paper shows that an idealized version of stochastic gradient descent converges when learning autoencoders with ReLu non-linearities under strong sparsity assumptions. Convergence rates are also determined. The result is another one in the emerging line of proving convergence guarantees for non-convex optimization problems arising in machine learning, and aims to explain certain phenomena experienced in practice.\n\nThe paper is generally nicely written, providing intuitions, but there are several typos (both in the text and in the math, e.g., missing indices), which should also be corrected.\n\nOn the negative side, while the proof technique in general looks plausible, there seem to be some mistakes in the derivations, which must be corrected before the paper can be accepted. Also, the assumptions in the in the paper seem quite restrictive, and their implications are not discussed thoroughly. \n\nThe assumptions are the following:\n1. The input data is coming from a mixture distribution, in the form x=w_I + eps, where {w_1,...,w_k} is a collection of unit vectors, I is uniform in {1,...,K}, eps is some noise (independent for each sample). \n2. The maximum norm of the noise is O(1\/k).\n3. The number n of hidden neurons in the autoencoder is Omega(k) (this is not explicitly assumed but is necessary to make the probability of \"incorrect\" initialization small as well as the results to hold).\n\nUnder these assumptions it is shown that the weights of the autoencoder converge to the centers {w_1,...,w_k} (i.e., for any i the autoencoder has at least one weight converging to w_i). The rate of convergence depends on the coherence of the vectors w_i: the less coherent they are the faster the convergence is.\n\nFirst notice that some assumptions are missing from the main statement, as the error probability delta is certainly connected to the probability of incorrect initialization: when n=1<k, the convergence result clearly cannot hold. This comes from the mistake that in Theorem 3 you state the bound for the probability P(F^\\infty) instead of the conditional probability P(F^\\infty|E_o) (this is present everywhere in the proof). Theorem 3 should also depend on delta_o, which is used in the definition of F^\\infty. \n\nTheorem 2 also seems incorrect. Intuitively, the question is why it cannot happen that two neurons contribute to reproducing a given w_i, and so neither of their weights converge to w_i: E.g., assuming that {w_1,...,w_k,w_1',...,w_k'} form an orthogonal system and the noise is 0, the weight matrix of size n=2k defined as W_{2i-1,*}^T = 1\/sqrt{2}(w_i + w'_i) and W_{2i,*}^T=1\/sqrt{2}(w_i - w'_i), i \\in [k], with 0 bias can exactly recover any x=w_i (indeed, W_{2j-1,*} x= W_{2j,*} x = 1\/sqrt{2}, while the other products are 0, and so W^T W x = W^T W w_j = 1\/sqrt{2}(W_{2j-1,*}+W_{2j,*})^T = w_j). Then SGD does not change the weights and hence cannot recover the original weights {w_i }, in particular, it cannot increase the coherence in any step, contradicting Theorem 2. This counterexample can be extended even to the situation when k>d, as--in fact--we only need that the existence of a single j such that w_j and w'_j are orthogonal and also orthogonal to the other basis vectors.\n\nThe assumptions are also very strange in the sense that the norm of the noise is bounded by O(1\/k), thus the more modes the input distribution has the more separable they become. What motivates this scaling? Furthermore, the parameters of the algorithm for which the convergence is claimed heavily depend on the problem parameters, which are not known. How can you instantiate the algorithm then (accepting the ideal definition of b)? What are the consequences?\n\nGiven the above, at this point I cannot recommend the paper for acceptance. However, if the above problems are resolved, I would be very happy to see the paper at the conference.\n\n\nOther comments\n-----------------------\n- Add a short derivation why the weights of the autoencoder should converge to the w_i.\n- Definition 3: C_j is not defined in the main text.\n- While it is mentioned multiple times that the interesting regime is d<n, this is actually never used, nor needed (personally, I have never seen such an autoencoder--please give some references). What is really needed is n>k, which is natural if one wants to preserve the information, and also k>d for a rich family of distributions.\n- The area of the spherical cap is well understood (up to multiplicative constants), and better bounds than yours are readily available: with a cap of height 1-t, for sqrt{2\/d}<t<1, the relative surface of the cap is between P\/6 and P\/2 where \nP=1\/(t \\sqrt{d}) (1-t^2)^{(d-1)\/2}; see, e.g., A. Brieden, P. Gritzmann, R. Kannan, V. Klee, L. Lovasz, and M. Simonovits. Deterministic and randomized polynomial-time approximation of radii. Mathematika. A Journal of Pure and Applied Mathematics, 48(1-2):63–105, 2001. \n- The notation section should be brought forward (or referred the fist time the notation is actually used).\n- Instead of unit spherical Gaussian you could simply say uniform distribution on the unit sphere\n- While Algorithm 1 is called \"norm-controlled SGD training,\" it does not control the norm at all.\n\n\n","sentences":[{"sentence_type":"1","sentence":"The assumptions are also very strange in the sense that the norm of the noise is bounded by O(1\/k), thus the more modes the input distribution has the more separable they become.","rephrased":"The assumptions regarding the noise norm being bounded by O(1\/k) are intriguing and may warrant further discussion to clarify how this affects the separability of the input distribution as the number of modes increases."},{"sentence_type":"2","sentence":"Given the above, at this point I cannot recommend the paper for acceptance.","rephrased":"Based on the concerns outlined, I would suggest addressing these issues to strengthen the paper's candidacy for acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[3228,3406,"Not concerning"],[3691,3766,"Not concerning"]],"Comments":[]}
{"id":"rygvK39V2m","text":"ML models are trained on a predefined dataset formed by a set of classes. Those classes use to be the same ones for training and testing. However, what happen when during testing time images with classes unseen during training are shown to the model? This article focus in this problem which is not currently taking much attention by the mainstream research community and is of great importance for the real world applications.\n\nThis article tries to detect areas of the image where those out-of-distribution situations appear in semantic segmentation applications. The approach used is by training a classifier that detects which pixels are out of distribution. For training two datasets are used: the dataset of interest and another different one. The classifier learns to detect if a pixel is from the dataset of interest or from another distribution.\n\nThe main problem I found with this article is that I couldn't fully understand it. Maybe because the text needs a bit more of review and improvement or maybe because Im not very familiar with the topic. Moreover the article is 10 pages while it is encouraged to be 8. I find that the method of the paper is quite simple and can be explained more straight forward and in less pages. The related work section overlaps a lot with the intro, I suggest to combine both. First two paragraphs of the method seam that should be in the intro. Model details from the experiments I consider that should be explained in the method. I miss a figure explaining the architecture of the model. Why using the semantic segmentation model proposed and no something standard? For instance Tiramisu (That is also based on dense layers). Note that the method used for semantic segmentation is 10 points lower than the SOTA in Cityscapes. Figure 1 is impossible to read as the captions are too small. The representations of figures 2-5 are difficult to interpret. There is no comparison to SOTA\n\n","sentences":[{"sentence_type":"2","sentence":"The main problem I found with this article is that I couldn't fully understand it.","rephrased":"The main challenge I encountered with this article was difficulty in comprehension, which may be due to the need for further clarification in the text or my own unfamiliarity with the topic."},{"sentence_type":"2","sentence":"I find that the method of the paper is quite simple and can be explained more straight forward and in less pages.","rephrased":"I believe the method described in the paper could be articulated more concisely, potentially reducing the length of the manuscript."},{"sentence_type":"1","sentence":"Note that the method used for semantic segmentation is 10 points lower than the SOTA in Cityscapes.","rephrased":"It is worth noting that the performance of the method for semantic segmentation is currently 10 points below the state-of-the-art as benchmarked on Cityscapes."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[856,938,"Not concerning"],[1124,1237,"Not concerning"],[1672,1771,"Not concerning"]],"Comments":[]}
{"id":"7gLnIIPnjoM","text":"The report reproduces the result of the CVPR 2021 paper titled \"Lifting 2D StyleGAN for 3D-Aware Face Generation\".\n\nScope of reproducibility: The study shows that the qualitative and quantitative results in the original paper are reproducible. Beyond that, the paper explores the performance of the model on a different dataset showing its generalizability. \n\nCode: The authors have provided their code and they have reused the code of the authors mostly. They did not present results for which the code was not available.\n\nCommunication with original authors: Authors were in touch with the original authors all along.\n\nHyperparameter Search: The authors use the same hyperparameters as the original paper. \n\nAblation Study: The authors included the ablation study from the paper.\n \nDiscussion on results and Recommendations for reproducibility: The authors present a brief discussion of the results showing that the results were easy to reproduce. They claim that the paper was well written and code availability made it easy, but they do not provide more details beyond this. They vaguely mention that there were a few issues that the original authors helped resolve.\n\nResults beyond the paper: The authors present a small extension to the authors' work on cat faces. \n\nOverall organization and clarity: The paper does not provide much clarity or lacks in the following:\n* The parts of the original paper that were hard to reproduce. \n* The scope of this work seems limited given that the code was available and the original authors were able to clarify any missing information in the paper.  \n","sentences":[{"sentence_type":"2","sentence":"The paper does not provide much clarity or lacks in the following:","rephrased":"The paper could benefit from additional clarity in the following areas:"},{"sentence_type":"2","sentence":"The scope of this work seems limited given that the code was available and the original authors were able to clarify any missing information in the paper.","rephrased":"While the scope of this work is clear, future efforts could explore further applications or challenges, especially considering the availability of the code and the support from the original authors."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1307,1373,"Not concerning"],[1440,1594,"Not concerning"]],"Comments":[]}
{"id":"wySQifgFACp","text":"The main contribution of this paper is to propose new regularization methods in deep neural networks that produce well-calibrated probability scores. The authors argue that regularization is better than post-processing, such as temperature scaling, because temperature scaling would require a separate dataset for calibration. In addition, regularization is added to the loss so it does not alter other components of the neural network. There are two forms of regularization that the authors propose: (1) regularizing in the function space, and (2) in the probability space.  Interestingly, they show that both regularization methods yield well-calibrated scores, which cannot be attributed to minimizing the norm of the weights alone.\n\nWhile the contribution above is interesting, it is unfortunate that the paper digresses to unrelated topics and is quite hard to understand in a few places. Some of its claims can be misleading as well. For example, the title of the paper and its abstract suggest that regularization during training is \"required\" but the authors only show that there exists certain forms of regularization that are *sufficient* but not necessary. In fact, as the authors mention, a simple technique like temperature scaling performs equally well as their proposed method. In addition, some of the claimed contributions are not novel or new. It is known that probability scores of neural networks are not well-calibrated because the cross entropy loss and the expressive power of neural nets lead neural nets to make overconfident predictions on the training sample. So, the first contribution stated in Page 2 is not a new contribution to be precise.\n\nIn Section 2, the authors look into the fact neural nets make confident predictions on the training sample. This entire section is chatty, imprecise, and is not necessary for the main contribution of the paper (which is in Section 3). Some issues with Section 2 include: \n- The authors speak of \"optimal confidence\" without defining it. I originally thought that the optimal confidence of predicting y=1 is itself the true probability p(y=1|x) but Figure 2(c) shows that the authors have a different definition in mind, which they do not explain. \n- The authors use a cyclic argument to explain why neural nets are overly confident on their predictions. In the paragraph below Eq 3, he authors argue that given that *we know* that neural nets perfectly fits the training examples, the upper bound on the loss in Eq 3 suggests that the predictions must match with the true labels. But that's a cyclic argument because you used the conclusion as a premise. \n- There is a lengthy discussion about a \"divisor\" (alpha) that is not defined formally in the paper. \n- In the text, the authors state that the x-axis of the Figure 2(c) is the test accuracy, written as E_{y|x} 1_y(m_x), but the legend says it is the \"correct probability.\" Which one is it? \n- What is LL in Figure 2(a)? I could not find it in the text or the figure caption. \n\nAs mentioned earlier, the primary contribution is Section 3.2. The experimental results are interesting. But, the authors later mention that a simple technique like temperature scaling would achieve similar results. Given that temperature scaling does not require any hyper-parameter to tune, I am not sure if the proposed method would be useful in practice. Unfortunately, the authors do not show how sensitive their results are to their hyper-parameters. \n\nRegarding out-of-distribution detection, I personally do not agree that it should be used as a method for evaluating confidence scores. Suppose the data comes from a mixture of two Gaussians and you learn the mixture using expectation maximization. That algorithm would give good estimates of the probability scores because it estimates the means and covariance matrices of two Gaussian densities. However, if the distribution changes, i.e. we now have a different mixture of Gaussians, then the algorithm would still make many confident predictions that are wrong simply because the distribution has changed. That does not mean the algorithm is not well-calibrated to the distribution it was trained on.\n\nIn summary, the paper makes interesting contributions. It proposes a new method of learning well-calibrated probability scores using new forms of regularization but it is suitable for publication in its present form. \n","sentences":[{"sentence_type":"2","sentence":"While the contribution above is interesting, it is unfortunate that the paper digresses to unrelated topics and is quite hard to understand in a few places.","rephrased":"While the contribution is interesting, the paper could benefit from a more focused narrative and clearer explanations in certain sections."},{"sentence_type":"2","sentence":"Some of its claims can be misleading as well.","rephrased":"Additionally, some claims may benefit from further clarification to avoid potential misunderstandings."},{"sentence_type":"2","sentence":"In addition, some of the claimed contributions are not novel or new.","rephrased":"Furthermore, it would be helpful to distinguish more clearly between the contributions that are novel and those that build upon existing knowledge."},{"sentence_type":"3","sentence":"This entire section is chatty, imprecise, and is not necessary for the main contribution of the paper (which is in Section 3).","rephrased":"This section could be more concise and directly relevant to the main contribution of the paper outlined in Section 3."},{"sentence_type":"2","sentence":"Unfortunately, the authors do not show how sensitive their results are to their hyper-parameters.","rephrased":"It would be beneficial if the authors could provide an analysis of the sensitivity of their results to the chosen hyper-parameters."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[737,893,"Maybe"],[894,939,"Not concerning"],[1293,1361,"Not concerning"],[1781,1907,"Confirmed"],[3366,3463,"Not concerning"]],"Comments":[]}
{"id":"TrJS-nja7vd","text":"Summary:\nThis paper aims to learn the first control-centric vision-language representation for general-purpose control. To achieve it, the author proposed the LIV, a unified objective for vision-language representation and reward learning from action-free videos with text annotations. The experimental results in some target domain environments validate the effectiveness of the proposed approach, especially in the comparison of CLIP.\n\nOverall, I really liked this paper. And I think it is very important to learn a general control representation in RL, and this paper attempts to achieve it.\n\nStrong points: \n1. The motivation of this paper is exciting.\n2. The proposed LIV approach to learning the control-centric vision-language representation is making sense.\n3. The experimental results validate the effectiveness of the proposed approach. \n\nWeak points:\n1. I can not find the details of reward learning. \n\n\n","sentences":[{"sentence_type":"1","sentence":"I can not find the details of reward learning.","rephrased":"The paper could be improved by providing more details on the reward learning aspect."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[865,911,"Not concerning"]],"Comments":[]}
{"id":"rklpFLlUY4","text":"This paper proposes an empirical validation of the reinforced variation inference method proposed by Weber et al. 2015, as a  good candidate for transferring existing policy optimization techniques from variational inference.\nThe results, however, are not consistent, this work reports reasonable results on qualitative experiments, but quantitative experiments suggest that this approach does not perform better than handcrafted proposals on experiments with random walks. Furthermore, experiments with Chi-squared showed that is not a better alternative than KL-divergence.\n\nThis paper provides preliminary results on an interesting topic but with inconclusive remarks, I believe further investigation should be done, in particular regarding the effect of performing RVI on real VI problems and comparing against different VI approaches not only random MC. It would be interesting to understand where does this approach fail, for which cases? It is also not clear why the finetuned approach fails when compared with the simple pretrained model. How different is the proposed approach from Weber 2015? I believe a remark in the related work would better help understand the differences.\nIs RVI leveraging techniques from policy optimization, such as GAE and A3C, it would be interesting to see whether this is helping in the future. \n\nThis paper is written clearly and provides a thorough explanation of results, although some details could be clarified, such as more information on how the model is pretrained and fine tuned?  why would this objective be a wrong objective function? (5.4), and what are the family of proposal distributions  (q_theta) adopted. \n\nI believe this paper provides \n\nMinor revisions:\nequation equation -> equation (2.1)\namd -> and (5.4)\naas -> as (FigureS1)","sentences":[{"sentence_type":"2","sentence":"The results, however, are not consistent, this work reports reasonable results on qualitative experiments, but quantitative experiments suggest that this approach does not perform better than handcrafted proposals on experiments with random walks.","rephrased":"While the results show some promise, there appears to be inconsistency. The qualitative experiments yield reasonable outcomes, but the quantitative data indicates that this method may not outperform traditional handcrafted proposals in random walk experiments."},{"sentence_type":"1","sentence":"Furthermore, experiments with Chi-squared showed that is not a better alternative than KL-divergence.","rephrased":"Additionally, the Chi-squared experiments suggest that this method may not be a superior alternative to KL-divergence, which could be an area for further exploration."},{"sentence_type":"1","sentence":"It is also not clear why the finetuned approach fails when compared with the simple pretrained model.","rephrased":"It would be beneficial for the paper to provide more insight into why the finetuned approach does not yield better results compared to the simple pretrained model."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[226,473,"Not concerning"],[474,575,"Not concerning"],[945,1046,"Not concerning"]],"Comments":[]}
{"id":"rken2bFEcS","text":"Summary:\nThis paper presents an argument that massively overparameterized neural networks trained with gradient descent on a supervised learning problem with convex loss function will converge. It argues that by mapping each model to a truncated Fourier series we can recover a canonical representation for the functions in the model space. Viewing this as a linear map at each point in parameter space and assuming that this matrix is always full rank, they claim convergence of gradient descent.\n\n\nDecision:\nThis paper should be rejected because it lacks originality, the assumptions are often too strong, and the rigor of some claims is questionable.\n\nMain argument:\nOriginality:\nThis is the main issue with the paper. Several papers, for example the ones from Allen-Zhu et al. and Du et al. cited in the paper, have shown that gradient descent on supervised learning provably converges for massively overparameterized neural networks. Not only that, but those works give rigorous proofs of their claims and even handle issues like step size, convergence rates, and precise conditions on the size and architecture of the neural network. This paper does not attempt to handle any of these details, claiming to simplify the proof. To me the proof is only simplified since the details are all omitted.\n\nAssumptions:\nThe main way that details are avoided is by adding a strong assumption that the “disparity matrix” remains full rank over the course of training. This assumption is not supported in an empirical or formal way, but rather by appeal to some vague argument in section 3 that since the matrix is likely to be full rank at initialization, it is likely to remain so for large enough networks. \n\nRigor:\nAs explained above, many details are omitted in favor of strong assumptions, but there are also some technical details that I think may be wrong. On page 2, it is claimed that the mapping from Lambda_M to L^1 is surjective, this is not true. Every function in L^1 can be approximated by some function in Lambda^M, but for finite M this map cannot be surjective. Another similar issue arises in the proof of Theorem 1 when it is claimed that there is a unique theta_epsilon corresponding to each f. This is again false since by truncating the Fourier series, infinitely many functions will get mapped to the same truncation (when they only differ in the higher coefficients). These issues make me question the validity as well as the originality of the arguments presented.\n\n\nAdditional feedback:\n- I saw a few spelling and grammatical errors. For example: in the abstract the tenses alternate between present and past almost every sentence (“we have proved” should be “we prove”),  page 2 “parametarize”, page 3 “serie”, page 5 “distint”, page 7 “Liptschitz”, section 3.3 title should be “when does” not “when do”.","sentences":[{"sentence_type":"2","sentence":"This paper should be rejected because it lacks originality, the assumptions are often too strong, and the rigor of some claims is questionable.","rephrased":"The paper might benefit from further exploration of originality, a more balanced approach to assumptions, and additional rigor in supporting its claims."},{"sentence_type":"2","sentence":"To me the proof is only simplified since the details are all omitted.","rephrased":"The simplification of the proof appears to stem from the omission of certain details, which could be more thoroughly addressed."},{"sentence_type":"2","sentence":"This assumption is not supported in an empirical or formal way, but rather by appeal to some vague argument in section 3 that since the matrix is likely to be full rank at initialization, it is likely to remain so for large enough networks.","rephrased":"The assumption that the 'disparity matrix' remains full rank could be strengthened with empirical evidence or a more formal justification, particularly in relation to the arguments presented in section 3."},{"sentence_type":"2","sentence":"These issues make me question the validity as well as the originality of the arguments presented.","rephrased":"Addressing these issues could enhance the validity and potentially the originality of the arguments presented."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[510,653,"Maybe"],[1232,1301,"Not concerning"],[1462,1702,"Maybe"],[2387,2484,"Confirmed"]],"Comments":[]}
{"id":"JBrSzRyHul","text":"(+) An exhaustive validation of different experimental setups for liver lesion segmentation and classification on a self-collected database is provided.\n\n(+) Figure 1 nicely summarizes the tasks and experimental setups.\n\n(+\/-) The paper is mostly well written. However, I would recomment to restructure Section 2. Your paper is of type well-validated application. Thus, first describing the given segmentation and classification tasks and the collected data and afterwards experimental setups seems more resonable to me. In general, the paper focuses too much on the methodology of transfer and joint learning to my opinion.\n\n(-) Your motivation is quite weak. Why is such an automatic classification approach required? Please specify in abstract\/introduction.\n\n(-) No comparison to existing approaches on liver lesion segmentation (e.g. winners of the LiTS Challenge) is performed.\n\n(-) Transfer, joint and multi-task learning are well known approaches to deal with limited data. No methodical tricks are presented. \n\n(-) \"The  first  framework  incorporates  a  multi-task  U-Net, [...]\" This is confusing, as Figure 1 shows the multi-task approach as third framework.","sentences":[{"sentence_type":"2","sentence":"Your motivation is quite weak.","rephrased":"The motivation could be strengthened by clarifying the necessity of an automatic classification approach in the abstract or introduction."},{"sentence_type":"2","sentence":"No methodical tricks are presented.","rephrased":"It would be beneficial to include some innovative methodological techniques to address the issue of limited data."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[630,660,"Maybe"],[981,1016,"Not concerning"]],"Comments":[]}
{"id":"244u53IS73s","text":"## Summary\nThis paper provides a novel algorithm to estimate the optimal value of $n$ for $n$-step temporal difference methods. The paper derives an optimal value of $n$ based on minimizing a bias term, then utilizes intuition to derive an online approximation algorithm. The paper compares its adaptive $n$-step algorithm against fixed $n$-step values with both DQN and SAC empirically on several domains.\n\n## Review\n\n### Summary\nI am recommending a reject for this paper. The paper is built from the assumption that \"the underlying mechanism of why $n=3$ performs better than one-step temporal difference is still unclear.\" However, the paper misses a discussion on the well-understood bias-variance tradeoff present with $n$-step methods. I do not find that the paper provides any clarity or novelty in the _understanding_ of $n$-step methods. Although the proposed algorithm is novel, I remain unconvinced by the empirical demonstration and the lack of theoretical support for the algorithm.\n\nTo increase my rating of the paper, I would have liked to have seen at least some of:\n * A discussion and analysis of the bias\/variance properties of the proposed algorithm.\n * A proof that the proposed algorithm has better bias\/variance properties than a naive fixed $n$ approach.\n * A statistically sound empirical investigation of the proposed algorithm (even if on smaller domains, like tabular gridworlds).\n * Fewer meta-parameters for the proposed approach.\n * A sensitivity analysis of the meta-parameters for the proposed approach.\n\n### Theory\nThe theoretical components of the paper were largely poorly written, involving typos, inconsistencies, poorly motivated definitions, several forward references, etc. which made reading and reviewing quite challenging.\n\n* The terms \"off-policyness\" and \"policy age\" are used throughout the paper; however, they are only defined intuitively (i.e. not precisely) until section 5 where they are given an unsatisfactory definition. The paper defines \"off-policyness\" as the number of steps between when the behavior policy was recorded and the current timestep. This, however, does not take into account any aspect of the dynamical system defining the change in policies. For instance, imagine Q-learning with a stepsize of 0. The policy would never change, yet the \"off-policyness\" by definition would grow linearly according to this definition. The lack of solid definition here requires an unfortunate environment\/algorithm specific meta-parameter later in the analysis to account for this fact (more discussion on this later in the review).\n\n* Throughout the paper, the term \"error\" is used but the formula given is $\\mathbb{E}\\left[ \\hat{G} - v_\\pi \\right]$ which is the definition of bias. While a minor nitpick in terminology, this leads towards a lot of confusion throughout where some quantities are defined as \"errors\" while other as \"biases\", but what is ultimately meant is \"bias\". The term \"approximation error\" means something specific generally, and is not used correctly in the paper (for instance). Because \"bias\" is the only portion of the error that is investigated throughout the paper, then the most important portion of the discussion around $n$-step methods is ignored (namely, the variance). Even simplifying the setting investigated by this paper to being fixed-policy (e.g. policy evaluation) with target and behavior policies the same (i.e. on-policy), then still there is a trade-off between $n=1$ and $n=\\infty$. This trade-off results from balancing between bias and variance of the estimated returns. While adding shifting policies and considering the off-policy setting does yield an interesting conversation on bias, the variance simply cannot be ignored.\n\n* The error decomposition is incorrect. It does not account for all of the error in the estimate, resulting in a \"residual\" unaccounted for error. We do not know what causes this error, we do not know if it implies that the defined accounted for errors are incorrect due to the residual error, or if there is simply some additional term not being accounted for, but we do know that the magnitude of the residual error is non-negligible due to the empirical investigation in Figure 1. Further, because we are actually looking at biases not errors, we cannot make use of the non-negativeness of these quantities to assert their independence. The residual error appears positive. What if the residual error results from not accounting for all of the error due to \"off-policyness\" (which is always negative) and thus cancels with the off-policy error?\n\n* Where did Equation 7 come from? This appears to be entirely intuited from a couple of empirical plots? Does the equation even make sense? I see $n^* = \\text{round}\\left( \\frac{n_\\text{max}}{n} e^{\\min(1, \\frac{p}{d})} \\right)$ which results from an $\\text{argmin}_n$. How do we solve this equation with an $n$ on both sides wrapped in a non-linear function? Is this based on Bhandari et al. (2018) where this paper incorrectly reads that gradient descent has an **exponential** convergence rate? Where does gradient descent come into play (TD is not the gradient of any function)? Why limit the exponent to be at least 1? Doesn't this lead to an algorithm where $n=2$ is the smallest n-step method we can consider?\n\n### Empirical Study\nI highly appreciated section 4.2. I liked the investigation of the quantities defined in the theoretical section and asserting that assumptions hold. I however do not agree that the empirical results here imply the conclusion drawn. In what way do we see that \"N-step returns works because a suitable selection of $n$ makes the overestimation and underestimation cancel each other\"? This conclusion is not clear from the results. It also lacks the appropriate nuance given the highly limited study and lack of statistical evidence to support the claim.\n\nHow did you choose the meta-parameter value of $d = 122952$? This seems....arbitrary at best. What does the sensitivity of $d$ look like? $d$ appears to result from the fact that you did not account for the rate that the policy is changing, only the number of timesteps that have passed. This makes the fraction $\\frac{p}{d}$ become an approximation for policy change rate, where the onus is entirely on the algorithm user to estimate and tune this quantity for their given algorithm, other meta-parameters, and environment.\n\nThe rest of the plots in section 6 onwards have a fundamentally broken empirical methodology that renders the results largely uninterpretable. Comparing the mean and standard error (I believe this is what the shaded region shows?) of the top 4 out of 8 runs will not yield statistically valid results. The differences between the algorithms will be lost to variance and noise, making it impossible to know which algorithm is actually best. More runs would be needed and likely a different validation metric as well. Note that using the 50th percentile disproportionately favors high-variance methods as it cuts off their failing runs. This implies to me that the proposed algorithm has much higher variance (as I would guess from the algorithm itself) and only works a small percentage of the time. Perhaps this is still a desirable trait, but this should be stated and investigated explicitly and not hidden behind strange empirical decisions.\n\nI will refer to Henderson et al. 2015 for a discussion on why showing the mean and standard error of the top 4 out of 8 runs is insufficient for a statistically valid methodology. I will also attach a short python script which demonstrates a simplified version of Figure 5 from Henderson et al. 2015, demonstrating very clearly that no conclusions can be drawn from this methodology. Even ignoring my complaint at the unusability of the empirical results in section 6, still the difference in performance of the proposed algorithm and a 2-step baseline appear negligible; especially once one considers the introduction of two new meta-parameters to replace the original one meta-parameter, and that these two meta-parameters appear difficult to tune.\n\n#### A demonstration of methodology\n```python\nimport numpy as np\nnp.random.seed(0)\n\nN = 8\nTOP_N = 4\n\n# hidden underlying process\n# let's see which of these two \"algorithms\" is better\n# Note, however, that they are in fact the same\nalg1_performance = np.random.normal(0, 0.1, size=N)\nalg2_performance = np.random.normal(0, 0.1, size=N)\n\n# only look at top n points\nalg1_performance.sort()\nalg2_performance.sort()\n\nalg1_top = alg1_performance[-TOP_N:]\nalg2_top = alg2_performance[-TOP_N:]\n\n# which is better? (note both should be approximately 0)\nprint(\"mean 1:\", alg1_top.mean()) # => 0.17\nprint(\"mean 2:\", alg2_top.mean()) # => 0.08\n\n# can we estimate variance? (Nope)\nprint(\"std 1:\", alg1_top.std()) # => 0.046\nprint(\"std 2:\", alg2_top.std()) # => 0.042\n\n# what about confidence intervals? (Nope)\nalg1_stderr = alg1_top.std() \/ np.sqrt(TOP_N)\nalg2_stderr = alg2_top.std() \/ np.sqrt(TOP_N)\n\nprint(\"CI 1:\", (alg1_top.mean() - alg1_stderr, alg1_top.mean() + alg1_stderr))\nprint(\"CI 2:\", (alg2_top.mean() - alg2_stderr, alg2_top.mean() + alg2_stderr))\n# yields CI 1: (0.15, 0.19)\n# yields CI 2: (0.06, 0.10)\n# these confidence intervals don't overlap, therefore\n# conclusion: they must be different algorithms\n# and alg1 has better average performance, so alg1 must be better\n```\n","sentences":[{"sentence_type":"2","sentence":"The theoretical components of the paper were largely poorly written, involving typos, inconsistencies, poorly motivated definitions, several forward references, etc. which made reading and reviewing quite challenging.","rephrased":"The theoretical components of the paper could benefit from careful editing to address typos, ensure consistency, and provide clearer definitions and motivations, which would greatly facilitate the reading and review process."},{"sentence_type":"3","sentence":"The rest of the plots in section 6 onwards have a fundamentally broken empirical methodology that renders the results largely uninterpretable.","rephrased":"The methodology used in the plots from section 6 onwards could be improved to enhance the interpretability of the results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1549,1766,"Maybe"],[6401,6543,"Maybe"]],"Comments":[]}
{"id":"0Yh3a-x0E3R","text":"Summary:\nThis paper introduces the concept of adaptive label smoothing (ALS).  ALS uses bounding box annotations of objects to determine how much area in the image is covered by the object and uses this estimate to change the weight in the label smoothing operation, with the goal to encourage the classifier to focus on the object and not on the context around the object during classification. The experiments on ImageNet classification show an improved classifier calibration, while for detection, the improvements are marginal.\n\nPros:\n- The paper is well written and easy to understand\n- The problem of reducing the effect of background biases on a classifier's performance is important\n- The classifier calibration on ImageNet is improved\n\nCons:\n- The method requires additional supervision in terms of bounding box annotations. It would be interesting to study unsupervised methods for estimating the objectness, e.g., using unsupervised segmentation.\n- The proposed method does not significantly improve over the baselines on object detection. I think the authors should discuss this in more detail.\n- It would be great if the paper would also discuss alternative measures for adapting the smoothing factor. \n- The overall contribution of this paper is rather limited. While the idea is certainly very interesting and the problem is important, the authors should give a more elaborate experimental evaluation of their approach on a variety of datasets and with a larger set of network architectures and for different visual recognition tasks to highlight that their strategy indeed is of general relevance.\n\n----------------------------------------------------------------------------------------------------------\nPost rebuttal:\n\nThank you for your response. After reading the other reviewers' comments and your responses, I think the paper is not yet ready for publication. All reviewers are concerned by the lack of a technical contribution and the limited benefit of the paper. While I appreciate the effort of the authors to answer our concerns, I think the paper needs a major revision that incorporates our shared concerns. Therefore, I retain my initial rating.","sentences":[{"sentence_type":"2","sentence":"The overall contribution of this paper is rather limited.","rephrased":"While the paper presents an interesting concept, the scope of its contribution could be expanded by including a more comprehensive experimental evaluation across various datasets, network architectures, and visual recognition tasks."},{"sentence_type":"2","sentence":"I think the paper is not yet ready for publication.","rephrased":"The paper presents promising ideas but could benefit from further development and revision to address the concerns raised by the reviewers."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1218,1275,"Not concerning"],[1831,1882,"Not concerning"]],"Comments":[]}
{"id":"sh8fKXla_T","text":"The proposed study addresses the problem of style modeling in neural TTS and speaking style transfer across speakers. The proposed system is based on the supervised MSMS technique (multi-speaker multi-style). A one-hot encoding vector encoding style and speaker is used to bias\/condition the variance adaptor and the decoder of a Fastspeech2-like architecture. \n\nKey Strength of the paper\n\nSince the proposed MSMS is not novel (as mentioned by the authors), the main contribution of the paper is its extensive evaluation using MOS and ABX listening tests. This evaluation reveals that the MSMS approach is particularly suitable for processing long-form speaking style. \n\nMain Weakness of the paper\n\nThe paper does not describe with enough details the specificities at the prosodic level of each of the 4 speaking styles considered (books, knowledge, navigation, and dialog). For instance, what is the expected difference between « knowledge » and « books »?  Are there really different prosodic patterns between the different styles ? Similarly, the concepts of « long-form style » and « TTS style » are not well defined. Why Wikipedia is considered as  long-form  (the the best of my understanding) and not « dialogue »? Does long-form means « beyond the current sentence »? In addition, as the proposed method is fully supervised, it might have been interesting to assess the degree of consensus on style labeling (e.g. by reporting a measure of inter-rater agreement on the training data). This lack of information about the content of the data set and the prosodic specificities expected of each style prevents the reader from assessing the real difficulty of the task (and therefore the improvements brought about by the MSMS technique). \n\nNovelty\/Originality :\n\nAs mentioned by the authors, MSMS is not novel. However, an extensive evaluation of this technique is of interest for the SSW audience. \n\nTechnical Correctness : \n\nThe subjective tests along with their  statistical analyses are well conducted. However, with a proprietary dataset and a lack of detail about its content, this research is difficult to be reproduced and the scientific impact of this paper is therefore limited. \n\nSuggestions for improvement\n\n  Providing a better definition of TTS vs. long-form styles together with a more fine-grained analysis of the prosodic content of the training data for each style considered.  \n\nQuality of References  : Good enough \n\nClarity of Presentation : The  paper is well written.  ","sentences":[{"sentence_type":"2","sentence":"The subjective tests along with their  statistical analyses are well conducted. However, with a proprietary dataset and a lack of detail about its content, this research is difficult to be reproduced and the scientific impact of this paper is therefore limited.","rephrased":"While the subjective tests and statistical analyses are well conducted, the use of a proprietary dataset and the limited details provided about its content may pose challenges for reproducibility. Addressing this could enhance the scientific impact of the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1932,2193,"Not concerning"]],"Comments":[]}
{"id":"rkeFendXqE","text":"The authors present a simple method for training GANs to demix images. They train two separate generator networks, take the sum of their output, and then perform inference by finding the latent vectors for both GANs which minimize the distance in pixel space to the original (mixed) image, with a regularization penalty on the magnitude of the latent vector.\n\nWhile the approach is very simple, the experiments looked promising. When the two data distributions were very different, the demixing GAN was able to cleanly separate out the two classes. I would have appreciated more rigorous comparison against alternative methods, especially more on ICA and possibly NMF as baselines. More comparison on real world data would be interesting as well - for instance quite a lot of biomedical data contains mixed signals from different types of tissue and automatic demixing is very valuable there.","sentences":[{"sentence_type":"1","sentence":"While the approach is very simple, the experiments looked promising.","rephrased":"The approach is straightforward, and the experiments show promising results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[360,428,"Not concerning"]],"Comments":[]}
{"id":"XAwNWA8DefW","text":"The paper assesses if it is possible to merge layers from previously trained Decision Transformers (DTs) trained on independent tasks in order to form a multi-task policy that was never co-trained on all the tasks.\n\nThe main strengths of the paper are:\n* Very relevant to the workshop - the work directly addresses the question of how to re-use previously trained policies.\n* Novel and insightful analysis on the effect of merging layers from different DTs on policy performance. This nicely lays the groundwork for future work in the area.\n* Well motivated, well written and clearly presented throughout\n\nThe main weaknesses are:\n* No related work but I think this is fine for a workshop paper.\n\nOverall a strong workshop paper with interesting and insightful analysis that I think form a great basis for discussion in this workshop.","sentences":[{"sentence_type":"1","sentence":"No related work but I think this is fine for a workshop paper.","rephrased":"While the paper could be strengthened by including a section on related work, its absence is understandable given the workshop context."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[633,695,"Not concerning"]],"Comments":[]}
{"id":"HJlAnKJCKB","text":"In this paper, the authors claim to establish a Lipschitz bound on neural networks, initialized randomly, and trained until convergence.  They also claim to establish probabilistic concentration of the resolvent of the Gram matrix from a mixture of k distributions with varying means and covariances.  The authors also present the spectrum and leading eigenspace of the Gram matrix for representations by CNNs of images generated by a GAN.\n\nIt is not clear to this reviewer what exactly the authors have proved and what significance it has.  For example, in Proposition 3.1, the authors talk about dynamics with a learning rate, where W <- W - \\eta E where E has standard normal entries and \\eta is a learning rate.  It is unclear what the learning problem is, or why the learning rate is modifying a random modification.  I understand the general idea that Lipschitz functions of random-quantities-that-enjoy-concentration-estimates also enjoy concentration estimates.  This is well known from the random matrix theory literature.  The authors need to make a claim about how this informs either the development or understanding of deep learning technologies.  The authors should consider what the implications of their results could be, and then do the research to establish that those implications hold up.\n\nThe authors claim that their results constitute \"a first step towards the theoretical understanding of complex objects such as DL representations.\"  This claim is false.  This very conference is on Learning Representations, and presumably at least one paper in the past 7 years makes progress towards the theoretical understanding of Deep Learning representations.  \n\nBecause of the overly bold claims with insufficient clarity and justification, I recommend that this paper be rejected.","sentences":[{"sentence_type":"2","sentence":"This claim is false.","rephrased":"This claim appears to overlook significant prior work presented at this and other conferences."},{"sentence_type":"2","sentence":"Because of the overly bold claims with insufficient clarity and justification, I recommend that this paper be rejected.","rephrased":"Due to the claims requiring further clarity and justification, I would suggest a revision of the paper before considering acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1459,1479,"Not concerning"],[1678,1797,"Not concerning"]],"Comments":[]}
{"id":"Hkgb3hJ53X","text":"The authors propose a neural network architecture for lane detection in on-road driving. The architecture consists of multiple encoder-decoder stages. This is motivated by a need to overcome limitations of traditional CNNs with respect to considering high-level context while providing pixel-level accuracy. The paper additionally claims contributions in the analysis of the performance of various instantiations of this architecture as well as in considering limitations of the popular IoU metric. Experiments are reported on the publicly available CULane dataset.\n\nThe paper addresses a topical problem in autonomous driving and ADAS but is currently let down by a severe lack of accessibility. Much of the evidence corroborating the principal claims of the submission appears to be missing. While a number of CNN architectures do struggle to provide pixel-level segmentation accuracy particularly for objects of certain geometries there exists a whole host of literature regarding attempts to remedy this. The SegNet family of works as well as many works leveraging the now established skip-connection u-net architecture is missing entirely. The related works  section does list a number of recent relevant work but does not succeed in putting this into context given the approach proposed here. This is also not remedied in the experimental evaluation as almost no benchmarking to the established state of the art is performed. The evaluation itself is mainly qualitative and does not serve to convince the reader that the approach offered here is beneficial. For example, how does one choose between the different solutions offered in Fig. 8? When it comes to the quantitative evaluation some important detail appears to be missing. For example, what is a probmap and how is accuracy on these computed to arrive at Fig 7? Much of the experimental detail is also left unclear. \n\nThe submission also requires extensive spell and grammar checking. This would significantly improve accessibility, though much remains to be done to make the science case more convincing. \n\nOverall this makes the originality and significance of the work difficult to judge. As it stands I can not recommend publication.","sentences":[{"sentence_type":"2","sentence":"The paper is currently let down by a severe lack of accessibility.","rephrased":"Improving the paper's accessibility could enhance its impact and help in better understanding the authors' contributions."},{"sentence_type":"2","sentence":"Much of the evidence corroborating the principal claims of the submission appears to be missing.","rephrased":"Providing additional evidence to support the principal claims of the submission would strengthen the paper."},{"sentence_type":"2","sentence":"This is also not remedied in the experimental evaluation as almost no benchmarking to the established state of the art is performed.","rephrased":"Including benchmarking against the established state of the art in the experimental evaluation could demonstrate the relative performance of the proposed approach."},{"sentence_type":"2","sentence":"The evaluation itself is mainly qualitative and does not serve to convince the reader that the approach offered here is beneficial.","rephrased":"Augmenting the qualitative evaluation with more quantitative data could more effectively demonstrate the benefits of the proposed approach."},{"sentence_type":"3","sentence":"As it stands I can not recommend publication.","rephrased":"In its current form, the paper may require further development before I can recommend it for publication."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[697,793,"Not concerning"],[1299,1431,"Not concerning"],[1432,1563,"Not concerning"],[2157,2202,"Not concerning"]],"Comments":[]}
{"id":"GrpHofCjiuF","text":"S1. A large amount of experiment is conducted and plenty of result is shown in appendix.\n\nS2. A novel optimizing mode of grafting two different optimizers is proposed.\n\nW1. The paper structure is strange. I recommend to read some published proceedings to try to make this paper more clearly.\n\t\nW2. Some format maybe not legal. Such as the caption of table and content in Page 16.\n\t\nW3. The theory is not reasonable. In other word, you just tell me you do it like this but not why it’s reasonable. Actually, I don’t think ADAM#SGD will be better than ADAM. ADAM calculates the update direction according to loss function. In a multi-dimensional space, this direction is composed of the value of each gradient and positive or negative(symbol) of each gradient. However, you change the symbol of some parameters’ gradient according to SGD. This is why? I’m confused. In my view, this method is more like a SGD with multiplying a large const to its gradient.\n\t\nW4. I have a question, how to compute the norms (||w_m-w_t ||)\/(||w_D-w_t ||). Is ||w_m-w_t || calculated with all the parameters in neural network? If not, I think Figure~1 is a wrong example, cause M#D will step to different direction with D in multi-dimensional space.\n\t\nW5. The results shown in tables are not strong enough.","sentences":[{"sentence_type":"2","sentence":"The paper structure is strange. I recommend to read some published proceedings to try to make this paper more clearly.","rephrased":"The paper's structure could be improved for clarity. I suggest reviewing some published proceedings for guidance on structuring your paper effectively."},{"sentence_type":"2","sentence":"The theory is not reasonable. In other word, you just tell me you do it like this but not why it’s reasonable.","rephrased":"The theoretical foundation could be strengthened by providing a clearer rationale for your approach."},{"sentence_type":"1","sentence":"Actually, I don’t think ADAM#SGD will be better than ADAM.","rephrased":"It would be beneficial to include a comparison or evidence to support the claim that ADAM#SGD outperforms ADAM."},{"sentence_type":"1","sentence":"This is why? I’m confused.","rephrased":"Could you please clarify the reasoning behind this approach?"},{"sentence_type":"1","sentence":"In my view, this method is more like a SGD with multiplying a large const to its gradient.","rephrased":"From my perspective, this method seems akin to SGD with a scaled gradient. Could you elaborate on how it differs?"},{"sentence_type":"2","sentence":"The results shown in tables are not strong enough.","rephrased":"The results presented in the tables could be further substantiated to demonstrate the effectiveness of your approach."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[173,291,"Not concerning"],[386,496,"Not concerning"],[497,555,"Not concerning"],[837,863,"Not concerning"],[864,954,"Not concerning"],[1235,1285,"Not concerning"]],"Comments":[]}
{"id":"rkl2hXp627","text":"in this work the authors propose to replace Gaussian distribution over latent variables in standard variational autoencoders (VAEs) with a sparsity inducing spike-and-slab distribution. While taking the slab to be Gaussian, the authors approximate the spike with a scaled sigmoid function, which is then reparameterized through a uniform random variable. The authors derive an extension of the VAE lower bound to accommodate KL penalty terms associated with spikes. The variational lower bound (VLB) is optimized stochastically using SGD (with KL-divergence computed in closed form). Results on benchmarks show that as compared to standard VAE, the proposed method achieves better VLB for higher number of latent dimensions. Classification results on latent embeddings show that the proposed method achieves stable classification accuracy with increasing number of latent dimensions. Lastly the authors visualize sampled data to hint that different latent dimensions may encode interpretable properties of input data.\n\nOriginality and significance: In my opinion, the approach taken in this work does not constitute a major methodological advancement; the VLB authors derive is a relatively straight-forward extension of VAE's lower bound. \n\nPros:\nThe paper is well-written and easy to follow. \nThe idea of having a sparse prior in latent space is indeed relevant, \nThe approximation and reparameterization of the spike variable is however functionally appealing. \nPotentially useful for semi-supervised learning or conditional generative modeling.\n\nConcerns:\nThe authors show various empirical results to highlight the performance of their approach, but I am still not sure where it is best to use sparse embeddings that are induced by the proposed approach vs. those of standard VAE (or other of its sparse variants e.g., rectified Gaussian priors by Tim Salimans).  For instance in all experiments VAE seems to be competitive or better for low-dimensional latent space, so one may ask, why is it necessary to go to a higher number of latent variables? In a VAE setup, one can simply tune the number of latent dimensions through cross-validation, as one would probably need to do to tune the prior sparsity parameter in the proposed method. \n\nI am also wondering if the disparity between VAE and proposed method w.r.t. classification performance for increasing number of latent dimensions vanishes as more labeled data is used for training? Fig. 11 in appendix seems to indicate that. \n\nLastly I am not sure how we can expect to always converge to interpretable encodings since there is nothing explicit in the objective function to encourage interpretable solutions. Perhaps samples such as those shown in the paper can also be generated by modulating VAE embeddings?\n\nMaybe the proposed approach offers potential for tasks such as semi-supervised learning or conditional generative modeling, but the current set of empirical results does not allow one to draw any conclusions there. ","sentences":[{"sentence_type":"2","sentence":"In my opinion, the approach taken in this work does not constitute a major methodological advancement; the VLB authors derive is a relatively straight-forward extension of VAE's lower bound.","rephrased":"While the approach taken in this work builds upon existing methodologies, further exploration could help clarify its potential as a significant methodological advancement beyond the current extension of VAE's lower bound."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1049,1239,"Not concerning"]],"Comments":[]}
{"id":"z93CzEQa0S4","text":"Originality. It seems novel to me. \n\nClarity. The presentation is reasonably clear. \n\nSignificance. The topic itself is important. However, the result is not convincing, as I pointed out in the quality part below. \n\nQuality. See concerns below. \n\n1. Section 3.1. I would not consider PER and DisCor are two representative algorithms. In some sense, PER also leads to a more accurate Q value faster. Please see the missing citation later. In fact, one can definitely argue that a regular ER is also trying to learn more accurate Q values faster. Without ER, one may use a single experience to update the network\/value function, which is definitely slower. \n\nFurther, L101-L104 is simply not justified. Using a target different from maximizing the expected return is common, from policy-based methods to value-based methods. L103, “for example, when the Bellman target is inaccurate, … ” For any stochastic optimization algorithm, there is no guarantee that each single updating step can lead to an improvement in the reduction of the loss function. Hence, such an example is meaningless. \n\nThe motivating example in Fig 1 is invalid because of both lack of details and the design itself.  \n\na. Why compare PER to uniform? The latter has access to all the states, and hence I guess it also has access to the model?  Does PER have access to all the states and the model? \nIf not, the comparison is unfair and pointless. First, PER does not have the same information as Uniform. Second, Uniform across state space is usually not doable in continuous domains. Are you trying to claim uniform sampling is what you want to design? \nIf yes, PER should learn really quickly, as it should learn s_0 to s_3’s values really quickly, and when at s_0, it would realize that the right action has a larger value. \nb. On such a simple domain, the learning rate should be finely swept rather than fixed as a constant 0.1. \nc. The domain should be more useful to demonstrate the exploration strategy. What is the exploration strategy used?  \n\n2. The theoretical result is not rigorous. \n\nFirst, the formulation of minimizing regret is problematic. According to objective (1),  the optimal Q_k should simply be B^\\ast Q_{k-1}, then the constraint is satisfied. Or do you mean it should not be a constraint; it should also be part of the objective? Furthermore, are there any constraints on the magnitude of the weights w_k? I would be surprised if there is no such constraint. \n\nHow can a theorem be informal? Would you please provide a clear answer? The assumption and important technical lemmas should be moved to the main body. \n\nFurther, I believe assumption 1 in the appendix is invalid. First, what is H? It is an undefined notation. How large could it be? Do you concern about the finite horizon setting? If so, it is different from the background section in the main body. \n\nAnd, such an assumption is counter-intuitive. It says once a state-action pair gets visited, the chance of going back to it is low. It seems contrary to the traditional ergodic\/recurrency assumption. The paper also says, “the assumption is trivial in continuous spaces”; however, the theorem is designed for the tabular case. \n\nThe result of theorem 1 requires access to Q^\\ast. How can this be true?\n\n3. The proposed approach. The proposed approach to approximate the terms in Theorem 1 is not convincing. First, approximating |Q_k - Q^\\ast| is difficult. Does it require learning an environment model? Second, it is hard to believe an algorithm that needs so many approximations can work well. The algorithm should be very fragile. This can also be seen in the experiments as I discuss below. \n\n4. What are the relationships between ReMERT and ReMERN? Which one should be preferred in what cases? I cannot see a clear message from the paper. Is ReMERT the ultimate algorithm you propose? And ReMERN is just an intuitive baseline? \n\n5. The experiments. Why compare with SAC? Aren’t your methods generic to be used with many algorithms? (As indicated from L53-54: “Similar to PER, ReMERN, and ReMERT can be a plug-in module to all off-policy RL algorithms 54 with a replay buffer”) I expect the comparison should be DDPG-PER, DDPG-ReMERN, DDPG-REMERT, etc.… Anyway, PER should also be included. \n\nIn addition to PER, an intuitive baseline is to use PER with both long-term and short-term buffers, according to the paper’s theoretical result. \n\nThe variance is too high to distinguish different algorithms. It is not clear how the parameter sweep is done for all these algorithms. ReMERN\/T should have many more parameters to tune. \n\n6. Important citation missing: Beyond Prioritized Replay: Sampling States in Model-Based Reinforcement Learning via Simulated Priorities. The work discusses PER in detail and points out its limitations and solutions. \n\nMinors: \n\n1. L26, “For example, minimizing TD error is different from the objective of RL, which is to maximize the expected return of the policy.” This statement is not accurate. First, Q learning does find the optimal policy in the tabular case. And the statement seems to reject all value-based methods. Second, RL has both policy evaluation and control problems. The former does not seek to maximize expected returns. It just evaluates a policy. \n\n2. The notations do not differentiate random variables and realized r.v. \n\n3. L72, the Bellman optimal operator is incorrect. It seems r(s, a) is an r.v., and it should be inside the expectation. The notation of function f can be replaced by Q. \n\n4. some references are messy. Editors are mixed with publication venue. ","sentences":[{"sentence_type":"2","sentence":"Hence, such an example is meaningless.","rephrased":"Therefore, it would be beneficial to provide additional justification or context for this example to clarify its relevance and significance."},{"sentence_type":"2","sentence":"The motivating example in Fig 1 is invalid because of both lack of details and the design itself.","rephrased":"The example in Figure 1 could be strengthened by providing more details and reconsidering the design to better support the argument."},{"sentence_type":"2","sentence":"If not, the comparison is unfair and pointless.","rephrased":"If not, the comparison may not be adequately balanced, and further clarification or adjustment might be necessary to ensure fairness."},{"sentence_type":"2","sentence":"The theoretical result is not rigorous.","rephrased":"The theoretical result could benefit from additional rigor and a more detailed explanation to enhance its clarity and robustness."},{"sentence_type":"2","sentence":"How can a theorem be informal? Would you please provide a clear answer?","rephrased":"Could you please clarify the informal aspects of the theorem to ensure a comprehensive understanding?"},{"sentence_type":"1","sentence":"And, such an assumption is counter-intuitive.","rephrased":"This assumption appears to be unconventional and may benefit from further explanation to align with common understanding."},{"sentence_type":"2","sentence":"The result of theorem 1 requires access to Q^*. How can this be true?","rephrased":"Could you elaborate on how the result of Theorem 1 is achievable given that it requires access to Q^*?"},{"sentence_type":"2","sentence":"Second, it is hard to believe an algorithm that needs so many approximations can work well.","rephrased":"It may be challenging to understand how an algorithm requiring numerous approximations can perform effectively; could you provide further empirical evidence or theoretical justification?"},{"sentence_type":"2","sentence":"The algorithm should be very fragile.","rephrased":"There is a concern that the algorithm may be sensitive to parameter settings or variations in the data; additional robustness analysis could be helpful."},{"sentence_type":"2","sentence":"The variance is too high to distinguish different algorithms.","rephrased":"The high variance observed in the results may make it difficult to distinguish between the performance of different algorithms; a more detailed analysis could be beneficial."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1048,1086,"Maybe"],[1089,1186,"Not concerning"],[1369,1416,"Maybe"],[2027,2066,"Not concerning"],[2459,2530,"Not concerning"],[2863,2908,"Not concerning"],[3467,3558,"Not concerning"],[3559,3596,"Not concerning"],[4407,4468,"Not concerning"]],"Comments":[]}
{"id":"BygFOVRG5E","text":"This paper proposes a model family that unifies NFs, VAEs and DAEs. It also introduces an extension of this model that allows for using non-invertible encoders (e.g. projection to a smaller dimensionality) and discrete data. Overall, the idea is promising, but the empirical results are not strong enough to warrant a strong commendation.\n\nPros\n- The proposed model that blends NFs, VAEs and DAEs is original, and generalises over standard NFs in that it allows non-zero noise levels.\n- When latent dimensionality is smaller than the input space, the model consistently outperforms the VAE baseline.\n\nCons\n- Performance deteriorates for bigger latent dimensionalities (e.g. when n=m)","sentences":[{"sentence_type":"2","sentence":"Overall, the idea is promising, but the empirical results are not strong enough to warrant a strong commendation.","rephrased":"Overall, the idea is promising, and with further empirical evidence, it could warrant a strong commendation."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[225,338,"Not concerning"]],"Comments":[]}
{"id":"BkgnPV1FKV","text":"This paper clearly sets out a hypothesis, method to test the hypothesis, and the presents the core (negative) result \"BigGANs cannot be currently used for data augmentation and more work is required for it to be\nused in downstream tasks\". This work overall is clear and direct, and I enjoyed reading and reviewing it. I will focus the remainder of the review on suggestions, questions and ideas for perhaps pushing this work in some other directions.\n\nThe experiments here are quite detailed, though the nature of the work opens a whole new series of questions that I hope the authors continue exploring. Rather than only using the model for data augmentation, the images \/ representations for the classifier could also be augmented using discriminator features extracted learned by the learned-and-frozen GAN - this could perhaps still be an improvement even if the direct images \/ dataset augmentation isn't sufficient to improve classification. These types of \"bootstrapping\" of the GAN with discriminator features can be seen in papers such as \"Denoising Feature Matching\", though used in a different setting https:\/\/openreview.net\/forum?id=S1X7nhsxl .\n\nOne big question I have is in regard to the use of GAN (trained on very large datasets, potentially) as a regularization technique for much smaller datasets than ImageNet. This setting might allow the use of much larger models on small data, due to better regularization - though ImageNet has been (slightly) overfit these days, it is still enormous compared to many practical \"in-the-wild\" datasets and seems a particularly hard test for this data augmentation setup. Out-of-domain generalization is potentially another area to explore with practical application.","sentences":[{"sentence_type":"1","sentence":"BigGANs cannot be currently used for data augmentation and more work is required for it to be used in downstream tasks","rephrased":"While BigGANs may not yet be fully optimized for data augmentation, further research could enhance their applicability in downstream tasks."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"uQE0juyC5gB","text":"The paper targets  an interesting question about the connection between generalization and privacy. However, there are some \nIssues:\n\nMy main issue with the paper is the idea of using MI-attack-accuracy as a the definition of privacy risk. The membership attack metric only captures one type of adversary that is trying to learn the data. Depending on the implementation of the MI attack you might get very different accuracy and thus I don’t think it is a good metric for privacy in general. In my view differential privacy is a more principled privacy definition because it protects privacy agains the worst case adversary.  \n\nAlso I was confused about the key results: I don’t find it surprising that achieving generalization does not provide more privacy and showing that there is not connection between generalization and privacy does not seem difficult to do. As for stable features, I don’t see a clear connection between stable features and differential privacy. For example  I would be interested in seeing is Mean-Rank vs Epsilon , to see if more differentiable privacy methods learn better stable features. \nOther than that, I find the presentation of key results not very clear. For example in Figure 1 it’s not easy to see the correlated between OOD accuracy and MI attack accuracy. Would it make more sense to have a plot with OOD accuracy in the y-axis and MI-loss in the x-axis?\n","sentences":[{"sentence_type":"2","sentence":"I don't find it surprising that achieving generalization does not provide more privacy and showing that there is not connection between generalization and privacy does not seem difficult to do.","rephrased":"While the paper suggests that achieving generalization does not necessarily enhance privacy, it would be beneficial to explore this relationship further to understand if there are scenarios where generalization could contribute to privacy."},{"sentence_type":"1","sentence":"Other than that, I find the presentation of key results not very clear.","rephrased":"It would be helpful if the presentation of the key results could be clarified to enhance the reader's understanding."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1119,1190,"Not concerning"]],"Comments":[]}
{"id":"bV13DskJMfC","text":"The authors in the paper describe a deep learning approach to detect copy number variants (CNVs) from DNA sequencing data, CNV-Net.  It described the approach by transforming the pileups into images and pass them through a CNN. This strategy has been proposed four or five years back to do SNPs and indels calling (DeepVariant).  It is challenging for SVs and CNVs as they can be arbitrarily large. However, there are also several existing models for this task (e.g. DeepSV, RDBKE). In this work, the authors only consider \"candidate CNV regions\" which are 201-bp small genomic regions that centered at the breakpoints. \n\nThe paper is only 4.5 pages. First, the authors did not explain or investigate many decisions in their model design. Then the experiments are flawed. I have many questions and concerns. \n1) First of all, this should not be called a CNV detector because it is in fact a breakpoint detector\n2) How did the authors do negative sampling? Were the negative samples randomly drawn from the genome? This creates bias as the sequence features might shift dramatically. \n3) Why are the negative samples not balanced with the positive samples?\n4) Are there differences in performance between deletion and duplications breakpoints? Does the model distinguish these two types? \n5) When splitting the training\/validation\/testing dataset, there will be significant data leakage if this is done randomly. Many SV\/CNV regions have characteristic repeats patterns.\n6) The comparison between CNV-Net and other methods is not fair as the other methods are finding CNVs in the whole genome while CNV-Net is given a pre-defined set of \"candidate breakpoint regions\" in which positive samples have breakpoints perfectly centered in the middle. Moreover, such candidate regions might suffer from data leakage. \n7) Does HG002 really only has 174 duplications while NA12878 has 22,936? \n8) GIAB has more than two genomes available. Can we test on more genomes? \n9) Minor: RELU -> ReLU \n","sentences":[{"sentence_type":"2","sentence":"Then the experiments are flawed.","rephrased":"The experimental design could benefit from further clarification and potential improvements."},{"sentence_type":"2","sentence":"First of all, this should not be called a CNV detector because it is in fact a breakpoint detector","rephrased":"The term 'CNV detector' might be misleading as the tool primarily identifies breakpoints."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[622,649,"Missed Maybe"],[651,738,"Missed by Model"],[739,771,"Confirmed"],[812,910,"Maybe"]],"Comments":[]}
{"id":"r1gjKT42Kr","text":"Summary of claims:\n\nThe paper proposes an imitation learning method that aims to align state distributions rather than state-action distributions to account for cases where the imitator dynamics differ from expert dynamics. They achieve this by two objectives: one local, the other global. The local objective aligns the next state to be close to the expert's next state in each transition by first training a VAE on the expert demonstrations, and using the trained VAE in conjunction with a pretrained inverse dynamics model to compute the action that the imitator needs to imitate. The global objective tries to do a global alignment of states encountered in the imitator and expert trajectories, by minimizing the Wasserstein distance between the two trajectory distributions. The paper claims that using these two objectives results in a method that outperforms existing inverse reinforcement learning and behavior cloning approaches in settings where the imitator and expert dynamics differ.\n\nDecision:\n\nI recommend the paper to be rejected. I have three main reasons for my decision (with more details in the next section):\n1. The paper is very poorly written : A lot of details are missing in the paper, notation is not standardized,  related work is just a list of previous papers without any context on how the proposed method is related, previous methods are referred to without any citations, and quite a few blanket statements which are not substantiated.\n2. Incomplete approach description: Quite a few components of the approach are not explained (or even discussed), no intuition provided for the choices made in the approach, the concept of different dynamics is not formalized, some technical inconsistencies in the algorithm, no formal problem statement (which would really help in standardizing notation), and most claims made about the approach are not justified or substantiated\n3. Poor experiments: Experiments are not well chosen to reflect the premise and claims of the paper, little to no details given for how the baseline approaches were trained, no details on policy parameterization, and missing comparison with baseline approaches in some experiments\n\nComments:\n\n(1) Problem setup: \n(a)Problem setup is very vague and not formalized. \n(b) Differing dynamics could mean several things: different agent dynamics (like different action spaces; different actuators; etc.), different environment dynamics (different moving obstacles in the world;) etc. \n(c) Basically, different dynamics can mean a lot more than what was accounted for in the paper\n\n(2) Blanket Statements: \n(a) The authors keep saying that their framework is more flexible without any justification as to why, \n(b) \"simply train an inverse dynamics model\"- training an inverse dynamics model can be very hard especially when environment dynamics are stochastic\/when the inverse model is multimodal, \n(c) \"constraint becomes loosened\" - this statement doesn't make any sense without more explanation,\n(d) Several other blanket statements about existing approaches\n\n(3) Notation : \n(a) Notation was never standardized in the paper, \n(b) what is \\phi? what is the input-output of \\phi? \n(c) What is \\theta_old? What is \\sigma? \n(d) There are a lot of things that needed explanation, especially in the algorithm\n\n(4) Related Work : \n(a) The related work section is just a dump of citations without giving any context for where the proposed work lies in the spectrum of these works. How does it compare? Why is it better\/worse? \n(b) Missing related work that was publshed in ICML 2019 that has a very similar approach in matching state distributions (\"Provably efficient Imitation Learning from Observations Alone\" or FAIL) and works very well.\n\n(5) Motivation : \n(a) The approach, in general, needs better motivation. The toy example in the introduction was good but the experiments did not reflect the complexity of that example. \n(b) Try to have a running example in the paper that will help you motivate the approach better.\n\n(6) Background : \n(a) The background section is very minimal and lacks any details necessary. \n(b) I had to read the beta-VAE paper to understand what it does. \n(c) The section also lacks any minimal background in IL\/RL and the notation could also have been standardized in this section\n\n(7) Figures: \n(a) All the figures in this paper could use a lot of improvement in terms of descriptive captions, more informative legends, bigger fonts, descriptive text, and more figures as well\n\n(8) Algorithm : \n(a) The algorithm was not referenced anywhere in the text, \n(b) No definition for \\tau, details on pretraining inverse dynamics model lacking in both text and algorithm, \n(c) *Policy prior is used to pretrain policy before the VAE was trained!* which doesn't make any sense since the policy prior is obtained using the VAE, \n(d) the equation at the end of Sec 4.3 has r(s, a) whereas reward is defined as r(s_t, s_{t+1}) but they are not equivalent when dynamics are stochastic\n\n(9) Experiments: \n(a) What is AIRL? No reference was given. \n(b) Why is keeping the variance of the policy constant reasonable? How do you come up with the value? \n(c) How do you pretrain the VAE, invserse dynamics model? \n(d) The setup of making the ant's legs smaller or body heavier seems very artificial. I am sure its easy to come up with more realistic setups in navigation domains, for example. Try to use more realistic experiments in the future. \n(e) For results in Fig 3, is AIRL, GAIL also pretrained with VAE or by BC? Seems like SAIL was pretrained but the others weren't since SAIL starts off with a high score at the start. \n(f) For Sec 5.1.2, comparison with baseline approaches are missing. Legends for the plots are terribly small.\n\nConceptual questions:\n1. How do you account for cases where due to differing dynamics, states reached by expert in demonstrations are unreachable by the imitator? \n2. How do you account for cases where the environment dynamics changes between expert and imitator?\n3. Why does using Wasserstein distance make sense? Why not other f-divergences? Also, matching global distributions can be very misleading if you have states that are visited multiple times in the same trajectory. FAIL recommends matching state distribution at each time-step instead and is much more stable\n4. How is this different from GAIL where we match state visitation distribution (instead of state-action visitation distribution?)\n\nThings to improve:\n1. Writing needs to be improved a lot\n2. Better experiments - more realistic domains\n3. Approach needs to be explained more formally","sentences":[{"sentence_type":"2","sentence":"The paper is very poorly written","rephrased":"The paper could benefit from improvements in clarity and detail"},{"sentence_type":"2","sentence":"Incomplete approach description: Quite a few components of the approach are not explained (or even discussed)","rephrased":"The approach description could be more comprehensive, including explanations of all components"},{"sentence_type":"2","sentence":"Poor experiments: Experiments are not well chosen to reflect the premise and claims of the paper","rephrased":"The experimental design could be more closely aligned with the paper's premise and claims"},{"sentence_type":"2","sentence":"The related work section is just a dump of citations without giving any context","rephrased":"The related work section would benefit from more context and analysis regarding how the proposed method relates to existing literature"},{"sentence_type":"2","sentence":"The background section is very minimal and lacks any details necessary","rephrased":"The background section could be expanded to include necessary details for better understanding"},{"sentence_type":"2","sentence":"All the figures in this paper could use a lot of improvement","rephrased":"The figures in the paper could be enhanced with more descriptive captions and informative legends"},{"sentence_type":"2","sentence":"The setup of making the ant's legs smaller or body heavier seems very artificial","rephrased":"The experimental setup could be made more realistic, perhaps by considering more practical scenarios in navigation domains"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[1133,1165,"Confirmed"],[1471,1580,"Not concerning"],[1903,1999,"Not concerning"],[3326,3405,"Confirmed"],[4040,4110,"Not concerning"],[4324,4384,"Not concerning"],[5226,5306,"Not concerning"]],"Comments":[]}
{"id":"SyYO2aIlG","text":"This paper addresses the well-known stability problem encountered when training GANs. As many other papers, they suggest adding a regularization penalty on the discriminator which penalizes the gradient with respect to the data, effectively linearizing the data manifold.\n\nRelevance: Although I think some of the empirical results provided in the paper are interesting, I doubt the scientific contribution of this paper is significant. First of all, the penalty the author suggest is the same as the one suggest by Gulrajani for Wasserstein GAN (there the motivation behind this penalty comes from the optimal transport plan). In this paper, the author apply the same penalty to the GAN objective with the alternative update rule which is also a lower-bound for the Wasserstein distance.\n\nJustification: The authors justify the choice of their regularization saying it linearizes the objective along the data manifold and claim it reduces the number of non-optimal fixed points. This might be true in the data space but the GAN objective is optimized over the parameter space and it is therefore not clear to me their argument hold w.r.t to the network parameters. Can you please comment on this?\n\nRegularizing the generator: Can the authors motivate their choice for regularizing the discriminator only, and not the generator? Following their reasoning of linearizing the objective, the same argument should apply to the generator.\n\nComparison to existing work: This is not the first paper that suggests adding a regularization. Given that the theoretical aspect of the paper are rather weak, I would at least expect a comparison to existing regularization methods, e.g.\nStabilizing training of generative adversarial networks through regularization. NIPS, 2017\n\nChoice of hyper-parameters: The authors say that the suggested value for lambda is 10. Can you comment on the choice of this parameter and how it affect the results? Have you tried  annealing lambda? This is a common procedure in optimization (see e.g. homotopy or continuation methods).\n\nBogonet score: I very much like the experiment where the authors select 100 different architectures to compare their method against the vanilla GAN approach. I here have 2 questions:\n- Did you do a deeper examination of your results, e.g. was there some architectures for which none of the method performed well?\n- Did you try to run this experiment on other datasets?\n","sentences":[{"sentence_type":"2","sentence":"I doubt the scientific contribution of this paper is significant.","rephrased":"I would like to see further elaboration on the scientific contribution of this paper to better understand its significance."},{"sentence_type":"2","sentence":"Given that the theoretical aspect of the paper are rather weak, I would at least expect a comparison to existing regularization methods.","rephrased":"It would be beneficial to strengthen the theoretical aspects of the paper, perhaps by including a comparison with existing regularization methods."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[370,435,"Not concerning"]],"Comments":[]}
{"id":"UQSSKzD45jG","text":"Strengths,\n\nthis paper is well-written and easy to follow.\n\nThe performance on ImageNet-1K is impressive.\n\nWeaknesses,\n\n1. lack of ablation study w\/wo KD loss.\n\n2. why can the ** dynamic ** token sparsification have throughput gain in Table1(batch size =32) because Different images have different tokens \nremain and may result in parallel problems during the inference phase.\n\n3. why does the learning rate of the prediction module differ from the backbone.\n\n4. The model was initialized from a pre-trained model but compared with the models training from scratch.","sentences":[{"sentence_type":"1","sentence":"lack of ablation study w\/wo KD loss.","rephrased":"Including an ablation study with and without KD loss could strengthen the paper by providing clearer insights into the model's performance."},{"sentence_type":"2","sentence":"why can the ** dynamic ** token sparsification have throughput gain in Table1(batch size =32) because Different images have different tokens remain and may result in parallel problems during the inference phase.","rephrased":"It would be helpful to clarify how dynamic token sparsification achieves throughput gains in Table 1, given that varying tokens across images could potentially lead to parallelization issues during inference."},{"sentence_type":"1","sentence":"The model was initialized from a pre-trained model but compared with the models training from scratch.","rephrased":"For a fair comparison, it would be beneficial to discuss the impact of initializing the model from a pre-trained state versus training from scratch."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[123,159,"Not concerning"],[463,565,"Not concerning"]],"Comments":[]}
{"id":"Sye52SE_FN","text":"The authors propose a technique for improving the performance of audio classification neural networks by simultaneously training them to solve various auxiliary self-supervised tasks. This is achieved by sharing a common \"trunk\" network with multiple \"head\" networks, each tailored to solve a specific task. Typically, a network will be optimized with four head networks, one to solve a main task and the rest to solve three auxiliary tasks. Since the trunk is shared for the different tasks, the idea is that the auxiliary tasks will result in an improved trunk network compared to only optimizing the main objective. The authors present experimental results on three main tasks: audio tagging, speaker identification, and speech command classification. These were coupled with three auxiliary, self-supervised tasks: next-step prediction, denoising, and upsampling. Since training data for these auxiliary tasks could be created from unlabeled data, it represents a virtually inexhaustible supply of potential training data. Experimental results for this architecture showed a significant improvement was obtained by joint training with these auxiliary tasks. However, the authors also present results for a transfer learning experiment, where the network was first trained on the auxiliary tasks and then fine-tuned for the main task. This yielded an even greater improvement, which calls into question the utility of the proposed method. Unfortunately, no analysis of explanation of this fact is presented.\n\nThe description of the method is quite comprehensive, but at times vague and lacking some details. First, while the paper describes three main tasks (audio tagging, speaker identification, and speech command classification), much of the description of the architecture only refers to audio tagging. The method for the joint training is also only mentioned towards the end, in the appendix. It would be clearer if some of these details were included in the main text. It is also not completely clear whether the trunk network is jointly trained between all three main tasks and the auxiliary tasks, or between a main task and the auxiliary tasks. While it is likely the latter, it is never clearly spelled out. There is also little motivation for the auxiliary tasks. Why were these chosen as opposed to others? For example, what do the authors expect the next-step prediction task to add? If it is simply a matter of predicting the next sample in a time series, this shouldn't necessary require a very high-level knowledge of the audio signal structure, since continuity already provides a very strong prior. Similar questions can be posed for the other auxiliary tasks. Furthermore, some auxiliary tasks are trained with an L^2 loss, while others are trained with a smoothed L^1 loss. Why were these different choices made? Finally, the method of choosing hyperparameters is also not clear. The authors state that they were chosen \"heuristically favoring performance on the main task\". What does this mean?\n\nThe experiments provide interesting results, but are not as complete as they could be. For example, there are several popular datasets for audio tagging. why were the particular datasets chosen? More importantly, why are no results for state-of-the-art methods presented? It is not necessary that the proposed architecture perform better than the current state of the art, but it is important to provide a context for the results. The authors also add a significant amount of training data to the problem through the auxiliary training tasks, but neglect to discuss any impact on training time. While this may not always be an issue, it is a relevant trade-off to be made when considering when to adopt the proposed architecture. Finally, the authors make a claim about additivity (or complementarity) of their proposed approach when coupled with data augmentation. It would be interesting to see to what extent the changed labels overlap between the two methods. If they are indeed complementary, there would be little overlap between the set of labels changed by adding one and then the other.\n\nFinally, the transfer learning results (as mentioned above), pose a significant problem with respect to the utility of the proposed algorithm. If we can simply train the network trunk for the auxiliary tasks separately, and then add a new head network and train that for the main task, why should we consider the whole apparatus proposed in the current manuscript? This holds doubly true considering that the transfer learning approach significantly outperforms the proposed approach for the considered tasks. There may be some properties like reduced training time, fewer hyperparameters to select, and so on, but no discussion is provided. Since this is a potentially very important alternative, analysis and discussion of the merits of the two approaches is strictly necessary.\n\nSome more minor comments follow:\n- With respect to general-purpose audio representations, the authors may want to mention the audio scattering transforms developed by Mallat and collaborators.\n- In Section 3, the authors mentioned experiments being made with \"0 to 3\" auxiliary tasks. The subsequent experiments only present results for 0 _and_ 3 auxiliary tasks, with no results for 1 or 2 tasks. This should be corrected.\n- One dataset is described as containing \"uncompressed PCM\", another as \"WAVE format files\", while the format of the third is not specified. If the authors insist on including this information, they should be consistent in their descriptions. What is the format of the third dataset? Are the WAVE files also stored as PCM? Or are they stored in µ-law or some other format?\n- The authors make the claim that \"spectral\/cepstral representations of audio ... significantly restrict the range of audio processing tasks which they can perform\". A finely sampled spectral representation contains enough information for synthesizing a new signal which sounds virtually identical to the original. Where they may fall short is in sample-by-sample reconstructions, since they do not include the phase. One could argue that this sample-by-sample reconstruction is rarely what's desired in audio classification tasks. Indeed, the type of tasks for which they are necessary mostly includes low-level processing tasks such as the auxiliary tasks introduced in this paper. The fact that that there is such an \"impedance mismatch\" between the main and auxiliary tasks should be cause for concern.\n- The MAP@3, Top-1, and Top-5 metrics, although well-known, should be defined completeness.\n- The difference between the \"baseline\" and \"none (0)\" rows in Table 1 is a bit subtle. While the second does not include any unlabeled data, it still performs joint training on the main and auxiliary tasks but on the main task's training data. This is not obvious from a first glance and should be clarified.\n- In Table 2, it would be useful to provide results for \"NI + PS\", \"NI + PS + MTL100\" and the same for \"MTL500\". In the interest of space, however, it may be better to simply sketch these results in the text if they do not add too much more information.\n- The authors state that \"Interestingly, the performance gains from augmenting with noisy data are similar to those obtaining by training the main task jointly with a self-supervised noise-reduction task.\" Why is this interesting? Why could this be the case? Is there a similarity in label assignment as well? I suggest the authors finish this train of though.\n- In Table 3, please write out the full names of the tasks as in Table 1.\n- There are several capitalization errors in the bibliography. In particular, several uppercase characters have been converted to lowercase: \"English\", \"Mandarin\", \"ChiME\", \"PyTorch\".\n- Having figures in gray make them hard to read, especially when printed. Unless there is some compelling reason not to, I suggest they be regenerated in black.\n- Please provide a definition for dilated convolution.\n- The sequence in Section 6.2.1 should be delimited by parentheses, not curly braces (which delimit sets).\n- The \"smoothed L^1\" norm is also known as the Huber loss in statistics and other fields.\n- \"Python\" has the first letter capitalized.\n- Please define SNR.\n\nFinally, I strongly suggest the authors make their code available to the general public.","sentences":[{"sentence_type":"2","sentence":"Unfortunately, no analysis of explanation of this fact is presented.","rephrased":"It would be beneficial for the paper to include an analysis or explanation of this observation."},{"sentence_type":"1","sentence":"The description of the method is quite comprehensive, but at times vague and lacking some details.","rephrased":"The method is described comprehensively, though there are some areas where additional details could enhance clarity."},{"sentence_type":"1","sentence":"The experiments provide interesting results, but are not as complete as they could be.","rephrased":"The experiments yield interesting results, and there is potential for further completeness in future work."},{"sentence_type":"2","sentence":"Finally, the transfer learning results (as mentioned above), pose a significant problem with respect to the utility of the proposed algorithm.","rephrased":"The transfer learning results raise important questions regarding the utility of the proposed algorithm that merit further discussion."},{"sentence_type":"1","sentence":"Why is this interesting? Why could this be the case? Is there a similarity in label assignment as well? I suggest the authors finish this train of though.","rephrased":"This observation is intriguing and could be further explored to understand the underlying reasons and any similarities in label assignment."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1442,1510,"Not concerning"],[1512,1610,"Not concerning"],[3021,3107,"Not concerning"],[4118,4260,"Not concerning"],[7366,7520,"Not concerning"]],"Comments":[]}
{"id":"SyxZXAkCiE","text":"This paper presents an adaptation of an automated scheduling system, CLASP, to target an EO experiment (ECOSTRESS) on the ISS.\n\nThis particular problem presents some peculiarities wrt more standard observation scheduling problems for similar scenarios that required an adaptation of the scheduling system:\n\n- a long-term science campaigns requiring to be able to account for previously executed observations when scheduling for the future\n- an issue with the instrument on-board memory required a specific memory management approach\n- the uncertainty in the orbital ephemeris requires scheduling flexibility to to ensure no targets are missed at execution time (schedules in this scenario are pre-computed and uploaded for execution)\n\nThe topic is interesting and it fits the SPARK workshop.\n\nThe paper is clearly written and good balanced between the scenario description, the problem definition and the technical approach presentation. The application is mature and in use.\n\nThe solution presented appears interesting, especially the one to tackle into account the memory management issue (long-term science campaigns problems and uncertainty on observations' outcomes are let's say more \"standard\" issues). Degradation of assets to during their life-cycle is definitely a problem in space applications, and this paper presents an interesting solution.\n\nOne things wasn't clear to me: what is exactly a \"buffer for contingencies\" mentioned when describing the sliding windows approach?","sentences":[{"sentence_type":"1","sentence":"The solution presented appears interesting, especially the one to tackle into account the memory management issue (long-term science campaigns problems and uncertainty on observations' outcomes are let's say more \"standard\" issues).","rephrased":"The solution presented is quite interesting, particularly the approach to memory management. While long-term science campaigns and uncertainty in observations' outcomes are common issues, the paper addresses these effectively as well."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[977,1209,"Not concerning"]],"Comments":[]}
{"id":"ryePM53AFB","text":"The authors analyze the stability of a randomly initialized ResNet in terms of the scaling of the network and its depth. They claim to characterize the spectral stability of a randomly initialized network (and local perturbations of it), as well as that of the forward and backward process. These results, along with some further results, are used to extend convergence proofs of ResNets towards more standard initializations. Some of the claims are evaluated empirically.\n\nUnfortunately, this paper is not a good contribution at the moment, as the work, although potentially interesting, is somewhat incremental and poorly presented. In particular, the results (including the proofs) only extend the results from Allen-Zhu et al, and are often hard to follow. The presented empirical results are nonetheless interesting and should be expanded upon. Here are some detailed comments\n\n- The theorems should be stated more carefully, and in particular, care should be given to make precise which constant terms are hidden away in the big-O and big-Omega notations. E.g. in theorem 2 the probability must have some dependency on c hidden away, which should be made explicit, especially given the assertion “where c can be arbitrarily small”. Similarly, in theorem 1, it is claimed that c is constant, but the theorem is only non-vacuous for either m growing or c ~ log L. There are also some typos in theorem statements (e.g. missing O in theorem 3 and lemma 3), which can easily confuse the reader.\n\n- Although I did not have time to check all the proofs, they should be treated with more care. I recommend avoiding big-O and big-Omega notations in the proofs as much as possible, as it can make some steps extremely confusing: in the proof of theorem 1, after “taking an \\epsilon-net over …”, the probability does not change despite applying an union bound! The union bound argument should be more clearly spelled out, especially given the fact that some smoothness should also be established for this argument (e.g. the trivial sub-multiplicative bound).\n\n- The empirical results are interesting, and I think could be taken even further. Indeed, the authors show promising results for learning a global scale parameter (in terms of performance), and it would be interesting to explore: 1) the value of the learned \\tau after training: is it still of the order 1 \/ \\sqrt{L}? Or does it take some other value. 2) whether it is better to have a \\tau per layer or one for the whole network. The presentation of the current results could be improved by including standard deviation when averages are reported, and changing figure 4 with axes starting at zero (bar charts which do not start at zero are extremely misleading).\n\n- There are also many typo and grammar issues. Although these do not seriously impede understanding, the paper could be improved by addressing those (at least running a spell-check).","sentences":[{"sentence_type":"2","sentence":"Unfortunately, this paper is not a good contribution at the moment, as the work, although potentially interesting, is somewhat incremental and poorly presented.","rephrased":"While the paper presents potentially interesting work, there is room for improvement in terms of presentation and novelty. Clarifying the incremental nature of the results and enhancing the presentation could strengthen the contribution."},{"sentence_type":"2","sentence":"Although I did not have time to check all the proofs, they should be treated with more care.","rephrased":"I recommend dedicating additional attention to the proofs to ensure clarity and rigor, which would enhance the paper's reliability."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[474,634,"Not concerning"],[1499,1591,"Not concerning"]],"Comments":[]}
{"id":"1cb0a9IKEyE","text":"The manuscript addresses a relevant task but presents some weaknesses. Some methodological choices are not clearly explained: for example, which are the benefits of including squeeze and excitation blocks for the addressed task?  The survey of the state of the art can be improved, e.g., by citing and discussing more relevant literature. I strongly suggest the authors to ask a native English speaker to proofread the manuscript. The overall manuscript readability also can be improved.\n \nMy specific comments can be found hereafter.\n\nAbstract\n- The authors should give more space to the description of the method, shortening the introduction if needed.\n- The sentence “Cardiac left ventricular (LV) segmentation [...] is a necessary step in the processing allowing the identification [...]” should be changed in “Cardiac left ventricular (LV) segmentation [...] allows the identification and diagnosis of cardiac diseases.” \n- How were the \"best trained proposed models\" chosen? This should be clearly stated. \n \nIntroduction\n- The authors write that “[...] deep learning-based models have been applied for LGE MRI segmentation in various disease areas.” However,  only one paper is cited. A more comprehensive literature review should be provided. For example, the authors could cite [Moccia, Sara, et al. \"Development and testing of a deep learning-based strategy for scar segmentation on CMR-LGE images.\" Magnetic Resonance Materials in Physics, Biology and Medicine 32.2 (2019): 187-195.] and [Li, Lei, et al. \"Atrial scar quantification via multi-scale CNN in the graph-cuts framework.\" Medical Image Analysis 60 (2020): 101595.]\n- The benefits of (i) including squeeze and excitation blocks and (ii) processing volumes in a 2.5D fashion should be introduced. \n-Why do the authors refer to 2.5D instead of 3D?\n\nDatasets\n- How was the manual segmentation performed? Did the clinicians make use of any annotation software? If an expert performed the manual annotation, how was the inter-subject variability computed?\n\n2.5 D proposed RSE-Net Model\n- What do the authors mean by special convolutional module?\n- I suggest the authors to give more space to the SE module description, considering that introducing this block is the central part of the paper.\n- How were the three models chosen? This should be clearly explained in this section.  \n- The authors should be more accurate in reporting the learning-rate and batch-size values, as well as the used loss function.\n \nResults and Discussion\n- Why were the DSC and HD computed in their 2D formulation?\n- How was the correlation value computed? \n- Table 1 should show also dispersion metrics.\n- To my knowledge. the scar tissue is rather well contrasted with respect to the myocardial region in CMR-LGE volumes (that’s why CMR-LGE is used over standard CMR). A figure to show sample challenging slices, with the obtained segmentation, may help the reader in appreciating more the challenges that have to be tackled.\n- Please, change \"myocardial architecture\" with \"myocardial anatomy\".\n- As a general comment, it would be nice to reference publicly available datasets in the field (if any). Testing the proposed methodology on publicly available datasets would promote a fair comparison with the literature. \n \nMinor\n- All acronyms should be defined at their first use (e.g., SE)\n","sentences":[{"sentence_type":"2","sentence":"I strongly suggest the authors to ask a native English speaker to proofread the manuscript.","rephrased":"I recommend that the authors consider having the manuscript proofread for language clarity, possibly by a colleague with proficiency in English."},{"sentence_type":"1","sentence":"To my knowledge. the scar tissue is rather well contrasted with respect to the myocardial region in CMR-LGE volumes (that's why CMR-LGE is used over standard CMR).","rephrased":"It is generally understood that scar tissue contrasts well with the myocardial region in CMR-LGE volumes, which is an advantage of using CMR-LGE. It would be helpful if the authors could provide figures to illustrate challenging cases where this contrast is less apparent."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[339,430,"Confirmed"]],"Comments":[]}
{"id":"rybCT6Olf","text":"\n\n- Lack of novelty\n\nThe paper has very limited novelty since the proposed method is a straightforward combination of two prior works on the same topic (unpair\/unsupervised image translation or cross-domain image generation) where the two prior works are the DTN work [a] and the UNIT [b] work. To be more precise, the proposed method utilizes the weight-sharing design for enforcing the shared latent space constraint proposed in the UNIT work [b] and the feature consistency loss term for ensuring common embedding in the DTN work [a] for solving the ill-posed unpaired\/unsupervised image-to-image translation problem. Since the ideas are already published in the prior work, the paper does not contribute additional knowledge to the problem. \n\nIn addition, the combination is done in a careless manner. First of all, the paper proposes jointly minimizing the common embedding loss [a] and the domain adversarial loss [b]. However, minimizing the common embedding loss [a] also results in minimizing the domain adversarial loss [c]. This can be easily seen as when the embeddings are the same, no discriminators can tell them apart. This suggests that the paper fails to see the connection and blindly put the two things together. Moreover, given the generators, minimizing the common embedding loss also results in minimizing the cycle-consistency loss [d]. As the UNIT work [b] utilize both the weight-sharing constraint and cycle-consistency loss, the proposed method becomes a close variant to the UNIT work [b].\n\n- Poor experimental verification\n\nThe paper only shows visualization results on translating frontal face images to cartoon images in the resolution of 64x64. This is apparently short as compared to the experimental validations done in several prior works [a,b,d]. In the CycleGAN work [d], the results are shown on several translation tasks (picture to painting, horse to zebra, map to image, and different scenarios) in a resolution of 256x256. In the UNIT work [b], the results are shown in various street scene (sunny to rainy, day to night, winter to summer, synthetic to real) and animal portraits (cat species and dog breeds) where the resolution is up to 640x480. In the DTN [a] and UNIT [b] work, promising domain adaptation results (SVHN to MNIST) are reported. Due to the shortage of results, the credibility of the paper is damaged. \n\n- Lack of clarity in presentation\n\nThe paper tends to introduces new key words for existing one. For example, the \"semantic style transfer\" is exactly the unpaired\/unsupervised image-to-image translation or cross-domain image generation. It is not clear why the paper needs to introduce the new keyword. Also, the Coupled GAN work [e] is the first work that utilizes both weight-sharing (shared latent space assumption) and GAN for unpaired\/unsupervised image-to-image translation. It is unfortunately that the paper fails to refer to this closely related prior work.\n\n[a] Yaniv Taigman, Adam Polyak, Lior Wolf \"Unsupervised Cross-Domain Image Generation\", ICLR 2017\n\n[b] Ming-Yu Liu, Thomas Breuel, Jan Kautz \"Unsupervised Image-to-Image Translation Networks\", NIPS 2017 \n\n[c] YaroslavGanin et al. \"Domain-adversarial Training of Neural Networks\" JMLR 2016\n\n[d] Jun-Yan Zhu, Taesung Park, Philip Isola, and Alexei A. Efros \"Unpaired Image-to-Image Translation Using Cycle-consistent Adversarial Networks\" ICCV 2017\n\n[e] Ming-Yu Liu, Oncel Tuzle \"Coupled Generative Adversarial Networks\", NIPS 2016","sentences":[{"sentence_type":"2","sentence":"In addition, the combination is done in a careless manner.","rephrased":"Furthermore, the integration of the two methods appears to lack a detailed justification for their combination."},{"sentence_type":"3","sentence":"This suggests that the paper fails to see the connection and blindly put the two things together.","rephrased":"This could indicate that the paper might not fully acknowledge the overlap between the two approaches and could benefit from a more thorough analysis of their integration."},{"sentence_type":"2","sentence":"Due to the shortage of results, the credibility of the paper is damaged.","rephrased":"The limited scope of the results may raise questions about the robustness of the paper's findings."},{"sentence_type":"1","sentence":"It is unfortunately that the paper fails to refer to this closely related prior work.","rephrased":"It would be beneficial for the paper to acknowledge and discuss this closely related prior work."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[747,805,"Confirmed"],[1135,1232,"Not concerning"],[2291,2363,"Not concerning"],[2848,2933,"Not concerning"]],"Comments":[]}
{"id":"H1g9GJoN37","text":"This paper extends the previous work (Dharmaretnam & Fyshe, 2018), which provided a analytic tool for understanding CNNs through word embeddings of class labels. By analyzing correlations between each CNN layers and class labels, enables to investigates how each layer of CNNs work, how much it performed well, or how to improve the performance.\n\nI felt it is little hard to read this paper. Although the short summary of contributions of this paper in the Introduction, I could not easily distinguish contributions of this paper from the ones of the previous work. It's better to explicitly explain which part is the contributions of this paper in detail. For example, \"additional explorations of the behavior of the hidden layers during training\" is not clear to me because this expression only explain what this paper do briefly, not what this paper is actually different from the previous work, and how this difference is important and crucial.\n\nSimilarly, I could not understand why adding concepts, architectures (FractalNet), datasets (CIFAR-100) is so important. Although this paper states these changes are one of the contributions, it is unclear whether these changes lead to significant insights and findings which the previous work could not find, and whether these findings are so important as contributions of this paper. Again, I think it is better to describe what main contributions of this paper are in more detail.","sentences":[{"sentence_type":"2","sentence":"I felt it is little hard to read this paper.","rephrased":"I found some sections of the paper challenging to read, which could be improved for clarity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[347,391,"Not concerning"]],"Comments":[]}
{"id":"br9mnAMaZb","text":"**Originality**: \nThe proposed BCD makes a Tayler expansion to approximate the $x^2$ with the first order Tayler expansion $e^{x^2} \\approx 1 + x^2$ ($x^2 \\approx 1 - e^{x^2}$). Therefore, it bounds each point-level distance to a value between 0 and 1. Also, due to the exponential function, it potentially mitigates the outlier prediction when $x^2$ becomes large. \n\nTo further handle the imbalance ambiguity of CD, the authors propose to add one extra normalization term for each point-level distance by considering points' surroundings, point-specific query frequency. Based on the frequency, the authors also designed a discriminator to guide point sampling to sample important points.\n\nThe reviewer considers the overall pipeline to be novel.\n\n**Quality**: The paper is intuitive and straightforward to implement. \nHowever, the major limitation the reviewer captures from the paper is that the BCD is only used during the test stage. As both CD and EMD are widely used for self-supervised learning for point-related problems, it seems to be quite unfortunate that the authors didn't try to use BCD as the objective function to guide the learning tasks and report the numbers. This could be making it more useful for point cloud literature.\n\nAs the authors only use BCD for evaluation, the improvement made from the paper seems to mainly come from an empirical approach to conduct better sampling compared to FPS based on point query frequency. It is somewhat an incremental contribution. \n\n**Clarity**: It is not clear on the details of the proposed model. For example, the authors should have mentioned the baseline architecture without the balanced design. It is not clear to the reviewer whether the authors built their method upon PCN, PCN++, TopNet, MSN or VRC. Therefore, it is difficult for the reviewer to evaluate whether the balanced design indeed improves the performance.\n\n**Significance**: The authors propose a bounded version of Chamfer Distance, the Balanced Chamfer Distance, for distance measurement on point clouds. It is tackling important problems that are interesting to the point cloud literature.  However, its limitation is obvious that the metric is only limited for evaluation and can not be used for training as CD and EMD. \n\nIn the end, the method of the paper tends to 'degrade' to designing a better sampling based on point query frequency, which is unfortunately considered as an incremental contribution.\n\nTherefore, the reviewer tends to give a borderline rejection given its current version as the work seems to be still an on-going work that remains to explore the training with BCD. The authors have attempted solving an important research problem, the reviewer encourages them to further move forward along the direction.\n\n[1] A Point Set Generation Network for 3D Object Reconstruction from a Single Image\n","sentences":[{"sentence_type":"2","sentence":"It is somewhat an incremental contribution.","rephrased":"While the contribution builds upon existing methods, its refinement of the sampling process based on point query frequency could be further emphasized to highlight its potential impact."},{"sentence_type":"3","sentence":"In the end, the method of the paper tends to 'degrade' to designing a better sampling based on point query frequency, which is unfortunately considered as an incremental contribution.","rephrased":"Ultimately, the paper focuses on enhancing the sampling process using point query frequency, which is a valuable addition to the field, although it may be seen as a refinement rather than a fundamental change."},{"sentence_type":"2","sentence":"Therefore, the reviewer tends to give a borderline rejection given its current version as the work seems to be still an on-going work that remains to explore the training with BCD.","rephrased":"Therefore, the reviewer is inclined to consider a conditional acceptance, provided that future work includes exploration of training with BCD, as the current version suggests that this is an area with room for further development."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1449,1492,"Not concerning"],[2259,2442,"Not concerning"],[2444,2624,"Not concerning"]],"Comments":[]}
{"id":"8CY4JCWtr","text":"The authors compare five different approaches for motion estimation and forecasting in a “chicken breast sample” OCT experiment. The main result is that taking into account the temporal nature of the data (eg. by 4D-convolution and especially using appropriate spatial preprocessing of the data) allows for improved motion estimation and prediction. \n\nFrom the methodical perspective, the authors highlight the applied *4D* deep learning approaches, which indeed are still not commonly applied in the medical imaging domain. At this, it should be noted that their application is also not novel per se. However, the proposed joined spatial preprocessing of the individual OCT frames (inspired by the underlying publication Gessert et al, 2019) is an interesting idea.\n\nIn general, the manuscript is well structured and written. As \"Cons\" points: central aspects that are necessary to interpret  the results are not given (at least not in the manuscript; some are listed in the underlying paper by Gessert et al, 2019): temporal resolution, image resolution, motion span and velocity range of the trajectory. Furthermore, which are the actual OCT applications that are addressed, what are typical motion patterns and ranges – and what are corresponding application-driven requirements in terms of eg. MAE?\n\nIn summary: The contribution offers a nice comparison study of 3D vs. 4D approaches for deep learning-based motion forecasting. Due to missing information, it is, however, hard to interpret the results besides the obvious gain in motion estimation and prediction accuracy.","sentences":[{"sentence_type":"2","sentence":"Due to missing information, it is, however, hard to interpret the results besides the obvious gain in motion estimation and prediction accuracy.","rephrased":"To fully interpret the results, it would be beneficial if the manuscript included additional information such as temporal resolution, image resolution, motion span, and velocity range of the trajectory."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1433,1577,"Not concerning"]],"Comments":[]}
{"id":"D_WOSzPOBe","text":"Overall evaluation:\n* The paper fits very well within the framework of this workshop as it investigates how pre-training might help in ObjectNav tasks.\n* Paper is written quite clearly and the appendix contains a lot of important details which help the reader understand the tested methods. The authors also clearly explain all of the preliminaries and nicely introduce the ObjectNav problem and the experiment setting.  \n* I would say the quality and the significance of the paper are quite high, I appreciate the numerous experiments the authors ran, as well as including some negative results (e.g. on whether frontier exploration demonstration help). \n\nAs such, I have no doubt that the paper should be presented at this workshop. Below, I attached a few comments and suggestions, but overall I think this is a good fit for this venue.\n\nFeedback and comments:\n* I find Figure 1 slightly confusing, especially the two different Y-axis scales. I think it might make more sense to show the absolute IL performance rather than plotting the difference `IL-RL`? \n* Dividing fine-tuning into two phases (the first one being critic-only) seems quite interesting, but makes me think about whether we can do better. One could try to train the value function on the offline dataset with Monte Carlo rollouts. As you rightly point out, \"a critic learned on human demonstrations (during behaviour cloning) would be overly optimistic since all it sees are successes\". But it should be fairly easy to generate some imperfect rollouts. To be clear, I'm not asking the authors to add such an experiment, I'm only wondering whether this would strengthen the pre-training phase somehow.\n* The experiment in Figure 3 is quite interesting, but I wonder what the results would look like if you start from models with equal *validation* successes. I think validation success should better reflect the overall quality of the model.\n* I appreciate the comparison to VPT in the Appendix. Out of curiosity, have you tried using only the KL distillation trick without using the \"set parameters of the critic to zero\" trick? I'd be interested to know what is their \"disentangled\" impact, as KL distillation makes more sense to me than the critic zero init.\n* I'm not sure if I understand Figure 8 in the Appendix. Why does the blue line performance drop (even slightly) in the first phase if we only train the critic? Shouldn't it stay exactly the same if the actor does not change?","sentences":[{"sentence_type":"1","sentence":"I'm not sure if I understand Figure 8 in the Appendix. Why does the blue line performance drop (even slightly) in the first phase if we only train the critic? Shouldn't it stay exactly the same if the actor does not change?","rephrased":"Regarding Figure 8 in the Appendix, could you please clarify the observed slight drop in the blue line's performance during the first phase when only the critic is being trained? I would expect the performance to remain constant if the actor is unchanged."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[2234,2457,"Not concerning"]],"Comments":[]}
{"id":"HJx9csHQ5H","text":"In this paper, the authors present a method that transforms data into graph. They emphasize on the fact that the proposed method is scalable, using a spectral embedding to construct the graph.\n\nWe think that the paper is not of enough quality to be accepted in ICLR. Without going in detail in the derivations, we give below some major issues in this submitted paper.\n\nThe studied problem has been widely investigated in the literature. Many methods have been proposed within the same objective, including taking care of the scalability issue. The authors fail to provide the state of the art, as well as describe the contributions with respect to previous work. As a consequence, the contributions are not clear. Maybe the proposed framework is original, but the there has been plenty of methods that have considered the same problem.\n\nExperiments are poor and not convincing. The authors compare the proposed method to only two spectral clustering methods, which as the standard kNN and the Consensus kNN from 2013. These two methods are pretty old and many more recent methods have been introduced in the literature. Moreover, the results in Table 1 are somehow misleading, as the standard kNN is faster that the proposed method on 3 out of 4 datasets. Experiments in graph recovery are not clear, starting from the fact that the datasets are not defined (what are the Gaussian graph and ER graph?), neither the experimental setting (what is the problem at hand?). The same goes to the application of t-SNE which is also very weak.\n\n--------------\nReply to Rebuttal \n\nThe authors have modified the paper to take into consideration our previous comments and suggestions. However, we think that it is still of not sufficient quality. We give below some elements, without providing a thorough review.\n\nIt is pretty pretentious to say that \"this is the first work that introduces a spectral method for learning ultra-sparse (tree-like) graphs from data\", while not comparing to the state of the art. There have been many spectral methods in graph learning for large-scale datasets.\n\nIn experiments, the only added method is the one of Kalofolias and Perraudin (submitted in 2017 to ArXiv). However, results show that this method is the worst of all methods. It is even the worst compared to the simple standard knn. It is not clear how the authors get such results; It looks like something is wrong in experiments, or they are cherrypicking.\n","sentences":[{"sentence_type":"2","sentence":"We think that the paper is not of enough quality to be accepted in ICLR.","rephrased":"We believe that the paper could benefit from further development to meet the high standards of ICLR."},{"sentence_type":"2","sentence":"Experiments are poor and not convincing.","rephrased":"The experiments could be strengthened and made more compelling with additional comparisons and clarifications."},{"sentence_type":"3","sentence":"It is pretty pretentious to say that \"this is the first work that introduces a spectral method for learning ultra-sparse (tree-like) graphs from data\", while not comparing to the state of the art.","rephrased":"The claim that this is the first work to introduce a spectral method for learning ultra-sparse graphs would be more credible with a comprehensive comparison to existing state-of-the-art methods."},{"sentence_type":"3","sentence":"It is not clear how the authors get such results; It looks like something is wrong in experiments, or they are cherrypicking.","rephrased":"The results would be more transparent if the authors could provide a detailed explanation of their experimental methodology to ensure there is no inadvertent bias."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[194,266,"Not concerning"],[837,877,"Not concerning"],[1802,1998,"Confirmed"],[2315,2440,"Maybe"]],"Comments":[]}
{"id":"MeEBu3Tt4zT","text":"The authors themselves admit that all the secure computation building blocks described in Section 3 are already known individually. In fact, they also admit that all these building blocks are available in the high-level library that comes with the MP-SPDZ framework. Even on the machine learning side, the paper merely exploits existing network architectures reported in earlier papers without any modification or optimization. So the only contribution is to put the various pieces together to implement MNIST training and benchmarking the time taken with some previous publications. While this is indeed an useful effort that could be beneficial to the privacy-preserving machine learning community, the lack of any pretense of originality makes the paper unsuitable for publication. Unfortunately, the paper does not even attempt to analyze why the proposed implementation works faster, what are the bottlenecks, and what are the avenues for improvement.\n\n","sentences":[{"sentence_type":"2","sentence":"So the only contribution is to put the various pieces together to implement MNIST training and benchmarking the time taken with some previous publications.","rephrased":"While the paper's primary contribution appears to be the integration of existing components to implement MNIST training and benchmarking against previous publications, it would be beneficial to highlight any novel aspects of this integration or discuss potential optimizations."},{"sentence_type":"3","sentence":"the lack of any pretense of originality makes the paper unsuitable for publication.","rephrased":"The paper would be strengthened by a clearer demonstration of originality or by discussing how this work advances the field, which is important for suitability in a publication."},{"sentence_type":"2","sentence":"Unfortunately, the paper does not even attempt to analyze why the proposed implementation works faster, what are the bottlenecks, and what are the avenues for improvement.","rephrased":"The paper could be improved by including an analysis of why the proposed implementation offers speed improvements, identifying potential bottlenecks, and suggesting avenues for future enhancements."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[428,583,"Not concerning"],[701,784,"Confirmed"],[785,956,"Maybe"]],"Comments":[]}
{"id":"WEdl0dkAmP","text":"This paper aims to apply Fuzzy c-Means (FCM) clustering to persistence diagrams and prove convergent subsequence of iterates tends to a local minimum or saddle point. The motivation of the work is direct and clear. This paper addresses the problem of persistence diagram clustering via using  weighted Frechet mean . \n\nThis is a incremental work though replacing Euclidean distance in FCM by Wasserstein distance. The contributions in this work are not quite promising. For instance, the weighted Frechet mean in Sec3.2 is the well-known Wasserstein Barycenter whose behavior is well studied in optimal transport works. Thus Theorem2 can be not be considered as the contribution of this work. \n\nAnother drawback is that experiment in this work is very weak. There are only three dataset tested in this work. It's not quite convincing. It would be promising if the proposed work valid in other shape datasets such as SHREC2010 or SHREC2014. These datasets were frequently used for testing algorithms of topological data analysis .\n\nI cannot recognize the merits of this work compared with previous papers, such as: Large Scale computation of Means and Clusters for Persistence Diagrams using Optimal Transport.\n\n","sentences":[{"sentence_type":"2","sentence":"The contributions in this work are not quite promising.","rephrased":"The contributions of this work could be further strengthened and more clearly highlighted to showcase their significance."},{"sentence_type":"2","sentence":"Thus Theorem2 can be not be considered as the contribution of this work.","rephrased":"Theorem 2 appears to overlap with well-established results in optimal transport works, and it would be beneficial to clarify its unique contributions within this context."},{"sentence_type":"2","sentence":"Another drawback is that experiment in this work is very weak.","rephrased":"The experimental section could be strengthened by including additional datasets, such as SHREC2010 or SHREC2014, to provide a more comprehensive validation of the proposed method."},{"sentence_type":"2","sentence":"There are only three dataset tested in this work. It's not quite convincing.","rephrased":"Expanding the number of datasets tested could enhance the convincing power of the results and provide a more robust evaluation of the proposed method."},{"sentence_type":"2","sentence":"I cannot recognize the merits of this work compared with previous papers, such as: Large Scale computation of Means and Clusters for Persistence Diagrams using Optimal Transport.","rephrased":"It would be helpful to more explicitly compare the merits of this work with key previous papers, such as 'Large Scale computation of Means and Clusters for Persistence Diagrams using Optimal Transport', to better understand its unique contributions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[414,469,"Not concerning"],[620,692,"Not concerning"],[695,757,"Confirmed"],[758,834,"Not concerning"],[1031,1209,"Not concerning"]],"Comments":[]}
{"id":"5raflgxMmIm","text":"This paper shared some interesting observations about gradient values and correlations and utilized these findings in the context of neural architecture search to improve the search efficiency. To be specific, they use the gradients at initialization to filter out many \"bad\" architectures and then fully train the rest to find the best one.\n\nPros:\n- The analysis of gradient correlations looks interesting to me, while I'm not sure whether it has been studied in previous works.\n- The proposed approach is a kind training-free NAS method, which is an interesting direction in NAS.\n- A comprehensive appendix.\n\nCons:\n- The presentation should be improved. After reading the introduction, I'm still unclear about the proposed approach; if there could have a figure to explain some high-level concept of the proposed gradient-based kernel approach, it would be helpful to understand the paper.\n- To make the paper self-contained, I would suggest the authors include the technical details in the main paper, such as how to sample?\n- The proposed method is highly related to nas-without-training, where both of them can somehow estimate the quality of an architecture without the need of training. Therefore, I would encourage the authors compare the proposed method with https:\/\/github.com\/BayesWatch\/nas-without-training in a fair setting.\n- The proposed method needs to sample-s-models and train-k-models. For a relatively small search space, it can be efficient. However, on a large search space such as 10^20 candidates, I feel it is much worse than differentiable methods. Coould the authors comment on that?\n- A following question is the generalization ability of the proposed method on other search space. Would the authors try the proposed method on other search spaces, such as the size search space in NATS-Bench (an extension version of NAS-Bench-201) or NAS-Bench-101?\n\nSome minor issues:\n- In the second paragraph of Page 2, the reference for NAS-Bench-201 is incorrect, where the cited is NAS-Bench-101.\n- In the \"NAS\" paragraph in the related work section, \"Ying et al. (2019) propose a reinforcement learning based search policy\" the reference seems incorrect, Ying et al. (2019) is NAS-Bench-101 instead of the RL-based NAS algorithm.\n- In the paragraph, the authors said \"the dependence on validation accuracy still leads to huge computation costs.\", which is incorrect. The computation of validation accuracy is not expensive (depends on how to compute it). The huge computation costs are because that those approaches will need to fully train and evaluate each candidate architecture to get their validation accuracy. Also, the efficient search is due to the weight sharing approach, where the differentiable approach is a kind of popular direction.\n- Therefore, I would suggest the authors revise the related works to fix these misleading parts and inaccurate references.\n\n**Post Rebuttal**: The authors did not provide any responses, so I decreased the scores.","sentences":[{"sentence_type":"1","sentence":"The presentation should be improved.","rephrased":"Improving the presentation, particularly in the introduction, could help clarify the proposed approach. Including a figure to explain the high-level concept of the proposed gradient-based kernel approach would be beneficial for understanding."},{"sentence_type":"1","sentence":"Coould the authors comment on that?","rephrased":"Could the authors provide their insights or comments on this aspect?"},{"sentence_type":"2","sentence":"The authors did not provide any responses, so I decreased the scores.","rephrased":"As the authors did not provide a response, I have adjusted the scores accordingly."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[619,655,"Not concerning"],[1575,1610,"Not concerning"],[2910,2979,"Not concerning"]],"Comments":[]}
{"id":"dii89aXe-V7","text":"Strengths:\n- This paper is particularly well-written and understandable. I appreciated the intuitive explanations of chunking in cognitive science and its extension to common machine learning use cases like language and visual data. The examples of instances where hierarchical chunk learning could both help and hurt a learned model were well-chosen. The figures effectively demonstrated the training process and the learned representations in each domain. Even the theorems were more interpretable than I typically see, being subdivided and laid out piece by piece.\n- The method is reasonably novel and broadly applicable. The paper shows HCM applied to temporal, visual, visuo-temporal, and language domains. Given a domain with some hierarchical structure, a fairly reasonable assumption, this method is able to find that hierarchy with some guarantees. The learned hierarchy itself, as the authors note in the conclusion, could be applied to down-the-line endpoints such as -causal learning.\n- This method really leans into explainability\/interpretability and could thus be more compatible in human-ML frameworks\n\nWeaknesses:\n- While the method is novel and seems to recover structure quite well, the results are not as convincing as I’d like.  To lay this out:\nGiven a toy generative hierarchical model, HCM is able to more effectively predict sequences than a basic RNN, particularly as the levels of hierarchy increased. Not to be too glib, but I should hope so!\n\n- In an environment where the HCM representations overlap with the underlying model, it outperforms a learned-from-scratch HCM, while in the opposite case, it underperforms. The authors suggest that the nature of the HCM (as compared to something like a DNN) allows users to understand a priori whether their pretrained model will work well, which I agree with\n- In toy visual domains with and without temporal correlations, HCM learns reproduces the underlying representations. But how does its ability to reproduce the actual sequences compare with appropriate baselines.\n\n- Finally, HCM is applied to a corpus from the Hunger Games and is able to learn commonly-repeated phrases over time.\n\nMy main concern with all of this is the lack of actual baselines. I agree that the models are interpretable and useful, but they aren’t applied to any previously-used datasets or compared (empirically) to other SOTA methods. HCM doesn’t necessarily need to *win* in performance, given its other advantages, but I’d like to see whether it’s competitive\n\n- On a related note, the authors provide both idealized and online HCM algorithms. Even the “online” algorithm, while theoretically tractable, seems practically quite slow, which I assume is why the chosen domains are simple. While the online algorithm seems to work well for these domains, I would imagine the loss of guarantees is more likely to be impactful in harder domains.\nIt was not clear to me how the chunks were generated until I read the independence tests section in the appendix, and I think that this is too important to push out of the body of the paper. It also introduces the hyperparameter of statistical significance p, which isn’t really discussed.\n","sentences":[{"sentence_type":"2","sentence":"Not to be too glib, but I should hope so!","rephrased":"As expected, HCM outperforms a basic RNN, especially with increasing levels of hierarchy, which is a promising result."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1429,1470,"Not concerning"]],"Comments":[]}
{"id":"aLcUnnu4VGQ","text":"Towards progressing language models (LMs) capacity in in-context learning for reasoning, the authors propose the novel algorithm of LMLP. It uses logic rule templates and examples combined with pre-trained knowledge to do in-context learning iteratively to answer a relational query. This effectively yields a question-answering perspective to the task. Overall, LMLP consists of two LMs: Planning-LM and Translation-LM. The model is being compared with different versions of Chain-of-Thought models in experimental settings of CLUTRR-LP and Countries-LP datasets. Interestingly enough, few-shot in-context learning allows for LMs to incorporate background-knowledge without retraining. Overall, the proposed method offers an interesting perspective for further explorations to be carried out. Except for a few typos, there are no remarks to be made. ","sentences":[{"sentence_type":"1","sentence":"Except for a few typos, there are no remarks to be made.","rephrased":"While there are a few typos, the paper is well-composed and presents its ideas clearly."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[794,850,"Not concerning"]],"Comments":[]}
{"id":"HklOGRbmc4","text":"This paper derives a variational lower bound to the data log likelihood, which allows us to\nimpose a prior constraint on the bulk statistics of the aggregate posterior distribution for the entire\ndataset. The analysis shows that the proposed method achieves better reconstruction quality, as well as forming a smooth, compact and meaningful latent representation. I would like to accept the paper for the workshop.","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"fdNBTmdwM_","text":"Strength:\nThe authors conduct experiments on multiple datasets.\n\nWeaknesses:\n1. The motivation of this work is problematic or unconvincing. It is not clear why the auxiliary interest-based item representations are necessary because they can be inherently encoded by item-based user interest models. The authors do not provide evidence on this point. In addition, it is not clear why the training task is also the recommendation task. It seems that the proposed method is in fact a kind of ensemble.\n2. The contribution of this paper is also marginal. The authors directly adopt the off-the-shelf capsule network MIND for multi-interest modeling. There are also many other existing multi-interest modeling works [1-3]. The authors do not cite nor compare any other multi-interest modeling methods. \n3. The evaluation is rather flawed. The authors only compare the results of adding MICN to several methods. However, there are many methods that aim to enhance item embeddings in existing literature (like [1]). In addition, the authors do not evaluate the effectiveness of the MICN method. Thus, it is not clear whether the improvement is brought by the multi-interest architecture or simply brought by the increase of model complexity. \n4. Many important details are missing. For example, many hyperparameters in this work are not included, and the methods for constructing training and evaluation samples are not introduced.\n5. The coverage of related work is too limited. The authors should track the recent advances in the recommender system community.\n6. The writing and presentation also need improvement. The motivation part needs revisions most. Many sentences are not clear. The experimental discussions are uninformative. There are many typos and grammatical errors. The fonts in figure 1 are too small.\n\n\n[1] Pal, Aditya, et al. \"PinnerSage: multi-modal user embedding framework for recommendations at pinterest.\" Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2020.\n[2] Qi, Tao, et al. \"HieRec: Hierarchical User Interest Modeling for Personalized News Recommendation.\" arXiv preprint arXiv:2106.04408 (2021).\n[3] Liu, Zheng, et al. \"Octopus: Comprehensive and Elastic User Representation for the Generation of Recommendation Candidates.\" Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020.","sentences":[{"sentence_type":"2","sentence":"The motivation of this work is problematic or unconvincing.","rephrased":"The motivation of this work could be strengthened and made more convincing."},{"sentence_type":"2","sentence":"The contribution of this paper is also marginal.","rephrased":"The contribution of this paper could be more clearly articulated, especially in the context of existing literature."},{"sentence_type":"2","sentence":"The evaluation is rather flawed.","rephrased":"The evaluation could be improved by addressing certain methodological concerns."},{"sentence_type":"1","sentence":"The writing and presentation also need improvement.","rephrased":"The writing and presentation could benefit from further refinement for clarity and coherence."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[80,139,"Not concerning"],[502,550,"Not concerning"],[801,833,"Not concerning"],[1558,1609,"Not concerning"]],"Comments":[]}
{"id":"Hye-MhpZT7","text":"This paper introduces a family of attack on confidence thresholding algortihms. Such algorithms are allowed to refuse to make predictions when their confidence is below a certain threshold. \n\nThere are certainly interesting links between such models and KWIK [1] algorithms (which are also supposed to be able to respond 'null' to queries), however they are not mentioned in this paper, which focuses mainly on evaluation methodologies.\n\nThe definition of the metric is certainly natural: you would expect some trade-off between performance in the normal versus the adversarial regime. I am not certain why the authors don't simply measure the success rate on both natural and adversarial conditions, so as to have the performance metric uniform. Unfortunately the paper's notationleaves something to be desired, as it fails to concretely define the metric.\nLet me do so instead, and consider the classification accuracy of a classification rule $P_t$ using a threshold $t$ under a (possibly adaptive) distribution $Q$ to be $U(P,Q)$. Then, we can consider $Q_N, Q_A$ as the normal and adversarial distribution and measure the corresponding accuracies. \n\nEven if we do this, however, the authors do not clarify how they propose to select the classification rule. Should they employ something like a convex combination:\n\\[\nV(P_t) := \\alpha U(P_t, Q_N) + (1 - \\alpha) U(P_t, Q_A) \n\\]\nor maybe take a nimimax approach\n\\[\nV(P_t) := \\min \\{U(P_t, Q) | Q = Q_A, Q_N\\}\n\\]\n\nIn addition, the authors simply plot curves for various choices of $t$, however it is necessary to take into account the fact that measuring performance in this way and selecting $t$ aftewards amounts to a hyperparameter selection [2]. Thus, the thresholding should be chosen on an independent validation set in order to optimise the chosen performance measure, and then the choice should evaluated on a new test set with respect to the same measure $V$\n\nThe MaxConfidence attack is not very well described, in my opinion. However, it seems it simply wishes to find to find a single point $x \\in \\mathbb{S}$ that maximises the probability of misclassification. It is not clear to me why performance against an attack of this type is interesting to measure.\n\nThe main contribution of the paper seems to be the generalisation of the attack by Goodfellow et al to softmax regression. The proof of this statement is in a rather obscure place in the paper. \n\nI am not sure I follow the idea for the proof, or what they are trying to prove. The authors should follow a standard Theorem\/Proof organisation, clearing stating assumptions and what the theorem is showing us. It seems that they want to prove that if a solution to (1) exists, then MaxConfidence() finds it. But the only definition of MaxConfidence is (1). Hence I think that their theorem is vacuous. There are quite a few details that are also unclear such as what the authors mean by 'clean example' etc. \n\nHowever the authors do not explain their attack very well, their definition of the performance metric is not sufficiently formal, and their evaluation methodology is weak. Since evaluation methodology is the central point of the paper, this is a serious weaknes. Finally, there doesn't seem to be a lot of connection with the conference's topic.\n\n[1] Li, Lihong, Michael L. Littman, and Thomas J. Walsh. \"Knows what it knows: a framework for self-aware learning.\" Proceedings of the 25th international conference on Machine learning. ACM, 2008.\n\n[2] Bengio, Samy, Johnny Mariéthoz, and Mikaela Keller. \"The expected performance curve.\" International Conference on Machine Learning, ICML, Workshop on ROC Analysis in Machine Learning. No. EPFL-CONF-83266. 2005.\n","sentences":[{"sentence_type":"2","sentence":"Unfortunately the paper's notationleaves something to be desired, as it fails to concretely define the metric.","rephrased":"The paper could benefit from a clearer definition of the metric, which would help in understanding the evaluation methodology more concretely."},{"sentence_type":"1","sentence":"The MaxConfidence attack is not very well described, in my opinion.","rephrased":"The description of the MaxConfidence attack could be elaborated upon to enhance the reader's understanding."},{"sentence_type":"3","sentence":"However the authors do not explain their attack very well, their definition of the performance metric is not sufficiently formal, and their evaluation methodology is weak.","rephrased":"The authors could improve the paper by providing a more detailed explanation of their attack, formalizing the definition of the performance metric, and strengthening the evaluation methodology."},{"sentence_type":"2","sentence":"Since evaluation methodology is the central point of the paper, this is a serious weaknes.","rephrased":"Given that the evaluation methodology is central to the paper, further development in this area would significantly enhance the work."},{"sentence_type":"2","sentence":"Finally, there doesn't seem to be a lot of connection with the conference's topic.","rephrased":"Additionally, it would be beneficial to clarify how the paper's contributions relate to the main themes of the conference."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[747,857,"Not concerning"],[1921,1988,"Not concerning"],[2931,3102,"Not concerning"],[3103,3193,"Not concerning"],[3194,3276,"Not concerning"]],"Comments":[]}
{"id":"SJ2P_-YgG","text":"The main idea of this paper is to replace the feedforward summation\ny = f(W*x + b)\nwhere x,y,b are vectors, W is a matrix\nby an integral\n\\y = f(\\int W \\x + \\b)\nwhere \\x,\\y,\\b are functions, and W is a kernel. A deep neural network with this integral feedforward is called a deep function machine. \n\nThe motivation is along the lines of functional PCA: if the vector x was obtained by discretization of some function \\x, then one encounters the curse of dimensionality as one obtains finer and finer discretization. The idea of functional PCA is to view \\x as a function is some appropriate Hilbert space, and expands it in some appropriate basis. This way, finer discretization does not increase the dimension of \\x (nor its approximation), but rather improves the resolution. \n\nThis paper takes this idea and applies it to deep neural networks. Unfortunately, beyond rather obvious approximation results, the paper does not get major mileage out of this idea. This approach amounts to a change of basis - and therefore the resolution invariance is not surprising. In the experiments, results of this method should be compared not against NNs trained on the data directly, but against NNs trained on dimension reduced version of the data (eg: first fixed number of PCA components). Unfortunately, this was not done. I suspect that in this case, the results would be very similar. \n\n","sentences":[{"sentence_type":"2","sentence":"Unfortunately, beyond rather obvious approximation results, the paper does not get major mileage out of this idea.","rephrased":"While the paper presents some approximation results, it would be beneficial to see further exploration and applications of this idea to demonstrate its full potential."},{"sentence_type":"2","sentence":"Unfortunately, this was not done. I suspect that in this case, the results would be very similar.","rephrased":"It would be informative to include a comparison with neural networks trained on a dimension-reduced version of the data, such as the first fixed number of PCA components, to provide a more comprehensive evaluation of the method's performance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[846,960,"Maybe"],[1282,1379,"Not concerning"]],"Comments":[]}
{"id":"ryht5AYlM","text":"This paper proposes a geometric based approach to solving the problem of one-shot and few-shot learning. The basic idea is to use the feature vectors of a particular class to construct a simplex. (I am assuming the dimensions of the vectors are selected so as to exactly construct a simplex? It is not clearly written in the paper). The volume of the simplex is then taken to be a measure of class scatter, and classification happens by assigning the test feature vector to the nearest simplex, where the distances are normalized by the volume of the simplex. \n\nWhile the approach makes sense, I am not convinced that this geometric method plays an important role in increasing the performance on one-shot\/few-shot tasks. In particular, one could try simpler approaches like k-NN where the distances to the cluster centers are also normalized by the variance within the clusters. I would suspect that this method is not superior to this simpler baseline. \n\nThe other issue I have with this paper is misleading claims about being state of the art on Omniglot. In particular see Kaiser et al (ICLR 2017), where on 5-way-1-shot an accuracy of 98.4% is reached compared to 94.6% in this paper, and on 5-way-5-shot an accuracy of 99.6% is reached compared to 99.1% in this work. The paper also misses evaluations on various other data sets such as GNMT etc., on which Kaiser et al evaluated their approach.","sentences":[{"sentence_type":"2","sentence":"I would suspect that this method is not superior to this simpler baseline.","rephrased":"It would be beneficial to compare this method with simpler baselines, such as k-NN normalized by cluster variance, to clearly establish its advantages."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[880,954,"Not concerning"]],"Comments":[]}
{"id":"m_syxD6G3u9","text":"On the methodology side, the paper is thorough, well-executed, with (mostly) clear results and well-designed experiments. Unfortunately, I think it lacks a strong selling point as most of the proposed insights are not novel enough.\n\nFor example, it is well-known that fine-tuning a pretrained model improves performance on downstream tasks, especially when those downstream tasks differ from upstream ones. See, for example, the work of Li et al. (2020) for an in-depth study on pretrained vision models, and Dodge et al. (2020) on language models. Similarly, the conclusion that larger models and datasets improve transfer is also well-studied — see the literature around \"neural scaling laws\", e.g., Kaplan et al. (2020) or Zhai et al. (2021) and references therein.\n\nMaybe the most interesting contribution is the insight that smaller learning rates improve OOD accuracy even thought they perform on par with larger learning rates in ID data. But here the results are muddied, since this seems to be true for some settings but not all (p. 5, 1st paragraph). Could the authors expand on why ImageNet-pretrained models benefit from larger learning rates but not other models? What is their intuition for when practitioners should choose larger or smaller learning rates for OOD fine-tuning?\n\nReferences:\n\n- Hao Li, Pratik Chaudhari, Hao Yang, Michael Lam, Avinash Ravichandran, Rahul Bhotika, Stefano Soatto, \"Rethinking the Hyperparameters for Fine-tuning\", 2020.\n- Jesse Dodge, Gabriel Ilharco, Roy Schwartz, Ali Farhadi, Hannaneh Hajishirzi, Noah Smith, \"Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping\", 2020.\n- Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, Dario Amodei, \"Scaling Laws for Neural Language Models\", 2020.\n- Xiaohua Zhai, Alexander Kolesnikov, Neil Houlsby, Lucas Beyer, \"Scaling Vision Transformers\", 2021.","sentences":[{"sentence_type":"2","sentence":"Unfortunately, I think it lacks a strong selling point as most of the proposed insights are not novel enough.","rephrased":"While the paper is methodologically sound, it would benefit from a clearer articulation of its unique contributions, as some of the insights appear to overlap with existing literature."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[122,231,"Not concerning"]],"Comments":[]}
{"id":"BNxxvrMexGc","text":"The paper proposes a method for learning structured world models by capturing cause and effect relationships between actors and obects. \nPros of the paper\n1. The paper is very well written, it is clear and easy to follow. \n2. The paper looks at an very interesting problem of learning cause-effect relationships between actors and objects in a world model. This is a very promising direction of research, since learning cause and effect relationships could allow models to generalize much better, especially OOD.\n3. The method is interesting and makes sense, thanks for the evaluating on the mutual information between states. \n\nThere are a few things that might be interesting to take into consideration in the next version.\n1. I believe that this method assumes  certain structures in the cause-effect relationship. For example, the method assumes that there is a bipartite relationship between actors and objects only. For example, if the actor acted on object A, and later, the changes in object A effects object B. Im not sure the current model could capture this. However, this is very important for causal learning (as most of the time, the causal structure is not a bipartite graph).  The method also assumes that the object can not influence the actor, which may not always hold true in the real world. It might be nice to include a section that discusses about this.\n2. I believe the method can not necessarily disentangle correlations in the data. It might be nice to include a section that discuss about this in the paper. \n3. There is a very related paper called \"Neural Production Systems\" at NeurIPS 2021. The NPS method can similarly learn relationships between objects and rules. It might be nice to include a discussion about this paper.\n4. Lastly, it might be interesting to see the method working on other tasks that involves more complicated transfers between training and test tasks.\n\nOverall, the paper is very well written, the method is interesting and I would be very excited to see further experiments and results on this method.","sentences":[{"sentence_type":"1","sentence":"Im not sure the current model could capture this.","rephrased":"It's unclear if the current model can capture this complexity, and further investigation could be beneficial."},{"sentence_type":"2","sentence":"I believe the method can not necessarily disentangle correlations in the data.","rephrased":"It would be valuable to explore how the method might disentangle correlations in the data more effectively."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1020,1069,"Not concerning"],[1380,1458,"Not concerning"]],"Comments":[]}
{"id":"OLCYPVZAmhN","text":"This study presents estimates for COVID incidence cases, deaths, and vaccination rates based on a survey study. \n\nOverall, the paper is really good in quality, clarity, originality and significance. The paper is well-written; however, there are a few areas that the authors should address:\n\n1. In section 2.1, the authors conducted an online survey in Australia and the UK for validation. It would be beneficial for the authors to provide justification for selecting these specific countries. For example, they should explain why China was not included in the online survey.\n\n2. If space allows, it would be helpful to include a figure illustrating the skewness in the data, as discussed in Section 2.2. This figure could demonstrate the requirement of Medcouple statistics.\n\n3. Please include a reference for the Cronbach's alpha coefficient. This would provide readers with additional information and support the use of this measure.\n\n4. To  enhance the paper's transparency, the authors should clarify how the 95% confidence interval (C.I.) was computed in Table 1 and Table 2. \n\n5. It is unclear how a small sample size, such as the one used for all the cities, can be utilized to derive the confidence interval and make any valid claims. \n\nBy addressing these points, the authors can further improve the clarity and comprehensiveness of their work.\n\n\n","sentences":[{"sentence_type":"2","sentence":"It is unclear how a small sample size, such as the one used for all the cities, can be utilized to derive the confidence interval and make any valid claims.","rephrased":"The authors may want to elaborate on the methodology used to derive confidence intervals from the small sample size, to strengthen the validity of the claims made."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1086,1242,"Maybe"]],"Comments":[]}
{"id":"H1gGrehCOr","text":"Summary: \n\nThis paper proposes an optimization principle that is called \\gamma-optimization principle for stochastic algorithms (SA) in nonconvex and over-parametrized optimization. The author(s) provide convergence results under this “\\gamma-optimization principle” assumption. Numerical experiments are conducted on classification datasets CIFAR-10 and CIFAR-100 for Alexnet and Resnet-18 with different activation functions. \n\nComments: \n\n1) Could you please explain how you could achieve the value of \\theta* (common global minimizer for the loss on all individual component functions)? It is unclear to me how you could obtain it. \n\n2) You have not mentioned the loss function that you are using for your numerical experiments. From my view, you are using softmax cross-entropy loss for classification problems (CIFAR-10, CIFAR-100). Can you show that Fact 1 is true for softmax cross-entropy loss? I wonder how you could train the total loss to achieve zero for this loss. \n\n3) Fact 1 with over-parameterized model could be true if the loss, for example, is mean square (for regression problems). Therefore, I would suggest you to consider other numerical examples rather than classification problems. If not, the numerical part is not very consistent with the theoretical part. \n\n4) The assumption that the author(s) use in the paper, that is, \\gamma-optimization principle in Definition 1, is indeed strong and not reasonable. You simply assume what you want in order to achieve the convergence result. It is not easy to verify this assumption since you include \\theta* unless it has only a unique solution. Note that the learning rate (eta) and gamma are very sensitive here and it is not clear how to determine these values. \n\n5) There is related work that you may need to consider: Vaswani et al 2019, \"Fast and Faster Convergence of SGD for Over-Parameterized Models (and an Accelerated Perceptron)\" in AISTATS 2019. \n\nI think the paper still needs lots of work to be ready. Theoretical result is not strong and the numerical experiments are not convincing. I do not support the publication for this paper at the current state. \n\nMinor: \n1) I am not really why you have a question mark (?) in the title. \n","sentences":[{"sentence_type":"2","sentence":"You simply assume what you want in order to achieve the convergence result.","rephrased":"The assumption of the \\\\(gamma\\\\)-optimization principle in Definition 1 appears to be quite strong. Could you provide further justification for this assumption or discuss its feasibility in the context of achieving the convergence result?"},{"sentence_type":"2","sentence":"I think the paper still needs lots of work to be ready. Theoretical result is not strong and the numerical experiments are not convincing.","rephrased":"The paper could benefit from further development to strengthen the theoretical results and provide more compelling numerical experiments."},{"sentence_type":"2","sentence":"I do not support the publication for this paper at the current state.","rephrased":"I believe that the paper is not yet ready for publication in its current form and would benefit from additional work and revisions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1435,1510,"Not concerning"],[1931,2069,"Not concerning"],[2070,2139,"Not concerning"]],"Comments":[]}
{"id":"KRD0zkNQEmJ","text":"\n*** Key idea justification ***\n\nThis work shows that contrastive loss (for self-supervised learning) is an upper bound of cross-entropy loss (for supervised learning) and leads to a conclusion that this is the underlying reason why self-supervised learning can help supervised learning in FSL. This reasoning makes little sense with little logic. \n\nConcretely, there exist a number of to-be-answered questions before connecting the two things and making theoretical conclusion: \n1) Why we need to know the upper bound of supervised learning loss given that we already have label data with the training data? \n2) Decreasing SSL loss does not necessarily mean that supervised learning loss is also decreased, as it is just an upper bound. No guarantee there. \n3) Assume SSL helps decrease the supervised learning loss, then why is this needed when we can simply use class labels to minimize it? Intuitively, the two are overlapping and SSL should be not useful. \n\nBesides, this paper only considers the case of contrastive loss which involves false negative samples. What if applying other SSL loss function, for example rotation? I do see the same analysis applies to that.\n\nIn conclusion, the proposed theory makes little sense and is also over-claimed. The whole study is neither theoretical nor logical. \n\n\n*** Presentation clarity ***\n\n1) In general, the presentation of this paper is poor. One reason is using odd\/strange terminologies and equation expressions. For example, contrastive loss (Eq 1) and cross-entropy loss (Eq 3) both are not given in their common expression. Other examples are \"Supervised Metric for Representations\" and \"Self-Supervised Metric (SSM) for Representations\", \"a metric loss\", etc. \n\n2) Quite a few equations are hard to read and understand. First, Eq (1) and (3) are not expressed in a standard way. How are they derived? \n\n3) What is the difference between a class-wise prototype pc and an episodic mean of support samples (At the end of Sec 3).\n\n4) What means by \"the class distribution ρ is uniform\" in the proof of Theorem 2?\n\n5) What is implied by the last sentence of Sec 4: Theoretically, if given an unsupervised set with infinite classes and data, the performance achieved by SSM can be very close to that by supervised training?\n\n\n\n*** Grammatical errors ***\n1) a episodic -> an episodic\n","sentences":[{"sentence_type":"2","sentence":"This reasoning makes little sense with little logic.","rephrased":"The reasoning presented could benefit from additional clarification and logical support."},{"sentence_type":"3","sentence":"In conclusion, the proposed theory makes little sense and is also over-claimed. The whole study is neither theoretical nor logical.","rephrased":"In conclusion, the proposed theory could be more rigorously substantiated, and the claims made may require further theoretical and logical evidence."},{"sentence_type":"2","sentence":"In general, the presentation of this paper is poor.","rephrased":"The presentation of the paper could be improved for better clarity and understanding."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[295,347,"Not concerning"],[1175,1306,"Maybe"],[1343,1394,"Maybe"]],"Comments":[]}
{"id":"DGzYVuzXJb","text":"Overall the paper is interesting since the author provides an alternative perspective in domain generalization: searching the proper loss function.  However, this reviewer still found a couple of important concerns (including theory, method, and paper writing) that prevent me from accepting the current version. Based on these, I believe a major revision and rethinking about the cons can significantly improve the paper.\n\nPros:\n\n- This paper proposes a novel direction in domain generalization: searching the proper loss. Although this idea is not completely novel in the related domains such as NAS or AutoML, applying them to the domain generalization seems quite interesting and novel.\n- The empirical studies and analysis are extensive.\n\nCons (see detailed reviews for explanations):\n\n- The main concern lies in the theoretical aspects: why and when it works or fails? The proposed idea currently seems a bit ad-hoc. \n- The paper is not self-contained. Some details are quite difficult to follow or lack motivation.\n\n---------------Detailed reviews\n\n**About theoretical understanding.**\n\nI totally agree with the author’s viewpoint about the problem revealed in domainBed. However, in this paper, the author fails to clearly justify why the proposed parametric loss $w$ can effectively solve this problem. Specifically,\n\n1. Does the bi-level optimization indeed search for the correct parametric loss rather than over-fitting? Note in the domain generalization, the source number is generally quite limited (different from NAS), supposing you only have 3 sources, it is quite difficult to show the bi-level indeed finding the best configuration. (It is more likely overfitting). To address this, the author should provide a clear theoretical analysis to show when the proposed method can work. \n\n2. The selected Taylor Polynomial representation is wired and lacks motivation. Why do we choose this specific loss? What is the convergence behavior in the bi-level optimization if this loss is adopted? Why not MSE loss? Triple loss? This paper lacks a clear motivation in illustrating why it is essential.\n\n3. The experimental settings in the single DG are also wired. Clearly, one source could not generalize to other related targets. Therefore I am a bit doubtful about the proposed method...\n\n**Other technique details**\n\n- Some parts are not self-contained and unclear. For example, \n\n1. Algo 1, Line 15 there is no description of the grad-surgery approach.\n\n2. Algo1, Line 16. h{update...} what does it mean?\n\n3. In algorithm 2, the description seems inconsistent with the sum of the Neumann series. The role of j is missing in the loop. \n\n4. Computing jacobian-vector product in PyTorch seems a bit difficult if we directly adopt PyTorch since PyTorch currently does not support the form (algorithm 2) Jacobian-vector-product(parameter of neural-network,\\theta,v). I am wondering how you addressed this.\n\n- The convergence bound of using Neumann series or Implicit gradient is highly expected to provide. (I think it is feasible under proper assumptions.)\n\n- There may exist a memory complex concern since the $H$ in the algorithm depends on the task number. If n is large, the memory complexity can be quite high (although the implicit function addressed the computational complexity).\n\n\n\n\n\n\n\n","sentences":[{"sentence_type":"2","sentence":"However, in this paper, the author fails to clearly justify why the proposed parametric loss $w$ can effectively solve this problem.","rephrased":"However, in this paper, the justification for why the proposed parametric loss $w$ can effectively solve the problem could be made clearer."},{"sentence_type":"2","sentence":"The selected Taylor Polynomial representation is wired and lacks motivation.","rephrased":"The choice of the Taylor Polynomial representation is unconventional and could benefit from additional motivation."},{"sentence_type":"2","sentence":"The experimental settings in the single DG are also wired.","rephrased":"The experimental settings in the single DG are also unconventional."},{"sentence_type":"1","sentence":"Therefore I am a bit doubtful about the proposed method...","rephrased":"Therefore, I would appreciate further clarification on the proposed method's effectiveness in this context."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1179,1311,"Not concerning"],[1805,1881,"Not concerning"],[2114,2172,"Not concerning"],[2240,2298,"Not concerning"]],"Comments":[]}
{"id":"8zXCZjK1rZ7","text":"In this paper, the authors study a procedure for pruning (sparsifying) and binarizing neural networks through a pruning procedure. They do this by taking a trained dense network, pruning the synapses to get to a sparser network, and then doing a stochastic search over \"connection swaps\" to further optimize the pruned network.\n\nReasonable performance is shown on MNIST. They also show data for a car-racing imitation task; the details of that task are a bit sparse, so I am not sure how impressive their 90% performance figure is for that task.\n\nI found some other details to be missing (discussed below), and also have a few conceptual criticisms of this work. I like the concept a lot: of searching over sparse network configurations to find high performance small networks. But this work seems somewhat preliminary. \n\nCriticisms:\n\n1) Sec 4.1 could have used more detail:\na) how do you decide which connections to prune in step 2? Is it the weakest ones? Or did you find those for which the gradients of the loss with respect to the weights were smallest in magnitude? Or do something else?\n\nb) what is the training procedure during step 4 (training after binarizing)? Is that a combinatoric search over the connection swaps? Or was this just done by adjusting the thresholds for individual units? Or some other thing?\n\n2) Sec. 4.2: is the search over swaps greedy (one connection swap at a time)? If so, that seems likely to miss global optima that require, say, a \"bad\" bit swap to get over to a better region of the space. That should be discussed I think, even if there is not an immediately effective solution available.\n\n3) This work doesn't seem architecture agnostic: you are still specifying the number of layers, conv vs dense, etc. It seems more like you have an approach for sparsifying (which could still be useful!). But I am not persuaded that this work solves the architecture search problems in any meaningful way. There has been some nice recent progress in this area (e.g., the autoML zero work from Quoc Le et al.) that might interest the authors if they are curious about genuine progress in architecture agnostic NNs.\n\n\n\n- autoML zero\n- doesn't seem architecture agnostic","sentences":[{"sentence_type":"2","sentence":"But this work seems somewhat preliminary.","rephrased":"While this work is a promising start, it appears to be in the early stages and could benefit from further development."},{"sentence_type":"2","sentence":"But I am not persuaded that this work solves the architecture search problems in any meaningful way.","rephrased":"I am not yet convinced of the extent to which this work addresses the challenges of architecture search, and I look forward to seeing more evidence of its impact in this area."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[778,819,"Not concerning"],[1834,1934,"Not concerning"]],"Comments":[]}
{"id":"e65ePnScK6N","text":"This paper introduces Neighbourhood Distillation (ND), a new training pipeline for knowledge distillation (KD), which splits the student network into smaller neighbourhoods and trains them independently. The authors breaks away from the end-to-end paradigm in previous KD methods and provides empirical evidence to reveal feasibility and effectiveness of ND. Specially, ND can: 1) speed up convergence, 2) reuse in neural architecture search and 3) adapt to the synthetic data.\n\nStrengths\n1) The paper is well written and easy to follow. An empirical evidence of the thresholding effect is provided to explain the motivation.\n2) The idea is simple and intuitive. The ND seems more like an initialization method for DNN’s local components and a finetuning procedure is sometimes needed for recovering the accuracies. Benefit from parallelism and small training components, such training schema can speed up the convergence of standard KD.\n3) Several different applications are conducted to demonstrate the flexibility of ND.\n\nWeaknesses\n1) Missing a relevant paper. [1] proposes a similar blockwise knowledge distillation method. The authors should cite and explain the differences between ND and [1].\n2) What is sparsification in Sec. 4? Is it the sparseness of the convolutional kernel or the channel? \n3) The authors mention that the work seeks to overcome the limitations of training very deep networks. However, the ResNet50 (the deepest model in experiments) is not deep enough. Usually, it is easy to converge.  \n4) In Sec. 5, only the width search experiments are conducted, which is more like layer-wise or block-wise pruning. However, architecture search is a general method that can not only search the widths but also the operations. Why only mentions “This set could contain variants of the same architecture...”? Is there any limitation when the searched candidates contain different architectures\/operations? \n5) All the experiments are done on ResNet series. Different teacher and\/or student architectures, such as VGG, ShuffleNet etc., should be considered.\n6) Does the observation of thresholding effect benefit from the shortcut in Resblok？Is it suitable for plain CNN, such as VGG? Which blocks are chosen in Fig. 1(a)? Does the shallow and deep blocks have the same phenomenon when perturb small number of blocks?\n7) How to record the GPU time of ND? Is it the time of paralleling on multi-GPUS or on single GPU?\n\nI am currently leaning towards a slightly negative score but would like to see the authors' responses and other reviewer's comments.\n\n\n[1] Hui Wang, Hanbin Zhao, Xi Li, Xu Tan. Progressive Blockwise Knowledge Distillation for Neural Network Acceleration. IJCAI, 2018.\n","sentences":[{"sentence_type":"1","sentence":"The authors breaks away from the end-to-end paradigm in previous KD methods and provides empirical evidence to reveal feasibility and effectiveness of ND.","rephrased":"The authors depart from the end-to-end paradigm in previous KD methods and present empirical evidence to demonstrate the feasibility and effectiveness of ND."},{"sentence_type":"2","sentence":"The authors mention that the work seeks to overcome the limitations of training very deep networks. However, the ResNet50 (the deepest model in experiments) is not deep enough. Usually, it is easy to converge.","rephrased":"While the authors aim to address the limitations of training very deep networks, it would be beneficial to include models deeper than ResNet50 in the experiments, as ResNet50 is generally known for its ease of convergence."},{"sentence_type":"2","sentence":"I am currently leaning towards a slightly negative score but would like to see the authors' responses and other reviewer's comments.","rephrased":"I am currently inclined to give a cautious score, pending further clarification from the authors and insights from other reviewers' comments."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[204,358,"Not concerning"],[1307,1516,"Not concerning"],[2434,2566,"Not concerning"]],"Comments":[]}
{"id":"EB2nH2OydHP","text":"The paper demonstrates that selectively re-using the policies of some agents are important to realize the benefit of Reincarnation in the multi-agent reinforcement learning setting. The setting studied is interesting and I agree with the paper that this is a rich area for further scientific exploration.","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[],"Comments":[]}
{"id":"rkl9XBCfcN","text":"This paper proposes a new generative model for unordered data, with a particular application to point clouds. This model includes an inference method and and a novel objective function based on sandwiching the Wasserstein distance between an upper and lower bound.  The paper includes a clear description of the problem and motivation and strong experimental results, both quantitative and qualitative.\n\nPros:\n- Novel, reasonable model\n- Clear writing\n- Strong evaluation and results\n- Interesting new objective based on Wasserstein bounds\n\nCons:\n- For the practical problem of 3D shape modeling, could compare to other representations e.g. Surface Networks: http:\/\/openaccess.thecvf.com\/content_cvpr_2018\/papers\/Kostrikov_Surface_Networks_CVPR_2018_paper.pdf","sentences":[{"sentence_type":"1","sentence":"For the practical problem of 3D shape modeling, could compare to other representations e.g. Surface Networks: http:\/\/openaccess.thecvf.com\/content_cvpr_2018\/papers\/Kostrikov_Surface_Networks_CVPR_2018_paper.pdf","rephrased":"To further strengthen the practical implications of the model for 3D shape modeling, it would be beneficial to include comparisons with other representations, such as Surface Networks: http:\/\/openaccess.thecvf.com\/content_cvpr_2018\/papers\/Kostrikov_Surface_Networks_CVPR_2018_paper.pdf"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[549,759,"Not concerning"]],"Comments":[]}
{"id":"xxBo_y5ncg","text":"# Thank you\n\nThank you for your comments. I see the new manuscript clarified many points.\nUnfortunately, I cannot honestly change my general opinion about the acceptance of the paper.\nThe Sokoban part per see is interesting, although not enough for acceptance.\nThe notion of left-heavy tail is something else. In figure 3-right, the problem can be just very hard to solve.\nFor many algorithms, there are classes of problems that generate a worst-case behaviour.\nI wonder if I could be deeply confused, and tried to challenge my understanding given the comments made and the improvement.\nI couldn't. If you insist this is important, please re-submit to a search-minded venue like Socs,\nor to a journal like the AIJ or JAIR.\n\n# Previous main review\nBefore examining the contributions, I feel obliged to clarify some points that I'd use in the rest of the review.\n\n1. The abstract does not mention that this empirical work is for one domain in particular: Sokoban. Two theorems are stated in the paper but without proofs. That means the observations must be circumscribed to the experiments that compare A* using\n\t- A very basic heuristic\n\t- PHS: DRL policy from previous work\n\t- PHS*: a variation of PHS proposed here.\n2. That leaves only two interesting cases in the experiments: PHS and PHS*. So, the observation about the distribution of complexity and the conjectures are circumscribed to Sokoban and these two related heuristics.\n3. The paper refers to heavy-trail distribution in SAT solving. That's an interesting connection, but it's important to consider that SAT solvers are general tools, not specialized algorithms for specific domains.\n4. Moreover, the paper seems to say that A* is a planning algorithm. The culture of the research community always mediates the name of techniques. Now, the search community –that publishes in SOCS, ICAPS, AAAI and IJCAI– would say that A* is a search algorithm that could be used for planning.\n\t- For instance, specialized algorithms for Sokoban use search algorithms like A*. The search community won't call them planners.\n\t- However, some DRL papers say that MCTS is a planning algorithm, while MCTS is a search algorithm like A*. I do respect that different communities might use different names.\n\t- For completing the picture: the planners that participate in the International planning competitions (IPC) are general solvers, like SAT solvers are. The simple class of problems in the IPC is PSPACE-complete. However, it doesn't mean that all the specific problems are PSPACE-complete. That leads me to the next point.\n5. The observations about the distribution depend on the distribution of the original problem. As shown in many combinatorial domains, algorithms tend to have strengths and weaknesses depending on the domain. For instance, in the SAT competitions, the winner of the industrial track tends to be different from the random track.\n6. That means that observations on the distribution of behaviour need to be grounded on the problem distribution and might not translate in the same way to other algorithms.\n\nThese six points above justify the summary I made about this paper: the paper is not about A* + DRL for policy\/value. Instead, it's about Sokoban and two specific DRL techniques that end up having properties previously observed in SAT solving, and domain-independent planning as SAT.\n\nMoreover, the comparison between using A* with DRL heuristics and other methods is not trivial because of the following.\n\nTypically, non-ML based specialized search algorithms have very efficient node generation. For instance, the reference below discusses cases of over 1 million nodes expanded. On the other hand, DRL networks tend to have lower generation speed, but the training time is not accounted for and can provide an edge in certain instances. That means that neither of these metrics allow a complete picture of the comparison between non-ML vs NN-based heuristics:\n- Running time\n- Number of expansion.\nSo, in table 2, the no-policy versions might generate nodes much faster than the policy-based. On the contrary, it'd make sense to compare node expansions of PHS and PHS+.\n\nI'll finish this section of the review with some questions I'd like to answer in the rebuttal. Then I'll continue with some more comments about the paper.\n\n## Questions to be answered in rebuttal.\n\n0. Could some properties of the instance explain the left-tail? For instance, they could be mostly small instances or very easy to solve.\n1. How many nodes per second expands A* for the different configurations mentioned in Table 2?\n2. The use of SPFA reported before section 4 make it hard to compare the number of expanded nodes with previous work. It is also hard to compare the findings with previous work on A*. How do the experimental results look like if SPFA is not used?\n3. Page 2 says: *In fact, deep learning guided search algorithms that combine traditional search-based methods such as A star with deep neural networks heuristic prediction have shown promising progress. These methods can solve a significant number of hard planning instances that specialized solvers cannot solve.*\n\t- Please add concrete references and comment on the comparison.\n\t- Please take into account that specialized solvers tend to assume a higher running time, and that the good performance might depend on properties of the problem like size. For instance, A* + nontrivial non-ML heuristics might perform well in big environments where the agent needs to travel long distances to move between a few boxes.   \n4. What's the heuristics PureDistance?\n\t- Were other heuristics considered? Indeed, specialized solvers use heuristics too. \n5. How does  Sokosolution compares with the rest of the experiments? Please report running time, expanded nodes, and nodes per second.\n6. How costly is to train the DRL heuristics?\n\t- What parameters were used?\n\t- How were the hyper-parameters tuned? \n\n## Additional comments\n\npage 1: *Recent work based on deep learning guided search algorithms that combine traditional search-based methods, such as A and MCTS search, with deep neural networks' heuristic prediction has shown promising progress*.\nPlease add a reference. There is work all the way from TSP to game-playing. I'm not sure what previous work the paper should consider as relevant.\n\n#### Introduction\n\npage 1: *such as problems captured by the Planning Domain Definition Language (PDDL) (Bylander, 1994) and Sokoban*\nConfusing. I'd switch Sokoban and PDDL. By the way, Sokoban can be expressed in PDDL. Sometimes that's used as a homework: https:\/\/github.com\/Tarrasch\/sokoban-planner\/blob\/master\/sokoban-pddls\/sokoban-domain.pddl\n\npage 1: *(QBF), the canonical example of a PSPACE-complete problem*.\nYes. A reference, please\n\npage 2: *These advances naturally raise the question of whether the success in game domains can be transferred to PSPACE-hard planning domains.*\nAs I mentioned above, trained DRL for game-playing can play one kind of game. So, trained DRL can be compared with a specialized solver. However, suppose the same architecture can be trained in for multiple environments. In that case, they are more general than specialized solvers, depending on how hard they are to tune and the sample complexity. The main question is always how hard it is to generate a good algorithm in a new problem.\n\npage 2: *we explore and generalize the cost distribution profiles of search methods from NPhard domains to PSPACE-hard planning domains, and show heavy-tailed cost distributions exist ubiquitously among planning instances.*\nand page 2: *We identify heavy-tailed runtime distributions of PSPACE-hard planning problems*\nThis holds for Sokoban with these particular heuristics.\n\npage: *Such heavy-tailed distributions have been observed before in NP-hard domains, such as SAT and CSP (Gomes et al., 1997; 1998) but not in PSPACE settings.*\nNot true. See Eldan Cohen, J. Christopher Beck:\nFat- and Heavy-Tailed Behavior in Satisficing Planning. AAAI 2018: 6136-6143.\nSatisfying planning of classical planning is PSPACE. That includes Sokoban.\n \npage 2: *We study the interplay of the policy and value networks in A*-based deep RL. Our experiments show the surprising effectiveness of the policy network*\nWhy is this surprising?\n\npage 3: *We show how a restart strategy can improve the deep RL planner effectiveness. In particular, our experiments show how for a given search budget, there is an optimal restart strategy. For larger budgets, more frequent restarts are most effective.*\nThis depends on the algorithm. State of the art planners sometimes use variations of A* that use extra information from the domain or follow the heuristic more greedily. Search for \"greedy best first search\" and \"enforced hill-climbing\". See also the planner FastDownward: http:\/\/fast-downward.org. \n\n#### Background and Related Work\n\npage 3: *Luby et al. (1993) prove that when we have full knowledge about the distribution p A, the optimal strategy that achieves the minimum expected time*\nWhat about hard tasks that need more time than t_A?\n\npage 3: *figure 1 shows the comparison of heavy tails and exponential tails on various statistics.*\nIs this A* over Sokoban or a synthetic problem such that t_A can be defined analytically?\n\npage 4: *Orseau & Lelis (2021) add path probability π(n) to the minimizing term of A star search*\nWhat's the minimizing term of A*? It searches following the min f=g+h, where g is the cost and h is the heuristic value. Here \\pi(n) is a probability. How is that added?\nI see this explained in more detailed below. I suggest to say here that \"O&L divide the minimize value by \\pi(n)\" or weigth by 1\/\\pi(n).\n\npage 4: *The search quickly degenerates into BFS when goals require a long plan since shallow nodes are always preferred by A star based on π(n). Our method modifies the term π(n) to p(s l|s l−1) to avoid exponential growth of the minimizing term of A* as the depth of nodes grows.*\nIt depends on the heuristic used. Is \\pi(n) as used a heuristic? An heuristic is an estimate of the cost of achieving the goal. Both terms of \\pi(n) would produce values < 1, while the usual cost in Sokoban is 1 per action.    \n\n#### Data preparation\n\npage 5: *remaining unsolved 2609 instances as the hard set to further study the cost distribution of instances that are way harder than the training instances.*\nThey could be slightly harder as it'd take 11 minutes to solve them. I suggest to sample a subset of them and try to solve in 30m or 2h.\n\npage 5: *move\" consists of four actions: upward, downward, rightward, and downward. The framework only needs to detect whether the four adjacent cells are empty, or whether the box is pushable if one occupies an adjacent cell.*\nAnother used alternative is to define push a requiring an adjacent box.\n\n#### Policy-guided A* search\n\npage 5: *We use the path length as the cost of A* search so that g(n) is the depth of node n.*\nI guess the implementation detects repeated nodes. Please clarify\n\npage 5]: PHS star is a significantly improved version*\nSay before that the change is called PHS*\n\npage 5: *We found the combinatorial search is so challenging that the model cannot reliably solve planning instances in the training set even has been trained on ground truth labels from it.*\nI think this argument does not follow. The negative empirical result does not imply that the problem is more or less challenging. I'd accept a weaker statement of the form \"The model couldn't solve instances used for training\".\n\npage 6: *As the evaluation time of deep networks heavily depends on hardware, we use the number of expanded nodes of A star as the runtime cost instead of the actual running time.*\nThis is standard in search research \n\npage 6: *We consider duplicate board detection so that various nodes with the same board will merge into a single node*\nSay this early to make sense of the cost being the path.\nMinor question: what if a shortest path if found later? Optimal A* reopens visited nodes\/states, unless properties of the heuristic imply that's not necessary. In this case, optimality is not required. However, it'd be better to say it clear: \n- duplicate states are not expanded. \n- The cost of a node is the cost of the 1s path to it.\n\npage 6: *To increase the algorithm's efficiency and improve the evaluation metric, each time a node n is popped out from the open set (frontier nodes of the search), we do a local Shortest Path Faster Algorithm (SPFA) starting from n to ensure that no relaxation exists in the closed set at any stage of A star search, i.e., g(u) + 1 ≥ g(v) for each pair of adjacent nodes u, v while u is in the closed set.*\nThis is non standard. I hope an ablation study is done about the impact of this. This description is not enough for reproducing the results\n\n\n#### Heavy tails on the left\n\npage 6: *Our proposed model assumes the existence of O(log(n)) critical nodes among the plan from which a wrong child node selected by A star will result in extra exponential search space.*\nWhy log(n)? What's N in this case? For NP problems, the upper bound is O(n) because that's exactly the complexity in a non-deterministic Turing machine. \nIf this a conjecture, please say so. The conjecture would have value if the empirical results validate it. However, Sokoban is PSpace-complete, so I don't expect this conjecture to be validated in the Experiments section.\n\npage 6: *Theorem 4.1*\nProof of both theorems are not in the main body of the paper. There is no appendix\n\npage 7: *We empirically found that in the search graph of A, the majority of nodes do not branch — heuristics provided by the network is accurate enough to prefer the right child node with high confidence.*\nThis general statement is at odds with the idea of heavy right tail. It'd be inconvenient to change this statement to talk about the mean since that's not well defined for heavy-tail distribution. \n\npage 7: *To explain why SAT solvers work so well in practical instances, Hoffmann et al. (2006) examine various benchmarks and identify that for most practically solvable SAT instances, after assigning values to logarithmic variables, the remaining problem instance quickly becomes polynomially solvable by propagation rules.*\nHoffman et al examine planning instances solve by translation to SAT. Those propositional theory have a particular structures that might not apply directly to SAT. The backdoor conjecture was examined in previous work by the co-authors the Hoffman of that paper. \n\npage 7: *This result illuminates the prototypical patterns of the structure causing the empirical behavior observed in the International Planning Competitions benchmarks.*\nReference? In general, it'd be good to discuss other domains of the planning competition. Some of them have complexity analysis like the referred paper on Sokoban being PSpace-complete.\n\n#### Structure of real search graphs\npage 7: *Whether AI planning systems can find routine macro action, i.e., a sequence of algorithmic actions to perform a sub-goal, has a great interest for researchers.*\nThis phenomenon is fairly common in instances that are solved using A*, when the solution is found quickly. The paragraph after this sentences implies this phenomenon is specific to this experiment. Instead, the paper show report experiments using A and a non-DL heuristic to see if the same phenomena appear. The non-DL heuristic could be a specialized solver or a general automated planner, even if it scales to smaller instances.\n\n#### Effectiveness of policy and value networks\n\npage 8: *5.2 EFFECTIVENESS OF POLICY AND VALUE NETWORKS*\nWhat is Pure Distance? The effectiveness of A* depends strongly on the heuristic. If the heuristic is ill-informed, using WA* tends to degrade the performance.\n\nGeometric Mean? Why? It's hard to qualify the meaning of this result without comparison with other algorithms. \n\nThe experiments are in a region of a relatively low number of expansions. See for instance, Pereira et al below where the number of expansions goes all the way to 1 million nodes.\n\nMoreover, the conclusion about what's the best algorithm depends on how much time is available. The last full international planning competition (2018) included these tracks:\n- satisfying. Score if instance solved in less than 30m.\n- agile. Positive score proportional to speed until a limit of 5m.\nhttps:\/\/ipc2018-classical.bitbucket.io\n\nEven for the same algorithms, the best configurations is different depending on the speed required.\n\nAndré G. Pereira, Marcus Ritt, Luciana S. Buriol,\nOptimal Sokoban solving using pattern databases with specific domain knowledge,\nArtificial Intelligence,\nVolume 227,\n2015,\nPages 52-70,\nISSN 0004-3702,\nhttps:\/\/doi.org\/10.1016\/j.artint.2015.05.011.\n\npage 8: *(3) Weighted A start does not help.*\nThis observation was done in a relative low number of expanded node.\n\n#### Experiment data for the abstract model\n\npage 9: *Hoffmann et al. (2006) has given an explanation to STRIPS-style planning with backdoor models — after finding and assigning logarithmic variables the remaining problem solving becomes polynomial. In contrast, finding these critical nodes is not necessary for expand-style search algorithms*\nThis is for SATPLAN: classical planning as SAT\n\npage 9: *It is widely believed and experimentally confirmed that with polynomially increasing model size, deep networks can achieve\" exponential\" scaling power to unseen states*\nWidely believed by whom? I don't believe that myself as a general statement. It is an interesting hypothesis, but it needs to be studied. A source of confusion is the tension between solving single problems vs general solvers. It does make sense that some learning based algorithms might be more powerful than specialized solvers. But what worked in one domain might not translate into another one. \n\nEnd of the day, what matters is the resources necessary  to get the solutions. If the same domain is to be solved multiple times, like Go, training makes sense. On the other hand, if many variations are solved, it'd make more sense to have a general solver. \n\n#### References\n\npage 10: *Joseph Culberson. Sokoban is pspace-complete. 1997.*\nCheck the font case of the references. Pspace, sat and others are upcase. Rubin is a proper name. \n\npage 11: *Laurent Orseau and Levi HS Lelis. Policy-guided heuristic search with guarantees. arXiv preprint preprint arXiv:1802.10501, 2018. arXiv:2103.11505, 2021.*\nThis was accepted to AAAI 2021. Please avoid arXiv references when the paper has been accepted. \n\nFinally, here are two interesting references:\n- Yaron Shoham and Gal Elidan. \"Solving Sokoban with forward-backward reinforcement learning\". SOCS 2021. (Both in arXiv and in the socs website, where this is a video too).\n\t- This might be a good algorithm for comparison. \n\t- I still think that's fairly standard in search. In a sense, the left-tail was always there as. \n- This is an undergrad thesis. I cite it with the best of intentions. It showed up as I was looking for references. It discusses cases where Sokoban becomes harder for non-specialized planners (using PDDL).\n\t- https:\/\/ai.dmi.unibas.ch\/papers\/theses\/haenger-bachelor-13.pdf\n- This is another relevant undergrad thesis\n\t- https:\/\/baldur.iti.kit.edu\/theses\/SokobanPortfolio.pdf\n\nSee below some extra problems that are also PSPACE-complete:\n- PSPACE-Completeness of Sliding-Block Puzzles and Other Problems through the Nondeterministic Constraint Logic Model of Computation. Robert A. Hearn, Erik D. Demaine\n- Aviezri S. Fraenkel and Elisheva Goldschmidt. 1987. PSPACE-hardness of some combinatorial games. J. Comb. Theory Ser. A 46, 1 (Sept. 1987), 21–38. DOI:https:\/\/doi.org\/10.1016\/0097-3165(87)90074-4\n","sentences":[{"sentence_type":"2","sentence":"Unfortunately, I cannot honestly change my general opinion about the acceptance of the paper.","rephrased":"While the manuscript has been clarified, my overall assessment regarding the paper's acceptance remains unchanged."},{"sentence_type":"2","sentence":"I wonder if I could be deeply confused, and tried to challenge my understanding given the comments made and the improvement. I couldn't.","rephrased":"I have considered the possibility that I may have misunderstood the paper, and despite reviewing the comments and improvements, my understanding remains the same."},{"sentence_type":"1","sentence":"The paper seems to say that A* is a planning algorithm. The culture of the research community always mediates the name of techniques.","rephrased":"The paper refers to A* as a planning algorithm, which may differ from the terminology typically used in the research community."},{"sentence_type":"1","sentence":"The observations about the distribution depend on the distribution of the original problem. As shown in many combinatorial domains, algorithms tend to have strengths and weaknesses depending on the domain.","rephrased":"It is important to note that the observations regarding the distribution are influenced by the distribution of the original problem, and as is common in combinatorial domains, algorithms may exhibit varying strengths and weaknesses across different domains."},{"sentence_type":"1","sentence":"This general statement is at odds with the idea of heavy right tail.","rephrased":"This general statement seems to contrast with the concept of a heavy right tail, which may require further clarification."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[90,183,"Not concerning"],[2573,2778,"Not concerning"],[13710,13778,"Not concerning"]],"Comments":[]}
{"id":"BklMqjW_F4","text":"The paper investigates sentiment with respect to climate change and how this changes in tweets after specific natural disasters.\nTweets from hand-picked influencers are collected, such that these tweets can be assumed to have a specific label and are then used for training a climate change sentiment classifier. \nSeveral well-established models are compared, with the RNN model achieving the best results.\nThe classifier is then applied on a wider selection of tweets to measure the change in sentiment before and after specific natural disasters.\nThe results show that the sentiment moves slightly towards the positive after some hurricanes, but is largely not affected by the natural disasters.\n\nThe paper is an interesting pilot work and makes some useful contributions, but not necessarily in the target area of the LLD 2019 Workshop. \nThe workshop focus is on representation learning with limited data, whereas the paper does not address representation learning and the novelty of the limited data part is minimal (selecting specific users whose tweets are assumed to have the same label).\n\nThere are definitely interesting contributions here in the area of social sciences and social media research. The analysis of sentiment timed with specific events was interesting to see.\nThe paper also identifies specific shortcomings of the current work, which is useful as a pilot experiment and can drive future work.\n\nIt seems unlikely that out of 500 randomly sampled tweets exactly 50.0% were positive and negative. Was there actually a more imbalanced distribution that was specifically corrected?\n\nThe images in Figure 2 are too small to be interpretable.","sentences":[{"sentence_type":"1","sentence":"The paper is an interesting pilot work and makes some useful contributions, but not necessarily in the target area of the LLD 2019 Workshop.","rephrased":"While the paper presents interesting pilot work and contributes usefully, it appears to diverge somewhat from the core focus of the LLD 2019 Workshop."},{"sentence_type":"2","sentence":"It seems unlikely that out of 500 randomly sampled tweets exactly 50.0% were positive and negative.","rephrased":"Could you please provide more details on the sampling process? The exact 50.0% split between positive and negative tweets in a random sample seems statistically unusual and may benefit from further clarification."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[699,839,"Not concerning"],[1419,1518,"Not concerning"]],"Comments":[]}
{"id":"H1exfgYCYB","text":"This submission studies losses at local minima of a set of neural networks trained on an XOR-like synthetic dataset, finds that local minima are of varying quality, and proposes a network pruning method to find better local minima. The pruning method is evaluated on XOR-like datasets as well as real-world datasets. \n\nThe use of an XOR-like dataset to study loss landscapes is interesting, making for a controlled and analyzable setting to carry out the study. The way the authors set it up, the XOR-like problem involves nuisance variables that naturally introduce suboptimal local minima into the loss landscape (this is my observation as a reviewer -- I am not sure if the authors were aware of this). I am unsure if Section 2 of the paper was intended as a core contribution or as a motivation for the pruning algorithm proposed in Section 3. Given the set-up's simplicity, a short theoretical argument (maybe even a theorem) about the quality and number of local minima one would expect to find could have been more concise and compelling than the empirical analysis from the paper. The findings from Section 2 may not be surprising enough to warrant two full pages. \n\nSection 3 proposes a network pruning method to find better local minima. The authors cite a paper by Adrian Barbu as the inspiration for their pruning algorithm with annealing, and use it \"to improve the capability of NNs to find a deep local minimum even when there are irrelevant variables\". The cited paper by Barbu as well as https:\/\/arxiv.org\/pdf\/1805.01930.pdf (also by Adrian Barbu, not cited, maybe because it appeared) explore feature selection and regularization with (nearly) the same annealed pruning algorithm in some detail. I would be grateful if the authors could highlight the differences between their work and Barbu's. \n\nI vote to \"weak reject\" this paper. The paper discusses interesting ideas, but other ICLR submissions present deeper and more novel material, and there appears to be some (unintentional, I believe) overlap with already-published work. I recommend that the authors cite and discuss https:\/\/arxiv.org\/pdf\/1805.01930.pdf , and possibly submit the paper at a less competitive conference. \n\n\nFurther comments \/ questions \/ advice\n=================================\n\n- It would be helpful if the authors made more clear what they consider the key contributions of their paper. If contributions build directly on earlier work, it's helpful to highlight the differences. \n\n- Section 4.2 states that datasets were \"carefully selected\" in what sounds like a case-by-case basis, probably with the goal of finding data sets on which CPNA outperforms networks trained with vanilla gradient descent methods. This process would have selection bias and surface data sets on which CPNA outperforms. I could be grateful if the authors could clarify if this was indeed the process, or if a less biased criterion was used. For example, one could have chosen data sets on which a 1-layer fully connected neural network achieves between 50% and 90% F-1. \n\n- A reader of the paper might wonder for what data sets they should use CPNA in order to train network that achieves low out-of-sample loss. I could be grateful if the authors could comment on this. Following up on the previous point: it would be great the authors could include data sets where CPNA does not outperform. \n\n- Could the authors include information on how long training takes for the experiments from Table 3? \n\n- https:\/\/openreview.net\/pdf?id=HkghWScuoQ should probably be cited\n\n- https:\/\/arxiv.org\/pdf\/1805.01930.pdf should definitely be cited","sentences":[{"sentence_type":"2","sentence":"The findings from Section 2 may not be surprising enough to warrant two full pages.","rephrased":"The findings from Section 2, while interesting, could potentially be presented more succinctly without allocating two full pages."},{"sentence_type":"2","sentence":"I vote to \"weak reject\" this paper. The paper discusses interesting ideas, but other ICLR submissions present deeper and more novel material, and there appears to be some (unintentional, I believe) overlap with already-published work.","rephrased":"My recommendation is a \"weak reject\" for this paper. While the paper discusses interesting ideas, it would benefit from a deeper exploration of the novel aspects, especially considering the competitive nature of ICLR submissions and the potential overlap with previously published work, which I assume is unintentional."},{"sentence_type":"1","sentence":"This process would have selection bias and surface data sets on which CPNA outperforms.","rephrased":"This process might introduce a selection bias, favoring datasets where CPNA shows better performance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1089,1172,"Not concerning"],[1815,2049,"Not concerning"],[2708,2795,"Not concerning"]],"Comments":[]}
{"id":"0aRleGLPEHb","text":"##########################################################################\n\nSummary:\n\nThis paper proposes a semantically-adaptive upsampling approach for layout-to-image translation. It uses the semantic label map to predict spatially-adaptive upsampling kernels for feature map upsampling.  Compared with traditional upsampling methods, it has a larger receptive field to focus on not only nearby pixels, but also semantically-related pixels at a longer distance. Experiments are conducted on Cityscapes, ADE20K, COCO-Stuff, DeepFashion, CelebAMask-HQ, and Facades datasets, and the proposed approach achieves better results compared with the baseline.\n\n##########################################################################\n\nPros: \n\n1. The semantically-adaptive upsampling approach considers the semantic information for upsampling. It has a larger receptive field and can take far-away pixels which are semantically related for upsampling, so that it can better preserve the semantic consistency within the instance or stuff with the same semantic label.\n\n2. The proposed semantically-adaptive upsampling is efficient compared with spatial attention or prediction convolution kernels.\n\n3. The writting and explanations are clear.\n \n##########################################################################\n\nCons: \n\n1. In Figure.2, both the SAFU branch and the SAKG branch take the feature f as input. Based on my understanding of this paper, the input of the SAKG branch should be the semantic layout map, rather than the feature map f. I think this figure is a little confusing and misleading.\n\n2. The novelty of the semantically-adaptive upsampling is limited. On the one hand, semantic-adaptive operations have been proposed in previous work SPADE (semantically-adaptive normalization) and CC-FPSE (semantically-adaptive convolution). The difference from the conditional convolution in CC-FPSE is that the semantically-adaptive upsampling does not learn the feature transformation across channels, so the parameter size to be predicted is smaller. On the other hand, content-adaptive upsampling operations have also been explored in previous work CARAFE [A]. Especially the architecture design of this paper is almost the same as CARAFE (even with the same submodule names such as \"channel compression\" and \"channel-wise normalization\"). The only difference from CARAFE is that the proposed method uses the semantic label maps rather than the feature maps to predict the upsampling kernels.\n\n[A] CARAFE: Content-Aware ReAssembly of FEatures, ICCV 2019\n\n3. The authors claim that the proposed upsampling approach can aggregate information in a global view, but the receptive field of the upsampling layer is still limited to the kernel size of the upsampling kernels. The kernel size used in this paper is k=5. Have the authors experiment using different kernel sizes to see the effect of kernel size on the image generation performance?\n\n4. The visual results do not seem to be significantly better than previous methods.\n\n##########################################################################\n\nReasons for score: \n\nMy main reason for rating this paper as below the acceptance threshold is that the noveltly is limited (see the 2nd point in Cons for explanation), and there is not a large improvement on the quality of the synthesized images.\n\n##########################################################################\n\nQuestions during the rebuttal period: \n\nPlease address my concerns in the Cons part.\n\n##########################################################################\n\nPost-rebuttal:\n\nI have read other reviewers' comments. Since the authors did not provide feedback to our reviews, I would change my score from 5 to 4.\n","sentences":[{"sentence_type":"2","sentence":"The novelty of the semantically-adaptive upsampling is limited.","rephrased":"The novelty of the semantically-adaptive upsampling could be further delineated, especially in relation to prior work such as SPADE and CC-FPSE."},{"sentence_type":"2","sentence":"The visual results do not seem to be significantly better than previous methods.","rephrased":"It would be beneficial if the authors could provide more evidence or quantitative analysis to demonstrate the superiority of the visual results compared to previous methods."},{"sentence_type":"3","sentence":"Since the authors did not provide feedback to our reviews, I would change my score from 5 to 4.","rephrased":"I would appreciate the authors' feedback on our reviews to better understand the approach and its implications, which could potentially influence my scoring."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1607,1670,"Not concerning"],[2952,3032,"Not concerning"],[3652,3747,"Not concerning"]],"Comments":[]}
{"id":"tAtpqJuUTwg","text":"The paper uses familiar techniques from metric embedding literature to suggest an algorithm for the k-median problem. The contributions does not seem to be very strong.\n- The Metric embedding based algorithm for k-median is shown to give approximation guarantee of log{min(k, d)} which is better than k-means++ which gives O(log k). However, there are other algorithms that give much better approximation guarantees. It is not clear why the comparison is done with k-means++ here. This is something that the paper does not elaborate. Perhaps the algorithm is being suggested as an initialisation routine and hence the comparison is done with k-means++ but then that cannot be the only reason since the other algorithms with better approximation guarantees can also be suggested as initialisation routines. The discussion seems to be lacking on this aspect in my opinion.\n- The improvement with respect to the Differentially Private seems to be minor over the previous work.","sentences":[{"sentence_type":"2","sentence":"The contributions does not seem to be very strong.","rephrased":"The contributions could be further strengthened or more clearly highlighted to showcase their significance."},{"sentence_type":"2","sentence":"The improvement with respect to the Differentially Private seems to be minor over the previous work.","rephrased":"The improvement in the context of Differentially Private methods appears to be incremental when compared to previous work, and it would be beneficial to discuss the advancements in more detail."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[118,168,"Not concerning"],[873,973,"Not concerning"]],"Comments":[]}
{"id":"BygnDHKBsE","text":"This paper proposes a (PDDL) planning model of the problem of migrating IT services into a cloud environment.\n\nThe paper is well written over all, but it is lacking details about the planning model. It is only 2 pages long. While I appreciate short papers, I think that in this case it would be preferable to use another page or two to provide a detailed explanation of the actions and planning decisions that are encoded in the PDDL planning model, and perhaps a small example of a migration problem and the planning dilemmas it poses.  It would also be good if the authors make their PDDL model (domain and example problems) publicly available: both because it gives the planning community a further application benchmark problem, and also because it provides a complete understanding of how the problem is formulated.\n\nIf the paper is accepted for the workshop, I hope the authors will adopt at least one, preferably both, of these suggestions to provide readers with the full details of their planning problem and its formulation.","sentences":[{"sentence_type":"1","sentence":"The paper is well written over all, but it is lacking details about the planning model.","rephrased":"The paper is generally well written; however, it would benefit from additional details about the planning model to enhance understanding."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[111,198,"Not concerning"]],"Comments":[]}
{"id":"4_XlO29Ch6s","text":"## Summary:\nThis paper looks at how we can leverage unlabeled data for offline RL, framing this as a semi-supervised learning problem (SS-ORL). Specifically, the paper is interested in setting where we have a larger number of “unlabeled” trajectories with only states, rewards, but a smaller and lower quality set of fully labeled trajectories with full states, actions, and reward transitions. To adapt to this setting, the paper uses a framework consisting of learning (stochastic multi-transition) inverse-dynamics models (IDMs) from labeled data, then pseudo or proxy labeling unlabeled data, followed by standard offline RL. In this setting, the paper studies trends related to varying various aspects of data quality\/quantity and algorithm decisions.\n\n## Strengths:\n- The paper makes good contributions, using extensive empirical evaluation, towards understanding what settings SS-ORL can match fully supervised offline RL by varying data quality, size, IDM design, and with different offline RL algorithms (CQL, DT, TD3-BC) on D4RL MuJoCo benchmarks. \n- The general goal of adapting offline RL to datasets with heterogeneous labels is also quite relevant.\n- The paper very clearly illustrates their motivations, and relevant prior work, and has clearly designed experiments. Additionally, the paper also looks at some interesting baselines, such as joint training to predict states\/rewards in trajectories in unlabeled trajectories, instead of using IDMs (DT-Joint), as well as using self-training for IDMs. I also find the positive results in the low percentage, but high quality, labeled (e.g., 1%) regime to be quite interesting.  \n## Weaknesses:\n- While the paper highlights the potential of leveraging internet videos for offline RL, this paper focuses on MuJoCo experiments with low-dimensional and structured state spaces, so the findings may not generalize to high-dimensional image data. \n- Some of the novelty of the IDM design may be slightly overstated, in that prior work such as VPT (Baker et al. 2022), also use multi-transition models. However, this paper studies design choices (window size, including future versus past context, etc.) that are relevant for multi-transition IDMs in offline RL, which is not investigated in prior work. \n\n\n## Questions and Comments:\n- I am also curious about the importance of IDM stochasticity. While the probability of action is modeled by a Gaussian, when proxy labeling, only the mean is used.  What would be the performance of just using a deterministic IDM with L2 loss? If capturing variation of actions is important, then it seems that it could also be interesting to investigate sampling different possible action sequences, increasing data volume, instead of the single sequence generated from using the mean. \n- While plots varying labeled data quality (q) are generally monotonically increasing, in the main sections, I am curious about what is happening in the appendix in  Fig. C1, with hopper-medium, where we see performance peak at low q. \n- Line 293: and add the most [uncertain] ones into the training set\n","sentences":[{"sentence_type":"1","sentence":"Some of the novelty of the IDM design may be slightly overstated, in that prior work such as VPT (Baker et al. 2022), also use multi-transition models.","rephrased":"While the IDM design introduces interesting elements, it's worth noting that similar approaches, such as multi-transition models used in VPT (Baker et al. 2022), have been explored in prior work. It would be beneficial for the paper to discuss how this work's approach differs from and builds upon these existing methods."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1907,2058,"Not concerning"]],"Comments":[]}
{"id":"ryxyH98XYr","text":"After rebuttal edit:\nNo clarifications were made, so I keep my score as is.\n\n------------------------------------------------------\nClaims: Explicitly requiring a small number of labels allows for successful learning of disentangled features by either using them as a validation set for hyper parameter tuning, or using them as a supervised loss. \n\nDecision: Reject. This paper needs a substantial rewrite to make clear what specific contributions are from the multitude of experiments run in this study. As is, the two contributions stated in the introduction are both obvious and not particularly significant -- that having some labels of the type of disentanglement desired helps when used as a validation set and as a small number of labels for learning a disentangled representation space. There are no obviously stated conclusions about which types of labels are better than others (4.2). Section 3.2 seems to have some interesting findings that small scale supervision can help significantly and fine-grained labeling is not necessarily needed, but I don't understand why that finding is presented there when Fig. 4 seems to perform a similar experiment on types of labels with no conclusion based on its results. Conclusion sentence of 4.3 is hard to decipher, but I assume is just saying S^2\/S beats U\/S even when S^2\/S is subject to noisy labels. Overall, I find it very difficult to absorb the huge amount of results and find the analysis not well presented.\n\n","sentences":[{"sentence_type":"2","sentence":"As is, the two contributions stated in the introduction are both obvious and not particularly significant","rephrased":"The contributions stated in the introduction could be articulated more clearly to emphasize their novelty and significance."},{"sentence_type":"2","sentence":"Overall, I find it very difficult to absorb the huge amount of results and find the analysis not well presented.","rephrased":"The paper presents a large volume of results which could benefit from a more streamlined presentation and clearer analysis to enhance readability and comprehension."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[505,610,"Not concerning"],[1357,1469,"Not concerning"]],"Comments":[]}
{"id":"r1ehpIDThX","text":"While overall the writing quality of the paper is high, the paper itself is a strong rejection.  I believe the analysis of the paper is at points flawed, and the experiments are minimal.  \n\nThis work attempts to study the degree to which a layer by layer information bottleneck inspired objective can improve performance, as well as generally attempt to clarify some of the discussion surrounding Shwartz-Ziv & Tishby 2017.  Here, the authors study a deterministic neural network, for which the mutual information estimation is difficult (I(X,L)) and error prone.  To combat this they use the noise-regularized mutual information estimator (I(X; L+eps)).  To actually estimate the mutual information the authors use the MINE estimator of Belghazi (2018).  Here they suggest using the neural network itself as a structural element in the form of the discriminator to take advantage of the specific circumstances in this case.  Doing this ensured that their estimator diverged in the zero noise limit as expected.  From here they show some experimental results of the effect of their objective on an MNIST \/ CIFAR10 classification task.\n\nThis paper fits into what is an increasingly large discussion in the literature, surrounding Information Bottleneck.  The paper itself does a very good job of citing recent relevant work.  Technically however I take issue with the framing of previous work in the last paragraph of the \"Deep neural nets\" subsection of Section 2.  Technically Achille & Soatto explicitly formed a variational approximation to the posterior over the weights of the neural network and so was not a \"single bottleneck layer\" as stated in the paper.  More generally at the end of that paragraph it is implied that the single bottleneck layer scheme \"deviates from the original theory\".  This is a misleading characterization of the original information bottleneck (Tishby et al 1999) in which there was a single random variable, a representation of the data (Z) satisfying the Markov conditions Z <- X -> Y.   I believe the authors instead meant to say that the cited works deviate from the information bottleneck theory of learning suggested in (Shwartz-Ziv & Tishby 2017).  In general the paper does a poor job of distinguishing between the Shwartz-Ziv & Tishby paper and the rest, but this is a distinction that should be maintained.  The original information bottleneck may and has demonstrated utility regardless of whether the information bottleneck generally can help explain why ordinary deterministic feed forward networks trained with cross entropy and sgd generalize well.  \n\nThis also raises one of the main problems with the current work. The title, abstract and especially the conclusion (\"This provides, for the first time, strong and direct emperical evidence for the validity of the IB theory of deep learning\") seem to present the paper as somehow offering some clarity and further support for the assertions of the Shwartz-Ziv & Tishby 2017 paper, but that paper hoped to establish that information bottleneck can explain the workings of ordinary networks.  Here the authors modify the ordinary cross entropy objective, and so their networks are necessarily not ordinary and so they cannot claim they have helped clarify our understanding of the vast majority of neural networks currently being trained.  Again, this is distinct and should be kept distinct from the utility of their proposed objective, itself inspired by the information bottleneck.  Here too the paper falls flat.  If instead of attempting to comment on networks as they are designed today they aim to proposed a new information bottleneck inspired objective they really ought to directly compare other attempts along those lines (such as the ones they themselves cite  Alemi et al. 2018, Kolchinsky et al. 2017, Chalk et al. 2016, Achile & Soatto 2018, Belghazi et al. 2018) but there are no comparative studies.\n\nThe experiments are extremely lacking, not only are any of their cited alternatives compared, they don't compare to what would be an equivalent network to their but where they did utilize the noise at every layer and actually made the network stochastic.  Their reported numbers are not very impressive with their top MNIST number at 98.09 and their baseline at 97.73. These numbers are worse than many of the papers they themselves cite.  Only a single comparative results for both a limited training set run and the full one are shown, as well as only a single choice of beta.  The CIFAR10 numbers are not very good either.  There is some discussion of the text suggesting they believe their method acts like an approximate weight decay, but there are no results showing the effect of weight decay just on the baseline classification accuracies they compare against.\n\nTechnically a deterministic function need not have infinite mutual information, if it is non-invertible, i.e. the sign function, or just floating point discretization. \n\nTheir own results in Figure 2 and the main body of the text highlight that the authors believe the true mutual information between the activations of the intermediate layers and the input is infinite.  If the true mutual information is infinite and the noise regularized estimator is only meant for comparative purposes, why then are the results of the training trajectories interpreted so literally as estimates of the true mutual information?\n\nJust plugging in the Discriminator for the objective (equation (7)) is flawed.  The discriminator, if optimal would learn to approximate the density ratio 1 + log p(x,y)\/(p(x) p(y)) .   ( see f-GAN, Norowin et al. 2016).  How does this justify using the individual elements of the discriminator in the functional form of the IB objective?  \n\nAt the bottom of page 6 they rightfully say that mutual information is invariant to reparameterizations, but their noise regularized mutual information estimator is not (by their own reference (Saxe et al 2017).\n\nThe discussion at the center of page 8 is confusing.   They claim that Figure 5 (a) is more 'quantized' than (b) and \"has reduced entropy\".  I think it should be the other way.  More clusters should translate to a higher KL divergence, or higher entropy.  If you need only identify which cluster an activation is in, that should require log K nats where K is the number of clusters.  (a) shows more clusters and so seems like it should cost more and have a higher entropy not a lower one.\n\nDespite a recurring focus of the text that this paper applies and information theoretic objective at each layer of the network, and hence is novel, the final sentence of the paper suggests it might not actually be needed and single layer IB objectives can work as well.","sentences":[{"sentence_type":"2","sentence":"the paper itself is a strong rejection.","rephrased":"I recommend rejection of the paper based on the concerns outlined."},{"sentence_type":"1","sentence":"Technically however I take issue with the framing of previous work in the last paragraph of the \"Deep neural nets\" subsection of Section 2.","rephrased":"I have concerns regarding the framing of previous work in the last paragraph of the \"Deep neural nets\" subsection of Section 2."},{"sentence_type":"2","sentence":"In general the paper does a poor job of distinguishing between the Shwartz-Ziv & Tishby paper and the rest, but this is a distinction that should be maintained.","rephrased":"The paper could benefit from a clearer distinction between the Shwartz-Ziv & Tishby paper and other related work."},{"sentence_type":"2","sentence":"Here too the paper falls flat.","rephrased":"The paper could be improved by addressing this aspect more thoroughly."},{"sentence_type":"2","sentence":"The experiments are extremely lacking, not only are any of their cited alternatives compared, they don't compare to what would be an equivalent network to their but where they did utilize the noise at every layer and actually made the network stochastic.","rephrased":"The experimental section could be strengthened by including comparisons with the cited alternatives and an equivalent network that utilizes noise at every layer."},{"sentence_type":"1","sentence":"Their reported numbers are not very impressive with their top MNIST number at 98.09 and their baseline at 97.73.","rephrased":"The reported results, such as the top MNIST number at 98.09 and the baseline at 97.73, could be further contextualized within the field's current benchmarks."},{"sentence_type":"2","sentence":"Just plugging in the Discriminator for the objective (equation (7)) is flawed.","rephrased":"The approach of using the Discriminator for the objective (equation (7)) may need further justification or refinement."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[56,95,"Not concerning"],[1325,1464,"Not concerning"],[2190,2350,"Not concerning"],[3484,3514,"Confirmed"],[3916,4170,"Maybe"],[4172,4284,"Not concerning"],[5402,5480,"Not concerning"]],"Comments":[]}
{"id":"BImZlrLdOIb","text":"Strengths:\n1. The idea of iterative decoding for compositional generalization is interesting and intuitively makes sense. It encourage the model to learn how the reasoning (generalization) is unfolded.\n2. The experimental results on the PCFG and cartesian product datasets is promising and show clear improvements compared to seq2seq counterparts.\n\nWeaknesses:\n1. The main method (iterative decoding) is described after spending much space on describing datasets, which is somewhat inconvenient for  readers. Maybe consider introducing the datasets in the experiments section will make the paper easier to follow.\n2. According to my understanding, iterative decoding will significantly increases the computational costs (roughly x number of intermediate steps). This could be a significant drawback but is not mentioned in the paper.\n3. Iterative decoding can be seen as autoregressive generation in the level of reasoning steps. Therefore, if the iterative decoding model is trained with MLE and teacher forcing (training of iterative decoding is not described in the paper), it will face the exposure bias problem. How much is that problem affecting the performance is needed to be investigated.\n4. As shown in the CFQ dataset, the proposed only works in cases where intermediate steps can be clearly defined. However, in most cases it is not the case, therefore is unclear whether the proposed method can generalize to many tasks. Therefore the application of the method can be quite limited.","sentences":[{"sentence_type":"1","sentence":"The main method (iterative decoding) is described after spending much space on describing datasets, which is somewhat inconvenient for  readers.","rephrased":"It might enhance the paper's clarity if the main method (iterative decoding) is introduced before the detailed description of the datasets, to help readers grasp the core concept earlier."},{"sentence_type":"2","sentence":"According to my understanding, iterative decoding will significantly increases the computational costs (roughly x number of intermediate steps). This could be a significant drawback but is not mentioned in the paper.","rephrased":"It would be beneficial for the paper to discuss the potential increase in computational costs due to iterative decoding, as this could be an important consideration for readers."},{"sentence_type":"2","sentence":"As shown in the CFQ dataset, the proposed only works in cases where intermediate steps can be clearly defined. However, in most cases it is not the case, therefore is unclear whether the proposed method can generalize to many tasks. Therefore the application of the method can be quite limited.","rephrased":"The paper could be strengthened by exploring the applicability of the proposed method beyond cases with clearly defined intermediate steps, as this would provide a better understanding of its potential for generalization to various tasks."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[364,508,"Not concerning"],[617,833,"Not concerning"],[1201,1495,"Not concerning"]],"Comments":[]}
{"id":"r1xp--ns2m","text":"The paper investigates the exploratory conditions under which spatial representations will emerge as a byproduct of learning to predict the next sensory observation. In particular, the authors test three exploratory conditions:\n(i) When the set of sensory-motor interactions (st, mt, s_{t+1}, m_{t+1}) are inconsistent. \n(ii) Environment is static and set of sensory-motor interactions are consistent. \n(iii)  Environment is dynamic and the set of sensory-motor interactions are consistent. \n\nAuthors measure the quality of learned spatial representations by computing disparity between the set of agent positions and the corresponding embedding of motor commands learned by predicting the next sensory observation. They conclude that under condition (iii), the disparity is minimum -- i.e. the agent is best able to discover the spatial structure of it environment. \n\nPhilosophically, I love the direction of this work -- understanding the origins of our spatial representations. But, I am concerned with the delivery. My concerns\/questions are as following:\n\n(a) Firstly, the writing is too verbose and vague without clarifying the details and there are too many references to Laflaquiere et al. I would recommend the authors to be more precise, i.e. define topological\/metric invariants, clarify how in-consistent sensory\/motor pairs are sampled in MTM condition and how environment is perturbed in MMT condition. These things are defined at a high-level and not precisely. \n\n(b) The whole premise of comparing the embedding of motor commands and the agent's spatial configuration only works under a special condition -- s = φε(m) (section 3 of the paper), which is not general. For e.g. if an arm is “torque controlled” it is not possible to predict the location of the arm (i.e. a potential sensory observation) just from the torques. Additional knowledge of the agent’s state such as current position and the velocity of the arm is required. In the examples mentioned in the paper, the arm is “position” controlled, i.e. given the orientation of each joint (i.e. the motor command) it is possible to predict the sensory observation.  This is a very special case. In biology for example, we control the flexing of muscle fibers using the motor system, we can’t directly output positions of the arm. The general, condition of operation should be: s_{t+1} = φε(m_t, s_t). \n\n(c) Authors argue that in order to learn metric invariants, the agent needs to observe the same sensory state under different motor commands. They further argue that in the MMT condition, where the environment also translates, this affect is achieved and therefore metric invariants are learned. My position is that this is simply an artifact of the restricted problem setup where  s = φε(m) holds. In a more general setup, s_{t+1} = φε(m_t, s_t) there is no requirement for the environment to move. An arm with different torques can be at the same position and hence the condition imposed by authors should be specified naturally even in MM environments. What do the authors think? \n\n(d) Under the condition of,  s = φε(m) difference between MM and MMT appears that in one case (MM), neural network is trained without translation perturbations, and in other case MMT is a form of data augmentation with translation perturbations. I am not sure if there is any other justification for why only topological invariants should be learned with MM and metric invariants with MMT. To me it seems like training with data augmentation leads to better metric learning. Do the authors have any other insights — I would love to know. \n\n(e) Finally the embeddings are useful, if they are useful for an end-task. I would love, if the authors evaluated the learnt embeddings in each of the three conditions for some end tasks such as reaching in case of an arm or something else that is more feasible. \n\nDespite it being a very interesting topic, due to theoretical concerns outlined above, I cannot recommend the paper for acceptance. With a strong rebuttal it is possible to convince me otherwise.  \n","sentences":[{"sentence_type":"2","sentence":"Firstly, the writing is too verbose and vague without clarifying the details and there are too many references to Laflaquiere et al.","rephrased":"I suggest that the authors aim for more concise writing and provide clearer details, particularly in areas where references to Laflaquiere et al. are frequent."},{"sentence_type":"2","sentence":"Despite it being a very interesting topic, due to theoretical concerns outlined above, I cannot recommend the paper for acceptance.","rephrased":"Although the topic is intriguing, I believe addressing the theoretical concerns mentioned is crucial before I can recommend the paper for acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1065,1197,"Not concerning"],[3867,3998,"Not concerning"]],"Comments":[]}
{"id":"qtP-eFDf87S","text":"* **Significance**:  While I like some aspects of the write-up, I find there's some blind spots in the work as it currently stands, which limit its significance:\n\n  *   The proposed method has a strong assumption that the data is homophilous (edges are more likely to link nodes sharing the same label, so clusters of the same label are present in the data).  Should this not hold, all nodes are on the graph's \"class boundary\" (per the Totoro PPR definition). While true for many academic datasets which are hand-selected for this condition (especially citation networks like Cora, etc), this is just *not* the case for most real GNN datasets.  The authors acknowledge this limitation, but the phenomenon needs to be studied in my opinion.\n\n  *   In both absolute *and* relative terms, the performance gains by applying ReNode for all datasets is actually quite low.  (~1% absolute, ~<2% relative?)  This seems to indicate that ReNode doesn't really address imbalance much better than other proposed approaches (e.g. consider Table 3).  Furthermore it seems like there's no baseline in Table 3 that considers both kinds of imbalance (TINL and QINL)?\n\n  *  There seems to be no study of alternative reweighting strategies to validate the choice of PPR.  There are probably dozens of alternatives possible here -- this choice needs to be defended.\n\n  *  Understanding how ReNode works with other models (than GCN) is necessary to understand its significance.  For example, Figure 5 shows that there may be some difference in sensitivity between methods, but we don't know how ReNode effects different graph convolutions.\n\n* **Clarity**:  The paper is well written and easy to understand.  \n\n* **Quality**:  Generally high, but aside from the issues mentioned in significance, there were other obvious analysis that need to be performed:\n\n  *  A more thorough analysis of imbalance and its effect on performance (only two imbalance ratios [5,10] are used...it'd be nice to understand how ReNode (and baselines) performed as imbalance was more smoothly varied.\n\n  *  There's an assertion that  GAT is the least sensitive to topological imbalance (Figure 5), but quite frankly, I don't know if I believe this -- GAT (as the most parameterized model) is much more capable of overfitting.  Instead, I wonder if the hyper-parameters were not adequately searched for all 3 methods for each imbalance setting.\n\n* **Originality**:  There's a number of work out there which considers quantity and graph imbalance, so the onus is on ReNode to show that its unique.  I'm curious if related work for graphs *really* doesn't consider topology imbalance.  To be more specific, some of the regularizations to tackle quantity imbalance might end up encoding topology indirectly (e.g. via unlabeled nodes, edge generation, or something else).  \n\n  *  There has also been a lot of work studying PPR & GNNs lately, but the authors seem to do an ok job surveying the field.","sentences":[{"sentence_type":"2","sentence":"This seems to indicate that ReNode doesn't really address imbalance much better than other proposed approaches (e.g. consider Table 3).","rephrased":"The data suggests that the performance gains with ReNode are modest when compared to other approaches. It would be beneficial to see a more detailed comparison with these methods, perhaps including additional baselines in Table 3 that consider both kinds of imbalance."},{"sentence_type":"2","sentence":"but quite frankly, I don't know if I believe this -- GAT (as the most parameterized model) is much more capable of overfitting.","rephrased":"The assertion that GAT is the least sensitive to topological imbalance warrants further investigation, especially considering its capacity for overfitting due to being a highly parameterized model. It would be helpful to ensure that the hyper-parameters for all models are thoroughly optimized for each imbalance setting."},{"sentence_type":"1","sentence":"so the onus is on ReNode to show that its unique.","rephrased":"Given the existing body of work on quantity and graph imbalance, it would be valuable for the paper to more clearly demonstrate the unique contributions of ReNode in this context."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[901,1036,"Not concerning"],[2155,2282,"Not concerning"],[2503,2552,"Not concerning"]],"Comments":[]}
{"id":"8q0mVZKVyt7","text":"The paper presents an evaluation of recently developed uncertainty measures on Brain Tumour Segmentation. \n\nPros: The paper is well-written and relevant to MIDL topics. Further, it introduces two additional metrics to evaluate the performance of uncertainty on a publicly available database. \n\nCons:  Calibration wasn't performed and discussed here. The paper would have been even stronger if a quantitative assessment against labels uncertainty, due to intra\/inter-observer variability, was performed. \n\nDetailed Feedback: \n- As you might know, predictive uncertainty is underestimated, and calibration has been recently investigated in this context, e.g. Guo et al. [1]. Some methods claimed better calibration, e.g. Deep Ensemble. So i was wondering whether reported uncertainty methods were well-calibrated on a validation set or not. It would have been better if the methods were well-calibrated first before running the evaluation, or at least the authors have discussed this point in this discussion and conclusion. \n- One of the concluding remarks that I was hoping to see is the need of novel techniques and tools that measure the labels uncertainty, similar to the work of Tomczack et al. [2]. I think this is extremely important as we need to urge researchers to look at this.\n\n[1] Guo, C., Pleiss, G., Sun, Y. and Weinberger, K.Q., 2017, August. On calibration of modern neural networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70 (pp. 1321-1330). JMLR. org.\n\n[2] Tomczack, A., Navab, N. and Albarqouni, S., 2019. Learn to estimate labels uncertainty for quality assurance. arXiv preprint arXiv:1909.08058.\n","sentences":[{"sentence_type":"1","sentence":"So i was wondering whether reported uncertainty methods were well-calibrated on a validation set or not.","rephrased":"It would be informative to know if the reported uncertainty methods were calibrated on a validation set, as this could enhance the robustness of the results."},{"sentence_type":"2","sentence":"It would have been better if the methods were well-calibrated first before running the evaluation, or at least the authors have discussed this point in this discussion and conclusion.","rephrased":"I recommend that future work includes calibration of the methods prior to evaluation, or at least a discussion of calibration in the paper's discussion and conclusion sections."},{"sentence_type":"1","sentence":"One of the concluding remarks that I was hoping to see is the need of novel techniques and tools that measure the labels uncertainty, similar to the work of Tomczack et al. [2].","rephrased":"It would be valuable to include concluding remarks on the potential for novel techniques and tools to measure label uncertainty, drawing inspiration from works like Tomczack et al. [2]."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[734,838,"Not concerning"],[839,1022,"Not concerning"],[1026,1203,"Not concerning"]],"Comments":[]}
{"id":"SkeYRMmW54","text":"The paper is based on the idea of extending the VAE framework beyond the simplistic IID assumption that it makes on the data. They do so by using structured priors that explicitly take the correlations between data points into account. The methods can be used to learn meaningful representation directly from a weighted graph of the data as shown in the experiments section. The only downside is that the paper does not compare or provide any detail of how their method relates to hierarchical Bayesian models such as LDA that also capture global level correlational statistics in categorical data. \n\nMinor:\nSentences repeated twice at the end of page 2.","sentences":[{"sentence_type":"1","sentence":"The only downside is that the paper does not compare or provide any detail of how their method relates to hierarchical Bayesian models such as LDA that also capture global level correlational statistics in categorical data.","rephrased":"It would be beneficial for the paper to include a comparison or a detailed discussion of how their method relates to hierarchical Bayesian models like LDA, which also capture global level correlational statistics in categorical data."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[375,598,"Not concerning"]],"Comments":[]}
{"id":"HJlClhzCtS","text":"The authors propose a new semi-supervised boosting approach. The approach takes a set of supervised learning algorithms to simulate \"crowd-source\" labels of the unlabeled data, which are then used to generate a noisy label per unlabeled instance. The noise level is then estimated with an agreement-based scheme, and fed to a modified AdaBoost algorithm that is more noise-tolerant given the noise level. Some theoretical guarantee of the modified AdaBoost algorithm is derived and promising experiment results are demonstrated.\n\nMy suggestion is to reject the paper, with the following key reasons.\n\n(1) Contribution is insufficient, or perhaps not well-highlighted. For the three pieces of contribution, Section 4.1 (self-labeling, which is highlighted within the title) seems to be a trivial borrowing of an existing idea in crowd sourcing from 1979. It is not clear whether Section 4.2 (error estimation) is an original contribution or not, but even if it is original Lemma 1 seems marginally trivial. Section 3 (noise-resistant AdaBoost) plugs a known surrogate loss for noisy labels into AdaBoost. But despite the ugly math, the results seem to be equivalent to a heuristically-shrunk alpha_t for AdaBoost. None of the pieces seem to make a solid contribution to the problem of interest.\n\n(2) Assumptions are not reasonable. Section 3 and Sections 4.2 both rely on \"homogeneous error rates\" which does not seem to be the case when the noise is generated from classifier-target mismatch. In particular, the noisy will only happen in mismatch areas, and not happen in other areas, making it non-homogeneous. The authors did not discuss the rationality of this assumption and\/or how it affects the designed approach. In Section 4.2, there is another assumption that \"in practice we can balance the dataset\", which might be true for the labeled part through sampling, but not necessarily true for the unlabeled part. So it is not clear whether this assumption can be met. Section 4.2 also assumes that \"the probability can be estimated through the data\" but did not mention how large the data needs to be for an accurate estimation.\n\n(3) Experiments cannot be easily replicated. To begin with, the authors claim to use 10 classifiers from scikit-learn as the initial labeler, but the exact 10 (including parameters) are not pinged down. In the data sets, there is a procedure \"or turned linear regression datasets into binary labels\" that does not seem sufficiently clear for replication. It is not clear whether \"feature normalization\" considers only the training set or the whole training+test set.\n\nHaving said that, there are some other suggestions:\n\n(4) Writing needs improvement. Many of the parts contains unnecessarily ugly math notations without motivation. Even the core Section 3 looks like a LaTeX math demo than a clear illustration of scientific ideas.\n\n(5) It is not clear what the importance of Theorem 1 is. There doesn't seem to be a guarantee of gamma_t > 0 given the authors' definition of hat{epsilon}_t (worse case error of the two classes), and then the first part of Theorem 1 is not fast decreasing. It is not clear whether the N in the second term is N_noisy. In any case, the theorem is not clearly described enough to help understand the contribution of the paper.\n\n(6) A baseline that should be considered is to treat the noisy labels as \"soft labels\" and then apply confidence-based boosting.\n\nImproved Boosting Algorithms Using Confidence-rated Predictions, Schapire and Singer 1999.\n","sentences":[{"sentence_type":"1","sentence":"(1) Contribution is insufficient, or perhaps not well-highlighted.","rephrased":"The contributions could be better highlighted or further developed to showcase their significance."},{"sentence_type":"2","sentence":"But despite the ugly math, the results seem to be equivalent to a heuristically-shrunk alpha_t for AdaBoost.","rephrased":"However, the mathematical complexity does not seem to translate into a significant difference from a heuristically-shrunk alpha_t for AdaBoost."},{"sentence_type":"2","sentence":"(4) Writing needs improvement. Many of the parts contains unnecessarily ugly math notations without motivation.","rephrased":"The writing could be improved by simplifying the mathematical notations and providing clearer motivations for their use."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[601,667,"Not concerning"],[1104,1212,"Maybe"],[2657,2768,"Maybe"]],"Comments":[]}
{"id":"4HncdD-lsNg","text":"A very similar version has been accepted into the ICML 2021 Workshop, probably from the same authors. See the link https:\/\/openreview.net\/forum?id=7oziDfK4Fs for details. Hence, I have to reject this paper, due to the duplicate submission. ","sentences":[{"sentence_type":"2","sentence":"Hence, I have to reject this paper, due to the duplicate submission.","rephrased":"Therefore, I must recommend rejection of this paper on the grounds of duplicate submission."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[171,239,"Not concerning"]],"Comments":[]}
{"id":"SknKUAteG","text":"This paper proposes to use self-training strategies for using unlabeled data in GAN. Experiments on only one data set, i.e., MNIST, are conducted \n\nPros:\n* Studying how to use unlabeled data to improve performance of GAN is of technical importance. The use of the self-training in GAN for exploiting unlabeled data is sound.\n \nCons:\n* The novelty and technical contribution is low. The unlabeled data are exploited by off-the-shelf self-training strategies, where the base learner is fixed to GAN. Using GAN does not make the self-training strategy special to the existing self-training approaches. Thus, the proposed approaches are actually a straight application of the existing techniques. In fact, It would be more interesting if the unlabeled data could be employed to the “G” and “A” in GAN.\n\n* In each self-training iteration, GAN needs to be retrained, whose computational cost is high..\n\n* Only one data set is used in the experiment. Some widely-used datasets, like SVHN or CIFAR-10, are not used in the experiment. \n\n* Important baseline methods are missing. The proposed methods should be evaluated with the state-of-the-art semi-supervised deep learning methods, such as those mentioned in related work section.\n","sentences":[{"sentence_type":"2","sentence":"The novelty and technical contribution is low.","rephrased":"The novelty and technical contribution could be further highlighted or enhanced to better distinguish the work from existing self-training strategies."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[335,381,"Not concerning"]],"Comments":[]}
{"id":"Byg37fo2hm","text":"Pros:\n- Addresses several interesting and important problems all at once: covariate shift, concept drift, mismatch between training loss and test loss.\n- Fairly simple and elegant solution.\n- Multiple examples of the method working.\n- Clearly written\n\nCons:\n- Examples don't feel like full-fledged machine learning examples, where you  tune your learning algorithm on the validation set, as well as the example weights (their approach).  \n- Needs discussion of potential overfitting issues (see comments below).\n\nComments:\n- I think one area that is underexplored in this paper is overfitting.  One issue is overfitting the validation data by having more complicated weight functions. For example, in Figure 3(b), as the embedding dimension goes beyond 14, it seems like the error metric gets worse.  Would be interesting to see a plot of the validation error metric alongside this test error metric.  Also, what happens when we use even larger embedding dimensions -- that should clarify whether this is an overfitting situation, or just a random chance fluctuation.\n- In machine learning contexts, it's standard to try many different ML methods (or at least network architectures) with various hyperparameter settings and regularization methods, yet this isn't discussed at all in the paper.  Would you use the search for alpha as an inner loop in your model search and hyperparameter selection process?  I'd expect there could be additional issues with overfitting the validation set as you used more complicated models.  I think not discussing or investigating this makes the examples feel a little bit more like toys.  I think tuning your learning algorithm settings on a validation set is pretty intrinsic to machine learning approaches.\n- Relatedly, you say \"we impose no regularization on the model parameters\"... does this include things like early stopping, dropout, or other things that are used to prevent overfitting?  This seems just part of the \"no hyperparameter tuning\" setting of the paper.  \n- In the introdution you say \"MOEW . . . reshapes the total loss function to better match the testing metric.  This is similar to the idea of basis expansion, where we approximate the metric function using a linear combination of per example loss functions\".  You make a similar statement in the conclusion. This is an interesting idea, but it doesn't seem to represent what you're doing. This explanation suggests that you are fitting \\alpha's so that the objective function value approximates the validation metric for each theta.  But that's not what you're doing, right?\n- In 3.2, you say that c \"is a constant that normalizes the weights over a (batch from) the training set T\".  Why would you renormalize per batch?  This seems to potentially negate the effect of the reweighting, especially for small batches.\n- It might have been interesting to see if there was any significant differences between hinge loss and cross-entropy loss for the binary case.\n- In the MNIST experiment, am I correctly understanding that the difference between the 300 uniform weighted models you tried was the random initialization of the weights? Was there a lot of variation in performance among these trials?  Folk wisdom makes me think there would not be large performance differences.  \n","sentences":[{"sentence_type":"2","sentence":"Examples don't feel like full-fledged machine learning examples, where you  tune your learning algorithm on the validation set, as well as the example weights (their approach).","rephrased":"It would be beneficial to see examples that include tuning the learning algorithm on the validation set, in addition to the example weights, to better reflect common machine learning practices."},{"sentence_type":"3","sentence":"I think not discussing or investigating this makes the examples feel a little bit more like toys.","rephrased":"Discussing and investigating the application of various ML methods and hyperparameter settings could enhance the practical relevance of the examples presented."},{"sentence_type":"1","sentence":"This seems just part of the \"no hyperparameter tuning\" setting of the paper.","rephrased":"Could you clarify if the approach includes common regularization techniques like early stopping or dropout, which are typically used to prevent overfitting?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[260,436,"Not concerning"],[1525,1622,"Confirmed"],[1932,2008,"Not concerning"]],"Comments":[]}
{"id":"C8TUrdt2Kt","text":"This paper proposes an operator splitting method (i.e. ADMM) to deal with neural network verification problems. This is because the ADMM is scalable to large datasets. Specifically, they solve the convex relaxations of problems analytically. Extensive experiments on network verifications demonstrate outstanding performance as well as excellent scalability.  This paper has several limitations, which are discussed as follows:\n1.\tSome statements in the paper are unclear. For example, in the introduction, the authors state that neural networks lack formal guarantees. However, the meaning of formal guarantees is unclear, and how does it relate to safety-critical applications should be explained better. As another example,  the background of the neural network verification problem is missing. It is unclear what are potential applications of this problem, and examples should be provided to better understand required properties.  \n2.\tThe novelty of this paper should be justified better. The authors just utilize an existing optimization framework ADMM to relax nonconvex problems into convex ones, which lead to analytic solutions. As they mentioned, several papers consider similar ideas, but the difference seems subtle. it is unclear how ADMM resolves the incomplete problem (i.e. methods are guaranteed to detect all false negatives but also produce false positives). Moreover, the ADMM usually converges slowly to the solution, how do authors address this issue?\n3.\tExperimental details are missing.  Even though the authors show many experimental results,  the background of problems in the experiments is missing, and little information such as architectures and hyperparameter settings is provided.  So it is difficult to reproducible experimental results.\n","sentences":[{"sentence_type":"1","sentence":"The novelty of this paper should be justified better.","rephrased":"The authors could further clarify the novelty of their approach in comparison to existing literature."},{"sentence_type":"2","sentence":"The authors just utilize an existing optimization framework ADMM to relax nonconvex problems into convex ones, which lead to analytic solutions.","rephrased":"The authors have applied the existing optimization framework ADMM to relax nonconvex problems into convex ones, resulting in analytic solutions, and it would be beneficial to discuss how this application differs from previous work."},{"sentence_type":"2","sentence":"As they mentioned, several papers consider similar ideas, but the difference seems subtle.","rephrased":"The authors mention that several papers consider similar ideas; it would be helpful to more clearly delineate the distinctions and contributions of the current work."},{"sentence_type":"1","sentence":"it is unclear how ADMM resolves the incomplete problem (i.e. methods are guaranteed to detect all false negatives but also produce false positives).","rephrased":"It would be helpful if the authors could clarify how the ADMM approach addresses the challenge of detecting all false negatives without significantly increasing false positives."},{"sentence_type":"1","sentence":"Moreover, the ADMM usually converges slowly to the solution, how do authors address this issue?","rephrased":"Additionally, it would be informative if the authors discussed their strategies for dealing with the typically slow convergence of ADMM."},{"sentence_type":"2","sentence":"So it is difficult to reproducible experimental results.","rephrased":"To facilitate reproducibility, it would be helpful if the authors could provide more details on the experimental setup, including architectures and hyperparameter settings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[940,993,"Not concerning"],[994,1138,"Maybe"],[1139,1229,"Not concerning"],[1230,1378,"Not concerning"],[1379,1474,"Not concerning"],[1715,1771,"Not concerning"]],"Comments":[]}
{"id":"ZkLYcCndgEm","text":"The idea of this paper is clear and sensible: use a pretrained Q-function to estimate whether an augmentation of offline goal-conditioned data (substituting one trajectory's goal for another) can improve learning. This clearly fits with the theme of the workshop. To more clearly demonstrate the value of the idea, I think the paper would benefit from comparing to other, potentially better ways of using the prior agent, such as some sort of auxiliary policy distillation loss across the offline dataset (i.e. a loss for the divergence from the student policy to the pretrained expert). But the current results seem acceptable for a workshop.","sentences":[{"sentence_type":"2","sentence":"But the current results seem acceptable for a workshop.","rephrased":"While the current results are suitable for a workshop setting, further refinement and comparison with alternative methods could enhance the paper's contribution."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[588,643,"Not concerning"]],"Comments":[]}
{"id":"FKOHLRGVfw","text":"This work extends the reincarnation framework to Multi-agent Reinforcement Learning (MARL).\nIt first defines Multi-agent Reincarnation and then Selective Reincarnation, in which only a subset of the agents are reincarnated.\nEmpirically, they show that arbitrary selective reincarnation interpolates the performance between Tabula Rasa and Full reincarnation as the subset of reincarnated agents increases.\nThen, they show that targeted reincarnation can have a significant effect on performance and can sometimes offer small gains over full reincarnation. \nThis is a good paper and very much aligned with the spirit of the Workshop.\nI'd encourage the authors to keep improving this work if a publication is a goal.\nIn its current state, there's not much insight to be gained from the experiments nor a new method that can be used in practice.\n","sentences":[{"sentence_type":"2","sentence":"In its current state, there's not much insight to be gained from the experiments nor a new method that can be used in practice.","rephrased":"While the experiments provide a foundation, further work could enhance the practical applicability of the methods and offer more substantial insights."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[715,842,"Not concerning"]],"Comments":[]}
{"id":"B1xIAMv8Yr","text":"This paper proposed to use KL and reversed KL as its new objective function for text generation GAN training.\nHowever, this paper missed a lot important references. Basically, the authors only compare results with seqGAN and leakGAN. MaliGAN (https:\/\/arxiv.org\/pdf\/1702.07983.pdf), TextGAN (https:\/\/arxiv.org\/pdf\/1706.03850.pdf), etc. \nAlso, KL + reversed KL training method for GAN framework is first proposed in Symmetric VAE (https:\/\/arxiv.org\/abs\/1709.01846), and the Proposition 2 basically are the same as the Symmetric VAE paper.\n\nTherefore, I think this work is lack of novelty, and still need more time to work on.","sentences":[{"sentence_type":"2","sentence":"However, this paper missed a lot important references.","rephrased":"However, the paper could be strengthened by including additional key references such as MaliGAN, TextGAN, etc."},{"sentence_type":"2","sentence":"Therefore, I think this work is lack of novelty, and still need more time to work on.","rephrased":"Therefore, to enhance the novelty of the work, it would be beneficial to further develop the proposed methods and differentiate them from existing approaches like Symmetric VAE."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[110,164,"Not concerning"],[538,623,"Not concerning"]],"Comments":[]}
{"id":"SJcdJ0tez","text":"This paper attempts to improve the beta-VAE (Higgins et al, 2017) by removing the trade-off between the quality of disentanglement in the latent representation and the quality of the reconstruction. The authors suggest doing so by explicitly modelling the noise of the reconstructed image Gaussian p(x|z). The authors assume that VAEs typically model the data using a Guassian distribution with a fixed noise. This, however, is not the case. Since the authors are trying to address a problem that does not actually exist, I am not sure what the contributions of the paper are. \n\nApart from the major issue outlined above, the paper also makes other errors. For example, it suggests using D_KL(q(z)||p(z)) as a measure of disentanglement, with lower values being indicative of better disentanglement. This, however, is incorrect, since one can have tiny D_KL by encoding all the information into a single latent z_i. Such a representation would be highly entangled while still satisfying all of the conditions the authors propose for a disentangled representation. \n\nGiven the points outlined above and the fact that the paper is hard to read and is excessively long, I do not believe it should be accepted.","sentences":[{"sentence_type":"2","sentence":"Since the authors are trying to address a problem that does not actually exist, I am not sure what the contributions of the paper are.","rephrased":"It appears that the authors may have mischaracterized the problem they are aiming to solve. Clarification on the novelty and contributions of their approach would be beneficial."},{"sentence_type":"2","sentence":"Given the points outlined above and the fact that the paper is hard to read and is excessively long, I do not believe it should be accepted.","rephrased":"Considering the issues mentioned, I would recommend a revision to improve readability and conciseness before reconsidering the paper for acceptance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[442,576,"Maybe"],[1066,1206,"Not concerning"]],"Comments":[]}
{"id":"ryxQH_TlsH","text":"This paper considers the problem of how to improve the performance of an existing DP classifier, with the help of the labelled public data. The paper considers the following process: 1. find a public dataset containing relevant samples; 2. carefully select a subset of public samples that can improve the performance of the classifier; 3 fine-tune the existing classifier on the selected samples. Two different techniques from active learning are utilized in order to select representative samples from a public dataset and fine-tune a DP classifier. This paper also conducts some experiments on   the MNIST and SVHN datasets and demonstrates improvement compared with the benchmark.\n\nI vote for rejecting for this paper, because of the following two concerns:\n\n1. I do not think this paper has made a lot of contribution to either differential privacy or active learning. It just \"borrows\" some fine-tuning techniques from active learning and apply it in DP. There is almost no theoretical contribution made by this paper. Besides, from the experimental perspective, neither can I see an obvious improvement compared with the benchmarks.\n\n2. I do not think the privacy analysis of the NearPrivate algorithm (Algorithm 2) is correct. The paper uses private argmax algorithm and claims that it satisfies $eps_{support}$-DP. However, this is only true when $N_{labeled} = 1$. Generally, it should satisfy $eps_{support} \\cdot N_{labeled}$-DP. So if we look at the experimental setting of MNIST, roughly thousand times less noise is added! Since this amount of noise is non-trivial at all, I can not judge the effectiveness of the algorithm.\n------------------------------------------------------------------------------------------\nThanks for the authors' classification. I missed the part that each private sample was only assigned to one public sample. Now I can confirm the correctness of the algorithm and increase my score accordingly.","sentences":[{"sentence_type":"2","sentence":"I do not think this paper has made a lot of contribution to either differential privacy or active learning.","rephrased":"The paper could benefit from a clearer demonstration of its contributions to differential privacy and active learning."},{"sentence_type":"2","sentence":"It just \"borrows\" some fine-tuning techniques from active learning and apply it in DP.","rephrased":"The paper might explore more original applications of fine-tuning techniques from active learning within the context of DP."},{"sentence_type":"2","sentence":"There is almost no theoretical contribution made by this paper.","rephrased":"The paper could be strengthened by including more theoretical analysis to support its findings."},{"sentence_type":"2","sentence":"Since this amount of noise is non-trivial at all, I can not judge the effectiveness of the algorithm.","rephrased":"A more detailed analysis of the noise impact could enhance the assessment of the algorithm's effectiveness."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[765,872,"Not concerning"],[873,959,"Not concerning"],[960,1023,"Not concerning"],[1537,1638,"Not concerning"]],"Comments":[]}
{"id":"_oyaIfM066f","text":"**Paper Summary**:\n\nCompressing 3D scene is an interesting problem to explore. The paper proposes to add entropy penalized reparametrization (Oktay et al. (2020)) technique into Nerf (Mildenhall et al. (2020)) and compress the neural network in Nerf. Experiments also show some compressing rates improvement with the proposed baseline, which I have some concerns in the weakness below.  \n\n**Strength**:\n1. The problem this paper is attacking is interesting, compressing 3D scene plays an important role in real-time applications. \n2. The paper also showed the approach to compress multiple scenes in one network (though I have some concerns for the experiments in weakness below).\n\n**Weakness**:\n1. Lack of novelty. The main technique from this paper is merging two methods together (Oktay et al. (2020), and Mildenhall et al. (2020)),  with some improvements by extending the nerf to multiple scenes. However, the multiple scenes experiments are not performed well to demonstrate the effectiveness of the proposed method (see below), so the overall novelty is not enough. \n\n2. Experiments are not great enough to show the effectiveness of the full pipeline. \n\n   a) In single scene experiment, I think the main reason why HEVC+LLFF has lower PSNR is that LLFF is interpolating multiple training views, and this is obvious and has already been shown in the original Nerf paper (Table 1, Fig 5 in  Mildenhall et al. (2020)). Therefore, this is not a valid experiment to show the pipeline in this paper is better in compression. A more valid baseline should be: receiver receives the training images compressed by HEVC -> decode the images -> receiver train a new Nerf on the decoded images -> run the trained model on the test set. \n\n  b) In multiple scenes experiment. The paper only showed the experiments on compressing two scenes, it's not clear how will the performance be and conclusion generalize to more scenes, e.g. train only one model on all 8 synthetic scenes together. \n\n3. The paper also didn't consider the efficiency problem, training a Nerf model takes a long time, and also the author did not report the running time when doing inference on a trained nerf model, and do not have a comparison with HEVC+LLFF baseline. In literature, Nerf model takes more than one day to converge, while HEVC is very fast for both encoding and decoding.\n\nOverall, considering the novelty and the experiment section in this paper, I don't think they are enough to reach the bar of ICLR, so I vote for rejection. \n","sentences":[{"sentence_type":"2","sentence":"Lack of novelty.","rephrased":"The paper could benefit from a clearer demonstration of its novel contributions beyond the combination of existing techniques."},{"sentence_type":"2","sentence":"Experiments are not great enough to show the effectiveness of the full pipeline.","rephrased":"The experiments could be strengthened to more convincingly demonstrate the effectiveness of the full pipeline."},{"sentence_type":"2","sentence":"I don't think they are enough to reach the bar of ICLR, so I vote for rejection.","rephrased":"In its current form, the paper may not meet the criteria for acceptance at ICLR, and I would recommend further development before resubmission."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[699,715,"Not concerning"],[1078,1158,"Not concerning"],[2429,2509,"Not concerning"]],"Comments":[]}
{"id":"3njY0I1L9pk","text":"Strengths:\n\n1. This paper studies an interesting problem of causal discovery from heterogeneous data, and does a comprehensive survey of related literature.\n\n2. This paper proposes a novel Multiple-Domain Score Search algorithm for score-based causal discovery from different domains.\n\n3. This paper conducts experiments on both synthetic and real-world data with comparison to state-of-the-art baselines, and the results seem promising.\n\nWeaknesses:\n\n1. The difficulty of causal discovery in multiple domains is not clearly shown in the experiments.\n\n2. Some parts of the writing can be improved.\n\n3. There might still be some important aspects of the method left to evaluate.\n\nThis paper studies a problem of causal discovery from heterogeneous data, the problem is well-motivated, and the authors give a comprehensive survey of the related work. This paper proposes a novel algorithm Multiple-Domain Score Search (MDSS) to address the problem, which searches over the space of augmented graphs to avoid the spurious edges, characterizes distribution shift with the additional domain index, and uses a novel Multiple-Domain Score (MDS) to identify causal directions. The paper evaluates the proposed method on synthetic and real-world datasets, it achieves better performance than baselines.\n\nHere are some concerns about this paper:\n\n1. In the experiment, it is not very clear how difficult it is for causal discovery in multiple domains (e.g. the number of spurious edges, the difference of data distributions in multiple domains, especially in the real-world dataset), which brings challenges to convincingly evaluate the superiority of the proposed method.\n\n2. As for the writing, some parts of the paper are not very easy to follow for non-experts. It would be better if the terms (e.g., causal sufficiency, causal modules) can be briefly introduced when first mentioned.\n\n3. Also, I think there may be many interesting aspects to evaluate in the experiments, e.g., how robust the algorithm is under different levels of domain shift; how each component in the method contributes to the performance (some ablation studies may be considered).","sentences":[{"sentence_type":"1","sentence":"Some parts of the writing can be improved.","rephrased":"The paper could benefit from some additional clarity in certain sections to enhance its accessibility."},{"sentence_type":"1","sentence":"There might still be some important aspects of the method left to evaluate.","rephrased":"Further evaluation could be conducted to explore additional important aspects of the method."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[555,597,"Not concerning"],[602,677,"Not concerning"]],"Comments":[]}
{"id":"wQxtExoy4lz","text":"Summary:\nThe authors address the problem of offline RL learning from action limited datasets. They propose to pretrain an inverse dynamics model on multiple environments to provide action labels for a decision transformer. They demonstrate the performance of ALPT by comparing their algorithm to a few baselines on Atari games. Their results support the importance of generalist inverse dynamics models as an efficient approach to large-scale RL.\n\nStrong points:\nOverall, I really liked this paper. The proposed method is simple, the motivations and intuitions are well explained. I will list the main strong points:\n- In many real scenarios, obtaining manually labelled data could be extremely expensive or even impossible. This paper proposes to overcome this challenge by combining large but sparsely-annotated datasets from a target environment of interest with fully-annotated datasets from other source environments.\n- The paper is clearly written and well organized.\n- The related work is relevant and seems complete.\n- The experiments are overall well designed. I found the empirical study to be very thorough and comprehensive, including multiple baselines and ablations. In addition, the authors support their claims regarding the generalization issues with well-designed experiments and metrics.\n\nWeak points:\nI will now list a few weak points of the paper：\n\n- In Section 5.5 and Section 5.6, the disjoint action example is too simple. Regarding generalization, more complex application scenarios can be given.\n- 3 seeds is a very small number. I know that very few works present much more than this, but I think it is bad practice. Please consider adding more (>=10). ","sentences":[{"sentence_type":"2","sentence":"3 seeds is a very small number. I know that very few works present much more than this, but I think it is bad practice.","rephrased":"While using 3 seeds is common, increasing the number to 10 or more could enhance the robustness of the results and is recommended as a best practice."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1524,1643,"Not concerning"]],"Comments":[]}
{"id":"H1gboOnDtE","text":"The authors of this work consider the problem of learning disentangled representations. They observe that if labeled data are used for model selection, than using them for training can lead to interesting results. They propose to regularize beta-VAE with a cross entropy loss for a small portion of labeled data, and show improvement on the models that use labeled data only for model selection. The experimental results indeed validate the authors hypothesis and show that even a small set of partially of noisily labeled data can have an interesting impact on the training.\n\nThe observation and initial results are interesting, and the work is wort to be discussed in this workshop.","sentences":[{"sentence_type":"1","sentence":"The observation and initial results are interesting, and the work is wort to be discussed in this workshop.","rephrased":"The observations and initial results are interesting, making this work a valuable contribution to the discussion at this workshop."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[577,684,"Not concerning"]],"Comments":[]}
{"id":"BkeqaMZJ5S","text":"The paper aims to study the topology of loss surfaces of neural networks using tools from algebraic topology. From what I understood, the idea is to effectively (1) take a grid over the parameters of a function (say a parameters of a neural net), (2) evaluate the function at those points, (3) compute sub-levelset persistent homology and (4) study the resulting barcode (for 0\/1-dim features) (i.e., the mentioned \"canonical form\" invariants). Some experiments are presented on extremely simple toy data.\n\nOverall, the paper is very hard to read, as different concepts and terminology appear all over the place without a precise definition (see comments below). Given the problems in the writing of the paper, my assessment is that this idea boils down to computing persistent homology of the sub-levelset filtration of the loss surface sampled at fixed parameter realizations. I do not think that this will be feasible to do, even for small-scale real-world neural networks, simply due to the difficulty of finding a suitable grid, let alone the vast number of function evaluations involved.\n\nThe paper is also unclear in many parts. A selection is listed below:\n\n(1) What do you mean by gradient flow? One can define a gradient flow in a linear space X and for a function F: X->R, e.g., as  a smooth curve R->X, such that x'(t) = -\\nabla F(x(t)); is that what is meant? \n\n(2) What do you mean by \"TDA package\"? There are many TDA packages these days (maybe the CRAN TDA package?)\n\n(3) \"It was tested in dimensions up to 16 ...\" What is meant by dimension here? The dimensionality of the parameter space?\n\n(4) The author's talk about the \"minima's barcode\" - I have no idea what is meant by that either; the barcode is the result of sub-levelset persistent homology of a function -> it's not associated to a minima.\n\n(5) Is Theorem 2.3. not just a restatement of a theorem from Barannikov '94? At least the proof in the appendix seems to be .\n\n(6) Right before Theorem 2.3., what does the notation F_sC_* mean? This needs to be introduced somewhere.\n\nFrom my perspective, the whole story revolves around how to compute persistence barcodes from the sub-levelset filtration of the loss surface, obtained from function values taken on a grid over the parameters. The paper devotes quite some time to the introduction of these concepts, but not in a very clear or understandable manner. The experiments are effectively done on toy data, which is fine, but the paper stops at that point. I do not buy the argument that \"it is possible to apply it [the method] to large-scale modern neural networks\". Without a clear strategy to extend this, or at least some preliminary \"larger\"-scale results, the paper does not meet the ICLR threshold. The more theoretical part is too convoluted and, from my perspective, just a restatement of earlier results.\n\n\n\n\n\n\n\n\n\n\n","sentences":[{"sentence_type":"2","sentence":"Overall, the paper is very hard to read, as different concepts and terminology appear all over the place without a precise definition (see comments below).","rephrased":"The paper could benefit from a clearer structure and more precise definitions of concepts and terminology to enhance readability."},{"sentence_type":"2","sentence":"I do not think that this will be feasible to do, even for small-scale real-world neural networks, simply due to the difficulty of finding a suitable grid, let alone the vast number of function evaluations involved.","rephrased":"The feasibility of this approach for small-scale real-world neural networks may be challenging due to the difficulty of grid selection and the extensive number of function evaluations required."},{"sentence_type":"2","sentence":"The more theoretical part is too convoluted and, from my perspective, just a restatement of earlier results.","rephrased":"The theoretical sections could be streamlined for clarity and should distinguish more clearly how they build upon or differ from previous results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[507,662,"Not concerning"],[879,1093,"Not concerning"],[2736,2844,"Not concerning"]],"Comments":[]}
{"id":"S1xrQYsfq4","text":"The paper proposes a method for generating diverse high resolution images with vector-quantised autoencoders (VQ-VAEs). The approach can generate images with much higher visual fidelity than the original VQ-VAE paper via two main ingredients: (1) hierarchical multi-scale latent maps and (2) PixelSNAIL instead of PixelCNN.\n\nThe motivation and the contributions of this paper are very similar to De Fauw et al., 2019 (Hierarchical Autoregressive Image Models with Auxiliary Decoders; https:\/\/arxiv.org\/abs\/1903.04933), in that De Fauw et al. also used hierarchical VQ-VAEs (specifically, 2-layer) to generate high fidelity images. Also their autoregressive priors are closely related to PixelSNAIL. I'm assuming the authors were not aware of this paper, as they did not cite it. De Fauw et al. report IS\/FID\/Test NLL, none of which this paper reports. Given De Fauw et al. 2019 was submitted to arxiv on March 9th, this should be considered concurrent work, but should be cited in the revision.\n\nPros\n- Clear exposition and motivation\n- High fidelity and diversity in the generated images\n\nCons\n- No test NLL comparisons with other likelihood based approaches (e.g. SPN, Parallel Multiscale)\n- I'd have liked to see Inception\/FID results from the proposed model (as done by De Fauw et al., 2019).","sentences":[{"sentence_type":"2","sentence":"I'm assuming the authors were not aware of this paper, as they did not cite it.","rephrased":"It would be beneficial for the authors to consider referencing De Fauw et al., 2019, as it presents closely related work and was available at the time of this submission."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[699,778,"Not concerning"]],"Comments":[]}
{"id":"S1gJmHhziH","text":"This paper studies the performance of the mirror gradient method when applied to the overparameterized network. The authors claim that the SMD method could find the regularized global minimize for different potential functions, in terms of minimal Bregman distance. Further experiments are carried out to back up the authors' claim.\n\nHowever, the drawbacks of this paper are listed in these several points:\n\n1) The regularization w.r.t. Bregman distance is quite different from the regularization used in network training: instead of $\\|w - w_0\\|$, we use $\\|w\\|$ more often, therefore, the virtue of sparsity shared by 1-norm is not exploited.\n\n2) The authors' assumption in Assumption 3.1 is too fuzzy: instead of detailed analysis in the papers related to the overparameterized network, the author does not give ANY relationship between the $\\epsilon$ and these three important parameters: a) network width, b) probability introduced by random initialization, c) the number of input data.\n\n3) Therefore, according to the too strong and fuzzy assumption mentioned in the last point, Assumption 3.1 simply makes the network equals to the linear model, which leads to minor contributions according to the study of the overparameterized network.\n\n4) The `over parameterized network' discussed now, including the work of (Li & Liang, 2018; Du et al., 2018; Azizan & Hassibi, 2019; Allen-Zhu et al., 2019; Cao & Gu, 2019), are mainly focused on the `network of infinite width', however, in the authors' experiment, the network architecture, e.g. ResNet18, is more to be a `very deep network' rather than a `very wide network'. Therefore, the authors' theory is built on Assumption 3.1, which is based on `network of infinite width', while the experiment is built on the `very deep network'. The result of the experiments is not enough to support the authors' theorem.\n\nIn conclusion, I am convinced that the authors' work is over-claimed in this paper.","sentences":[{"sentence_type":"2","sentence":"The authors' assumption in Assumption 3.1 is too fuzzy: instead of detailed analysis in the papers related to the overparameterized network, the author does not give ANY relationship between the \n","rephrased":"The clarity of Assumption 3.1 could be improved. A more detailed analysis or explicit relationship between the parameters mentioned could strengthen the paper."},{"sentence_type":"2","sentence":"Therefore, according to the too strong and fuzzy assumption mentioned in the last point, Assumption 3.1 simply makes the network equals to the linear model, which leads to minor contributions according to the study of the overparameterized network.","rephrased":"The implications of Assumption 3.1 may be worth revisiting, as it appears to simplify the network to a linear model, which could limit the perceived novelty or contribution of the study."},{"sentence_type":"3","sentence":"In conclusion, I am convinced that the authors' work is over-claimed in this paper.","rephrased":"In conclusion, it may be beneficial for the authors to consider tempering some of the claims to more closely align with the presented evidence."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[996,1244,"Maybe"],[1866,1949,"Not concerning"]],"Comments":[]}
{"id":"Y9SPZBTcrDA","text":"The paper seeks to propose an end-to-end learnable retrieval model for recommendation, to replace existing two-step based approaches (learn embeddings first, then do MIPS search).\n\nThe underlying model structure is motivated by KD-code (Chen et al. 2018), where each item is encoded as a D-dimensional discrete vector (with a cardinality K in each dim). Then a conditional, probabilistic framework is proposed to learn the model with a multi-path extension for further improvement. After training, Beam Search is adopted to retrieve top candidates.\n\nThe paper is technically sound, and it's new to adopt a KD-code like model for retrieval. However, I have some concerns in motivation, methods, and experiments.\n\n- The significant feature of the DR model (from the claim in the abstract) to encode all candidates in a discrete latent space. However, there are some previous attempts in this direction that are not discussed. For example VQ-VAE[1] also learns a discrete space. Another more related example is HashRec[2], which (end-to-end) learns binary codes for users and items for efficient hash table retrieval. It's not clear of the connections and why the proposed discrete structure is more suitable.\n\n- The experiments didn't show the superiority of the proposed method. As a retrieval method, the most common comparison method (e.g. https:\/\/github.com\/erikbern\/ann-benchmarks) is the plot of performance-retrieval time, which is absent in this paper. The paper didn't compare the efficiency against the baselines like TDM, JTM, or ANN-based models, which makes the experiments less convincing as the better performance may due to the longer retrieval time.\n\n- It's not clear to me what retrieval\/MIPS search methods are adopted for Item-CF, Youtube DNN.\n\n- What's the performance of purely using softmax?\n\n- It seems only DR uses RNNs for sequential behavior modeling, while the baselines didn't. This'd be a unfair comparison, and sequential methods should be included if DR uses RNN and sequential actions for training.\n\n- I didn't understand the motivation of using the multi-path extension. As you already encode each item in D different clusters, this should be enough to express different aspects with a larger D. Why a multi-path variant is needed for making the model more expressive?\n\n- The Beam Search may not guarantee sub-linear time complexity due to the new hyper-parameter B. It's possible that a very large B is needed for retrieving enough candidates.\n\nIn summary, it's not clear to me why the proposed discrete structure is more suitable for the task given we have Tree-based and binary code based approaches (that are also end-to-end learnable). And the experiments didn't show the superiority of the proposed method due to the lack of important comparisons (retrieval time, against HashRec, etc.).\n\n[1]Neural Discrete Representation Learning, NIPS'17\n[2]Candidate Generation with Binary Codes for Large-scale Top-N Recommendation, CIKM'19","sentences":[{"sentence_type":"2","sentence":"The experiments didn't show the superiority of the proposed method.","rephrased":"The experiments could be strengthened by demonstrating the superiority of the proposed method more clearly."},{"sentence_type":"2","sentence":"This'd be a unfair comparison, and sequential methods should be included if DR uses RNN and sequential actions for training.","rephrased":"To ensure a fair comparison, it would be beneficial to include sequential methods, especially if DR employs RNN and sequential actions for training."},{"sentence_type":"1","sentence":"I didn't understand the motivation of using the multi-path extension.","rephrased":"The motivation for using the multi-path extension could be clarified further."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1210,1277,"Not concerning"],[1905,2029,"Not concerning"],[2033,2102,"Not concerning"]],"Comments":[]}
{"id":"PvGh73wfAD3","text":"The paper proposes a policy gradient style RL algorithm that optimizes an expected quadratic utility, a commonly used objective of risk management in finance and economics. The key idea here is based on the observation that when using the quadratic utility function, the use of mean-variance RL methods can be shown to optimize the utility of the agent. To this effect, the paper considers the use of expected quadratic utility maximization in the policy gradient. The quadratic utility can be naturally modeled using mean and variance. The paper implements two variations -- policy gradient and actor-critic with EQUM framework. \n\nThe main contributions of the paper listed as follow:\n1 The paper shows that maximizing the expected utility by balancing the mean and variance term is equal to reward targeting optimization or constrained cumulative expected reward problem, and could also be interpreted as maximizing the expected reward with the variance as regularizer.\n2 It introduces two algorithms, standard policy gradient and actor-critic, with the EQUM framework.\n\n\nI quite like the paper. The problem is well motivated. I like the idea of using EQUM motivated by economics as the objective function. The paper addresses all relevant works and is written well. The theoretical justification is quite good. The algorithms appear to be well designed and as far as I can see, they are technically correct.  The proposed framework is easier to compute and could be extended to many policy gradient methods, so there is a lot of potential for future works and applications.\n\nWhile I like the paper, there is clearly some room for improvement.\n\nThe justification of \\psi as \\beta\/2\\alpha is not well justified. I find the explanation that this is based on economic players and economic empirical studies quite vague. I would have preferred to see the citations and proof. This is crucial to make sure that the algorithm does converge to the correct values. The values are quite important and not being precise will make it hard to reproduce the results. \n\nThe choice of \\psi through cross-validation also appears vague. I understand the nice properties that you have in your framework (particularly avoiding double sampling) but replacing a costly sampling with a cross-validation search for a regularization parameter is not quite convincing. As shown in Figure 1, it is clear that the method is quite sensitive to the choice of \\psi and so this choice needs to be well defined. \n\nWhile the empirical evaluation appears nice and comprehensive, I was a bit disappointed at the choice of atari games for evaluation. I would have liked to see more domains from finance and economics that would provide a better idea of the efficacy of the proposed methods. \n\nIt is true that EQUM methods perform best in R\/R, but there is no consistent story here. Different psi can have arbitrarily different performance and I cannot tease out any performance discussion clearly. What really is missing is a good analysis of the empirical performance.\n\nI think the paper has a lot of merit and can be of high impact. But more work is needed in the analysis and discussion part of the paper. With this, it can be a really good submission.\n\nTypos:\n\nPage 2 section 3.1: The formula of maximizing expected reward with regularization has a pair of redundant parenthesis.\n\nPage 3: “Our proposed EQUM framework more focus on this problem.” Reads awkward\n\nPage 4: “Here, we introduce three interpretations of EQUM.” And you present a list of 4.\n","sentences":[{"sentence_type":"1","sentence":"The justification of \\psi as \\beta\/2\\alpha is not well justified.","rephrased":"The rationale for defining \\psi as \\beta\/2\\alpha could be strengthened with additional justification or citations."},{"sentence_type":"2","sentence":"I find the explanation that this is based on economic players and economic empirical studies quite vague.","rephrased":"The explanation drawing on economic players and empirical studies could be clarified and elaborated upon for better understanding."},{"sentence_type":"2","sentence":"The values are quite important and not being precise will make it hard to reproduce the results.","rephrased":"Ensuring precision in the values is crucial for the reproducibility of the results."},{"sentence_type":"2","sentence":"The choice of \\psi through cross-validation also appears vague.","rephrased":"The method for selecting \\psi via cross-validation could be described more clearly to enhance the paper's clarity."},{"sentence_type":"1","sentence":"I was a bit disappointed at the choice of atari games for evaluation.","rephrased":"It would be beneficial to include more evaluation domains from finance and economics to better demonstrate the efficacy of the proposed methods."},{"sentence_type":"2","sentence":"Different psi can have arbitrarily different performance and I cannot tease out any performance discussion clearly.","rephrased":"A more detailed analysis of how different psi values affect performance would enhance the discussion of the empirical results."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1647,1712,"Not concerning"],[1713,1818,"Not concerning"],[1959,2055,"Not concerning"],[2058,2121,"Not concerning"],[2547,2616,"Confirmed"],[2848,2963,"Not concerning"]],"Comments":[]}
{"id":"INPiNBJw2","text":"The paper proposes to apply Deep Weight Prior to the problem of transfer learning in medical imaging. The authors learn a U-Net on MS lesion segmentation and evaluate transferability to the BRATS2018 dataset. The use of DWP is well motivated and the results indicate improved performance over regular transfer learning.\n\nFollowing the results of the paper, I believe the use of DWP can improve settings in medical image analysis with only limited available training data but availability of related datasets. However, the authors should improve the explanation of DWP and introduce the used variables. For example, I assume that $p, k$ in the equation on page 2 refers to the input and output  channel dimensions of the convolutional kernels. It would be interesting to report Dice scores which are more commonly used for the BRATS dataset. It would be beneficial for the authors to release code or add training details to the appendix as the results seem to be irreproducible in its current form. Lastly, a longer study should test different freezing regimes for transfer learning, as freezing the middle seems like a rather arbitrary choice.\n\nMinor:\n- page 2, 1. dataset instead of dataest\n- page 2, the figure and the enumeration could use a little margin between them","sentences":[{"sentence_type":"2","sentence":"It would be beneficial for the authors to release code or add training details to the appendix as the results seem to be irreproducible in its current form.","rephrased":"To enhance the reproducibility of the results, I recommend the authors to release the code or include more detailed training information in the appendix."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[841,997,"Not concerning"]],"Comments":[]}
{"id":"H1lEWJjkcN","text":"Summary of the paper:\n\nThis work proposes a “best of both worlds approach”, by introducint an online meta-learning algorithm.\nThe “follow the meta leader” algorithm (and its analysis) heavily builds on the “follow the leader” algorithm from online convex optimization, which leaves the door open for future improvements.\nSome numerical experiments favorably comparing the approach with previous work are provided.\n\nA few comments and questions:\n-there is a (small) typo, line 7 of section A1 page 8, in the appendix\n-second corollary, page 11: why put a 32 in the big O notation (same comment for the proof)?\n\nReviewer’s assessment:\nI found the paper to be well written. The ideas are exposed clearly and the numerical results support the approach. Since the problem tackled by this work clearly falls within the scope of the workshop, I recommend to accept this paper.\n\n\n","sentences":[{"sentence_type":"1","sentence":"there is a (small) typo, line 7 of section A1 page 8, in the appendix","rephrased":"I noticed a minor typo on line 7 of section A1 on page 8 in the appendix that can be easily corrected."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[446,515,"Not concerning"]],"Comments":[]}
{"id":"SkghvLwZ9H","text":"This paper proposes two techniques for fast linear interpolation on CPUs. They achieved speedups by reducing 1) fixed overhead cost and 2) per example computation (linear interpolation operation level optimization).\nAuthors consider this problem for small operation models like linear interpolation rather than the models requiring large operations such as ResNet. In this case, dispatch overhead cannot be ignored and so they use the MLIR frameworks to optimize trained model into the C++ code (reducing fixed overhead cost). This results in 2-3x speed up. Secondly, they propose the way to construct auxiliary index-mapping function by considering spacing of the key points rather just using for example evenly spaced index-mapping.\nThey compare proposed method to C++ interpreter implementation on two-layer and deep lattice networks and achieve 5-10x speed improvements.\n\nIt seems the topic of this paper does not fit ICLR and most machine learning researchers are unlikely to be interested in and even understand this paper. This reviewer also does not have enough knowledge and background to judge this paper. But my impression is that achieving speed up using existing MLIR framework has no surprising novelty. \nMoreover, the experimental results seems quite limited in the sense that they only experiment with trained 2 and 4-layer calibrated lattice models which are kind of small.  \n\nIt would be better to highlight why the proposed method is meaningful and provide more background knowledge to understand this paper. \n\nThis is only consider optimization on CPUs. What about the case of using GPUs?\n\nIs branch free assumption for functions ‘Adjust’ & ‘T’ is valid? (I don’t have much knowledge on compiler..)","sentences":[{"sentence_type":"2","sentence":"It seems the topic of this paper does not fit ICLR and most machine learning researchers are unlikely to be interested in and even understand this paper.","rephrased":"The relevance of this paper's topic to the ICLR audience may not be immediately clear, and it could benefit from a discussion on its broader appeal to machine learning researchers."},{"sentence_type":"1","sentence":"This reviewer also does not have enough knowledge and background to judge this paper.","rephrased":"As a reviewer, I acknowledge that my expertise does not fully cover the scope of this paper, which may limit my ability to evaluate it comprehensively."},{"sentence_type":"2","sentence":"But my impression is that achieving speed up using existing MLIR framework has no surprising novelty.","rephrased":"The paper could further emphasize the innovative aspects of the speed improvements achieved through the MLIR framework to highlight its novelty."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[876,1029,"Not concerning"],[1030,1115,"Not concerning"]],"Comments":[]}
{"id":"rJl5OkRLnm","text":"This paper is technically flawed. Here are three key equations from Section 2. The notations are simplified for textual presentation:  d – p_data; d(y|x) – p_d(y|x); m(y|x) – p_theta(y|x)\n\nmax E_x~d E_y~d(y|x) [ log m (y|x) ]                 \t\t\t\t               (1) \nmax E_x~d { E_y~d(y|x) ) [ log d(y|x) ]}  -  E_y~d(y|x) [ log m (y|x) ]}        (2)\nmax { E_y~d [  log  (y) ]  -  E_y~d  log E_x~d(x|y) [ m (y|x) ]}                        (3)\n\nFirst error is that the “max” in (2) and (3) should be “min”. I will assume this minor error is corrected in the following.\nThe equivalence between (1) and (2) is correct and well-known. The reason is that the first entropy term  in (2) does not depend on model.  The MAJOR ERROR is that (1) is NOT equivalent to (3). Instead, it is equivalent to the following:\n\n min { E_y~d [  log d (y) ]  -  E_y~d  E_x~d(x|y) [ log m (y|x) ]}                     (3’)\n\nNotice the swap of “E_x” and “log”. By Jensen’s nequality, we have \n\n log E_x~d(x|y)  m (y|x) ]  > E_x~d(x|y) [ log m (y|x)\n -  E_y~d  log E_x~d(x|y)  [ m (y|x) ]    < -  E_y~d  E_x~d(x|y) [ log m (y|x) ]                    \n\nSo, minimizing (3) amounts to minimizing a lower bound of the correct objective (3’). It does not make sense at all.\n","sentences":[{"sentence_type":"2","sentence":"This paper is technically flawed.","rephrased":"There are some technical issues in the paper that need to be addressed."},{"sentence_type":"2","sentence":"The MAJOR ERROR is that (1) is NOT equivalent to (3).","rephrased":"A significant concern is that equation (1) is not equivalent to (3), which needs further investigation."},{"sentence_type":"3","sentence":"It does not make sense at all.","rephrased":"This approach seems to be incorrect, and it would be beneficial to re-evaluate the derivation of equation (3)."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[0,33,"Maybe"],[707,760,"Maybe"],[1211,1241,"Confirmed"]],"Comments":[]}
{"id":"BkeMtm2WcH","text":"This paper proposes Policy Message Passing, a Bayesian GNN which models edge message passing as a mixture distribution with corresponding coefficient generated by a learnable prior defined on graph state. I think the motivation is reasonable and the experiment on Jigsaw Puzzle is impressive. But the writing and other experiments can be further improved, as detailed below.\n\nSec 3.1: What does ```````+1 mean in Eq. (6)?\n\nSec 3.2: The choice for the variational distribution q is not mentioned. Is q a parametric model (e.g., NN) or non-parametric? It is hard to connect prior, posterior and variational posterior in Sec 3.2 to the reasoning agent\/message formulation in Sec 3.1. I suggest reformulating Sec 3.1 & 3.2 to give a thorough presentation of the training objective, model structure and optimization details of PMP.\n\nModeling graph using graph neural network with Bayesian framework has been investigated in several papers, e.g., [1-2]. They also take a probabilistic perspective. I think this paper should discuss the connections to previous Bayesian GNNs and compare their performance with PMP at least in Sec 4.2. Besides, GNN with edge information (e.g., [3]) has also been investigated in several papers. According to my understanding, PMP can also be regarded as a GNN with latent edge information (modeled with a learnable prior and inferred with a variational posterior). So I think adding discussion\/experiment to them can better support your claim.\n\nAs for the experiment part, my major concern is whether the comparison with other models (e.g., GCN and GAT) is fair. It seems that the number of parameters of PMP is much larger than GCN and GAT. Could you provide details for the model size and the training\/inference time cost?\n\nSec 4.2. What's the performance of PMP when no noisy edges is added? \n\n[1] Bayesian graph convolutional neural networks for semi-supervised classification, AAAI 2019\n[2] Bayesian Semi-supervised Learning with Graph Gaussian Processes, NIPS 2018\n[3] Exploiting Edge Features for Graph Neural Networks, CVPR 2019\n","sentences":[{"sentence_type":"1","sentence":"But the writing and other experiments can be further improved, as detailed below.","rephrased":"The writing and other experiments show potential for further refinement, as I will detail below."},{"sentence_type":"1","sentence":"It is hard to connect prior, posterior and variational posterior in Sec 3.2 to the reasoning agent\/message formulation in Sec 3.1.","rephrased":"Clarifying the connection between the prior, posterior, and variational posterior in Sec 3.2 and the reasoning agent\/message formulation in Sec 3.1 would be beneficial."},{"sentence_type":"1","sentence":"As for the experiment part, my major concern is whether the comparison with other models (e.g., GCN and GAT) is fair.","rephrased":"Regarding the experimental section, I suggest ensuring that the comparison with other models (e.g., GCN and GAT) is conducted on a level playing field."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[293,374,"Not concerning"],[550,680,"Not concerning"],[1471,1588,"Not concerning"]],"Comments":[]}
{"id":"wsS232r33Tz","text":"This work derives a new upper bound on the dynamic regret for online convex optimization in the restricted setting where the comparison sequence is made up of the minimizers x^_1,...,x*_T of the loss sequence. There are three main parameters that control regret in this case: the path length C_T = ||x*_2-x*_1||+...+||x*_T-x*_{T-1}||. The squared path length C_T = ||x*_2-x*_1||^2+...+||x*_T-x*_{T-1}||^2. And the sum G_T of squared loss gradient norms evaluated at x*_1,...,x*_T. \n\nPrevious work by Zhang showed that when the loss functions are simultaneously strongly convex and strongly smooth w.r.t. the Euclidean norm, then Online Gradient Descent with multiple updates per step (OMGD) achieves regret of order min{C_T,S_T} whenever G_T < T G^2 for some G > 0 (i.e., the gradient norm of the loss is uniformly bounded). Note that this algorithm invokes the first-order oracle a constant number of times per step.\n\nThis work extends Zhang's results in two main directions. First, OMGD is replaced by OMMD (which is Online Multiple Mirror Descent). Accordingly, strong convexity and strong smoothness are now computed w.r.t. the Bregman divergence induced by the mirror map. Second, the condition G_T < T G^2 is dropped. The resulting bound is of order min{C_T,S_T,G_T}. Experiments with quadratic losses compare OMMD against OMGD and Dynamic Mirror Descent (DMD) by Hall and Willet. Both these algorithms have worse upper bounds than OMMD.\n\nI have some concerns about the significance of the results. I wonder what are interesting examples of loss functions that are simultaneously strongly convex and strongly smooth with respect to a Lipschitz continuous Bregman divergence induced by a regularization function which ---in turn--- is simultaneously strongly convex and strongly smooth with respect to some norm? We know that quadratic losses and regularized logistic losses satisfy these assumptions w.r.t the squared Euclidean mirror map (as shown by Zhang). I suspect that the generalization proposed in this work does not lead to include additional interesting losses.\n\nSince OMMD improves on the OMGD regret bound, it would be interesting to know whether OMMD reduces to OMGD when the regularizer is Euclidean.\n\nThe experiments use a decision set (the simplex) where OMD with entropic regularization is known to work better than OGD. This advantage appears to be simply transferred to the dynamic setting. Indeed, OMMD performs only marginally better than DMD, which also uses the entropic regularization.\n\nIt is not even clear whether the theory applies to the setting used in the experiments. The quadratic losses used in the experiments are strongly convex and smooth only with respect to Euclidean regularization and not with respect to entropic regularization (the regularization used by OMMD in the experiments).\n\nThe assumptions require Lipschitz continuity of the Bregman divergence. Does this condition apply to KL divergence? What is K in this case? \n\nIn the ridge regression experiment, z_i is defined as a scalar but treated as a vector in the definition of the loss.","sentences":[{"sentence_type":"2","sentence":"I suspect that the generalization proposed in this work does not lead to include additional interesting losses.","rephrased":"It would be beneficial for the paper to further explore and clarify how the proposed generalization could encompass a broader range of interesting loss functions."},{"sentence_type":"2","sentence":"It is not even clear whether the theory applies to the setting used in the experiments.","rephrased":"The connection between the theoretical framework and the experimental setting could be made more explicit to strengthen the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1966,2077,"Not concerning"],[2517,2604,"Not concerning"]],"Comments":[]}
{"id":"JKzEwqt4J3C","text":"While the algorithm designed in this paper sounds interesting, it does not appear to be sufficiently novel. In fact, random search methods for black-box optimization have been studied for many years. Especially, in the evolutionary computation community, various approaches to improve the search performance, including block-based search and statistical testing techniques, have been explored extensively in the past to solve various numerical optimization problems. In comparison to existing EC and local search algorithms, it is not clear which part of the new algorithm is truly novel.\n\nThe authors claim in the paper that reinforcement learning problems are black-box optimization problems. On such problems, critical gradient information is hard to obtain. However, the prominent success of many state-of-the-art deep reinforcement learning algorithms, such as TD3 and SAC, have already demonstrated the effectiveness of calculating and using gradients to train policies. In comparison to these deep reinforcement learning algorithms, it is not clear what key advantages the new algorithm has. Furthermore, any possible advantages of the new algorithm should be verified both experimentally and theoretically. In particular, the theoretical strength of adopting a gradient-free approach for reinforcement learning is not clearly justified in the paper.\n\nThe experimental analysis in the paper has some limitations. First, the number of benchmark problems utilized in the experimental study seems to be quite limited. It is not easy to draw any solid conclusion based on the results obtained from these benchmark problems. Second, the authors argued that the number of training iterations is more meaningful as a performance metric because the algorithms are only applied to simulated environments. Does that mean that the new algorithm cannot be applied to any real-world problems? If so, what is the practical value of the new algorithm? Even when the environment is simulated, it is still important to determine the final learning performance achievable by the new algorithm. For the Mujoco benchmarks, I cannot find any performance results in the main body of the paper. In fact, the authors claimed that the new algorithm can converge to the optimal solution on Swimmer-v2. However, it is not clear what the optimal solution is and how the optimal solution is obtained. Third, the hyper-parameter settings used to solve different problems appear to be different. For example, on the lunar lander problem, 5000 directions were sampled per iteration. Different from that, on half cheetah, the number of sampled policies is reduced to 500 per iteration. It is not clear how the change of hyper-parameters is determined and whether the hyper-parameter settings used present a fair comparison among all the competing algorithms.\n\nFinally, it is claimed in the abstract that this paper has the aim to learn robust policies for stochastic environments. However, to my understanding, most of the benchmark problems utilized in the paper are not highly stochastic in nature. Furthermore, the actual robustness of the learned policies is not evaluated in the paper.","sentences":[{"sentence_type":"2","sentence":"While the algorithm designed in this paper sounds interesting, it does not appear to be sufficiently novel.","rephrased":"While the algorithm designed in this paper is interesting, its novelty could be further highlighted, especially in the context of existing research in the field."},{"sentence_type":"2","sentence":"It is not easy to draw any solid conclusion based on the results obtained from these benchmark problems.","rephrased":"Drawing firm conclusions from the results of the limited benchmark problems is challenging and could benefit from a broader data set."},{"sentence_type":"2","sentence":"Does that mean that the new algorithm cannot be applied to any real-world problems? If so, what is the practical value of the new algorithm?","rephrased":"It would be beneficial to clarify if the new algorithm can be applied to real-world problems and to discuss its practical value in such contexts."},{"sentence_type":"2","sentence":"In fact, the authors claimed that the new algorithm can converge to the optimal solution on Swimmer-v2. However, it is not clear what the optimal solution is and how the optimal solution is obtained.","rephrased":"The paper would be strengthened by a clearer explanation of what constitutes the optimal solution on Swimmer-v2 and the method by which it is obtained."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,107,"Not concerning"],[1522,1626,"Not concerning"],[1803,1943,"Not concerning"],[2179,2378,"Not concerning"]],"Comments":[]}
{"id":"Odwc58Dr26","text":"The paper is very well organized. This is a well written paper and everything is clear. \nPaper is easy to follow with clear motivation about the method.\nThe dataset used in this study is large, from multiple sites and the performance of their segmentation network is interesting. However the weaknesses of this paper is that the authors didn't mention the effect of different reconstruction kernels, slice thickness or the effect of contrast injection in their model.","sentences":[{"sentence_type":"1","sentence":"However the weaknesses of this paper is that the authors didn't mention the effect of different reconstruction kernels, slice thickness or the effect of contrast injection in their model.","rephrased":"While the paper is strong in many aspects, it would be beneficial to include a discussion on the effect of different reconstruction kernels, slice thickness, and contrast injection in the model."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[280,467,"Not concerning"]],"Comments":[]}
{"id":"r1eF8AL5jN","text":" Quality & Significance: \nThe paper motivates the problem statement really well and explanation for major contributions are laid out precisely. The primary results of this work are promising. The work still needs to address scalability, redundancy and  reliability concerns surrounding DTN.  \n\nClarity:\nThe paper captures details regarding scheduler and DTN is quite depth and with some clarity. But certain sections in the paper (Methodology, Nature Run for Observing System Simulations, Orbital Mechanics and Attitude Control) are slightly tedious to follow and diverts attention from crux of the paper. \n\nOriginality:\nThe paper shows interesting contribution in terms on delivering on-board scheduler without significant loss in % of all GP observed. It also shows applicability of Delay\/Disruption Tolerant Networking (DTN) for near-Earth orbiting spacecraft.\n \nQuestions for authors:\n1. Is it unclear how \"Cumulative Value\" in Table 1 is calculated?\n\n2. Similarly the paper claims, \"The DTN-enabled decentralized solution provides 16% more value over 6 hours than the centralized implementation of the same algorithm.\", the exact experimentation showing that is not reflected or clear.\n\n3. The impact of <4 deg FOV constraint on applicability is unclear and can benefit from discussion.\n\n4. As pointed by authors, on-board scheduler is heavily reliant of DTN's performance, even though DTN has shown the time to reach a region for by satellites with priority>3 is long enough for all bundles to be delivered\nfor perfect consensus, deeper exploration in DTN's performance in terms of size and shape constellations would be interesting. \n\nFew minor fixes:\n1. Figure reference issues:\n\ta. Figure 1 mention in methodology section should be Figure 2.\n\tb. Figure 3 reference in \"Nature run for Observing system simulation\" should be Figure 4. \n\n2. Typo on page 2, 2nd paragraph: The algorithm is \"mow\" broadened in application scope \n\n3. Extra period in the last line above \"Methodology\" section.\n","sentences":[{"sentence_type":"2","sentence":"But certain sections in the paper (Methodology, Nature Run for Observing System Simulations, Orbital Mechanics and Attitude Control) are slightly tedious to follow and diverts attention from crux of the paper.","rephrased":"However, certain sections of the paper, such as Methodology, Nature Run for Observing System Simulations, Orbital Mechanics, and Attitude Control, could be made more concise to maintain focus on the central theme of the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[396,605,"Not concerning"]],"Comments":[]}
{"id":"SkgTDt7pYS","text":"This paper studies the importance of a neural networks weights and to which extend do they need to be updated. Particularly, the authors show that freezing weights which have small gradient in the very beginning of the training only results in a very slight drop in the final accuracy.\n\nThis paper should be rejected because (1) the paper only provides some empirical results on freezing network network weights, I don't think there are much insights and useful information; (2) To my knowledge, the phenomenon that only a few parameters are important has been observed before by many papers.\n\nGiven that, I vote for a rejection.","sentences":[{"sentence_type":"2","sentence":"This paper should be rejected because (1) the paper only provides some empirical results on freezing network network weights, I don't think there are much insights and useful information;","rephrased":"While the paper provides empirical results on freezing network weights, it would be beneficial to see more in-depth analysis and insights to enhance the paper's contribution to the field."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[287,474,"Not concerning"]],"Comments":[]}
{"id":"vTl9gv-9m-2","text":"The paper presents encoder-decoder architecture to predict motion for liver MRI.\nFirst, the authors generate displacement field between pair of images using (unknown) registration framework, then encode this displacement field into label, and generate a codebook between the label and a quantized vectorial components of the displacement field. \nSecondly, the authors train the network (decoder + LSTM) to predict the motion label, and finally use the codebook to recover motion field. \nthe method is validated using 50 MRI scans (2D) coming from 15 volunteers, the vessel tracking error is given for the presented method, and two other relevant methods, showing improvement accuracy for the presented method. \n\nPros:\n- (real time?) motion estimation for mri guided therapy is really emerging problem, and so the presented approach is interesting contribution\n\ncons\n- the approach consists of several steps, while it is not really clear whether they are needed. \n- Would be possible to train encoder-decoder to predict directly motion from the sequence? \n- What extra quantization add to overall accuracy?\n\nsince this is 2D(?) acquisition, and the problem described is the breathing motion, is there any issue with out-of-plane motion? Could this explain rather large error at the end of sequence?\n\nIt is also not clear whether this acquisition is 2d or 3d. Page 1 says that the registration is done between images to produce 2d motion field, then the data description (Page 3) says pixel spacing, and slice thickness. Is 3D MRI and split into 2d slices?\n\ntesting\/validating\n- 50 MRI scans from 12 volunteers. Were the same volunteer scans used for training and testing?\n\n- the authors wrote that the results are significantly better, no test, p-value given\n\n- what is vessel tracking error? \n- how many landmarks were used?\n\n\nMore general problem to consider:\nWhat registration between pair of images was used?\nThere has been a bit of research done on (both MRI and CT) liver motion estimation using discontinuous registration (\"A locally adaptive regularization based on anisotropic diffusion for deformable image registration of sliding organs.\" IEEE transactions on medical imaging 32.11 (2013): 2114-2126. \"GIFTed Demons: deformable image registration with local structure-preserving regularization using supervoxels for liver applications.\" Journal of Medical Imaging 5.2 (2018): 024001.)\n","sentences":[{"sentence_type":"2","sentence":"the approach consists of several steps, while it is not really clear whether they are needed.","rephrased":"It would be helpful if the authors could clarify the necessity of each step in the approach."},{"sentence_type":"2","sentence":"the authors wrote that the results are significantly better, no test, p-value given","rephrased":"The authors should provide statistical tests and p-values to substantiate the claim that the results are significantly better."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[868,961,"Not concerning"],[1674,1757,"Not concerning"]],"Comments":[]}
{"id":"B1eEz8qRKH","text":"The paper builds on a classical idea of sampling model parameters apart from learning them. Specifically, it combines hierarchical sampling with neural networks and proposes models that can help explore the parameter space efficiently. The proposal is evaluated appropriately.\n\nWhat exactly do we mean by intelligent exploration? Is this quantified via the #samples needed or variance of sampled parameters? Or is it via regret? \n\nThe paper is clearly written and the idea makes sense. However the experiments are essentially based on simulated data. It is not entirely clear as to how this would translate to real setups. \n\nIs it possible that the linear hypermodel is performing well because the data was generated according to a linear model in section 5?\n\nIf the baseline is a classical ensembling setup, then why not use classical performance measures to evaluate the benefit of hypermodeling? like accuracy etc. Why are we specifically talking about bandits? In other words, does the proposed hyper sampling allow for better weak learners in general as well? \n ","sentences":[{"sentence_type":"2","sentence":"However the experiments are essentially based on simulated data.","rephrased":"While the experiments provide valuable insights, it would be beneficial to see how the model performs with real-world data."},{"sentence_type":"1","sentence":"It is not entirely clear as to how this would translate to real setups.","rephrased":"It would be helpful to include a discussion on the potential application of the model to real-world scenarios."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[486,550,"Not concerning"],[551,622,"Not concerning"]],"Comments":[]}
{"id":"coFUd2X0s9","text":"Summary:\nThis paper proposes a modification of the Independent Learners trust region policy optimization method in general sum games. The modification consists of first forming a “meta game”—ie. the matrix game in which each agent’s options are his previous policy and his independent trust region optimized policy—-and then interpolating between the two for each agent according to a Nash equilibrium of the meta game. The paper shows that this algorithm results in each step generating a “weak stable fixed point”. The paper concludes by showing a number of experimental results indicating the convergence and overall performance of the method as compared with relevant baselines in a number of different games.\n\nStrengths:\n* good motivation of why independent learner algorithms may not converge due to missed coupling\n* clever construction of meta game\n* good choice of variety of experiments\n\nWeaknesses:\n* the notion of “weak stable fixed point” is extremely weak. For example , Mazumdar 2020 (who is cited) and many others consider much stronger criteria like local Nash or differential Nash, or even quasi-Nash. As I understand it, “weak stability” is just requiring that iterates don’t ever find a local minimum in the coupled strategy space of all agents. Not only is this artificially introducing a coupling requirement between the agents, but it is basically just saying that the agents shouldn’t ever find themselves all wishing to change collectively.\n* the preliminaries are sometimes stated in a way that indicates only two players and other times N players\n* figures 1 and 2 are confusing\n* I find theorem 1 to be hard to parse (much notation is not defined clearly), based on very strong assumptions (alpha coupling, discrete spaces), essentially pointing out a fact about prior work on independent methods (not the current proposed one), and overall unnecessary in the present paper. I would advocate removing it.\n* it should be clarified that the rho are really distributions corresponding to mixed Nash strategies in the meta game, rather than deterministic strategies (which may not even exist)\n* in the experiments, it is not statistically useful to show results for only 5 seeds. I understand that these things are expensive and I have this comment for the vast majority of work in RL I have ever read, but showing plots like figure 5 is misleading, esp. without an immediate caution in the caption and remain text\n* I found figure 6 and the related text very confusing and not really useful in understanding what is going on\n* only validating convergence in matrix games is very limited. I was missing a more complete discussion of convergence, if only experimental\n\nNitpicks:\n* there were numerous typos and syntax\/semantic errors throughout the paper. I would recommend employing the services of a copy editor in future\n\nOverall:\nI like the main concept of this paper, but I really can not recommend it for publication at this time, I have listed a number of directions in which I feel this paper could be improved in rebuttal or even in a later submission if it goes that route. My main concerns are: (1) the weakness of the theoretical property of “weak stability”, (2) lack of a more complete evaluation of convergence, (3) general confusion throughout reading the paper.\n","sentences":[{"sentence_type":"1","sentence":"the notion of \\","rephrased":"The concept of \\"},{"sentence_type":"2","sentence":"I like the main concept of this paper, but I really can not recommend it for publication at this time","rephrased":"While I appreciate the main concept of this paper, I believe it requires further refinement before I can recommend it for publication."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2857,2958,"Not concerning"]],"Comments":[]}
{"id":"Uh-5wh-565","text":"The proposed NAM is a DNN version of the generalized additive models (GAM). The proposed NAM allows one to exam the eact description of how NAM compute a prediction since one can sweep the input feature and see the prediction curve. The individual shape function provides the good intelligibility for the input feature. The proposed method contains certain amount of novelty in the NAM and the way to interprete the model, including the multi-task NAM architecture. However, I think the novelty of the proposed NAM is not that significant. Several experiments have been conducted to demonstrate the better accuracy compared with linear regression and the intelligible EBM. The paper also shows several examples on how to interpret the model and explain how the input features affect the performance. The paper is well-written and easy to understand.\n\nWhile it is good to allow each network attend to only one feature, the limitation of the proposed NAM is also evident. The major advantage of deep learning models lie in its representation learning, which learns the non-linear combination and transformation of interleaving features, not individual features. The relationship and interaction of different features empowers the development in many areas where deep learning applies such as computer vision, natural language processing, recommendation, etc. I don't see how the proposed NAM can be more generalized to other areas, where the input feature is of high-dimension and requires more complex understanding.\n\nOther concerns:\n- The proposed exp-centered hidden units (ExU) uses the exponential function for the weight. Will this introduce instability in training? It roughly only allows the weight to be in a much smaller range, and could cause the gradient to go to nan easily.","sentences":[{"sentence_type":"2","sentence":"However, I think the novelty of the proposed NAM is not that significant.","rephrased":"However, while the proposed NAM introduces some novel aspects, it may benefit from further exploration to fully highlight its innovative contributions."},{"sentence_type":"2","sentence":"I don't see how the proposed NAM can be more generalized to other areas, where the input feature is of high-dimension and requires more complex understanding.","rephrased":"It would be beneficial for the paper to explore and discuss potential generalization of the proposed NAM to other areas, particularly where input features are high-dimensional and require a more complex understanding."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[466,539,"Not concerning"],[1357,1515,"Not concerning"]],"Comments":[]}
{"id":"ZMRyYHFdwYv","text":"This is very interesting work looking at the performance of a decision transformer (DT), when its weights have been \"transplanted\" from another DT trained in a different (Mujoco) environment. The authors show that in some circumstances, they can recover performance on original tasks with merged weights, especially with finetuning. They perform ablation studies and analyses to identify which merged components (attention, MLP, Layer Norm) affect the performance the most, and discuss different scenarios. This work fits very well with the workshop goal of reusing prior computation in RL. The paper is well written and easy to read.\n\nSome suggestions\/comments\/questions:\n- Cite prior work in: \"Prior work considers merging models trained on the same data distribution, but we begin by using merging as a tool to see the similarity of DTs trained on different data\"\n\n- Figure 1: The x-axis can be wrongly interpreted by assuming 17 subsequent layers, where those are actually groupings corresponding to different merging types. It would help if you differently organize\/highlight the bars (perhaps space them out differently) and mark which bars correspond to which condition.\n\n- Using Identity Attention Parameters: I found it really interesting that identity parameters gives even higher scores than the Original for Walker2D. Could you speculate why that's the case?\n\n- \"For example, we can directly swap in the weights of HalfCheetah into the Walker2D transformer, and vice versa, with no decrease in return\" --> is this also true if you just swap in random weights?\n\n- Table 2: Report delta from \"Original\" instead, or in addition to total scores, and highlight interesting conditions\n\n\n\n\n\n","sentences":[{"sentence_type":"1","sentence":"The x-axis can be wrongly interpreted by assuming 17 subsequent layers, where those are actually groupings corresponding to different merging types.","rephrased":"To avoid potential confusion, consider clarifying that the x-axis in Figure 1 represents groupings corresponding to different merging types, rather than 17 subsequent layers."},{"sentence_type":"1","sentence":"is this also true if you just swap in random weights?","rephrased":"Could you provide insight into whether similar performance is maintained when random weights are used instead of the specific weights from HalfCheetah?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[880,1028,"Not concerning"],[1518,1571,"Not concerning"]],"Comments":[]}
{"id":"LZiBR8f0Ni","text":"# Summary\nThis paper presents a novel approach to reinforcement learning called Co-Imitation Learning. This enables two agents to share experiences and learn from each other without having access to expert demonstrations.\n\n---\n\n## Strengths\n- The paper is organized and well-written\n- The approach proposed in the paper is novel and interesting\n- The authors compared CoIL to a strong multi-actor reinforcement learning algorithm like A2C\n\n## Weaknesses\n- The approach seems to be only applicable in situations where it is possible to place the agent in arbitrary locations in the environment, which may not be possible in many difficult reinforcement learning tasks.\n- For large environments, a choice would have to be made about where the best places to start the different agents are.\n- It is unclear how the utility factor is used in the loss function. $\\mathcal{P}_{\\pi}$ is not used anywhere in the paper (unless I missed it).\n","sentences":[{"sentence_type":"2","sentence":"The approach seems to be only applicable in situations where it is possible to place the agent in arbitrary locations in the environment, which may not be possible in many difficult reinforcement learning tasks.","rephrased":"The applicability of the approach may be limited to scenarios where agents can be positioned in arbitrary locations within the environment, which could be challenging for certain complex reinforcement learning tasks."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[456,667,"Not concerning"]],"Comments":[]}
{"id":"ruWgIHUqwWq","text":"The authors propose a method to infer causal structure between some high-level variables using a pretrained generative model and a labeled dataset. To establish whether variable A causes variable B, they first train linear models to predict A and B from the latent space of the generative model. Next, they take samples from the data distribution, encode them to the latent space, and move them along the direction normal to the learned decision boundary for the variable A. They then say that a causal affect A -> B exists if the B model output changes during this latent traversal.\n\nThe problem setting certainly sounds interesting: it would be great if StyleGAN would learn a causal relation behind gender and baldness and we could infer that.\n\nUnfortunately, I believe the approach to be fundamentally flawed. The proposed method will determine only if the latent direction corresponding to the feature A and the latent direction corresponding to the feature B are approximately orthogonal or not. Under some assumptions (that the authors could have been clearer about), this translates to an independence test between A and B. But if two features are statistically dependent, this method cannot possibly distinguish the cases of A causing B, B causing A, and A and B being confounded. \n\nOn the one hand, the authors seem to acknowledge this: they write that for this method to work, they require unconfoundedness and knowing the causal ordering of the variables a priori. Under these assumption, we can infer the existence of a causal link from independence tests, for instance with this method. (But we could achieve this easier, for instance by directly performing independence tests on the distribution of labels in the training data.)\n\nOn the other hand, the authors also suggest that we can infer the causal direction (A -> B or B -> A) by performing two such tests with flipped roles for A and B. I do not understand why this should work. If the true causal graph is A -> B, moving in the latent space along the B-associated direction does *not* correspond to an intervention on B, and in general may also change A. Take Figure 1, for instance: moving from z(i) vertically to the bottom (an \"intervention\" on e) will also cross the decision boundary for c. More generally, distinguishing the causal graphs A -> B and B -> A from purely observational data requires model assumptions, and it is not clear to me that this approach makes any assumptions that allow for causal discovery.\n\nThere are several aspects I like about the paper: the \"counterfactual\" samples from the experiments look good, the perceptual evaluation through human annotators is a nice touch, and the writing is generally good. Unfortunately, assuming I am not missing an important point, the core idea of the method is flawed. I therefore lean towards rejecting this paper.\n\nSome minor points, questions, and typos:\n- In the beginning, the paper advertises suitability for GANs, but later assumes the existence of an encoder without further comments.\n- How is the intervention step size alpha chosen? How do the results depend on this choice?\n- It's nice that the authors develop a procedure for estimating the null distribution of the test quantity. It is not clear to me though that the null hypothesis really makes sense, as with a reshuffling of the latent features we not only decorrelate the latent variables, but also remove any relation between the latent space and the variables, which then means the linear classifiers don't make sense any more.","sentences":[{"sentence_type":"2","sentence":"Unfortunately, I believe the approach to be fundamentally flawed.","rephrased":"While the approach is innovative, there may be some fundamental challenges to address."},{"sentence_type":"2","sentence":"Unfortunately, assuming I am not missing an important point, the core idea of the method is flawed.","rephrased":"Unless I have overlooked a crucial aspect, there appear to be some issues with the core concept of the method that need further consideration."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[748,813,"Confirmed"],[2709,2808,"Not concerning"]],"Comments":[]}
{"id":"HVhgaic-x-5","text":"Unfortunately the paper does not cover an ICLR paper, which is part of the rules for this blogpost track. The added value of the post is also unclear.","sentences":[{"sentence_type":"2","sentence":"Unfortunately the paper does not cover an ICLR paper, which is part of the rules for this blogpost track.","rephrased":"The paper should address an ICLR paper to meet the submission criteria for this blogpost track."},{"sentence_type":"2","sentence":"The added value of the post is also unclear.","rephrased":"It would be beneficial to clarify the unique contributions of this work to enhance its value."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,105,"Not concerning"],[106,150,"Not concerning"]],"Comments":[]}
{"id":"rkxJ5NAgqr","text":"The authors propose a local label propagation approach for large-scale semi-supervised learning. The approach learns a representation that tries to minimize a combination of the cross-entropy loss on the labeled data and a negative inner-product-based likelihood between the propagated pseudo-label and other examples with the same true label. The pseudo-labels on the unlabeled data are then calculated with a weighted k-NN scheme, where the weights take a heuristic correction of a soft similarity. Some further computational speedup is done with a memory cache described in an earlier work (Wu 2018b). Experimental results seem significantly superior to the competitors. The design choices are mostly justified with ablation studies.\n\nThe whole idea is interesting and the results are promising. From the current manuscript, my remaining concerns are\n\n(1) How much contribution has readily been done by (Wu 2018a, b), and how much is the original design of the authors? From Section 3 (and without reading (Wu 2018a, b)), I cannot find a clear answer to this question. Currently it appears that the additional contribution over Wu's works is marginal.\n\n(2) It is not clear to me how the proposed approach reaches the asserted efficiency over global label propagation approaches. In particular, each P(v_i)*Z in Equation (2) is O(N) to compute. Each w_j(v) in Equation (5) is O(K) to compute after getting all P(v_i)*Z, and then there are N (or at least N-M) such w_j(v) needed. So the total complexity is naively O(N (N-M) K). Even ignoring the K as a small constant, I cannot see how LLP is O(NM). Some running time profiling of LLP versus global LP might be helpful.\n\n(3) For label propagation methods, it is important to understand whether the pseudo-labels are accurate and\/or whether the methods might be mis-guided by the pseudo-labels. Is there any evidence on whether the pseudo-labels are accurate (absolutely, or with respect to the confidence)?\n\n(4) For hyper-parameter selection, there is a \"Learning rate is initialized to 0.03 and then dropped by a factor of 10 whenever validation performance saturates.\" But it is not clear how the validation set is formed, and what performance is measured. Is it a performance based on a labeled validation set (and if so, how large is the set) or unlabeled one?\n\nI read the rebuttal. While it does not change my assessment, I thank the authors for clarifying some issues.","sentences":[{"sentence_type":"2","sentence":"Currently it appears that the additional contribution over Wu's works is marginal.","rephrased":"It would be helpful if the authors could clarify the extent of their original contribution beyond the work done by Wu (2018a, b), as it is not immediately clear from Section 3."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1072,1154,"Not concerning"]],"Comments":[]}
{"id":"s2rmsGxiiv","text":"Strengths:\n- the work generalizes the recovery scenarios to multiple samples and steps, compared with a single sample and step solution by an earlier pioneering work\n- the logic is clear\n\nWeakness:\n- It seems that the label not used in updating step also has the probability to be identified as \"used\". it is critical to provide rigorous proof for their proposed method.\n- As the authors admit, their method does not work when the batch size is greater than the number of classes, which might be a major concern for application.\n- The notation is unorganized and there are many typos that cause unnecessary troubles for understanding, e.g., the main result Remark 4.","sentences":[{"sentence_type":"2","sentence":"The notation is unorganized and there are many typos that cause unnecessary troubles for understanding, e.g., the main result Remark 4.","rephrased":"The notation could be more organized, and attention to detail in correcting typos would enhance clarity, particularly in key sections such as Remark 4."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[531,666,"Not concerning"]],"Comments":[]}
{"id":"ZIZvo9aTE9h","text":"The authors figure the bucket imbalance problem in ANN-derived content-based sparse attention and analyze its weakness on the imbalance problem. Attention Biclusteringis introduced to find the optimal attention utility. The learning to hash-based attention model is proposed to improve the effectiveness of sparse attention. Experiments on different applications support their claims.\n\nConcerns:\n1. It is well-known that LSH is data-independent hashing, which is formulated by random projection with some pre-defined metrics. Notably, using learning to hash is better than the LSH and its variants, in most cases, for representation learning. Therefore, the authors need to clarify why replacing LSH with learning to hash models is useful in sparse attention.\n2. Such a simple replacement could fully support your work in the present form. The authors should give full reasons for your contributions.\n3. The authors fail to convince the reviewer what are the connections between Theorem 1 and your proposed method. To me, you can directly claim there are some limitations on LSH-based methods, and implementing learning to hash can improve its representation capabilities on feature learning.\n4. Efficiency is one of the proposed methods, and more analysis on the efficiency and efficacy is necessary.\n","sentences":[{"sentence_type":"2","sentence":"Such a simple replacement could fully support your work in the present form.","rephrased":"The rationale behind the replacement strategy should be more thoroughly explained to fully substantiate your work."},{"sentence_type":"2","sentence":"The authors fail to convince the reviewer what are the connections between Theorem 1 and your proposed method.","rephrased":"The authors could provide a clearer explanation of the connections between Theorem 1 and the proposed method to strengthen the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[763,839,"Not concerning"],[904,1014,"Not concerning"]],"Comments":[]}
{"id":"qaPWEdfyEW","text":"This short paper describes a network architecture for segmentation of the left ventricle in short-axis contrast-enhanced MRI scans, aiming specifically at late gadolinium enhancement MRI scans. The authors propose to use three 2D networks with late fusion of the predictions (2.5D). The network architecture makes use of a ResNet50 as feature extractor and uses squeeze-and-excitation blocks to somehow combine the features extracted by the individual residual blocks of the ResNet into a single prediction. Unfortunately, the description of the network architecture is rather hard to follow, and there is also no illustration of the architecture - overall, it is difficult to grasp both the overall structure as well as the main novelty of the architecture.\n\nThe propose network was trained and evaluated with a large dataset (~350 scans) and compared with various other architectures. Inter- and intra-observer variations were also measured by repeating the manual segmentation of the test dataset. The method achieves mediocre Dice scores (overall 82% on average), but the paper demonstrates that this performance is close to the inter- and intra-observer agreement.\n\nIn summary, the details of the network architecture proposed in this paper are difficult to understand, but even though it is clear that this is still preliminary work that is being presented, the evaluation is quite detailed and the dataset relatively large. Provided that the authors improve the presentation of their method, this could be a good contribution to MIDL. ","sentences":[{"sentence_type":"2","sentence":"Unfortunately, the description of the network architecture is rather hard to follow, and there is also no illustration of the architecture - overall, it is difficult to grasp both the overall structure as well as the main novelty of the architecture.","rephrased":"The description of the network architecture could be clearer, and including an illustration might help readers to better understand the overall structure and the main innovations of the architecture."},{"sentence_type":"2","sentence":"The method achieves mediocre Dice scores (overall 82% on average), but the paper demonstrates that this performance is close to the inter- and intra-observer agreement.","rephrased":"While the method achieves Dice scores of 82% on average, which may be improved, it is noteworthy that this performance aligns closely with the inter- and intra-observer agreement."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[508,758,"Not concerning"],[1001,1169,"Not concerning"]],"Comments":[]}
{"id":"SJlO7o_dYE","text":"This paper succinctly describes a VAE based method driven by a \"reference set\" for factor discovery. \n\nI particularly appreciate the detailed experimental section, and extremely thorough comparisons with other architectures. The appendix is also a nice addition, though even the four page version stands on its own merit.\n\nThe work itself is quite clear, and the results speak for themselves. They also raise a number of follow-on questions, maybe the authors have explored these in other experiments - none of these are required to be answered, but the author's insights may be useful for other readers of the work (as well as myself).\n\nThe selection of the reference set seems important - is it critical that the the factors of interest be constant across every example? How much \"noise\" in this selection is tolerable? Does choosing different subsets which both hold the variable constant, result in different factors discovered? How does the size of the reference set impact the result generally, is there some threshold below which the method performs far worse?\nAre there any suggestions for (perhaps) automated discovery of these constant subsets, or ways to bootstrap this labeling via weak learners and pruning? \n\nThe primary things that would improve this paper's rating for me are larger scale experiments, or perhaps non-image data. The model, its baselines, the datasets used, and the experiments completed are all thoroughly spelled out in this paper. Will the authors also release code at some point? \n\nOne other paper of interest may be GLSR-VAE (https:\/\/arxiv.org\/abs\/1707.04588) - though not directly comparable to this work, the use of a simple \"reward\" \/ label to drive factorization of the latent space seems similar in some ways to the requirement of the reference set to contain the factor of interest.","sentences":[{"sentence_type":"1","sentence":"The primary things that would improve this paper's rating for me are larger scale experiments, or perhaps non-image data.","rephrased":"The paper could be further strengthened by including larger scale experiments or by exploring non-image data."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1223,1344,"Not concerning"]],"Comments":[]}
{"id":"BkxDPxaXcH","text":"[Summary]\nThe paper proposed to use gradient-based presentation in deep neural networks to capture missing information unavailable in the activation-based network representation. It is claimed that the missing information that could not be encoded during learning from training set can be revealed by taking the gradient of an example with respect to the model parameters. Based on this idea, a new learning algorithm is proposed to combine both the conventional loss for activation-based presentation and gradient-based regularization. As an illustration, the method is evaluated on anomaly detection benchmarks with gradient-based representation as part of the anomaly inference. \n\n[Comments]\nI’m not sure if I fully understand the claimed contribution and how it is justified either theoretically and empirically. It seems to me that the paper claims the the current activation-based network does not fully encode information from training set during learning, and taking the gradient over a novel example (either training or test) with respect to (w.r.t,) model parameters can encode the missing information. I don't quite follow a few things, and had a difficult time in interpreting the novelty here.\n- What is the missing information (a model should learn but fails to capture from training set) exactly? The example in the introduction uses digit 0 for training and digit 6 for testing and claims the vertical edge in 6 is missing. But isn’t that expected if the model is only trained with digit 0s only? How would one expect the model to learn the vertical edge if there is none in the training data?       \n- More critically, the idea of taking the gradient of a model w.r.t.its parameters over an example to encode geometric relationship of the example in the data manifold is by no means novel at the conceptual level. There have been at least a bunch of similar classical methods derived from the perspective of information geometry. For instance, the Fisher kernel and vector  have been well studied for more than a decade, with both theoretical treatment (e.g., “Exploiting Generative Models in Discriminative Classifiers” in NIPS 1998) and application across multiple areas (e.g., “Fisher Kernels on Visual Vocabularies for Image Categorization” in CVPR 2007). I don’t see any novelty here by doing this to a new model (deep neural networks), and it is frustrating to see classical methods are being “invented” over and over again by decorating them with fashionable wrappers without any reference to the origin in the literature.  \n- Besides, to use gradients to capture missing information, the paper proposes to append a regularization term by enforcing the gradient at particular learning iteration to be close to the mean of those of previous iterations (via cosine similarity) as in (3). This seems not quite different from many existing popular inertia-based strategies like gradients with momentum, Adam, etc. It needs to be elucidated more how the proposed optimizer compares to these benchmark methods.        \n\nIn terms of implementation, I also found some details missing. For instance, the objective function of (4) requires evaluation of second order derivatives (since the second term in the cosSIM involves dL\/dPhi(x, Phi)). How to efficiently compute this term is not clear to me yet.   It is also mentioned that only decoder of the AE is used for constraint gradient, The reason for this is also not explained.\n\nFor evaluation, only anomaly detection examples are provided. It would be great if more general tasks like image classification can be studied. After all, the proposed method is claimed to be a fairly general framework (the introduction actually uses image classification as the example), and evaluation on the most popular benchmarks provides the most convincing justification. Even on the anomaly detection tasks, the proposed approach does not seem to have solid advantages over baselines. I’m not sure how significant are the differences of 0.007 between GradCon and OCGAN (table 2 and 3), and those less than 1% in table 4.\n\nOverall the paper does not seem to have a clear and well-defined motivation, contribution is also vague and trivial compared to literature, plus very convincing empirical justification. Thus I do not think it is ready for publication at ICLR.     \n","sentences":[{"sentence_type":"2","sentence":"I don't see any novelty here by doing this to a new model (deep neural networks), and it is frustrating to see classical methods are being \\","rephrased":"The concept of applying gradient-based methods to new models such as deep neural networks is not entirely novel, as it shares similarities with classical methods like the Fisher kernel. It would be beneficial for the paper to acknowledge these precedents and differentiate the proposed approach more clearly."},{"sentence_type":"3","sentence":"Overall the paper does not seem to have a clear and well-defined motivation, contribution is also vague and trivial compared to literature, plus very convincing empirical justification.","rephrased":"The paper could benefit from a clearer articulation of its motivation and contributions, which currently appear to be less distinct when compared to existing literature. Additionally, a more robust empirical justification would strengthen the case for the proposed method."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[4076,4261,"Maybe"]],"Comments":[]}
{"id":"VrrNtIv9v4n","text":"SUMMARY \n\nThis work proposes to use an ensemble of very well-known machine learning models (mainly tree-based methods) to calibrate radio interferometric data from the KAT-7 telescope. This provides a more efficient alternative to the traiditional approach, which is based on the astrophysicists workforce.\n\nREASONS FOR SCORE\n\nIn my humble opinion, this work does not present a machine learning contribution of interest for the ICLR community. It applies standard and well-known approaches to an specific remote sensing problem.  I would point the authors to different venues, such as the IEEE International Geoscience and Remote Sensing Symposium. \n\nMoreover, I would recommend the authors to compare their approach to some others methodologies used in the field. Right now, the experimental section only analyzes the results of the proposed approach, with no baselines.\n\n","sentences":[{"sentence_type":"2","sentence":"In my humble opinion, this work does not present a machine learning contribution of interest for the ICLR community.","rephrased":"While the machine learning contribution may seem familiar, it would be beneficial to highlight the novel aspects that could be of interest to the ICLR community."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[327,443,"Not concerning"]],"Comments":[]}
{"id":"HlJaeFasEco","text":"This paper proposes a new augmentation method based on CutMix. The authors find out that randomly selecting may mix background textures and this will mislead the model. So, they propose to use saliency maps to control the selection of mixed patches, which is called SaliencyMix. This idea seems easy and reasonable, many experiments are conducted to prove the effectiveness of the proposed method. However, the experiments’ results fail to show the ability of the method, and some explanation is missed.\n \nPositive:\n1.     The idea is simple and clear, the paper is well organized and easy to follow.\n2.     The experiments are comprehensive, including classification and transfer learning.\n \nWeakness:\n1.     The main concern is the effectiveness of the proposed method. According to the authors’ experiments, the improvement over CutMix is very limited on all datasets. Especially on ResNet-101, the promotion over CutMix is only 0.08.\n2.     According to the authors’ ablation study in sec. 3.3, only using fast self-tuning background subtraction produces better results than CutMix. Why other methods even worse than CutMx? What’s the core reason for the improvement of using fast self-tuning background subtraction?\n3.     The authors use batchsize=256, lr=0.1 for CIFAR training, while usually batchsize=128, lr=0.1 is used in previous works (Cutout). And as described in [1], the learning rate should be increased linearly with batchsize. This change of hyperparameters may need further explanation.\n \n[1] Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour.\n\n\n============Post Rebuttal====================\nAfter reading the feedback from authors, I still have my concerns. The novelty of this paper is too limited for ICLR. I really do not think a combination of CutMix with existing saliency detection method is a novel method. Moreover, the improvement over CutMix is diminishing. These main concerns are not addressed by the authors. So, my final recommendation is still rejection.","sentences":[{"sentence_type":"2","sentence":"However, the experiments' results fail to show the ability of the method, and some explanation is missed.","rephrased":"However, the results of the experiments could be more compelling, and additional explanations would be beneficial."},{"sentence_type":"2","sentence":"I really do not think a combination of CutMix with existing saliency detection method is a novel method.","rephrased":"I believe that the combination of CutMix with an existing saliency detection method may not sufficiently meet the novelty criteria for ICLR."},{"sentence_type":"1","sentence":"Moreover, the improvement over CutMix is diminishing.","rephrased":"Additionally, it appears that the incremental improvement over CutMix is modest."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1739,1843,"Not concerning"],[1844,1897,"Not concerning"]],"Comments":[]}
{"id":"BklqJdQs3m","text":"The paper propose a adversary method to train a bidirectional GAN with both an encoder and decoder. Comparing to the existing works, the main contribution is the introducing of an augmented reconstruction loss by training a discriminator to distinguish the augmentation data from the reconstructed data. Experimental results are demonstrated to show the generating and reconstruction performance.\n\nThe problem studied in this paper is very important, and has drawn a lot of researchers' attentions in recent years.  However, the novelties of this paper is very limited. The techniques used to train a bidirectional GAN are very standard. The only new stuff may be is the proposed reconstruction loss defined on augmented samples and reconstructed ones. But this is also not a big contribution, seems just using a slightly different way to guarantee reconstruction. ","sentences":[{"sentence_type":"2","sentence":"However, the novelties of this paper is very limited.","rephrased":"However, the paper could benefit from a clearer articulation of its novel contributions beyond the standard techniques used in bidirectional GAN training."},{"sentence_type":"2","sentence":"But this is also not a big contribution, seems just using a slightly different way to guarantee reconstruction.","rephrased":"While the proposed reconstruction loss is an interesting approach, further elaboration on its impact and how it advances the field would strengthen the paper's contribution."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[516,569,"Confirmed"],[753,864,"Not concerning"]],"Comments":[]}
{"id":"iplCeK4Lm4Q","text":"*The purpose of the bound*\n\nThe authors derive an upper bound on Rademacher complexity. However, as a reader I am not convinced of the importance\/utility of these bounds:\nThe bounds depend on upper bounds on norms of the weights. The norms are distribution dependent. Further, such norms (in unregularized SGD and SGD with weight decay) have been shown to grow with the amount of data (Nagarajan and Kolter ‘19). Thus it is not even clear if the bound decreases with the amount of data when considering classifiers that are obtained with the proposed algorithm. Do the norms grow with the data? If so, how fast relative to the inter-layer activation diversity term?\nDemonstrating that the bound on Rademacher is tight for some distributions would be another way to demonstrate that the bounds are interesting.\n\nThe authors talk about studying generalization starting in the abstract and throughout the text, e.g.: “..we analyse the effect of the within-layer activation diversity on the generalization error bound of neural network.”.\n\nI see multiple inaccuracies with this and related statements: the authors provide a bound, rather than study an effect of within-layer activation diversity -- the effect would be totally different on a different upper bound. And these are just upper bounds, after all.\n\nI also wanted to note that what is actually provided in the paper is an estimation error bound, not a generalization error bound. I am guessing the authors arrived at the estimation error by starting from a Rademacher-based risk bound. But there is no mention of that. Why not state a generalization bound instead?\n\nHere is another statement (out of several) that is very misleading and incorrect (Section 3, first sentence):\n\n“As shown in the previous section, promoting diversity of activations within a layer can lead to tighter generalization bound and can theoretically decrease the gap between the empirical and the true risks.”\n\nWhere are the results showing that promoting diversity of activations decreases the gap between the risk and empirical risk? Also, the bounds are tighter than what? There is no comparison to any other bounds.\n\nJust after Eq (3), f* is defined as argmin_f L(f). What class is the minimization performed over?\n\n\n*How does activation diversity connect to the rest of the literature*\n\nThe authors discuss other approaches to increasing weight, activation, etc., diversity. However, since they argue that increased diversity improves generalization, it would be interesting to see a comparison to other properties that are linked to improvements in generalization. Probably one of the most recently discussed properties is the flatness of the minima. Are these complementary properties? Do they relate in any way? (see, e.g., work on Sharpness Aware minimization by Foret et al, Computing Nonvacuous Generalization Bounds by Dziugaite et al, Sharp minima work by Keskar et al., and many others)\n\nWhat exactly is “Standard Training” in Section 5? Is it regularized in any way? How would the performance of the proposed algorithm compare to various other regularization methods? \n\n*The efficiency*\n\nIn my opinion the real contribution of the paper is the algorithm, not the bound on estimation error. I do not see any discussion around the computational costs or training times of the algorithm.\n\n*Hyperparameter settings*\n\nThe algorithm requires tuning regularization-related hyperparameters. How are those chosen exactly? Do the authors have a held-out set? Based on Fig 1, it seems that the wrong values of these hyperparameters may wipe out all the improvements in generalization presented in Table 1.\n\nAlso, the discussion of Figure 1 and more generally section 5 once again suggest that one may expect to see a smaller generalization error gap when optimizing for the inter-layer activation diversity. There is no such theoretical connection made in the paper.\n\nHow about other hyperparameters? How are those set? Are they all standard or have they been changed at all?\n\n*Ensembling* \n\nThe authors several times relate activation diversity to functional diversity (introduction, section 4). I do not quite understand the connection. I can easily construct cases how improved activation diversity in individual classifiers would result in a poor ensemble. Can the authors explain the connection?\n\n\nMinor: The loss set  in Lemma 1 is undefined.\n","sentences":[{"sentence_type":"2","sentence":"In my opinion the real contribution of the paper is the algorithm, not the bound on estimation error.","rephrased":"While the algorithm presented is a significant contribution, I believe further discussion on the bound on estimation error would enhance the paper's impact."},{"sentence_type":"2","sentence":"Here is another statement (out of several) that is very misleading and incorrect (Section 3, first sentence):","rephrased":"I would like to point out a statement in Section 3, first sentence, that may benefit from further clarification to avoid potential misunderstandings."},{"sentence_type":"2","sentence":"I see multiple inaccuracies with this and related statements: the authors provide a bound, rather than study an effect of within-layer activation diversity -- the effect would be totally different on a different upper bound. And these are just upper bounds, after all.","rephrased":"I believe there is a need for greater precision in the statements regarding the study of the effect of within-layer activation diversity, as the current discussion seems to focus on providing a bound rather than examining the effect itself."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1036,1304,"Maybe"],[1622,1731,"Maybe"],[3134,3235,"Not concerning"]],"Comments":[]}
{"id":"sQ9IDvaqXz","text":"Summary:\nThis short paper discusses a method for cross-domain plaque detection using image translation methods, translating from pre-contrast to post-constrast CT. The method adds an additional constraint to the learning objective to force the translation model to learn a representation constructed of easily separable subspaces. The authors suggest that this allows the model to better represent the different structures in the images. Their experiments show a decreased drop in performance over competing methods.\n\nStrengths:\nThis is an interesting application of self-expressiveness loss and the reported results show that the proposed method might achieve a reasonable cross-domain performance. The experiments are very limited, but seem promising.\n\nWeaknesses:\nThe paper is not very generous with information about the implementation of the method: we are told nothing about the encoding and decoding networks or the segmentation model, for example. The comparison with competing methods is very limited.\n\nThe paper seems to depends heavily on work by Liu et al.\n\nIt is, of course, a short paper.\n\nQuestions:\nThe main assumption of the authors is that different anatomical structures would be represented by different subspaces in the representation. It would be interesting to know if this is really what happens in the model, or whether the proposed method improves in other ways.","sentences":[{"sentence_type":"2","sentence":"The paper is not very generous with information about the implementation of the method: we are told nothing about the encoding and decoding networks or the segmentation model, for example.","rephrased":"The paper could provide more detailed information about the implementation of the method, such as the encoding and decoding networks or the segmentation model, to enhance the reader's understanding."},{"sentence_type":"1","sentence":"The paper seems to depends heavily on work by Liu et al.","rephrased":"The paper appears to build substantially on the work by Liu et al., and it would be beneficial to clarify how the current method differentiates from their approach."},{"sentence_type":"1","sentence":"It is, of course, a short paper.","rephrased":"Given the constraints of a short paper format, it would be helpful if the authors could still attempt to include more comprehensive details within the allowed scope."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[767,955,"Not concerning"],[1012,1068,"Not concerning"],[1070,1102,"Maybe"]],"Comments":[]}
{"id":"rkxmIkzb34","text":"The paper is generally well-written and clear. The primary contribution is a formulation of human-in-the-loop planning problems that (1) captures existing approaches and (2) provides a computational advantage over previous approaches.\n\nDeciding when to perform explanation as part of the planning process (during plan generation or execution) is a novel consideration.\n\nThe paper could expand on how the user's model could be extracted since it is a core requirement of this approach.\n\nThis paper is highly relevant to the workshop and should lead to fruitful discussion. \n\nSmall comments\/grammar:\n\n7: \"many simpler fragments has been..\" --> \"many simpler fragments have been....\"\n7: \"is either due knowledge asymmetry...\" --> \"is either due to knowledge asymmetry...\"","sentences":[{"sentence_type":"1","sentence":"This paper is highly relevant to the workshop and should lead to fruitful discussion.","rephrased":"This paper is highly relevant to the workshop and is likely to stimulate valuable discussion."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[486,571,"Not concerning"]],"Comments":[]}
{"id":"09kpT_ytor8","text":"-Strengths: The paper is well-organized and the problem is also well-defined.\n-Weakness: \n1) The proposed approach is mainly based on YOLO5 and the novelty is really limited. No new or novel zero shot learning algorithms are proposed to solve this specific problem.\n2) There's no explanation about why the proposed model can detect the unseen objects.\n3) No ablation study are given to validate the effectiveness of each proposed component. There's only on experiment on YCB Video dataset, and the comparison with other state-of-the-arts zero shot learning methods is missing. \n","sentences":[{"sentence_type":"2","sentence":"The proposed approach is mainly based on YOLO5 and the novelty is really limited.","rephrased":"While the proposed approach builds on YOLO5, it would be beneficial to highlight the novel aspects that differentiate it from existing methods."},{"sentence_type":"1","sentence":"There's no explanation about why the proposed model can detect the unseen objects.","rephrased":"The paper would be strengthened by including a rationale for why the proposed model can detect unseen objects."},{"sentence_type":"1","sentence":"No ablation study are given to validate the effectiveness of each proposed component.","rephrased":"An ablation study could be useful to validate the effectiveness of each proposed component."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[93,174,"Confirmed"],[269,351,"Not concerning"],[355,440,"Not concerning"]],"Comments":[]}
{"id":"SrM3cfEII0a","text":"The paper is particularly hard to read and with a poor English. Authors must correct the grammar and spelling mistakes if the paper is accepted.\n\nPros:\n- challenging and interesting problem: multi-modal registration with deep learning\n- combining domain adaptation and registration is a novel idea\n- explores some interesting concepts such as approximating the Earth Mover's distance via a 1D projection\n\nCons:\n- 2D approach. Seems hard to extend to large 3D volumes\n- poor English\n- experiments are unclear. The registration is not directly evaluated. In particular, are the registration outputs well regularised? ","sentences":[{"sentence_type":"2","sentence":"The paper is particularly hard to read and with a poor English.","rephrased":"The paper could benefit from improvements in readability and language quality."},{"sentence_type":"2","sentence":"poor English","rephrased":"The manuscript would be strengthened by language editing for grammar and clarity."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[0,63,"Maybe"]],"Comments":[]}
{"id":"hpXu9RMQr79","text":"Strengths:\n\n- The paper proposes a simple recalibration algorithm\n- The proposed method works if the number of outputs is reasonably small (one or two)\n- Extensive simulation\n\nWeaknesses:\n\n- Unclear \/ small novelty compared to previous work\n- Theoretical results are asymptotic\n- Empirical results are quite weak\n\nI have previously served as a reviewer for this paper for NeurIPS 2021. We ended up rejecting the paper there and recommended a few major points for improvement:\n- Performance in higher dimensions: The current method seems to only work well in very low-dimensional settings (one to two dimensions or so). It should be discussed how it would (or would not) generalize to higher-dimensional problems, which are relevant and common in many areas.\n- Empirical results: The current results are missing error bars, which makes it impossible to assess their statistical significance. In fact, the proposed method underperforms the baselines in many settings, which may or may not be significant.\n- Missing baselines: Previous work has proposed to optimize specialized calibration losses, such as [1,2,3]. It would be necessary to compare to at least some of these related approaches to judge whether the proposed approach actually improves over prior work.\n\nGiven that it seems like the authors have unfortunately implemented none of these suggestions yet, I will for now have to stick to my previous assessment of the work and recommend rejection again.\n\n\n\n[1] Khosravi et al. 2011, https:\/\/ieeexplore.ieee.org\/document\/5672788\n\n[2] Pearce et al. 2018, https:\/\/arxiv.org\/abs\/1802.07167\n\n[3] Tagasovska et al. 2018, https:\/\/arxiv.org\/abs\/1811.00908","sentences":[{"sentence_type":"2","sentence":"Unclear \/ small novelty compared to previous work","rephrased":"The novelty of the work could be more clearly defined or expanded upon in comparison to previous work."},{"sentence_type":"2","sentence":"Empirical results are quite weak","rephrased":"The empirical results could benefit from further strengthening to support the proposed method."},{"sentence_type":"3","sentence":"Given that it seems like the authors have unfortunately implemented none of these suggestions yet, I will for now have to stick to my previous assessment of the work and recommend rejection again.","rephrased":"It appears that the suggestions made previously have not been incorporated, which leads me to maintain my prior recommendation for rejection. However, I encourage the authors to consider these points for future submissions."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[191,240,"Not concerning"],[280,312,"Not concerning"],[1265,1461,"Not concerning"]],"Comments":[]}
{"id":"TPo2KQL_ffA","text":"The main concern is about the practicability of SUPER-Adam in the Case 2 in Algorithm 1. It is known that the number of parameters of modern DNNs is typically more than 10 million, such as the number of parameters of VGG16 is ~134 million and that of ResNet18 is 33 million. Therefore, $H_t$ in SUPER-Adam in Case 2 will be at least 8 order of magnitude larger than that in $H_t$ in SUPER-Adam in Case 1 that is commonly used, so we need to scale the learning rate $\\eta_t$ by a factor of $>10$ million to maintain the comparable convergence rate with Adam. This overlarge factor may be impractical. Actually, from Section 6.1, we know the authors also did not set $\\eta$ so large.\n\nWhen $M_t \\rightarrow 0$ , SUPER-Adam in the Case 1 cannot ensure $\\rho H_t^{-1} \\rightarrow I_d$ in Eq. (17), and then $\\Vert\\nabla f(x_t) \\Vert \\rightarrow 0$ will not hold. In this case, Theorem 1 and Theorem 2 might be somewhat meaningless. \n\n\nTheorem 1 and Theorem 2 and their proofs are obviously followed the paper that proposed STORM with a little change, but the authors did not report this close relation. Therefore, the bright spot of the convergence analysis is discounted\n\nFrom the 1st and 5th subfigure of figure 2, we know the learning rate for SUPER-Adam decays by a factor (maybe 10) at the 70th and 100th epoch, respectively, which is not described in experimental settings. Moreover, this learning rate decay strategy seems to be not used for other optimizing methods except AdaBlief. Hence, the comparison may be unfair. Additionally, it is known that SGD-type methods commonly perform better for image classification than adaptive gradient methods, so I would like to see SGD will be also compared to SUPER-Adam.\n\n","sentences":[{"sentence_type":"1","sentence":"This overlarge factor may be impractical.","rephrased":"This significantly large factor could pose practical challenges."},{"sentence_type":"2","sentence":"In this case, Theorem 1 and Theorem 2 might be somewhat meaningless.","rephrased":"In this scenario, the applicability of Theorem 1 and Theorem 2 may need further clarification."},{"sentence_type":"3","sentence":"Theorem 1 and Theorem 2 and their proofs are obviously followed the paper that proposed STORM with a little change, but the authors did not report this close relation. Therefore, the bright spot of the convergence analysis is discounted","rephrased":"While Theorem 1 and Theorem 2 appear to be closely related to the paper that proposed STORM, it would be beneficial for the authors to explicitly acknowledge this connection to enhance the transparency of the convergence analysis."},{"sentence_type":"2","sentence":"Hence, the comparison may be unfair.","rephrased":"Therefore, to ensure a fair comparison, it may be worth revisiting the learning rate decay strategy used for SUPER-Adam."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[558,599,"Not concerning"],[859,927,"Maybe"],[931,1167,"Not concerning"],[1487,1523,"Not concerning"]],"Comments":[]}
{"id":"SEQVK4eRnY0","text":"### Summary ###\n\nThe paper presents a technique for code similarity. The paper combines two ideas: (1) a new “context-aware” representation for code which is used as a basis for computing code embeddings, (2) code similarity based on cosine similarity between the embeddings.\n\n### Strengths ###\n\n* The experimental results significantly improve previous work.\n\n### Weaknesses ###\n\n* Looks like an extension of AROMA, with a slightly more general approach for feature engineering, but no significant innovation beyond that. \n\n* The code2vec baseline is old and weak (should have used code2seq). \n\n### Questions for Authors ###\n\n* You need to provide specific human customization per programming language. Can't this customization be learned itself? For example by using a Tree RNN to represent different abstractions of subtrees as needed?\n\n* CASS seems to be closely related to an AST. In fact, the mapping of several syntactic elements (folding compound statements) could be viewed as a particular design choice when abstracting a syntax tree to an abstract syntax tree (in your case reflected in \"node lables\").\n\n* The GAT includes a very shallow abstraction of function signatures. As such, I am curious about it's contribution to the final accuracy. Do you have an ablation study of the results obtained when GAT is omitted? I assume it has a rather different contribution across different languages?\n\n* code2vec is a weak baseline. You should at least consider code2seq as it uses a significantly more powerful encoder.\n\n* I wonder what would be the results using a textual sequence encoder as a baseline.\n\n\n### Improving the Paper ###\n\n* It would help to have a comparison of CASS+GAT to a simple AST-based approach. Keep your entire pipeline identical, including the linearization of the tree mentioned in B.2, and show what is the gain from the CASS per-language customization. I am sure that CASS+GAT would do better, but I conjecture that their contribution would be marginal in many mainstream languages.\n\n* The comparison with Code2Vec is not clear to me. What do you mean by \"we feed the AST paths from all function(s) in a program into the neural network and train it using the metric learning task described in Section 2.2.2.\". Is this trained separately per program? \n\n### Minor questions and comments ###\n\n* This was a strange point to emphasize in Definition 1: \"A child node is either an internal node or a leaf node. An internal node has at least one child node while a leaf node has no child nodes.\"\n\n* Page 15, \"pretended\" -> prepended\n\n\n\n\n\n\n","sentences":[{"sentence_type":"2","sentence":"Looks like an extension of AROMA, with a slightly more general approach for feature engineering, but no significant innovation beyond that.","rephrased":"The work appears to build upon the foundation laid by AROMA, with a broader approach to feature engineering. It would be beneficial to highlight any distinct innovations that differentiate this work from its predecessors."},{"sentence_type":"2","sentence":"The code2vec baseline is old and weak (should have used code2seq).","rephrased":"Considering the advancements in the field, it would strengthen the paper to include a comparison with more recent baselines such as code2seq."},{"sentence_type":"2","sentence":"code2vec is a weak baseline. You should at least consider code2seq as it uses a significantly more powerful encoder.","rephrased":"To provide a more robust evaluation, it would be advisable to include code2seq as a baseline, given its more sophisticated encoder."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[383,522,"Not concerning"],[527,593,"Not concerning"],[1408,1524,"Not concerning"]],"Comments":[]}
{"id":"SklGnjYzqV","text":"This paper proposes a conditional adversarial model that iteratively generates images given a scene graph. The scene graph describes the relations between the different objects and components of the image. It is shown that images can be generated iteratively by augmenting the scene graph with new objects and relations, and the existing image content will be maintained.\n\nThis work uses a combination of many different building blocks that have recently gained traction in literature, including graph convolutional networks to process the scene graphs, networks for bounding box prediction and conditional generative adversarial networks. These are combined with a variety of loss functions (5 in total).\n\nThe resulting system is shown to work reasonably well, but it is quite complex and I feel that the importance of each individual component could be demonstrated better by including some ablations -- what would happen if a GAN were conditioned directly on the output of the GCN that processes the scene graph, for example? Is the intermediate step that produces segmentations and bounding boxes strictly necessary?\n\nIn two different places in the manuscript, it is stated that the model is the first of its kind to the authors' knowledge. I find such statements a bit inappropriate when they refer to very specific problem settings. There has definitely been a lot of closely related work e.g. on image generation conditioned on captions (including some that uses scene graphs as an intermediate representation). Stating that the work is presumably the first to use this particular specific combination of input representations and model structure is not very meaningful.\n\nThe manuscript contains quite a few grammatical and spelling errors and would benefit from proofreading.","sentences":[{"sentence_type":"2","sentence":"I find such statements a bit inappropriate when they refer to very specific problem settings.","rephrased":"It may be more precise to contextualize the novelty of the model within the broader scope of related work, especially when referring to specific problem settings."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1245,1338,"Not concerning"]],"Comments":[]}
{"id":"HklBPv9ljN","text":"This work introduces a framework for learning discrete domain models and a perception function in an iterative fashion, by executing actions and observing the resulting effects via perception variables. The proposed algorithm relies on the information provided by perception variables to generate a domain model form scratches (or updating an existing one).\n\nThe paper correctly position itself with regards to the relevant literature. Differently from existing works, it does not consider partial observability cases, and assumes that it is possible to freely and safely explore the environment. The latter, in particular, is a quite strong assumption, but it is needed in order to allow the framework to deal with the newly-introduced perception variables. However, from a practical perspective, I'm wondering how often that will be allowed in real-world applications.\n\nThe proposed approach (summarised in Algorithm 1) involves the exploration of the possible actions, in order to observe results and update relevant aspects of the extended domain model. The involved steps are well defined and easy to follow. I also appreciated the use of numerous examples, to guide the reader and better clarify how the proposed framework works. \n\nAs a comment for future extensions, it would be interesting to test how the proposed algorithm performs in practice, and what aspects of the application domain affect the quality of the generated final domain model. I'm also wondering whether this approach could be used in combination with existing works: other approaches provide a first domain model that ignores numerical aspects, and ALP extends them to handle them. It would also be great to evaluate whether ALP can be a suitable tool for cooperation between human and machine in generating domain models. \n\n- Latex Style comment: Please make sure to use the AAAI style.","sentences":[{"sentence_type":"2","sentence":"However, from a practical perspective, I'm wondering how often that will be allowed in real-world applications.","rephrased":"It would be beneficial to discuss the practical implications of the assumption that the environment can be freely and safely explored, and how this might translate to real-world applications."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[759,870,"Not concerning"]],"Comments":[]}
{"id":"H1xKiqomqH","text":"Observing shortcomings of BLEU and ROUGE, the paper proposes, JAUNE, a set of criteria for a good evaluation metric. These criteria include: high correlation with human judgement; being able to distinguish similar but contradicting statements; penalizing grammatical errors, and hard to game.\n\nThe paper, as its current form, is not ready for publishing. Some suggestions and comments:\n\n- Please carefully check the paper and fix typos and confusing sentences. I was collecting these errors but eventually stopped. Some examples. Sec. 2.3: punctuation missing between \"RUSE\" and \"this method\", comma missing after \"a discrete space\"; Sec. 4.1.1: \"made to ,for example\"....\n\n- The motivation of the paper is unclear. Is your criticism only about BLEU and ROUGE, or the state of the arts in NLP evaluation in general? To make JAUNE appealing, one has to argue that the state of the arts in NLP evaluation is ineffective. For this, the paper needs to review a boarder range of metrics beyond just BLUE and ROUGE. \n\n- While the authors suggest a data-driven metric, it reads to me like a model-driven metric (RoBERTAa specifically). Doesn't it systematically bias towards a certain family of metrics? \n\n- Better and more comprehensive experimental results are highly desired. ","sentences":[{"sentence_type":"2","sentence":"The paper, as its current form, is not ready for publishing.","rephrased":"The paper could benefit from further revisions before it is ready for publishing."},{"sentence_type":"2","sentence":"I was collecting these errors but eventually stopped.","rephrased":"I have noted some errors, which I encourage the authors to address comprehensively throughout the paper."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[294,354,"Not concerning"],[461,514,"Maybe"]],"Comments":[]}
{"id":"zlNf5tqiRq","text":"#Summary\nThis work proposed a new deep-learning architecture for the segmentation of normal organs at risk in thoracic CT data. The authors introduce residual connections from downed scale to upper scales for skip connection of U-Net architecture. They explained these residual connections between down-scaled feature map and upper feature maps achieve multi-resolution feature learning of volumetric data. \n\n#Pros\nPerformance comparison among the proposed method and the three best-performance methods in the AAPM grand challenge by using two independent datasets for train and test, respectively. \n-\tThe proposed method achieved 0.05-0.13 higher segmentation accuracy (dice similarity coefficient) than the other three methods for esophagus segmentation. \n-\tFor the other organs except esophagus, the proposed method achieved 0.01-0.02 less or equal segmentation performances than other methods. It looks comparable. \n\n#Cons\nNo theoretical and reasonable explanations about how to select the connection path in Fig. 1 There are several options to connect different scales. \n\nIn Fig.1, the paths from down-scaled features to upper-scale features exist even in up-convolution parts of U-Net. It looks strange for me, because feature extraction might be done in encoding part, that is, the former part of U-Net before up convolutions. Why?\n\nWhat kind of operations the architecture adopted is unclear for the handling of the different size of feature in residual connection. How to upsample is not presented. Just zero padding, nearest neighbor interpolation, bilinear or cubic interpolation, or Gaussian pyramid? ","sentences":[{"sentence_type":"1","sentence":"It looks strange for me, because feature extraction might be done in encoding part, that is, the former part of U-Net before up convolutions. Why?","rephrased":"I'm curious about the rationale for including paths from down-scaled features to upper-scale features in the up-convolution parts of U-Net, as typically feature extraction is performed in the encoding part. Could you please clarify this design choice?"}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[[1192,1338,"Not concerning"]],"Comments":[]}
{"id":"ayTXEckd31H","text":"### Comments:\n\n- The threat model is not stated anywhere. There is no definition of adversarial robustness\/robust accuracy. It is not clear then if (1) the attack is a minimum-distance or maximum-confidence attack, (2) it is a targeted or untargeted attack in the common sense used in the field (as opposed to the \"targeted\" version of APGD, that is instead just using the \"targets\" for reducing the number of adversarial classes to consider in the optimization), and (3) if the attack is only defined in the $\\ell_\\infty$ norm.\n\n\n### Flaws in the experimental evaluation\n\n- the evaluation does not consider a state-of-the-art attack such as [brendel2020]. This is a pity, as [brendel2020] is presented as a \"fast and reliable method\" for evaluating robustness, and has similar desired characteristics as this attack.\n- The parameters of the attacks used seem sub-optimal. There is no choice of the hyperparameters, and using 10 steps for PGD seems to be limiting the capabilities of the attack. The same can be true for the CW attack, especially as there is no mention on how many binary-search steps are being used. It is OK to test the attacks with limited resources, but a more detailed asymptotic analysis (e.g. with 1k steps) would concretely support the claims of the paper that the attack remains comparable to the other attacks while reducing computational time.\n- The runtimes are computed in an uneven scenario. The total time per-step, or better, per-query to the model should be used instead of the total cumulative time. This makes no sense. As an alternative, one should compare the capabilities of the PGD attack (depicted here as fast but not reliable) with a fixed computational time, i.e., by increasing the number of steps performed by PGD until it spends the same amount of time as the MM attack.\n- the authors did not state if they used some available implementations of the attack, or implemented their own versions. Since the computational time depends on the implementation, this might be a problem when using the runtime as a benchmark.\n\n### Incorrect statements and unsupported claims\n\n**Abstract**\n\n- there is no definition of the \"most adversarial example\", even though there are several references of this in the paper. This is also used in the abstract. Depending on the objective, a stong adversarial example can be seen in different ways. I suggest to expand this with a definition.\n- there is no evidence suggesting that the PGD attack is 100 times slower than AA. The comparison is performed in uneven scenario, where AA uses 100 iterations while PGD uses 10. Moreover, this is stated in the abstract, which makes the statement easy to take and quote, without knowing the context. This statement should be removed.\n\n\n**Introduction**\n\n- \"for practitioners who need real-time evaluation at each epoch of the training process of a robust model\". Is there real cases that require this kind of evaluation? This is missing a reference.\n- \"Unfortunately, PGD fails to reliably evaluate adversarial robustness of a robust DNN\". This sentence is over-generalistic and not true for the majority of the cases. PGD was succesfully used against many defenses, just by making it adaptive to the defense [tramer2020].\n- \"CE loss, which is based on the probability of the true label $p_y$, is not an appropriate measure to the quality of adversarial examples\". There is no definition in the paper for \"quality of adversarial examples\", which makes this statement very confusing.\n- \"Hence, the reliable method is to minimize $z_y - z_t$ for each $t \\neq y$ and take the most adversarial one, which is a widely used solution\". This is not widely-used, as for now it seems only used in [croce2020].\n\n**Preliminary**\n\n- \"$x^{(0)}$ refers to the starting point which corresponds to the natural example (or the natural example perturbed by a small Gaussian or uniformly random noise)\". The statement within parentheses makes the definition of the closed ball in eq. 2 makes the ball centered in $x^{(0)}$. This does not correspond to the adversarial robustness measured in the original clean sample.\n- many equations (see Eqs. 3-7) depend on f, x, y, but they often don't appear inside the equations.\n- \"They showed that using adaptive step size significantly improves the adversarial robustness\". Should be \"improves the adversarial examples\" or \"improves the adversarial evaluation\". The attacks are not improving robustness.\n\n**Realization**\n\n- Eqs. 8 and 9 use variables ($\\alpha$, $\\beta$) never introduced in the text.\n\n\n### Minor issues\n\n- the comparison with targeted-dlr loss in sect. 3 should be clarified. It is very difficult to read, and it does not really capture the advantage of using different methods for rescaling. This might be better supported by some evidence or toy example, and surely by adding some insight on which the hypothesis is based on. Moreover, the authors should then explain what is the difference from the CW loss, as it seems that they are using that one.\n- Figures and tables need descriptive captions that clarify what is being depicted. In particular, tables need improvements in the headers and some highlighting of the results. It is also a good practice to mention them in the text (Figure 1b). Figure 2 is difficult to understand, and contains a legend with unclear definitions (see \"classified area\"). In table 2, it is impossible to understand what are the values presented in the cells. The algorithm needs some hints\/comments\/description.\n\n\n### References:\n\n- [tramer2020] Tramer, Florian, et al. \"On Adaptive Attacks to Adversarial Example Defenses.\" Advances in Neural Information Processing Systems 33 (2020).\n\n- [croce2020] Croce, Francesco, and Matthias Hein. \"Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks.\" International conference on machine learning. PMLR, 2020.\n\n- [brendel2020] Brendel, W., et al. \"Accurate, reliable and fast robustness evaluation.\" Thirty-third Conference on Neural Information Processing Systems (NeurIPS 2019). Curran, 2020.","sentences":[{"sentence_type":"2","sentence":"This makes no sense.","rephrased":"This approach may not be the most effective for comparison. It could be beneficial to consider the total time per-step or per-query to the model for a more balanced evaluation."},{"sentence_type":"2","sentence":"This statement should be removed.","rephrased":"This statement could be misleading as presented in the abstract and might benefit from additional context or a more nuanced comparison."},{"sentence_type":"2","sentence":"This sentence is over-generalistic and not true for the majority of the cases.","rephrased":"This sentence may be perceived as too broad and could be refined to reflect the nuances of the cases where PGD has been successfully used."},{"sentence_type":"2","sentence":"This is not widely-used, as for now it seems only used in [croce2020].","rephrased":"The usage of this method appears to be limited, with the main reference being [croce2020]. It may be helpful to clarify its prevalence in the field."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1535,1555,"Maybe"],[2716,2749,"Not concerning"],[3056,3134,"Not concerning"],[3645,3715,"Not concerning"]],"Comments":[]}
{"id":"iTGQtmUBFBA","text":"The paper presents an empirical comparison of different approaches for data\nlabeling. The authors describe their experimental setup and findings, making\nrecommendations for when to use what approach in practice.\n\nThe authors reference their own anonymous work throughout the paper as\njustification for the presented investigation and its parameters. This is\nproblematic as the reviewers are now unable to confirm that the presented\ninvestigation is well-grounded.\n\nThe authors evaluate their approaches on only six datasets. It is unclear to\nwhat extent the results generalize, in particular as no detailed results per\ndataset are given. There could be significant differences between the different\ntypes of datasets, but not enough data is presented to judge. This matters in\nparticular with respect to the recommendations the authors make at the end of\nthe paper.\n\nSome details of the experimental setup are unclear. The authors say that they\nmeasure F1 score, but then refer to accuracy (e.g. in Figure 1). Which measure\nwas used? The experimental setup describes six datasets, but the results text\nrefers to seven. The results presented in Table 1 and Figure 1 seem to disagree\nwith Table 2 -- LabelSpreadingKNN is the highest-ranked algorithm, but\nUncertaintySampling performs better in terms of all the statistics presented in\nTable 1. The same is true for the second set of experiments (Tables 3 and 4).\nFor the first set of experiments it is unclear what fraction of labels were\nmissing.\n\nIt is unclear why the Bradley-Terry model was used here to compare outcomes.\nThere are multiple other methods to judge how and whether paired distributions\ndiffer. It appears that only ranks were used for this comparison and not the\nactual performance numbers.\n\nFinally, all methods evaluated by the authors have hyperparameters that need to\nbe set. It is unclear how the authors chose the particular values they used in\nthe experiments, and tuning them for best performance may have a major impact on\ntheir performance and the rankings. Conclusions from untuned methods are\nunlikely to generalize.\n\nThere are numerous typos and grammatical mistakes throughout the paper.","sentences":[{"sentence_type":"2","sentence":"The authors reference their own anonymous work throughout the paper as justification for the presented investigation and its parameters. This is problematic as the reviewers are now unable to confirm that the presented investigation is well-grounded.","rephrased":"The authors frequently reference their own prior work, which is not accessible for verification. For a more robust review process, it would be beneficial if the authors could provide additional evidence or citations to support the investigation's foundation."},{"sentence_type":"2","sentence":"Conclusions from untuned methods are unlikely to generalize.","rephrased":"To enhance the generalizability of the conclusions, it would be helpful if the authors could discuss the impact of hyperparameter tuning on the methods evaluated."},{"sentence_type":"1","sentence":"There are numerous typos and grammatical mistakes throughout the paper.","rephrased":"The paper would benefit from a thorough proofreading to correct the various typos and grammatical errors present."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[2097,2168,"Not concerning"]],"Comments":[]}
{"id":"x-pL7mEIRe4","text":"Summary:  \nThis paper proposes to use neural architecture search (NAS) to automatically discover useful conditional generative adversarial network (cGAN) architectures. Specifically, this work aims to find a dedicated architecture for each class.  \n\nStrengths:  \n-Paper is well written.  \n-Demonstrates that optimizing architectures for each class yields some improvement over using a single architecture for all classes.  \n-Architectures learned by the NAS reveal insights about how to use existing building blocks, such as where best to place feature modulation layers in the network.  \n\nWeaknesses:  \n-No random baseline (see [1]).  \n-Given how close NAS-cGAN and NAS-caGAN are in terms of performance, confidence intervals should be reported to confirm that improvement is significant.  \n-Majority of improvement comes from fine-tuning on each class individually. It is unclear how much of this improvement is simply due to additional capacity.  \n-Complexity of the model appears to be disproportionate to the improvement in performance (lots of implementation effort for a somewhat small gain in performance).  \n\nRecommendation and Justification:  \nWhile I think this paper is well written, after reading it I am not convinced of the usefulness of the core idea, which is that generator architectures should be class-aware. It is never explained why it might be desirable for each class to have a distinct generator network, and I cannot think of any reason why this may be the case aside from increased model capacity. For this reason I think that this paper is currently marginally below the acceptance threshold, but look forward to the author's explanation.  \n\nClarifying Questions:  \n-How is calibration performed exactly? Is this procedure the same for NAS-cGAN and NAS-caGAN? Is a separate copy of weights fine-tuned for each class?  If a new copy of weights needs to be created for each class, proper comparison would be to a non-NAS model with up to n_classes times more model capacity than the base model.  \n\n[1] Li, Liam, and Ameet Talwalkar. \"Random search and reproducibility for neural architecture search.\" Uncertainty in Artificial Intelligence. PMLR, 2020.  ","sentences":[{"sentence_type":"2","sentence":"While I think this paper is well written, after reading it I am not convinced of the usefulness of the core idea, which is that generator architectures should be class-aware.","rephrased":"Although the paper is well articulated, I would like to see a more compelling argument for the core idea that generator architectures should be class-aware, as the current justification does not fully convince me of its necessity."},{"sentence_type":"2","sentence":"For this reason I think that this paper is currently marginally below the acceptance threshold, but look forward to the author's explanation.","rephrased":"Therefore, I believe that the paper could benefit from further clarification on this point to meet the acceptance criteria, and I am eager to hear the author's additional insights."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[1154,1328,"Not concerning"],[1525,1666,"Not concerning"]],"Comments":[]}
{"id":"kfVQOpkWG3","text":"This paper proposes a new U-net like architecture for fast generation of signed distance functions (SDF) from parametric surfaces.  A mapping is learned between surface parameters and the corresponding SDF on synthetic data, and is compared to a vtk class performing conventional SDF calculation using Eikonal solving. The paper is well written and fluent and the methodology is very sound. The authors show a good correspondence between the two methods, with a much lower computational time when inferring SDF using their approach.  The authors show almost perfect correspondence between conventional SDF calculation and their approach on a 9 surface clinical cochlear dataset. One could ask  how the network learned so well with synthetic training examples.  The choice of sampling uniformly over the parameter space seems very suboptimal. In general, it is likely that some parameters have more influence than others on the output shape. I understand this is a short paper and that this could not be discussed.","sentences":[{"sentence_type":"2","sentence":"The choice of sampling uniformly over the parameter space seems very suboptimal.","rephrased":"Exploring different sampling strategies over the parameter space could potentially optimize the network's performance."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[761,841,"Not concerning"]],"Comments":[]}
{"id":"oHC7WdCmniH","text":"This paper produces a clear and well-motivated analysis of the strengths and limitations of continual learning agents. The authors demonstrate how CL agents compare against, multi-task agents, which are trained on all available tasks jointly, and how they are evaluated in the task-agnostic settings, where knowledge of the task ID is unavailable at training time. In general, the authors present two observations that seem to contradict common beliefs in CL; the first being that task-agnostic CL agents with recurrent memory can outperform task-aware agents and the second being that replay-based recurrent reinforcement learning (3RL) agents can reach the performance of its multi-task upper-bound despite being exposed to tasks in a sequential fashion. \n\nAdditionally, the authors propose four hypotheses that aim to further explain these results and conduct a large empirical study to compare different RL methods in various multi-task learning regimes. They show that 3RL quickly infers how new task relate to previous ones, enabling forward transfer of knowledge, and learns representations of underling MDPs that reduce task interference. \n\nOverall, the paper is well-written and informative, providing insights into the potential of CL agents paired with recurrent mechanisms. ","sentences":[],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["0"],"entities":[],"Comments":[]}
{"id":"SkevaUL15S","text":"The paper is built around the theme of adversarial attacks. The papers titled \"Towards...\" are usually records of failed attempts of an attack on a grand challenge. The reviewer generally believes, that such records can be of a value.\nIn case of this paper an alternative loss function is proposed, based on information theory. The authors claim and support their claims with graphs that this loss tracks the accuracy much more faithfully than the \"standard\" cross entropy. A natural question would be therefore - what happens if we use this new measure as a training loss? Would it lead to more adversarially-robust models? Should evidence for that be supported for that the reviewer would be strongly in favour of accepting the paper. In the present shape the reviewer does not see why such measure should be of an interest to community. The impact of \"inspiring the community to make interesting discoveries\" is in the reviewers opinion not sufficient to justify publication at a venue of such importance as ICLF.","sentences":[{"sentence_type":"2","sentence":"The papers titled \"Towards...\" are usually records of failed attempts of an attack on a grand challenge.","rephrased":"Papers with titles beginning with \"Towards...\" often document the progression towards addressing a grand challenge, which can be valuable in understanding the development of the field."},{"sentence_type":"2","sentence":"In the present shape the reviewer does not see why such measure should be of an interest to community.","rephrased":"The reviewer suggests that the paper could be strengthened by clarifying the measure's potential interest and relevance to the community."},{"sentence_type":"2","sentence":"The impact of \"inspiring the community to make interesting discoveries\" is in the reviewers opinion not sufficient to justify publication at a venue of such importance as ICLF.","rephrased":"The reviewer recommends providing more concrete evidence of the impact to justify publication at a prestigious venue like ICLF."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["1"],"entities":[[60,164,"Not concerning"],[737,839,"Not concerning"],[840,1016,"Not concerning"]],"Comments":[]}
{"id":"Sk3CQYOgG","text":"This paper explored the effectiveness of four existing sentence embedding models on ten different document summarization methods leveraging various works in the literature. Evaluation has been conducted on the DUC-2004 dataset and ROUGE-1 and ROUGE-2 scores are reported. \n\nOverall, the paper significantly suffered from an immature writing style, numerous typos\/grammatical mistakes, inconsistent organization of content, and importantly, limited technical contribution. Many recent sentence embedding models are missed such as those from Lin et al. (2017), Gan et al. (2017), Conneau et al. (2017), Jernite et al. (2017) etc. The evaluation and discussion sections were mostly unclear and the results of poorly performing methods were not reported at all making the comparisons and arguments difficult to comprehend. \n\nIn general, the paper seemed to be an ordinary reporting of some preliminary work, which at its current stage would not be much impactful to the research community.","sentences":[{"sentence_type":"3","sentence":"Overall, the paper significantly suffered from an immature writing style, numerous typos\/grammatical mistakes, inconsistent organization of content, and importantly, limited technical contribution.","rephrased":"The paper could benefit from improvements in writing style, proofreading to correct typos and grammatical errors, better organization of content, and a more substantial technical contribution."},{"sentence_type":"2","sentence":"The evaluation and discussion sections were mostly unclear and the results of poorly performing methods were not reported at all making the comparisons and arguments difficult to comprehend.","rephrased":"The evaluation and discussion sections could be made clearer, and including the results of all methods, including those that performed poorly, would strengthen the comparisons and arguments."},{"sentence_type":"2","sentence":"In general, the paper seemed to be an ordinary reporting of some preliminary work, which at its current stage would not be much impactful to the research community.","rephrased":"The paper appears to present preliminary findings and could be improved to enhance its potential impact on the research community."}],"comments":null,"annotation_info":{"type":"Automated","humans":[],"models":["GPT-4"]},"cats":["2"],"entities":[[274,471,"Maybe"],[628,818,"Maybe"],[821,985,"Not concerning"]],"Comments":[]}
